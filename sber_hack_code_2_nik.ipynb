{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML preprocessing/optimizing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import shap\n",
    "\n",
    "\n",
    "# Scoring\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Data formatting/preprocessing\n",
    "import time \n",
    "import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# NaN Imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "# Ml models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ctb\n",
    "\n",
    "\n",
    "### Advanse optimizing (HyperOpt Parameter Tuning)\n",
    "from hyperopt import tpe\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import Trials\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin\n",
    "\n",
    "## Useful\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_part1.pkl', 'rb') as f1:\n",
    "    train_part1 = pickle.load(f1)\n",
    "\n",
    "with open('train_part2.pkl', 'rb') as f2:\n",
    "    train_part2 = pickle.load(f2)\n",
    "    \n",
    "with open('test_data.pkl', 'rb') as f3:\n",
    "    test_data = pickle.load(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    732535\n",
       "1     31266\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part1.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    732074\n",
       "1     31723\n",
       "Name: TARGET, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part2.TARGET.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see class disbalance problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763801, 648)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763797, 648)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- проделать препроцессинг для второй части трайн сета\n",
    "- построить shap values\n",
    "- обучить градиентынй бустинг\n",
    "- пофитить гиперпараметры (random search + hyperopt)\n",
    "- засабмитить первый скор"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    '''\n",
    "    Fill nans and label encode\n",
    "    '''\n",
    "    for i, col in enumerate(data.columns[1:]):\n",
    "        if data[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            data[col] = le.fit_transform(data[col])\n",
    "            #joblib.dump(le, MODELS_PATH + f'le_{col}.pkl')\n",
    "    return data\n",
    "\n",
    "def numeric_preprocess(data):\n",
    "    \"\"\"This function operates with numerical data,\n",
    "    it fills na with mean values and replaces inf by nan and reduces them\"\"\"\n",
    "    \n",
    "    data = data.select_dtypes(include=np.number).apply(lambda x: x.fillna(x.mean()),axis=0)\n",
    "    data = data.select_dtypes(include=np.number)\n",
    "    data = data.set_index('ID')\n",
    "    \n",
    "    cat_columns = data.columns[data.nunique() < 10]\n",
    "    num_columns = data.columns[data.nunique() >= 10]\n",
    "    data = pd.concat([ data[cat_columns].fillna(data[cat_columns].mode().iloc[0,:]), data[num_columns].fillna(data[num_columns].mean()) ], axis=1)\n",
    "    data = preprocess_data(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two train parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = pd.concat([numeric_preprocess(train_part1), numeric_preprocess(train_part2)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_data = numeric_preprocess(train_part1)\n",
    "# numeric_data = numeric_data.drop(['x_19', 'x_614', 'x_615', 'x_634'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non numeric preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_numeric_preprocess(data):\n",
    "    \"\"\"This function handles with non numeric data (only 18 columns)\n",
    "    It is worth mention that mapping part required additional analysis\"\"\"\n",
    "    \n",
    "    # set id as index\n",
    "    data = data.set_index('ID')\n",
    "    \n",
    "    # Exclude numerics but not target\n",
    "    target = data['TARGET']\n",
    "    data = data.select_dtypes(exclude=np.number)\n",
    "    data = pd.concat([data, target], axis = 1)\n",
    "    \n",
    "    # count the duration of cradit period\n",
    "    data['period'] = (data['REPORT_DT'] - data['x_9']).dt.days\n",
    "    \n",
    "    # drop lot significant feeatures\n",
    "    data = data.drop(['x_617', 'x_618','x_17', 'x_25', 'x_26', 'x_27', 'REPORT_DT', 'x_9'], axis = 1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def rating_mean(data, name):\n",
    "    \"\"\"This function provides us with a dataframe that contains mean values of target.\n",
    "    We will use the to encide categorical features\"\"\"\n",
    "    \n",
    "    a = []\n",
    "    for i in data.select_dtypes(exclude=np.number)['{}'.format(name)].unique():\n",
    "        a.append(data[data['{}'.format(name)] == i].TARGET.mean())\n",
    "\n",
    "    res = pd.DataFrame([data.select_dtypes(exclude=np.number)['{}'.format(name)].unique(), a])    \n",
    "    res=res.T.sort_values(by = 1)\n",
    "    return res\n",
    "\n",
    "def mapping_non_numerics(data_resource, data_final):\n",
    "    \"\"\"Here we use 2 data bases for proper categorical feature encoding (non overlaping)\"\"\"\n",
    "    \n",
    "    # handle with binaries\n",
    "    #binaries = ['x_19', 'x_614', 'x_615', 'x_634']\n",
    "    #data_final[binaries] = data_final[binaries].apply(pd.to_numeric)\n",
    "    \n",
    "    # x_12 client significance\n",
    "    mapping = rating_mean(data_resource, 'x_12').set_index(0).to_dict()[1]\n",
    "    data_final['x_12'].replace(mapping, inplace=True)\n",
    "    \n",
    "    # x_18\n",
    "\n",
    "    \n",
    "    not_weekend = data_resource[((data_resource['x_18'] != 'Вс') & (data_resource['x_18'] != 'Сб'))].TARGET.mean()\n",
    "    weekend = data_resource[((data_resource['x_18'] == 'Вс') | (data_resource['x_18'] == 'Сб'))].TARGET.mean()\n",
    "    map_18 = {'Вс':weekend, \n",
    "         'Сб':weekend,\n",
    "         'Пн':not_weekend,\n",
    "         'Чт':not_weekend,\n",
    "         'Вт':not_weekend,\n",
    "         'Пт':not_weekend,\n",
    "         'Ср':not_weekend}\n",
    "    \n",
    "    data_final['x_18'].replace(map_18, inplace=True)\n",
    "    \n",
    "    # x_13\n",
    "    map_x_13 = rating_mean(data_resource, 'x_13')\n",
    "    not_1 = data_resource[data_resource['x_13'] != '1'].TARGET.mean()\n",
    "    map_13 = {'1':map_x_13.iloc[2,1], \n",
    "             '2':not_1,\n",
    "             '3':not_1,\n",
    "             '4':not_1,\n",
    "             '5':not_1,\n",
    "             '9':not_1,\n",
    "             '19':not_1}\n",
    "    \n",
    "    data_final['x_13'].replace(map_13, inplace=True)\n",
    "    \n",
    "    # x_21\n",
    "    x_21 = rating_mean(data_resource, 'x_21')\n",
    "    map_21 = x_21.set_index(0).to_dict()[1]\n",
    "    data_final['x_21'].replace(map_21, inplace=True)\n",
    "    \n",
    "    # x_625 town or not\n",
    "    x_625 = rating_mean(data_resource, 'x_625')\n",
    "    map_625 = x_625.set_index(0).to_dict()[1]\n",
    "    data_final['x_625'].replace(map_625, inplace=True)\n",
    "    \n",
    "    # x_628\n",
    "    x_628 = rating_mean(data_resource, 'x_628')\n",
    "    map_628 = x_628.set_index(0).to_dict()[1]\n",
    "    data_final['x_628'].replace(map_628, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets check, how mean target is connected with categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non numeric feature REPORT_DT\n",
      "             0         1\n",
      "513 2017-04-07       0.0\n",
      "813 2017-08-25       0.0\n",
      "814 2018-09-14       0.0\n",
      "815 2018-03-31       0.0\n",
      "816 2019-01-12       0.0\n",
      "..         ...       ...\n",
      "13  2017-07-03  0.068541\n",
      "440 2017-04-10  0.069372\n",
      "749 2017-07-10  0.070243\n",
      "286 2017-08-29  0.074457\n",
      "657 2017-03-06  0.083333\n",
      "\n",
      "[1028 rows x 2 columns]\n",
      "##############################################\n",
      "non numeric feature x_9\n",
      "              0      1\n",
      "1595 2015-01-06    0.0\n",
      "690  2017-07-08    0.0\n",
      "1663 2016-09-25    0.0\n",
      "1662 2012-10-26    0.0\n",
      "1661 2017-06-11    0.0\n",
      "...         ...    ...\n",
      "1644 2012-06-14  0.625\n",
      "1636 2016-01-24    0.9\n",
      "1834 2014-08-31    1.0\n",
      "1869 2013-10-20    1.0\n",
      "1872 2013-05-01    1.0\n",
      "\n",
      "[1873 rows x 2 columns]\n",
      "##############################################\n",
      "non numeric feature x_12\n",
      "    0         1\n",
      "6  A1  0.019427\n",
      "3   A  0.030718\n",
      "0  B1   0.03394\n",
      "5   B  0.042134\n",
      "1   D  0.049258\n",
      "4   C  0.050675\n",
      "2   N  0.059137\n",
      "##############################################\n",
      "non numeric feature x_13\n",
      "     0         1\n",
      "6   19       0.0\n",
      "7    3       0.0\n",
      "1    1   0.03625\n",
      "3    5  0.042838\n",
      "0    4  0.043497\n",
      "2    2  0.043583\n",
      "4    9  0.055659\n",
      "5  NaN       NaN\n",
      "##############################################\n",
      "non numeric feature x_17\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "##############################################\n",
      "non numeric feature x_18\n",
      "    0         1\n",
      "6  Вс  0.031562\n",
      "5  Сб  0.035158\n",
      "0  Пн  0.039736\n",
      "1  Чт  0.040383\n",
      "4  Вт  0.040936\n",
      "3  Пт   0.04275\n",
      "2  Ср  0.043311\n",
      "##############################################\n",
      "non numeric feature x_19\n",
      "   0         1\n",
      "1  0  0.037364\n",
      "0  1  0.044256\n",
      "##############################################\n",
      "non numeric feature x_21\n",
      "                                         0         1\n",
      "4                         Рефинансирование  0.009902\n",
      "1                           Инвестирование  0.028449\n",
      "0                             Приобретение  0.046135\n",
      "3  Нецелевой кредит под залог недвижимости  0.060576\n",
      "2             Индивидуальное строительство  0.086406\n",
      "##############################################\n",
      "non numeric feature x_25\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "##############################################\n",
      "non numeric feature x_26\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "##############################################\n",
      "non numeric feature x_27\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "##############################################\n",
      "non numeric feature x_614\n",
      "   0         1\n",
      "0  1  0.038552\n",
      "1  0  0.045624\n",
      "##############################################\n",
      "non numeric feature x_615\n",
      "   0         1\n",
      "1  0  0.037364\n",
      "0  1  0.044256\n",
      "##############################################\n",
      "non numeric feature x_617\n",
      "     0         1\n",
      "6   19       0.0\n",
      "7    3       0.0\n",
      "1    1   0.03625\n",
      "3    5  0.042838\n",
      "0    4  0.043497\n",
      "2    2  0.043583\n",
      "4    9  0.055659\n",
      "5  NaN       NaN\n",
      "##############################################\n",
      "non numeric feature x_618\n",
      "                                         0         1\n",
      "4                         Рефинансирование  0.009902\n",
      "1                           Инвестирование  0.028449\n",
      "0                             Приобретение  0.046135\n",
      "3  Нецелевой кредит под залог недвижимости  0.060576\n",
      "2             Индивидуальное строительство  0.086406\n",
      "##############################################\n",
      "non numeric feature x_625\n",
      "                         0         1\n",
      "0  living in city in apart  0.036371\n",
      "1                    other  0.049473\n",
      "##############################################\n",
      "non numeric feature x_628\n",
      "            0         1\n",
      "2  Сотрудники  0.030718\n",
      "0          ЗП   0.03401\n",
      "1       Улица  0.049625\n",
      "##############################################\n",
      "non numeric feature x_634\n",
      "   0         1\n",
      "1  1   0.03546\n",
      "0  0  0.043344\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "for i in train_part1.select_dtypes(exclude=np.number).columns:\n",
    "    try:\n",
    "        print('non numeric feature {}'.format(i))\n",
    "        print(rating_mean(train_part1, i))\n",
    "        print(\"##############################################\")\n",
    "    except ValueError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the categorical values by mapping avoiding overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1_base = non_numeric_preprocess(train_part1.drop(['x_19', 'x_614', 'x_615', 'x_634'], axis = 1))\n",
    "train_1_final = train_1_base.copy()\n",
    "train_2_base = non_numeric_preprocess(train_part2)\n",
    "train_2_final = train_2_base.copy()\n",
    "\n",
    "mapping_non_numerics(train_2_base, train_1_final)\n",
    "mapping_non_numerics(train_1_base, train_2_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = pd.concat([train_1_final, train_2_final], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = cat_data.drop(['x_19', 'x_614', 'x_615', 'x_634'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data.rename(columns={'x_12':'client_significance', 'x_18':'day_of_week', 'x_21':'credit_purpose',\n",
    "                            'x_625':'city', 'x_628':'street'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining (already non) catigorical and numerical training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### both dataframes contain TARGET, so one we will remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = numeric_data.drop(['TARGET'], axis = 1).merge(cat_data, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### x_0 and x_1 are meaningless so drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['x_0', 'x_1'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between target and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop(['TARGET'], axis = 1)\n",
    "target = train['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = features.select_dtypes(include=np.number).columns\n",
    "l = []\n",
    "for i in range(len(cols)):\n",
    "    l.append(target.corr(train.loc[:,cols[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_data = pd.DataFrame([cols, l]).T.iloc[:,:]\n",
    "corr_data = corr_data.rename(columns={0:'feature', 1:'corr_with_target'})\n",
    "corr_data['corr_with_target'] = pd.to_numeric(corr_data['corr_with_target'])\n",
    "corr_data.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr_with_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x_2</td>\n",
       "      <td>0.000651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x_3</td>\n",
       "      <td>0.012819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x_57</td>\n",
       "      <td>0.058172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x_79</td>\n",
       "      <td>0.021659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x_80</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>0.007803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>credit_purpose</td>\n",
       "      <td>0.048008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>city</td>\n",
       "      <td>0.032274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>street</td>\n",
       "      <td>0.040244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>period</td>\n",
       "      <td>0.089535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  corr_with_target\n",
       "0               x_2          0.000651\n",
       "1               x_3          0.012819\n",
       "2              x_57          0.058172\n",
       "3              x_79          0.021659\n",
       "4              x_80          0.090000\n",
       "..              ...               ...\n",
       "628     day_of_week          0.007803\n",
       "629  credit_purpose          0.048008\n",
       "630            city          0.032274\n",
       "631          street          0.040244\n",
       "632          period          0.089535\n",
       "\n",
       "[633 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot top 15 the most correlated and the least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr_with_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>x_286</td>\n",
       "      <td>0.121455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>x_292</td>\n",
       "      <td>0.117702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>x_189</td>\n",
       "      <td>0.109134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>x_330</td>\n",
       "      <td>0.109114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>x_421</td>\n",
       "      <td>0.102047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>x_183</td>\n",
       "      <td>0.100839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x_80</td>\n",
       "      <td>0.090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>period</td>\n",
       "      <td>0.089535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>x_643</td>\n",
       "      <td>0.088186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>x_584</td>\n",
       "      <td>0.087823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>x_544</td>\n",
       "      <td>0.087308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>x_124</td>\n",
       "      <td>0.087254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>x_420</td>\n",
       "      <td>0.086775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>x_227</td>\n",
       "      <td>0.086389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>x_478</td>\n",
       "      <td>0.084934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  corr_with_target\n",
       "58    x_286          0.121455\n",
       "399   x_292          0.117702\n",
       "320   x_189          0.109134\n",
       "422   x_330          0.109114\n",
       "484   x_421          0.102047\n",
       "34    x_183          0.100839\n",
       "4      x_80          0.090000\n",
       "632  period          0.089535\n",
       "622   x_643          0.088186\n",
       "579   x_584          0.087823\n",
       "551   x_544          0.087308\n",
       "263   x_124          0.087254\n",
       "483   x_420          0.086775\n",
       "340   x_227          0.086389\n",
       "521   x_478          0.084934"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data.nlargest(15, 'corr_with_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>corr_with_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>x_291</td>\n",
       "      <td>-0.109110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>x_630</td>\n",
       "      <td>-0.098233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>x_85</td>\n",
       "      <td>-0.087254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>x_188</td>\n",
       "      <td>-0.086354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>x_422</td>\n",
       "      <td>-0.084480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>x_346</td>\n",
       "      <td>-0.069847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>x_543</td>\n",
       "      <td>-0.062622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>x_134</td>\n",
       "      <td>-0.056502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>x_370</td>\n",
       "      <td>-0.055744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>x_237</td>\n",
       "      <td>-0.055434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>x_266</td>\n",
       "      <td>-0.050681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>x_252</td>\n",
       "      <td>-0.048514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>x_358</td>\n",
       "      <td>-0.048378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>x_60</td>\n",
       "      <td>-0.046239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>x_14</td>\n",
       "      <td>-0.044696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  corr_with_target\n",
       "398   x_291         -0.109110\n",
       "612   x_630         -0.098233\n",
       "246    x_85         -0.087254\n",
       "319   x_188         -0.086354\n",
       "485   x_422         -0.084480\n",
       "80    x_346         -0.069847\n",
       "550   x_543         -0.062622\n",
       "273   x_134         -0.056502\n",
       "90    x_370         -0.055744\n",
       "350   x_237         -0.055434\n",
       "378   x_266         -0.050681\n",
       "365   x_252         -0.048514\n",
       "85    x_358         -0.048378\n",
       "226    x_60         -0.046239\n",
       "188    x_14         -0.044696"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_data.nsmallest(15, 'corr_with_target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The idea is that simple linear correlation can tell us what features have more significant linear dependence - these features from the first point of view are better and should be chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facts from categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looks like weekends positively reflects on credibility \n",
    " (maybe because people working during the week and can receive a credit only on the weekends)\n",
    "- client status matters (A1 - N)\n",
    "- living in city matters (city -> more income -> better credibility)\n",
    "- more period -> more default rate!\n",
    "- loan on street -> more default rate\n",
    "- credit purpose matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### provement for days of week "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Вс</td>\n",
       "      <td>0.031562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Сб</td>\n",
       "      <td>0.035158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пн</td>\n",
       "      <td>0.039736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Чт</td>\n",
       "      <td>0.040383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Вт</td>\n",
       "      <td>0.040936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Пт</td>\n",
       "      <td>0.04275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ср</td>\n",
       "      <td>0.043311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1\n",
       "6  Вс  0.031562\n",
       "5  Сб  0.035158\n",
       "0  Пн  0.039736\n",
       "1  Чт  0.040383\n",
       "4  Вт  0.040936\n",
       "3  Пт   0.04275\n",
       "2  Ср  0.043311"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = []\n",
    "for i in train_part1.select_dtypes(exclude=np.number).x_18.unique():\n",
    "    a.append(train_part1[train_part1['x_18'] == i].TARGET.mean())\n",
    "\n",
    "res = pd.DataFrame([train_part1.select_dtypes(exclude=np.number).x_18.unique(), a])    \n",
    "res.T.sort_values(by = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REPORT_DT</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_9</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_12</th>\n",
       "      <th>x_13</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_17</th>\n",
       "      <th>x_18</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_21</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_25</th>\n",
       "      <th>x_26</th>\n",
       "      <th>x_27</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>x_188</th>\n",
       "      <th>x_189</th>\n",
       "      <th>x_190</th>\n",
       "      <th>x_191</th>\n",
       "      <th>x_192</th>\n",
       "      <th>x_193</th>\n",
       "      <th>x_194</th>\n",
       "      <th>x_195</th>\n",
       "      <th>x_196</th>\n",
       "      <th>x_197</th>\n",
       "      <th>x_198</th>\n",
       "      <th>x_199</th>\n",
       "      <th>x_200</th>\n",
       "      <th>x_201</th>\n",
       "      <th>x_202</th>\n",
       "      <th>x_203</th>\n",
       "      <th>x_204</th>\n",
       "      <th>x_205</th>\n",
       "      <th>x_206</th>\n",
       "      <th>x_207</th>\n",
       "      <th>x_208</th>\n",
       "      <th>x_209</th>\n",
       "      <th>x_210</th>\n",
       "      <th>x_211</th>\n",
       "      <th>x_212</th>\n",
       "      <th>x_213</th>\n",
       "      <th>x_214</th>\n",
       "      <th>x_215</th>\n",
       "      <th>x_216</th>\n",
       "      <th>x_217</th>\n",
       "      <th>x_218</th>\n",
       "      <th>x_219</th>\n",
       "      <th>x_220</th>\n",
       "      <th>x_221</th>\n",
       "      <th>x_222</th>\n",
       "      <th>x_223</th>\n",
       "      <th>x_224</th>\n",
       "      <th>x_225</th>\n",
       "      <th>x_226</th>\n",
       "      <th>x_227</th>\n",
       "      <th>x_228</th>\n",
       "      <th>x_229</th>\n",
       "      <th>x_230</th>\n",
       "      <th>x_231</th>\n",
       "      <th>x_232</th>\n",
       "      <th>x_233</th>\n",
       "      <th>x_234</th>\n",
       "      <th>x_235</th>\n",
       "      <th>x_236</th>\n",
       "      <th>x_237</th>\n",
       "      <th>x_238</th>\n",
       "      <th>x_239</th>\n",
       "      <th>x_240</th>\n",
       "      <th>x_241</th>\n",
       "      <th>x_242</th>\n",
       "      <th>x_243</th>\n",
       "      <th>x_244</th>\n",
       "      <th>x_245</th>\n",
       "      <th>x_246</th>\n",
       "      <th>x_247</th>\n",
       "      <th>x_248</th>\n",
       "      <th>x_249</th>\n",
       "      <th>x_250</th>\n",
       "      <th>x_251</th>\n",
       "      <th>x_252</th>\n",
       "      <th>x_253</th>\n",
       "      <th>x_254</th>\n",
       "      <th>x_255</th>\n",
       "      <th>x_256</th>\n",
       "      <th>x_257</th>\n",
       "      <th>x_258</th>\n",
       "      <th>x_259</th>\n",
       "      <th>x_260</th>\n",
       "      <th>x_261</th>\n",
       "      <th>x_262</th>\n",
       "      <th>x_263</th>\n",
       "      <th>x_264</th>\n",
       "      <th>x_265</th>\n",
       "      <th>x_266</th>\n",
       "      <th>x_267</th>\n",
       "      <th>x_268</th>\n",
       "      <th>x_269</th>\n",
       "      <th>x_270</th>\n",
       "      <th>x_271</th>\n",
       "      <th>x_272</th>\n",
       "      <th>x_273</th>\n",
       "      <th>x_274</th>\n",
       "      <th>x_275</th>\n",
       "      <th>x_276</th>\n",
       "      <th>x_277</th>\n",
       "      <th>x_278</th>\n",
       "      <th>x_279</th>\n",
       "      <th>x_280</th>\n",
       "      <th>x_281</th>\n",
       "      <th>x_282</th>\n",
       "      <th>x_283</th>\n",
       "      <th>x_284</th>\n",
       "      <th>x_285</th>\n",
       "      <th>x_286</th>\n",
       "      <th>x_287</th>\n",
       "      <th>x_288</th>\n",
       "      <th>x_289</th>\n",
       "      <th>x_290</th>\n",
       "      <th>x_291</th>\n",
       "      <th>x_292</th>\n",
       "      <th>x_293</th>\n",
       "      <th>x_294</th>\n",
       "      <th>x_295</th>\n",
       "      <th>x_296</th>\n",
       "      <th>x_297</th>\n",
       "      <th>x_298</th>\n",
       "      <th>x_299</th>\n",
       "      <th>x_300</th>\n",
       "      <th>x_301</th>\n",
       "      <th>x_302</th>\n",
       "      <th>x_303</th>\n",
       "      <th>x_304</th>\n",
       "      <th>x_305</th>\n",
       "      <th>x_306</th>\n",
       "      <th>x_307</th>\n",
       "      <th>x_308</th>\n",
       "      <th>x_309</th>\n",
       "      <th>x_310</th>\n",
       "      <th>x_311</th>\n",
       "      <th>x_312</th>\n",
       "      <th>x_313</th>\n",
       "      <th>x_314</th>\n",
       "      <th>x_315</th>\n",
       "      <th>x_316</th>\n",
       "      <th>x_317</th>\n",
       "      <th>x_318</th>\n",
       "      <th>x_319</th>\n",
       "      <th>x_320</th>\n",
       "      <th>x_321</th>\n",
       "      <th>x_322</th>\n",
       "      <th>x_323</th>\n",
       "      <th>x_324</th>\n",
       "      <th>x_325</th>\n",
       "      <th>x_326</th>\n",
       "      <th>x_327</th>\n",
       "      <th>x_328</th>\n",
       "      <th>x_329</th>\n",
       "      <th>x_330</th>\n",
       "      <th>x_331</th>\n",
       "      <th>x_332</th>\n",
       "      <th>x_333</th>\n",
       "      <th>x_334</th>\n",
       "      <th>x_335</th>\n",
       "      <th>x_336</th>\n",
       "      <th>x_337</th>\n",
       "      <th>x_338</th>\n",
       "      <th>x_339</th>\n",
       "      <th>x_340</th>\n",
       "      <th>x_341</th>\n",
       "      <th>x_342</th>\n",
       "      <th>x_343</th>\n",
       "      <th>x_344</th>\n",
       "      <th>x_345</th>\n",
       "      <th>x_346</th>\n",
       "      <th>x_347</th>\n",
       "      <th>x_348</th>\n",
       "      <th>x_349</th>\n",
       "      <th>x_350</th>\n",
       "      <th>x_351</th>\n",
       "      <th>x_352</th>\n",
       "      <th>x_353</th>\n",
       "      <th>x_354</th>\n",
       "      <th>x_355</th>\n",
       "      <th>x_356</th>\n",
       "      <th>x_357</th>\n",
       "      <th>x_358</th>\n",
       "      <th>x_359</th>\n",
       "      <th>x_360</th>\n",
       "      <th>x_361</th>\n",
       "      <th>x_362</th>\n",
       "      <th>x_363</th>\n",
       "      <th>x_364</th>\n",
       "      <th>x_365</th>\n",
       "      <th>x_366</th>\n",
       "      <th>x_367</th>\n",
       "      <th>x_368</th>\n",
       "      <th>x_369</th>\n",
       "      <th>x_370</th>\n",
       "      <th>x_371</th>\n",
       "      <th>x_372</th>\n",
       "      <th>x_373</th>\n",
       "      <th>x_374</th>\n",
       "      <th>x_375</th>\n",
       "      <th>x_376</th>\n",
       "      <th>x_377</th>\n",
       "      <th>x_378</th>\n",
       "      <th>x_379</th>\n",
       "      <th>x_380</th>\n",
       "      <th>x_381</th>\n",
       "      <th>x_382</th>\n",
       "      <th>x_383</th>\n",
       "      <th>x_384</th>\n",
       "      <th>x_385</th>\n",
       "      <th>x_386</th>\n",
       "      <th>x_387</th>\n",
       "      <th>x_388</th>\n",
       "      <th>x_389</th>\n",
       "      <th>x_390</th>\n",
       "      <th>x_391</th>\n",
       "      <th>x_392</th>\n",
       "      <th>x_393</th>\n",
       "      <th>x_394</th>\n",
       "      <th>x_395</th>\n",
       "      <th>x_396</th>\n",
       "      <th>x_397</th>\n",
       "      <th>x_398</th>\n",
       "      <th>x_399</th>\n",
       "      <th>x_400</th>\n",
       "      <th>x_401</th>\n",
       "      <th>x_402</th>\n",
       "      <th>x_403</th>\n",
       "      <th>x_404</th>\n",
       "      <th>x_405</th>\n",
       "      <th>x_406</th>\n",
       "      <th>x_407</th>\n",
       "      <th>x_408</th>\n",
       "      <th>x_409</th>\n",
       "      <th>x_410</th>\n",
       "      <th>x_411</th>\n",
       "      <th>x_412</th>\n",
       "      <th>x_413</th>\n",
       "      <th>x_414</th>\n",
       "      <th>x_415</th>\n",
       "      <th>x_416</th>\n",
       "      <th>x_417</th>\n",
       "      <th>x_418</th>\n",
       "      <th>x_419</th>\n",
       "      <th>x_420</th>\n",
       "      <th>x_421</th>\n",
       "      <th>x_422</th>\n",
       "      <th>x_423</th>\n",
       "      <th>x_424</th>\n",
       "      <th>x_425</th>\n",
       "      <th>x_426</th>\n",
       "      <th>x_427</th>\n",
       "      <th>x_428</th>\n",
       "      <th>x_429</th>\n",
       "      <th>x_430</th>\n",
       "      <th>x_431</th>\n",
       "      <th>x_432</th>\n",
       "      <th>x_433</th>\n",
       "      <th>x_434</th>\n",
       "      <th>x_435</th>\n",
       "      <th>x_436</th>\n",
       "      <th>x_437</th>\n",
       "      <th>x_438</th>\n",
       "      <th>x_439</th>\n",
       "      <th>x_440</th>\n",
       "      <th>x_441</th>\n",
       "      <th>x_442</th>\n",
       "      <th>x_443</th>\n",
       "      <th>x_444</th>\n",
       "      <th>x_445</th>\n",
       "      <th>x_446</th>\n",
       "      <th>x_447</th>\n",
       "      <th>x_448</th>\n",
       "      <th>x_449</th>\n",
       "      <th>x_450</th>\n",
       "      <th>x_451</th>\n",
       "      <th>x_452</th>\n",
       "      <th>x_453</th>\n",
       "      <th>x_454</th>\n",
       "      <th>x_455</th>\n",
       "      <th>x_456</th>\n",
       "      <th>x_457</th>\n",
       "      <th>x_458</th>\n",
       "      <th>x_459</th>\n",
       "      <th>x_460</th>\n",
       "      <th>x_461</th>\n",
       "      <th>x_462</th>\n",
       "      <th>x_463</th>\n",
       "      <th>x_464</th>\n",
       "      <th>x_465</th>\n",
       "      <th>x_466</th>\n",
       "      <th>x_467</th>\n",
       "      <th>x_468</th>\n",
       "      <th>x_469</th>\n",
       "      <th>x_470</th>\n",
       "      <th>x_471</th>\n",
       "      <th>x_472</th>\n",
       "      <th>x_473</th>\n",
       "      <th>x_474</th>\n",
       "      <th>x_475</th>\n",
       "      <th>x_476</th>\n",
       "      <th>x_477</th>\n",
       "      <th>x_478</th>\n",
       "      <th>x_479</th>\n",
       "      <th>x_480</th>\n",
       "      <th>x_481</th>\n",
       "      <th>x_482</th>\n",
       "      <th>x_483</th>\n",
       "      <th>x_484</th>\n",
       "      <th>x_485</th>\n",
       "      <th>x_486</th>\n",
       "      <th>x_487</th>\n",
       "      <th>x_488</th>\n",
       "      <th>x_489</th>\n",
       "      <th>x_490</th>\n",
       "      <th>x_491</th>\n",
       "      <th>x_492</th>\n",
       "      <th>x_493</th>\n",
       "      <th>x_494</th>\n",
       "      <th>x_495</th>\n",
       "      <th>x_496</th>\n",
       "      <th>x_497</th>\n",
       "      <th>x_498</th>\n",
       "      <th>x_499</th>\n",
       "      <th>x_500</th>\n",
       "      <th>x_501</th>\n",
       "      <th>x_502</th>\n",
       "      <th>x_503</th>\n",
       "      <th>x_504</th>\n",
       "      <th>x_505</th>\n",
       "      <th>x_506</th>\n",
       "      <th>x_507</th>\n",
       "      <th>x_508</th>\n",
       "      <th>x_509</th>\n",
       "      <th>x_510</th>\n",
       "      <th>x_511</th>\n",
       "      <th>x_512</th>\n",
       "      <th>x_513</th>\n",
       "      <th>x_514</th>\n",
       "      <th>x_515</th>\n",
       "      <th>x_516</th>\n",
       "      <th>x_517</th>\n",
       "      <th>x_518</th>\n",
       "      <th>x_519</th>\n",
       "      <th>x_520</th>\n",
       "      <th>x_521</th>\n",
       "      <th>x_522</th>\n",
       "      <th>x_523</th>\n",
       "      <th>x_524</th>\n",
       "      <th>x_525</th>\n",
       "      <th>x_526</th>\n",
       "      <th>x_527</th>\n",
       "      <th>x_528</th>\n",
       "      <th>x_529</th>\n",
       "      <th>x_530</th>\n",
       "      <th>x_531</th>\n",
       "      <th>x_532</th>\n",
       "      <th>x_533</th>\n",
       "      <th>x_534</th>\n",
       "      <th>x_535</th>\n",
       "      <th>x_536</th>\n",
       "      <th>x_537</th>\n",
       "      <th>x_538</th>\n",
       "      <th>x_539</th>\n",
       "      <th>x_540</th>\n",
       "      <th>x_541</th>\n",
       "      <th>x_542</th>\n",
       "      <th>x_543</th>\n",
       "      <th>x_544</th>\n",
       "      <th>x_545</th>\n",
       "      <th>x_546</th>\n",
       "      <th>x_547</th>\n",
       "      <th>x_548</th>\n",
       "      <th>x_549</th>\n",
       "      <th>x_550</th>\n",
       "      <th>x_551</th>\n",
       "      <th>x_552</th>\n",
       "      <th>x_553</th>\n",
       "      <th>x_554</th>\n",
       "      <th>x_555</th>\n",
       "      <th>x_556</th>\n",
       "      <th>x_557</th>\n",
       "      <th>x_558</th>\n",
       "      <th>x_559</th>\n",
       "      <th>x_560</th>\n",
       "      <th>x_561</th>\n",
       "      <th>x_562</th>\n",
       "      <th>x_563</th>\n",
       "      <th>x_564</th>\n",
       "      <th>x_565</th>\n",
       "      <th>x_566</th>\n",
       "      <th>x_567</th>\n",
       "      <th>x_568</th>\n",
       "      <th>x_569</th>\n",
       "      <th>x_570</th>\n",
       "      <th>x_571</th>\n",
       "      <th>x_572</th>\n",
       "      <th>x_573</th>\n",
       "      <th>x_574</th>\n",
       "      <th>x_575</th>\n",
       "      <th>x_576</th>\n",
       "      <th>x_577</th>\n",
       "      <th>x_578</th>\n",
       "      <th>x_579</th>\n",
       "      <th>x_580</th>\n",
       "      <th>x_581</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "      <th>x_590</th>\n",
       "      <th>x_591</th>\n",
       "      <th>x_592</th>\n",
       "      <th>x_593</th>\n",
       "      <th>x_594</th>\n",
       "      <th>x_595</th>\n",
       "      <th>x_596</th>\n",
       "      <th>x_597</th>\n",
       "      <th>x_598</th>\n",
       "      <th>x_599</th>\n",
       "      <th>x_600</th>\n",
       "      <th>x_601</th>\n",
       "      <th>x_602</th>\n",
       "      <th>x_603</th>\n",
       "      <th>x_604</th>\n",
       "      <th>x_605</th>\n",
       "      <th>x_606</th>\n",
       "      <th>x_607</th>\n",
       "      <th>x_608</th>\n",
       "      <th>x_609</th>\n",
       "      <th>x_610</th>\n",
       "      <th>x_611</th>\n",
       "      <th>x_612</th>\n",
       "      <th>x_613</th>\n",
       "      <th>x_614</th>\n",
       "      <th>x_615</th>\n",
       "      <th>x_616</th>\n",
       "      <th>x_617</th>\n",
       "      <th>x_618</th>\n",
       "      <th>x_619</th>\n",
       "      <th>x_620</th>\n",
       "      <th>x_621</th>\n",
       "      <th>x_622</th>\n",
       "      <th>x_623</th>\n",
       "      <th>x_624</th>\n",
       "      <th>x_625</th>\n",
       "      <th>x_626</th>\n",
       "      <th>x_627</th>\n",
       "      <th>x_628</th>\n",
       "      <th>x_629</th>\n",
       "      <th>x_630</th>\n",
       "      <th>x_631</th>\n",
       "      <th>x_632</th>\n",
       "      <th>x_633</th>\n",
       "      <th>x_634</th>\n",
       "      <th>x_635</th>\n",
       "      <th>x_636</th>\n",
       "      <th>x_637</th>\n",
       "      <th>x_638</th>\n",
       "      <th>x_639</th>\n",
       "      <th>x_640</th>\n",
       "      <th>x_641</th>\n",
       "      <th>x_642</th>\n",
       "      <th>x_643</th>\n",
       "      <th>x_644</th>\n",
       "      <th>x_645</th>\n",
       "      <th>x_646</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1943531</th>\n",
       "      <td>2019-09-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>157773.90</td>\n",
       "      <td>157773.90</td>\n",
       "      <td>2014-10-25</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>37</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Сб</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1270000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>8.709677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.967742</td>\n",
       "      <td>8.709677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.030137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>4</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>831600.0</td>\n",
       "      <td>45.40</td>\n",
       "      <td>731600.0</td>\n",
       "      <td>39.94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>28970.68</td>\n",
       "      <td>Улица</td>\n",
       "      <td>2</td>\n",
       "      <td>87449945</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28970.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.75</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>34.517588</td>\n",
       "      <td>58</td>\n",
       "      <td>16914.35</td>\n",
       "      <td>0.583844</td>\n",
       "      <td>0.583844</td>\n",
       "      <td>1943531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943532</th>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2580000.0</td>\n",
       "      <td>2187426.61</td>\n",
       "      <td>2183868.19</td>\n",
       "      <td>2017-08-17</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>240</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Чт</td>\n",
       "      <td>0</td>\n",
       "      <td>3524.50</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>240</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>4680000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19.741935</td>\n",
       "      <td>19.741935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.741935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>14.096774</td>\n",
       "      <td>14.354839</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.935484</td>\n",
       "      <td>12.467742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>19.741935</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>14.096774</td>\n",
       "      <td>14.354839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.935484</td>\n",
       "      <td>12.467742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>0.485830</td>\n",
       "      <td>11645.000000</td>\n",
       "      <td>28318.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>28318.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.380822</td>\n",
       "      <td>19.791781</td>\n",
       "      <td>2383.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>25.290323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>2274.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21858.00</td>\n",
       "      <td>104.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21858.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>11645.0</td>\n",
       "      <td>44991.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>2600000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>15.38</td>\n",
       "      <td>408026.0</td>\n",
       "      <td>15.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>36616.10</td>\n",
       "      <td>Улица</td>\n",
       "      <td>12</td>\n",
       "      <td>300798430</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65200.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.735124</td>\n",
       "      <td>0.735124</td>\n",
       "      <td>71.603967</td>\n",
       "      <td>3</td>\n",
       "      <td>23212.93</td>\n",
       "      <td>0.356027</td>\n",
       "      <td>0.633954</td>\n",
       "      <td>1943532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943533</th>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>385763.26</td>\n",
       "      <td>218655.96</td>\n",
       "      <td>2013-02-07</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Чт</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1228000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>4</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>62.50</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>62.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>21713.75</td>\n",
       "      <td>Улица</td>\n",
       "      <td>50</td>\n",
       "      <td>37572261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.858073</td>\n",
       "      <td>0.858073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73</td>\n",
       "      <td>18631.97</td>\n",
       "      <td>0.388166</td>\n",
       "      <td>0.858072</td>\n",
       "      <td>1943533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943534</th>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>637500.0</td>\n",
       "      <td>595369.13</td>\n",
       "      <td>595369.13</td>\n",
       "      <td>2015-11-16</td>\n",
       "      <td>637500.0</td>\n",
       "      <td>120</td>\n",
       "      <td>B1</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Пн</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>637500.0</td>\n",
       "      <td>2050000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>637500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>37500.00</td>\n",
       "      <td>ЗП</td>\n",
       "      <td>74</td>\n",
       "      <td>196722523</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37500.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.45</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>10071.45</td>\n",
       "      <td>0.402858</td>\n",
       "      <td>0.268572</td>\n",
       "      <td>1943534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943537</th>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1232500.0</td>\n",
       "      <td>1118118.29</td>\n",
       "      <td>1118118.29</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>1870000.0</td>\n",
       "      <td>300</td>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Пн</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>300</td>\n",
       "      <td>1870000.0</td>\n",
       "      <td>2076000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.548387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.548387</td>\n",
       "      <td>9.774194</td>\n",
       "      <td>9.548387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.193548</td>\n",
       "      <td>9.720430</td>\n",
       "      <td>9.967742</td>\n",
       "      <td>9.193548</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330452</td>\n",
       "      <td>0.377933</td>\n",
       "      <td>0.282971</td>\n",
       "      <td>19.548387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.548387</td>\n",
       "      <td>9.774194</td>\n",
       "      <td>9.548387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.193548</td>\n",
       "      <td>9.720430</td>\n",
       "      <td>9.967742</td>\n",
       "      <td>9.193548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330452</td>\n",
       "      <td>0.377933</td>\n",
       "      <td>0.282971</td>\n",
       "      <td>32500.000000</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.528767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6797.36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.548387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21242.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>21242.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>32500.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1870000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>330000.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>217500.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30450.00</td>\n",
       "      <td>Улица</td>\n",
       "      <td>59</td>\n",
       "      <td>63606611</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>15000.00</td>\n",
       "      <td>13.50</td>\n",
       "      <td>0.651646</td>\n",
       "      <td>0.651646</td>\n",
       "      <td>56.539372</td>\n",
       "      <td>56</td>\n",
       "      <td>14366.57</td>\n",
       "      <td>0.287331</td>\n",
       "      <td>0.471809</td>\n",
       "      <td>1943537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290365</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1021000.0</td>\n",
       "      <td>943992.37</td>\n",
       "      <td>940500.37</td>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>180</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Вт</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>180</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>3134000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>73.17</td>\n",
       "      <td>2970520.0</td>\n",
       "      <td>74.42</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>60900.00</td>\n",
       "      <td>Улица</td>\n",
       "      <td>50</td>\n",
       "      <td>298211036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.194099</td>\n",
       "      <td>0.194099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>10971.72</td>\n",
       "      <td>0.156739</td>\n",
       "      <td>0.180160</td>\n",
       "      <td>3290365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290366</th>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1546974.0</td>\n",
       "      <td>294040.56</td>\n",
       "      <td>290902.27</td>\n",
       "      <td>2015-06-08</td>\n",
       "      <td>1550000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Пн</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>1550000.0</td>\n",
       "      <td>6997000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1550000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>453026.0</td>\n",
       "      <td>22.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>34528.52</td>\n",
       "      <td>Улица</td>\n",
       "      <td>23</td>\n",
       "      <td>126116262</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150000.00</td>\n",
       "      <td>20000.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.649050</td>\n",
       "      <td>0.649050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57</td>\n",
       "      <td>24958.10</td>\n",
       "      <td>0.166387</td>\n",
       "      <td>0.722826</td>\n",
       "      <td>3290366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290367</th>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>498600.61</td>\n",
       "      <td>498600.61</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>784000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>B1</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Чт</td>\n",
       "      <td>1</td>\n",
       "      <td>6033.54</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>784000.0</td>\n",
       "      <td>5277000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>132.677419</td>\n",
       "      <td>32.838710</td>\n",
       "      <td>132.677419</td>\n",
       "      <td>32.838710</td>\n",
       "      <td>15.580645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.193548</td>\n",
       "      <td>35.741935</td>\n",
       "      <td>59.658065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.767742</td>\n",
       "      <td>71.767742</td>\n",
       "      <td>8.401075</td>\n",
       "      <td>8.401075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.121455</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>50.322581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.322581</td>\n",
       "      <td>50.322581</td>\n",
       "      <td>34.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.677419</td>\n",
       "      <td>32.838710</td>\n",
       "      <td>132.677419</td>\n",
       "      <td>32.838710</td>\n",
       "      <td>15.580645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.193548</td>\n",
       "      <td>16.258065</td>\n",
       "      <td>52.424731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.767742</td>\n",
       "      <td>71.767742</td>\n",
       "      <td>8.401075</td>\n",
       "      <td>8.401075</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068273</td>\n",
       "      <td>0.121455</td>\n",
       "      <td>0.015090</td>\n",
       "      <td>188333.333333</td>\n",
       "      <td>204250.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>247500.0</td>\n",
       "      <td>249000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.756164</td>\n",
       "      <td>132.756164</td>\n",
       "      <td>10833.54</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.01509</td>\n",
       "      <td>132.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>50.322581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>1233.54</td>\n",
       "      <td>1448.66</td>\n",
       "      <td>30606.74</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32055.4</td>\n",
       "      <td>133.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>188333.0</td>\n",
       "      <td>252000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>784000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>816000.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>50456.05</td>\n",
       "      <td>ЗП</td>\n",
       "      <td>2</td>\n",
       "      <td>173181407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21694.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50456.05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60000.00</td>\n",
       "      <td>21694.25</td>\n",
       "      <td>14.25</td>\n",
       "      <td>0.363178</td>\n",
       "      <td>0.363178</td>\n",
       "      <td>16.173589</td>\n",
       "      <td>53</td>\n",
       "      <td>12541.85</td>\n",
       "      <td>0.209031</td>\n",
       "      <td>0.248570</td>\n",
       "      <td>3290367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290368</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>712000.0</td>\n",
       "      <td>157083.71</td>\n",
       "      <td>147504.75</td>\n",
       "      <td>2016-05-27</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>B1</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Пт</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>120</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>2221000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.225806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.232877</td>\n",
       "      <td>19.232877</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>960000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>Приобретение</td>\n",
       "      <td>240000.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>178000.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>16582.26</td>\n",
       "      <td>ЗП</td>\n",
       "      <td>21</td>\n",
       "      <td>247877857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16582.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45000.00</td>\n",
       "      <td>1300.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>0.924713</td>\n",
       "      <td>57.893194</td>\n",
       "      <td>45</td>\n",
       "      <td>10630.92</td>\n",
       "      <td>0.236243</td>\n",
       "      <td>0.641102</td>\n",
       "      <td>3290368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3290369</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>467939.72</td>\n",
       "      <td>467939.72</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>120</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Чт</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Инвестирование</td>\n",
       "      <td>120</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>2050000.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Инвестирование</td>\n",
       "      <td>1774440.0</td>\n",
       "      <td>59.66</td>\n",
       "      <td>1774440.0</td>\n",
       "      <td>59.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>living in city in apart</td>\n",
       "      <td>1</td>\n",
       "      <td>31389.40</td>\n",
       "      <td>Улица</td>\n",
       "      <td>78</td>\n",
       "      <td>294060527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36000.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>15858.09</td>\n",
       "      <td>0.440503</td>\n",
       "      <td>0.505205</td>\n",
       "      <td>3290369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>763809 rows × 647 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         REPORT_DT  x_0  x_1  x_2  x_3        x_4         x_5         x_7  \\\n",
       "1943531 2019-09-01    1    0    1    1  1100000.0   157773.90   157773.90   \n",
       "1943532 2017-12-18    1    0    1    1  2580000.0  2187426.61  2183868.19   \n",
       "1943533 2019-04-24    1    0    1    1  1200000.0   385763.26   218655.96   \n",
       "1943534 2017-05-15    1    0    1    1   637500.0   595369.13   595369.13   \n",
       "1943537 2019-03-10    1    0    1    1  1232500.0  1118118.29  1118118.29   \n",
       "...            ...  ...  ...  ...  ...        ...         ...         ...   \n",
       "3290365 2020-03-09    1    0    1    1  1021000.0   943992.37   940500.37   \n",
       "3290366 2020-03-17    1    0    1    1  1546974.0   294040.56   290902.27   \n",
       "3290367 2020-03-01    1    0    1    1   800000.0   498600.61   498600.61   \n",
       "3290368 2020-03-05    1    0    1    1   712000.0   157083.71   147504.75   \n",
       "3290369 2020-03-22    1    0    1    1  1200000.0   467939.72   467939.72   \n",
       "\n",
       "               x_9       x_10  x_11 x_12 x_13  x_14  x_15  x_16  x_17 x_18  \\\n",
       "1943531 2014-10-25  1000000.0   120    D    4    37   2.0   2.0  None   Сб   \n",
       "1943532 2017-08-17  2600000.0   240    D    1    28  12.0  12.0  None   Чт   \n",
       "1943533 2013-02-07  1200000.0   120    D    4    56  50.0  50.0  None   Чт   \n",
       "1943534 2015-11-16   637500.0   120   B1    4    46  74.0  74.0  None   Пн   \n",
       "1943537 2014-03-24  1870000.0   300    D    2    25  59.0  59.0  None   Пн   \n",
       "...            ...        ...   ...  ...  ...   ...   ...   ...   ...  ...   \n",
       "3290365 2017-07-25  1100000.0   180    D    1    25  50.0  50.0  None   Вт   \n",
       "3290366 2015-06-08  1550000.0   120    D    1    40  23.0  23.0  None   Пн   \n",
       "3290367 2015-09-17   784000.0   120   B1    4    38   2.0   2.0  None   Чт   \n",
       "3290368 2016-05-27   960000.0   120   B1    4    24  21.0  21.0  None   Пт   \n",
       "3290369 2017-06-15  1200000.0   120    D    1    28  47.0  47.0  None   Чт   \n",
       "\n",
       "        x_19     x_20            x_21  x_22       x_23       x_24  x_25  x_26  \\\n",
       "1943531    0     0.00    Приобретение   120  1000000.0  1270000.0  None  None   \n",
       "1943532    0  3524.50    Приобретение   240  2600000.0  4680000.0  None  None   \n",
       "1943533    0     0.00    Приобретение   120  1200000.0  1228000.0  None  None   \n",
       "1943534    1     0.00    Приобретение   120   637500.0  2050000.0  None  None   \n",
       "1943537    0     0.00    Приобретение   300  1870000.0  2076000.0  None  None   \n",
       "...      ...      ...             ...   ...        ...        ...   ...   ...   \n",
       "3290365    1     0.00    Приобретение   180  1100000.0  3134000.0  None  None   \n",
       "3290366    0     0.00    Приобретение   120  1550000.0  6997000.0  None  None   \n",
       "3290367    1  6033.54    Приобретение   120   784000.0  5277000.0  None  None   \n",
       "3290368    1  1000.00    Приобретение   120   960000.0  2221000.0  None  None   \n",
       "3290369    0     0.00  Инвестирование   120  1200000.0  2050000.0  None  None   \n",
       "\n",
       "         x_27        x_28       x_29        x_30       x_31       x_32  x_33  \\\n",
       "1943531  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "1943532  None   19.741935  19.741935         NaN  19.741935        NaN   0.0   \n",
       "1943533  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "1943534  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "1943537  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "...       ...         ...        ...         ...        ...        ...   ...   \n",
       "3290365  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "3290366  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "3290367  None  132.677419  32.838710  132.677419  32.838710  15.580645   0.0   \n",
       "3290368  None   19.225806  19.225806         NaN  19.225806        NaN   0.0   \n",
       "3290369  None         NaN        NaN         NaN        NaN        NaN   NaN   \n",
       "\n",
       "         x_34  x_35       x_36       x_37       x_38  x_39  x_40       x_41  \\\n",
       "1943531   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "1943532   0.0   0.0        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "1943533   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "1943534   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "1943537   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "...       ...   ...        ...        ...        ...   ...   ...        ...   \n",
       "3290365   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "3290366   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "3290367   0.0   0.0  87.193548  35.741935  59.658065   NaN   NaN  71.767742   \n",
       "3290368   0.0   0.0        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "3290369   NaN   NaN        NaN        NaN        NaN   NaN   NaN        NaN   \n",
       "\n",
       "              x_42      x_43      x_44  x_45      x_46  x_47  x_48  x_49  \\\n",
       "1943531        NaN       NaN       NaN   0.0       NaN   0.0   0.0   0.0   \n",
       "1943532        NaN       NaN       NaN   0.0  0.000000   1.0   0.0   1.0   \n",
       "1943533        NaN       NaN       NaN   NaN       NaN   NaN   NaN   NaN   \n",
       "1943534        NaN       NaN       NaN   NaN       NaN   NaN   NaN   NaN   \n",
       "1943537        NaN       NaN       NaN   0.0       NaN   0.0   0.0   0.0   \n",
       "...            ...       ...       ...   ...       ...   ...   ...   ...   \n",
       "3290365        NaN       NaN       NaN   NaN       NaN   NaN   NaN   NaN   \n",
       "3290366        NaN       NaN       NaN   NaN       NaN   NaN   NaN   NaN   \n",
       "3290367  71.767742  8.401075  8.401075   4.0  0.666667   6.0   5.0   1.0   \n",
       "3290368        NaN       NaN       NaN   0.0  0.000000   1.0   0.0   1.0   \n",
       "3290369        NaN       NaN       NaN   NaN       NaN   NaN   NaN   NaN   \n",
       "\n",
       "         x_50  x_51  x_52  x_53  x_54  x_55  x_56  x_57  x_58      x_59  \\\n",
       "1943531   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0       NaN   \n",
       "1943532   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \n",
       "1943533   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN       NaN   \n",
       "1943534   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN       NaN   \n",
       "1943537   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0       NaN   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...       ...   \n",
       "3290365   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN       NaN   \n",
       "3290366   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN       NaN   \n",
       "3290367   3.0   4.0   4.0   0.0   2.0   2.0   1.0   1.0   1.0  0.666667   \n",
       "3290368   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  0.000000   \n",
       "3290369   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN       NaN   \n",
       "\n",
       "             x_60  x_61      x_62  x_63  x_64  x_65  x_66  x_67  x_68  x_69  \\\n",
       "1943531       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943532       NaN   0.0  0.000000   0.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943533       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943534       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943537       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "...           ...   ...       ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "3290365       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290366       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290367  0.666667   0.0  0.333333   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3290368       NaN   0.0  0.000000   0.0   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290369       NaN   NaN       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "         x_70  x_71  x_72  x_73  x_74  x_75  x_76  x_77  x_78  x_79  x_80  \\\n",
       "1943531   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   0.0   0.0   \n",
       "1943532   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   0.0   0.0   \n",
       "1943533   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943534   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943537   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   0.0   0.0   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "3290365   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290366   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290367   0.5   1.0   NaN   NaN   NaN   5.0   5.0   0.0   2.0   0.0   0.0   \n",
       "3290368   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   0.0   0.0   \n",
       "3290369   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "         x_81  x_82  x_83  x_84  x_85  x_86  x_87  x_88  x_89  x_90  x_91  \\\n",
       "1943531   0.0   0.0   0.0   0.0   NaN   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1943532   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1943533   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943534   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "1943537   0.0   0.0   0.0   0.0   NaN   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "3290365   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290366   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "3290367   0.0   0.0   0.0   6.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3290368   0.0   0.0   0.0   1.0   1.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3290369   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "         x_92  x_93  x_94  x_95  x_96  x_97  x_98  x_99  x_100  x_101  x_102  \\\n",
       "1943531   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    NaN    NaN    NaN   \n",
       "1943532   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    NaN    NaN    NaN   \n",
       "1943533   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN   \n",
       "1943534   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN   \n",
       "1943537   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    NaN    NaN    NaN   \n",
       "...       ...   ...   ...   ...   ...   ...   ...   ...    ...    ...    ...   \n",
       "3290365   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN   \n",
       "3290366   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN   \n",
       "3290367   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    NaN    NaN    NaN   \n",
       "3290368   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0    NaN    NaN    NaN   \n",
       "3290369   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_103  x_104  x_105  x_106  x_107  x_108  x_109  x_110  x_111  x_112  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_113  x_114  x_115  x_116  x_117  x_118  x_119  x_120  x_121  x_122  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_123  x_124  x_125  x_126  x_127     x_128     x_129    x_130  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "1943532    NaN    0.0    0.0    0.0    0.0       NaN       NaN      NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "1943537    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "...        ...    ...    ...    ...    ...       ...       ...      ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "3290367    NaN    0.0    0.0    0.0    0.0  0.068273  0.121455  0.01509   \n",
       "3290368    NaN    0.0    0.0    0.0    0.0       NaN       NaN      NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN       NaN       NaN      NaN   \n",
       "\n",
       "             x_131      x_132      x_133      x_134      x_135     x_136  \\\n",
       "1943531  40.967742  40.967742        NaN  40.967742   8.709677  0.000000   \n",
       "1943532  25.290323        NaN  25.290323  14.096774  14.354839  0.266667   \n",
       "1943533        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "1943534        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "1943537  19.548387        NaN  19.548387   9.774194   9.548387  0.000000   \n",
       "...            ...        ...        ...        ...        ...       ...   \n",
       "3290365        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "3290366        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "3290367  50.322581        NaN  50.322581  50.322581  34.064516  0.000000   \n",
       "3290368        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "3290369        NaN        NaN        NaN        NaN        NaN       NaN   \n",
       "\n",
       "            x_137     x_138      x_139      x_140      x_141     x_142  \\\n",
       "1943531  0.000000  0.000000        NaN        NaN        NaN       NaN   \n",
       "1943532  0.266667  0.266667  14.000000  10.935484  12.467742       NaN   \n",
       "1943533       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "1943534       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "1943537  0.000000  0.000000  10.000000   9.193548   9.720430  9.967742   \n",
       "...           ...       ...        ...        ...        ...       ...   \n",
       "3290365       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "3290366       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "3290367  0.000000  0.000000  16.258065  16.258065  16.258065       NaN   \n",
       "3290368       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "3290369       NaN       NaN        NaN        NaN        NaN       NaN   \n",
       "\n",
       "            x_143  x_144  x_145  x_146  x_147  x_148     x_149  x_150  x_151  \\\n",
       "1943531       NaN    NaN    NaN    NaN    NaN    0.0  0.000000    1.0    0.0   \n",
       "1943532       NaN    0.0    0.0    0.0    0.0    0.0  0.000000    2.0    2.0   \n",
       "1943533       NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "1943534       NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "1943537  9.193548    0.0    0.0    0.0    0.0    1.0  0.333333    3.0    3.0   \n",
       "...           ...    ...    ...    ...    ...    ...       ...    ...    ...   \n",
       "3290365       NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "3290366       NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "3290367       NaN    0.0    0.0    0.0    0.0    1.0  1.000000    1.0    1.0   \n",
       "3290368       NaN    NaN    NaN    NaN    NaN    0.0       NaN    0.0    0.0   \n",
       "3290369       NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN   \n",
       "\n",
       "         x_152  x_153  x_154  x_155  x_156  x_157  x_158  x_159  x_160  x_161  \\\n",
       "1943531    1.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    2.0    1.0    1.0    0.0    1.0    1.0    1.0    0.0    1.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    3.0    1.0    1.0    0.0    1.0    2.0    2.0    0.0    2.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    1.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "            x_162     x_163  x_164     x_165  x_166     x_167     x_168  \\\n",
       "1943531  1.000000       NaN    1.0  0.000000    0.0       NaN       NaN   \n",
       "1943532  0.500000  0.500000    NaN  0.500000    NaN  0.000000  0.000000   \n",
       "1943533       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "1943534       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "1943537  0.333333  0.333333    NaN  0.666667    NaN  0.666667  0.666667   \n",
       "...           ...       ...    ...       ...    ...       ...       ...   \n",
       "3290365       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "3290366       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "3290367  1.000000  1.000000    NaN  0.000000    NaN  0.000000  0.000000   \n",
       "3290368       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "3290369       NaN       NaN    NaN       NaN    NaN       NaN       NaN   \n",
       "\n",
       "         x_169  x_170  x_171  x_172  x_173  x_174     x_175  x_176     x_177  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "1943532    0.5    0.5    0.0    0.0    1.0    1.0  1.000000    NaN  0.000000   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "1943537    1.0    1.0    1.0    1.0    1.0    1.0  0.333333    0.5  0.666667   \n",
       "...        ...    ...    ...    ...    ...    ...       ...    ...       ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0       NaN    NaN       NaN   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN       NaN    NaN       NaN   \n",
       "\n",
       "         x_178  x_179  x_180  x_181  x_182  x_183  x_184  x_185  x_186  x_187  \\\n",
       "1943531    1.0    NaN    NaN    NaN    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "1943532    1.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    2.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    3.0    3.0    3.0    3.0    0.0    1.0    0.0    0.0    0.0    2.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    1.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    NaN    NaN    NaN    NaN    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "            x_188  x_189  x_190  x_191  x_192  x_193  x_194  x_195  x_196  \\\n",
       "1943531  1.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532  1.000000    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537  0.666667    1.0    0.0    0.0    0.0    0.0    0.0    2.0    0.0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367  0.000000    1.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \n",
       "3290368       NaN    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_197  x_198     x_199  x_200  x_201  x_202  x_203  x_204  x_205  \\\n",
       "1943531    0.0    0.0  0.000000    0.0    0.0    0.0    NaN    NaN    NaN   \n",
       "1943532    0.0    0.0  0.000000    0.0    0.0    0.0    NaN    NaN    NaN   \n",
       "1943533    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0  0.666667    0.0    0.0    0.0    1.0    NaN    NaN   \n",
       "...        ...    ...       ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0  0.142857    0.0    0.0    0.0    0.0    NaN    NaN   \n",
       "3290368    0.0    0.0  0.000000    0.0    0.0    0.0    NaN    NaN    NaN   \n",
       "3290369    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_206  x_207  x_208  x_209  x_210  x_211  x_212  x_213  x_214  x_215  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    NaN    1.0    NaN    NaN    NaN    0.0    0.0    0.0    1.0    NaN   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN    0.0    NaN    NaN    NaN    0.0    0.0    0.0    0.0    NaN   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN    NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_216  x_217  x_218  x_219  x_220  x_221  x_222  x_223  x_224  x_225  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    NaN    NaN    1.0    NaN    NaN    NaN    6.0    6.0    6.0    1.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN    NaN    0.0    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0    0.0    NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_226     x_227  x_228  x_229  x_230     x_231     x_232     x_233  \\\n",
       "1943531    NaN  0.000000    0.0    0.0    0.0       NaN       NaN       NaN   \n",
       "1943532    NaN  0.000000    0.0    0.0    0.0  0.485830  0.485830  0.485830   \n",
       "1943533    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "1943534    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "1943537    1.0  0.333333    0.0    0.0    0.0  0.330452  0.377933  0.282971   \n",
       "...        ...       ...    ...    ...    ...       ...       ...       ...   \n",
       "3290365    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "3290366    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "3290367    NaN  1.000000    0.0    0.0    0.0       NaN       NaN       NaN   \n",
       "3290368    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "3290369    NaN       NaN    NaN    NaN    NaN       NaN       NaN       NaN   \n",
       "\n",
       "              x_234      x_235       x_236      x_237      x_238  x_239  \\\n",
       "1943531   40.967742  40.967742         NaN  40.967742   8.709677    0.0   \n",
       "1943532   25.290323  19.741935   25.290323  14.096774  14.354839    0.0   \n",
       "1943533         NaN        NaN         NaN        NaN        NaN    NaN   \n",
       "1943534         NaN        NaN         NaN        NaN        NaN    NaN   \n",
       "1943537   19.548387        NaN   19.548387   9.774194   9.548387    0.0   \n",
       "...             ...        ...         ...        ...        ...    ...   \n",
       "3290365         NaN        NaN         NaN        NaN        NaN    NaN   \n",
       "3290366         NaN        NaN         NaN        NaN        NaN    NaN   \n",
       "3290367  132.677419  32.838710  132.677419  32.838710  15.580645    0.0   \n",
       "3290368   19.225806  19.225806         NaN  19.225806        NaN    0.0   \n",
       "3290369         NaN        NaN         NaN        NaN        NaN    NaN   \n",
       "\n",
       "         x_240  x_241      x_242      x_243      x_244     x_245     x_246  \\\n",
       "1943531    0.0    0.0        NaN        NaN        NaN       NaN       NaN   \n",
       "1943532    0.0    0.0  14.000000  10.935484  12.467742       NaN       NaN   \n",
       "1943533    NaN    NaN        NaN        NaN        NaN       NaN       NaN   \n",
       "1943534    NaN    NaN        NaN        NaN        NaN       NaN       NaN   \n",
       "1943537    0.0    0.0  10.000000   9.193548   9.720430  9.967742  9.193548   \n",
       "...        ...    ...        ...        ...        ...       ...       ...   \n",
       "3290365    NaN    NaN        NaN        NaN        NaN       NaN       NaN   \n",
       "3290366    NaN    NaN        NaN        NaN        NaN       NaN       NaN   \n",
       "3290367    0.0    0.0  87.193548  16.258065  52.424731       NaN       NaN   \n",
       "3290368    0.0    0.0        NaN        NaN        NaN       NaN       NaN   \n",
       "3290369    NaN    NaN        NaN        NaN        NaN       NaN       NaN   \n",
       "\n",
       "             x_247      x_248     x_249     x_250  x_251     x_252  x_253  \\\n",
       "1943531        NaN        NaN       NaN       NaN    0.0  0.000000    1.0   \n",
       "1943532   0.000000   0.000000  0.000000  0.000000    0.0  0.000000    3.0   \n",
       "1943533        NaN        NaN       NaN       NaN    NaN       NaN    NaN   \n",
       "1943534        NaN        NaN       NaN       NaN    NaN       NaN    NaN   \n",
       "1943537   0.000000   0.000000  0.000000  0.000000    1.0  0.333333    3.0   \n",
       "...            ...        ...       ...       ...    ...       ...    ...   \n",
       "3290365        NaN        NaN       NaN       NaN    NaN       NaN    NaN   \n",
       "3290366        NaN        NaN       NaN       NaN    NaN       NaN    NaN   \n",
       "3290367  71.767742  71.767742  8.401075  8.401075    5.0  0.714286    7.0   \n",
       "3290368        NaN        NaN       NaN       NaN    0.0  0.000000    1.0   \n",
       "3290369        NaN        NaN       NaN       NaN    NaN       NaN    NaN   \n",
       "\n",
       "         x_254  x_255  x_256  x_257  x_258  x_259  x_260  x_261  x_262  x_263  \\\n",
       "1943531    0.0    1.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0    0.0   \n",
       "1943532    2.0    1.0    2.0    1.0    1.0    0.0    1.0    1.0    1.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    3.0    0.0    3.0    1.0    1.0    0.0    1.0    2.0    2.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    6.0    1.0    4.0    5.0    5.0    0.0    3.0    2.0    1.0    1.0   \n",
       "3290368    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_264     x_265     x_266  x_267     x_268  x_269     x_270  \\\n",
       "1943531    0.0  1.000000       NaN    1.0  0.000000    0.0       NaN   \n",
       "1943532    1.0  0.333333  0.500000    0.0  0.333333    0.0  0.000000   \n",
       "1943533    NaN       NaN       NaN    NaN       NaN    NaN       NaN   \n",
       "1943534    NaN       NaN       NaN    NaN       NaN    NaN       NaN   \n",
       "1943537    2.0  0.333333  0.333333    NaN  0.666667    NaN  0.666667   \n",
       "...        ...       ...       ...    ...       ...    ...       ...   \n",
       "3290365    NaN       NaN       NaN    NaN       NaN    NaN       NaN   \n",
       "3290366    NaN       NaN       NaN    NaN       NaN    NaN       NaN   \n",
       "3290367    1.0  0.714286  0.750000    0.0  0.285714    1.0  0.000000   \n",
       "3290368    0.0  0.000000       NaN    0.0  0.000000    0.0       NaN   \n",
       "3290369    NaN       NaN       NaN    NaN       NaN    NaN       NaN   \n",
       "\n",
       "            x_271  x_272  x_273  x_274  x_275  x_276     x_277     x_278  \\\n",
       "1943531       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "1943532  0.000000    0.5    0.5    0.0    0.0    1.0  1.000000  1.000000   \n",
       "1943533       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "1943534       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "1943537  0.666667    1.0    1.0    1.0    1.0    1.0  1.000000  0.333333   \n",
       "...           ...    ...    ...    ...    ...    ...       ...       ...   \n",
       "3290365       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "3290366       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "3290367  0.000000    0.0    0.0    0.0    0.0    0.4  0.666667       NaN   \n",
       "3290368       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "3290369       NaN    NaN    NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "\n",
       "         x_279     x_280  x_281  x_282  x_283  x_284  x_285  x_286  x_287  \\\n",
       "1943531    NaN       NaN    1.0    NaN    NaN    NaN    0.0    0.0    0.0   \n",
       "1943532    NaN  0.000000    2.0    1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1943533    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.5  0.666667    3.0    3.0    3.0    3.0    0.0    1.0    0.0   \n",
       "...        ...       ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN       NaN    6.0    6.0    0.0    2.0    0.0    0.0    0.0   \n",
       "3290368    NaN       NaN    1.0    NaN    NaN    NaN    0.0    0.0    0.0   \n",
       "3290369    NaN       NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_288  x_289  x_290     x_291  x_292  x_293  x_294  x_295  x_296  \\\n",
       "1943531    0.0    0.0    1.0  1.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    3.0  1.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    2.0  0.666667    1.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...       ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    6.0  0.857143    1.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    1.0  1.000000    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_297  x_298  x_299  x_300  x_301     x_302  x_303  x_304  x_305  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    2.0    0.0    0.0    0.0  0.666667    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...       ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    1.0    0.0    0.0    0.0  0.142857    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0  0.000000    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_306  x_307  x_308  x_309  x_310  x_311  x_312  x_313  x_314  x_315  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    1.0    NaN    NaN    NaN    1.0    NaN    NaN    NaN    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    NaN    NaN    NaN    0.0    NaN    NaN    NaN    0.0    0.0   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_316  x_317  x_318  x_319  x_320  x_321  x_322  x_323  x_324  x_325  \\\n",
       "1943531    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0   \n",
       "1943532    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    1.0    NaN    NaN    NaN    1.0    NaN    NaN    NaN    6.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    NaN    NaN    NaN    0.0    NaN    NaN    NaN    0.0   \n",
       "3290368    0.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_326  x_327  x_328  x_329     x_330  x_331  x_332  x_333     x_334  \\\n",
       "1943531    0.0    0.0    NaN    NaN  0.000000    0.0    0.0    0.0       NaN   \n",
       "1943532    0.0    0.0    NaN    NaN  0.000000    0.0    0.0    0.0  0.485830   \n",
       "1943533    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN       NaN   \n",
       "1943534    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN       NaN   \n",
       "1943537    6.0    6.0    1.0    1.0  0.333333    0.0    0.0    0.0  0.330452   \n",
       "...        ...    ...    ...    ...       ...    ...    ...    ...       ...   \n",
       "3290365    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN       NaN   \n",
       "3290366    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN       NaN   \n",
       "3290367    0.0    0.0    NaN    NaN  0.142857    0.0    0.0    0.0  0.068273   \n",
       "3290368    0.0    0.0    NaN    NaN  0.000000    0.0    0.0    0.0       NaN   \n",
       "3290369    NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN       NaN   \n",
       "\n",
       "            x_335     x_336          x_337     x_338     x_339     x_340  \\\n",
       "1943531       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "1943532  0.485830  0.485830   11645.000000   28318.0   11645.0   44991.0   \n",
       "1943533       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "1943534       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "1943537  0.377933  0.282971   32500.000000   32500.0   32500.0   35000.0   \n",
       "...           ...       ...            ...       ...       ...       ...   \n",
       "3290365       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "3290366       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "3290367  0.121455  0.015090  188333.333333  204250.0  450000.0  450000.0   \n",
       "3290368       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "3290369       NaN       NaN            NaN       NaN       NaN       NaN   \n",
       "\n",
       "           x_341    x_342  x_343  x_344  x_345  x_346  x_347  x_348    x_349  \\\n",
       "1943531      NaN      NaN    NaN    NaN    NaN    NaN    0.0    NaN      NaN   \n",
       "1943532  11645.0  11645.0    NaN    NaN    NaN    NaN    0.0   25.0  11645.0   \n",
       "1943533      NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN      NaN   \n",
       "1943534      NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN      NaN   \n",
       "1943537  32500.0  30000.0    NaN    NaN    NaN    0.0    0.0   31.0  32500.0   \n",
       "...          ...      ...    ...    ...    ...    ...    ...    ...      ...   \n",
       "3290365      NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN      NaN   \n",
       "3290366      NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN      NaN   \n",
       "3290367  45000.0  45000.0    NaN    NaN    NaN    3.0    0.0  225.0  70000.0   \n",
       "3290368      NaN      NaN    NaN    NaN    NaN    NaN    0.0    NaN      NaN   \n",
       "3290369      NaN      NaN    NaN    NaN    NaN    NaN    NaN    NaN      NaN   \n",
       "\n",
       "           x_350    x_351    x_352    x_353    x_354  x_355  x_356  x_357  \\\n",
       "1943531      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "1943532  28318.0  11645.0  44991.0  11645.0  11645.0    NaN    NaN    NaN   \n",
       "1943533      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "1943534      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "1943537  32500.0  32500.0  35000.0  32500.0  30000.0    NaN    NaN    NaN   \n",
       "...          ...      ...      ...      ...      ...    ...    ...    ...   \n",
       "3290365      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "3290366      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "3290367  70000.0  70000.0  70000.0  70000.0  70000.0    NaN    NaN    NaN   \n",
       "3290368      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "3290369      NaN      NaN      NaN      NaN      NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_358  x_359  x_360     x_361     x_362     x_363     x_364    x_365  \\\n",
       "1943531    NaN    0.0    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "1943532    NaN    0.0   25.0       NaN       NaN       NaN       NaN      NaN   \n",
       "1943533    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "1943534    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "1943537    0.0    0.0   31.0       NaN       NaN       NaN       NaN      NaN   \n",
       "...        ...    ...    ...       ...       ...       ...       ...      ...   \n",
       "3290365    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "3290366    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "3290367    3.0    0.0   16.0  247500.0  249000.0  450000.0  450000.0  45000.0   \n",
       "3290368    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "3290369    NaN    NaN    NaN       NaN       NaN       NaN       NaN      NaN   \n",
       "\n",
       "           x_366  x_367  x_368  x_369  x_370  x_371  x_372  x_373  x_374  \\\n",
       "1943531      NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0   \n",
       "1943532      NaN    NaN    NaN    NaN    NaN    0.0    NaN    0.0    0.0   \n",
       "1943533      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537      NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0    0.0   \n",
       "...          ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367  45000.0    NaN    NaN    NaN    NaN    0.0  209.0    0.0    0.0   \n",
       "3290368      NaN    NaN    NaN    NaN    NaN    0.0    NaN    0.0    0.0   \n",
       "3290369      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_375  x_376  x_377  x_378  x_379  x_380  x_381  x_382  x_383  x_384  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_385  x_386  x_387  x_388  x_389  x_390  x_391  x_392  x_393  x_394  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_395  x_396  x_397  x_398  x_399  x_400  x_401  x_402  x_403  x_404  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    2.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_405  x_406  x_407  x_408  x_409  x_410  x_411  x_412  x_413  x_414  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    1.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    3.0    1.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    3.0    1.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    7.0    4.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    1.0    1.0    1.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_415  x_416  x_417  x_418  x_419  x_420  x_421   x_422  x_423  \\\n",
       "1943531    1.0    1.0    1.0    0.0    0.0    0.0    0.0  1.0000    0.0   \n",
       "1943532    2.0    2.0    0.0    0.0    1.0    1.0    1.0  1.0000    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "1943537    3.0    1.0    1.0    0.0    0.0    2.0    2.0  0.6667    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "3290367    1.0    5.0    0.0    0.0    6.0    2.0    1.0  1.0000    0.0   \n",
       "3290368    0.0    1.0    0.0    0.0    1.0    0.0    0.0  1.0000    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN    NaN   \n",
       "\n",
       "         x_424  x_425  x_426  x_427  x_428  x_429  x_430  x_431  x_432  x_433  \\\n",
       "1943531    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    1.0    2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_434  x_435  x_436  x_437  x_438  x_439  x_440  x_441  x_442  x_443  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    2.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_444  x_445  x_446  x_447  x_448       x_449       x_450     x_451  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0   41.030137    0.000000      0.00   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0   25.380822   19.791781   2383.78   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN         NaN         NaN       NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN         NaN         NaN       NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0   19.528767    0.000000   6797.36   \n",
       "...        ...    ...    ...    ...    ...         ...         ...       ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN         NaN         NaN       NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN         NaN         NaN       NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0  132.756164  132.756164  10833.54   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0   19.232877   19.232877      0.00   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN         NaN         NaN       NaN   \n",
       "\n",
       "         x_452  x_453  x_454  x_455  x_456  x_457  x_458  x_459  x_460  x_461  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    5.0    5.0    5.0    5.0    5.0    5.0    0.0    0.0   19.3    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    5.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   17.9   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_462    x_463  x_464  x_465      x_466  x_467  x_468  x_469  x_470  \\\n",
       "1943531    0.0      NaN   40.0    NaN        NaN    0.0    0.0    0.0    1.0   \n",
       "1943532   19.3  0.00000   25.0   19.0  25.290323    0.0    0.0    0.0    1.0   \n",
       "1943533    NaN      NaN    NaN    NaN        NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN      NaN    NaN    NaN        NaN    NaN    NaN    NaN    NaN   \n",
       "1943537   19.3      NaN   19.0    NaN  19.548387    0.0    1.0    0.0    1.0   \n",
       "...        ...      ...    ...    ...        ...    ...    ...    ...    ...   \n",
       "3290365    NaN      NaN    NaN    NaN        NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN      NaN    NaN    NaN        NaN    NaN    NaN    NaN    NaN   \n",
       "3290367   12.0  0.01509  132.0  132.0  50.322581    0.0    3.0    0.0    3.0   \n",
       "3290368    0.0  0.00000   19.0   19.0        NaN    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN      NaN    NaN    NaN        NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_471  x_472  x_473  x_474  x_475  x_476  x_477  x_478  x_479  x_480  \\\n",
       "1943531    0.0    0.0    0.0    0.0    1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1943532    0.0    1.0    1.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    1.0    1.0    1.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    3.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_481  x_482  x_483  x_484  x_485  x_486  x_487  x_488  x_489  x_490  \\\n",
       "1943531    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    NaN   \n",
       "1943532    0.0    0.0    0.0    3.0    2.0    1.0    0.0    0.0    0.0    NaN   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    3.0    2.0    0.0    0.0    2.0    0.0    NaN   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    5.0    2.0    1.0    0.0    0.0    0.0    NaN   \n",
       "3290368    0.0    0.0    0.0    1.0    1.0    1.0    0.0    0.0    0.0    NaN   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_491  x_492  x_493  x_494  x_495  x_496  x_497  x_498  x_499  x_500  \\\n",
       "1943531    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0   \n",
       "1943532    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    2.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    3.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    4.0   \n",
       "3290368    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_501  x_502  x_503  x_504  x_505  x_506  x_507  x_508  x_509  x_510  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_511  x_512  x_513  x_514  x_515  x_516  x_517  x_518  x_519  x_520  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_521  x_522  x_523  x_524  x_525  x_526  x_527  x_528  x_529  x_530  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_531  x_532  x_533  x_534  x_535     x_536  x_537  x_538     x_539  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0  1.000000    1.0    1.0  0.000000   \n",
       "1943532    0.0    0.0    0.0    0.0    0.0  0.666667    0.0    0.5  0.666667   \n",
       "1943533    NaN    NaN    NaN    NaN   -1.0 -1.000000   -1.0   -1.0 -1.000000   \n",
       "1943534    NaN    NaN    NaN    NaN   -1.0 -1.000000   -1.0   -1.0 -1.000000   \n",
       "1943537    0.0    0.0    0.0    0.0    0.0  0.333333    1.0    1.0  0.666667   \n",
       "...        ...    ...    ...    ...    ...       ...    ...    ...       ...   \n",
       "3290365    NaN    NaN    NaN    NaN   -1.0 -1.000000   -1.0   -1.0 -1.000000   \n",
       "3290366    NaN    NaN    NaN    NaN   -1.0 -1.000000   -1.0   -1.0 -1.000000   \n",
       "3290367    0.0    0.0    0.0    0.0    0.0  0.714286    0.0    0.8  0.400000   \n",
       "3290368    0.0    0.0    0.0    0.0   -1.0  1.000000    0.0    0.0  1.000000   \n",
       "3290369    NaN    NaN    NaN    NaN   -1.0 -1.000000   -1.0   -1.0 -1.000000   \n",
       "\n",
       "         x_540  x_541  x_542  x_543  x_544  x_545     x_546    x_547    x_548  \\\n",
       "1943531    NaN    NaN    1.0    NaN   -1.0   -1.0       NaN  50000.0      NaN   \n",
       "1943532    NaN    NaN    0.0    NaN    1.0    0.0   44991.0  11645.0  25000.0   \n",
       "1943533    NaN    NaN   -1.0    NaN   -1.0   -1.0       NaN      NaN      NaN   \n",
       "1943534    NaN    NaN   -1.0    NaN   -1.0   -1.0       NaN      NaN      NaN   \n",
       "1943537    NaN    NaN    0.0    NaN    1.0    0.0   65000.0  32500.0      NaN   \n",
       "...        ...    ...    ...    ...    ...    ...       ...      ...      ...   \n",
       "3290365    NaN    NaN   -1.0    NaN   -1.0   -1.0       NaN      NaN      NaN   \n",
       "3290366    NaN    NaN   -1.0    NaN   -1.0   -1.0       NaN      NaN      NaN   \n",
       "3290367    0.0    0.0    0.2    1.0    0.5    0.0  252000.0  70000.0  96000.0   \n",
       "3290368    NaN    NaN    0.0    NaN   -1.0    0.0       NaN      0.0  20000.0   \n",
       "3290369    NaN    NaN   -1.0    NaN   -1.0   -1.0       NaN      NaN      NaN   \n",
       "\n",
       "           x_549    x_550     x_551   x_552  x_553  x_554  x_555  x_556  \\\n",
       "1943531      NaN      NaN       NaN   -1.00    0.0    0.0    0.0    0.0   \n",
       "1943532  2274.50     0.00  21858.00  104.00    0.0    0.0    0.0    0.0   \n",
       "1943533      NaN      NaN       NaN   -1.00    NaN    NaN    NaN    NaN   \n",
       "1943534      NaN      NaN       NaN   -1.00    NaN    NaN    NaN    NaN   \n",
       "1943537     0.00      NaN  21242.00   -1.00    0.0    0.0    0.0    0.0   \n",
       "...          ...      ...       ...     ...    ...    ...    ...    ...   \n",
       "3290365      NaN      NaN       NaN   -1.00    NaN    NaN    NaN    NaN   \n",
       "3290366      NaN      NaN       NaN   -1.00    NaN    NaN    NaN    NaN   \n",
       "3290367  1233.54  1448.66  30606.74    1.74    0.0    0.0    0.0    0.0   \n",
       "3290368      NaN     0.00       NaN   -1.00    0.0    0.0    0.0    0.0   \n",
       "3290369      NaN      NaN       NaN   -1.00    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_557  x_558  x_559  x_560  x_561  x_562  x_563  x_564  x_565  x_566  \\\n",
       "1943531    0.0    0.0   -2.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943532    0.0    0.0   19.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    0.0   -1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0  132.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290368    0.0    0.0   19.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_567  x_568  x_569  x_570  x_571  x_572  x_573  x_574  x_575  x_576  \\\n",
       "1943531    0.0   -1.0   -2.0    1.0    1.0    0.0    0.0    1.0    0.0    0.0   \n",
       "1943532    0.0    0.0    0.0    3.0    1.0    2.0    1.0    0.0    1.0    1.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    0.0    5.0    0.1    3.0    0.0    3.0    0.0    0.0    2.0    1.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    0.0    0.0    0.0    5.0    1.0    4.0    1.0    0.0    1.0    3.0   \n",
       "3290368    0.0    0.0   -2.0    1.0    1.0    0.0    1.0    0.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_577  x_578  x_579  x_580  x_581  x_582  x_583  x_584  x_585  x_586  \\\n",
       "1943531    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   -2.0   \n",
       "1943532    1.0    0.0    0.0    1.0    2.0    0.0    0.0    2.0    0.0    0.0   \n",
       "1943533    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537    1.0    1.0    0.0    1.0    3.0    2.0    0.0    2.0    2.0   -2.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367    2.0    0.0    0.0    3.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "3290368    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0   \n",
       "3290369    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "           x_587  x_588  x_589  x_590  x_591  x_592  x_593  x_594  x_595  \\\n",
       "1943531     -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   \n",
       "1943532  21858.0   25.0   14.0   14.0   11.0   24.0   11.0   24.0   11.0   \n",
       "1943533      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943534      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1943537  21242.0   20.0   10.0   10.0   18.0   12.0   18.0   18.0   18.0   \n",
       "...          ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3290365      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290366      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3290367  32055.4  133.0   87.0   87.0   36.0  120.0  228.0  120.0  128.0   \n",
       "3290368      0.0   19.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   -2.0   \n",
       "3290369      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "         x_596  x_597  x_598  x_599    x_600     x_601     x_602     x_603  \\\n",
       "1943531   -2.0   -2.0   -2.0   -2.0     -2.0      -2.0      -2.0      -2.0   \n",
       "1943532   24.0   11.0   11.0   11.0  11645.0   44991.0   11645.0   44991.0   \n",
       "1943533    NaN    NaN    NaN    NaN      NaN       NaN       NaN       NaN   \n",
       "1943534    NaN    NaN    NaN    NaN      NaN       NaN       NaN       NaN   \n",
       "1943537   15.0   10.0   10.0   10.0  32500.0   30000.0   32500.0   35000.0   \n",
       "...        ...    ...    ...    ...      ...       ...       ...       ...   \n",
       "3290365    NaN    NaN    NaN    NaN      NaN       NaN       NaN       NaN   \n",
       "3290366    NaN    NaN    NaN    NaN      NaN       NaN       NaN       NaN   \n",
       "3290367  120.0   16.0   86.0   46.0  45000.0  252000.0  450000.0  252000.0   \n",
       "3290368   -2.0   -2.0   -2.0   -2.0     -2.0      -2.0      -2.0      -2.0   \n",
       "3290369    NaN    NaN    NaN    NaN      NaN       NaN       NaN       NaN   \n",
       "\n",
       "            x_604     x_605  x_606  x_607  x_608     x_609     x_610  \\\n",
       "1943531      -2.0      -2.0   -1.0   -1.0    0.0       NaN       NaN   \n",
       "1943532   11645.0   44991.0    0.0    0.0    0.0       NaN  0.500000   \n",
       "1943533       NaN       NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "1943534       NaN       NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "1943537   32500.0   32500.0    1.0    0.0    0.0       NaN  0.666667   \n",
       "...           ...       ...    ...    ...    ...       ...       ...   \n",
       "3290365       NaN       NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "3290366       NaN       NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "3290367  188333.0  252000.0    0.0    0.0    0.0  0.333333  0.000000   \n",
       "3290368      -2.0      -2.0    0.0   -1.0    0.0       NaN       NaN   \n",
       "3290369       NaN       NaN    NaN    NaN    NaN       NaN       NaN   \n",
       "\n",
       "            x_611  x_612      x_613 x_614 x_615  x_616 x_617           x_618  \\\n",
       "1943531       NaN      1  1000000.0     1     0     37     4    Приобретение   \n",
       "1943532  0.500000      1  2600000.0     0     0     28     1    Приобретение   \n",
       "1943533       NaN      1  1200000.0     1     0     56     4    Приобретение   \n",
       "1943534       NaN      1   637500.0     0     1     46     4    Приобретение   \n",
       "1943537  0.666667      1  1870000.0     0     0     25     2    Приобретение   \n",
       "...           ...    ...        ...   ...   ...    ...   ...             ...   \n",
       "3290365       NaN      1  1100000.0     1     1     25     1    Приобретение   \n",
       "3290366       NaN      1  1550000.0     1     0     40     1    Приобретение   \n",
       "3290367  0.250000      1   784000.0     1     1     38     4    Приобретение   \n",
       "3290368       NaN      1   960000.0     0     1     24     4    Приобретение   \n",
       "3290369       NaN      1  1200000.0     1     0     28     1  Инвестирование   \n",
       "\n",
       "             x_619  x_620      x_621  x_622  x_623  x_624  \\\n",
       "1943531   831600.0  45.40   731600.0  39.94      0      1   \n",
       "1943532   400000.0  15.38   408026.0  15.81      0      1   \n",
       "1943533  2000000.0  62.50  2000000.0  62.50      0      1   \n",
       "1943534   112500.0  15.00   112500.0  15.00      0      1   \n",
       "1943537   330000.0  15.00   217500.0  15.00      0      1   \n",
       "...            ...    ...        ...    ...    ...    ...   \n",
       "3290365  3000000.0  73.17  2970520.0  74.42      0      1   \n",
       "3290366   450000.0  22.50   453026.0  22.65      0      1   \n",
       "3290367   816000.0  51.00   400000.0  33.33      0      1   \n",
       "3290368   240000.0  20.00   178000.0  20.00      0      1   \n",
       "3290369  1774440.0  59.66  1774440.0  59.66      0      1   \n",
       "\n",
       "                           x_625  x_626     x_627  x_628  x_629      x_630  \\\n",
       "1943531                    other      1  28970.68  Улица      2   87449945   \n",
       "1943532  living in city in apart      1  36616.10  Улица     12  300798430   \n",
       "1943533  living in city in apart      1  21713.75  Улица     50   37572261   \n",
       "1943534                    other      1  37500.00     ЗП     74  196722523   \n",
       "1943537                    other      1  30450.00  Улица     59   63606611   \n",
       "...                          ...    ...       ...    ...    ...        ...   \n",
       "3290365  living in city in apart      1  60900.00  Улица     50  298211036   \n",
       "3290366  living in city in apart      1  34528.52  Улица     23  126116262   \n",
       "3290367  living in city in apart      1  50456.05     ЗП      2  173181407   \n",
       "3290368                    other      1  16582.26     ЗП     21  247877857   \n",
       "3290369  living in city in apart      1  31389.40  Улица     78  294060527   \n",
       "\n",
       "           x_631     x_632  x_633 x_634     x_635  x_636      x_637     x_638  \\\n",
       "1943531      0.0      0.00    0.0     0      0.00    0.0   28970.68      0.00   \n",
       "1943532      0.0      0.00    NaN     1      0.00    0.0   65200.00      0.00   \n",
       "1943533      0.0      0.00    0.0     1      0.00    0.0   48000.00      0.00   \n",
       "1943534      0.0      0.00    0.0     0  37500.00    1.0   25000.00      0.00   \n",
       "1943537  15000.0      0.00    0.0     0      0.00    0.0   50000.00  15000.00   \n",
       "...          ...       ...    ...   ...       ...    ...        ...       ...   \n",
       "3290365      0.0      0.00    NaN     1      0.00    0.0   70000.00      0.00   \n",
       "3290366  20000.0      0.00    0.0     1      0.00    0.0  150000.00  20000.00   \n",
       "3290367      0.0  21694.25    0.0     1  50456.05    1.0   60000.00  21694.25   \n",
       "3290368      0.0   1300.00    0.0     0  16582.26    1.0   45000.00   1300.00   \n",
       "3290369      0.0      0.00    0.0     0      0.00    0.0   36000.00      0.00   \n",
       "\n",
       "         x_639     x_640     x_641      x_642  x_643     x_644     x_645  \\\n",
       "1943531  13.75  0.530767  0.530767  34.517588     58  16914.35  0.583844   \n",
       "1943532   9.00  0.735124  0.735124  71.603967      3  23212.93  0.356027   \n",
       "1943533  14.00  0.858073  0.858073        NaN     73  18631.97  0.388166   \n",
       "1943534  14.45  0.268572  0.268572        NaN     17  10071.45  0.402858   \n",
       "1943537  13.50  0.651646  0.651646  56.539372     56  14366.57  0.287331   \n",
       "...        ...       ...       ...        ...    ...       ...       ...   \n",
       "3290365  10.00  0.194099  0.194099        NaN     31  10971.72  0.156739   \n",
       "3290366  15.00  0.649050  0.649050        NaN     57  24958.10  0.166387   \n",
       "3290367  14.25  0.363178  0.363178  16.173589     53  12541.85  0.209031   \n",
       "3290368  13.00  0.924713  0.924713  57.893194     45  10630.92  0.236243   \n",
       "3290369  10.00  0.505205  0.505205        NaN     33  15858.09  0.440503   \n",
       "\n",
       "            x_646       ID  \n",
       "1943531  0.583844  1943531  \n",
       "1943532  0.633954  1943532  \n",
       "1943533  0.858072  1943533  \n",
       "1943534  0.268572  1943534  \n",
       "1943537  0.471809  1943537  \n",
       "...           ...      ...  \n",
       "3290365  0.180160  3290365  \n",
       "3290366  0.722826  3290366  \n",
       "3290367  0.248570  3290367  \n",
       "3290368  0.641102  3290368  \n",
       "3290369  0.505205  3290369  \n",
       "\n",
       "[763809 rows x 647 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_numeric_preprocess_test(data):\n",
    "    \"\"\"This function handles with non numeric data (only 18 columns)\n",
    "    It is worth mention that mapping part required additional analysis\"\"\"\n",
    "    \n",
    "    # set id as index\n",
    "    data = data.set_index('ID')\n",
    "    \n",
    "    # Exclude numerics but not target\n",
    "    #target = data['TARGET']\n",
    "    data = data.select_dtypes(exclude=np.number)\n",
    "    #data = pd.concat([data, target], axis = 1)\n",
    "    \n",
    "    # count the duration of cradit period\n",
    "    data['period'] = (data['REPORT_DT'] - data['x_9']).dt.days\n",
    "    \n",
    "    # drop lot significant feeatures\n",
    "    data = data.drop(['x_617', 'x_618','x_17', 'x_25', 'x_26', 'x_27', 'REPORT_DT', 'x_9'], axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_test_data = numeric_preprocess(test_data)\n",
    "numeric_test_data = numeric_test_data.drop(['x_0', 'x_1'], axis = 1)\n",
    "\n",
    "\n",
    "test_cat = non_numeric_preprocess_test(test_data)\n",
    "test_cat.drop(['x_19', 'x_614', 'x_615', 'x_634'], axis = 1)\n",
    "mapping_non_numerics(train_2_base, test_cat)\n",
    "test_cat = test_cat.drop(['x_19', 'x_614', 'x_615', 'x_634'], axis = 1)\n",
    "test_cat.rename(columns={'x_12':'client_significance', 'x_18':'day_of_week', 'x_21':'credit_purpose',\n",
    "                            'x_625':'city', 'x_628':'street'}, inplace = True)\n",
    "\n",
    "test = numeric_test_data.merge(test_cat, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapes of train and test detesets corresponds (test does not contain target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(763809, 633)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527548, 634)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "cat_columns = train.columns[train.nunique() < 10]\n",
    "num_columns = train.columns[train.nunique() >= 10]\n",
    "train[cat_columns] = train[cat_columns].fillna(train[cat_columns].mode().iloc[0,:]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['TARGET'], axis = 1)\n",
    "y = train['TARGET']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=25)\n",
    "X_new = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7007812498206312"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf_logreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6915412802112906"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf_logreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA\n",
    "transformer = FastICA(n_components=25)\n",
    "X.drop(['x_13'], axis = 1, inplace = True)\n",
    "\n",
    "X_ica = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "clf_logreg = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf_logreg.predict_proba(X_test)\n",
    "\n",
    "\n",
    "roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightgbm + randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from random import uniform\n",
    "\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(random_state=0)\n",
    "\n",
    "distributions = {'learning_rate':[0.000001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "                 'max_depth' :[2,3,4,5],\n",
    "                 'n_estimators':[100,200, 300, 400, 600],\n",
    "                 'boosting_type':['gbdt', 'dart', 'goss', 'rf'],\n",
    "                 'random_state':[0],\n",
    "                 'importance_type':['split', 'gain'],\n",
    "                 'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "                 'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "                 'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "model_lgb_1 = RandomizedSearchCV(model_lgb, distributions, random_state=0, n_iter = 10, cv = 3, verbose=2, n_jobs = -1)\n",
    "model_lgb_1 = model_lgb_1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_lgb = model_lgb_1.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8623433984999345"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8623433984999345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost + randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6145706\ttotal: 66.9ms\tremaining: 13.3s\n",
      "1:\tlearn: 0.5553858\ttotal: 120ms\tremaining: 11.8s\n",
      "2:\tlearn: 0.5028983\ttotal: 168ms\tremaining: 11s\n",
      "3:\tlearn: 0.4582036\ttotal: 214ms\tremaining: 10.5s\n",
      "4:\tlearn: 0.4197509\ttotal: 265ms\tremaining: 10.4s\n",
      "5:\tlearn: 0.3866075\ttotal: 326ms\tremaining: 10.5s\n",
      "6:\tlearn: 0.3560872\ttotal: 406ms\tremaining: 11.2s\n",
      "7:\tlearn: 0.3275901\ttotal: 467ms\tremaining: 11.2s\n",
      "8:\tlearn: 0.3070679\ttotal: 519ms\tremaining: 11s\n",
      "9:\tlearn: 0.2891797\ttotal: 585ms\tremaining: 11.1s\n",
      "10:\tlearn: 0.2711699\ttotal: 667ms\tremaining: 11.5s\n",
      "11:\tlearn: 0.2577359\ttotal: 719ms\tremaining: 11.3s\n",
      "12:\tlearn: 0.2433918\ttotal: 775ms\tremaining: 11.1s\n",
      "13:\tlearn: 0.2330090\ttotal: 849ms\tremaining: 11.3s\n",
      "14:\tlearn: 0.2223322\ttotal: 932ms\tremaining: 11.5s\n",
      "15:\tlearn: 0.2151095\ttotal: 986ms\tremaining: 11.3s\n",
      "16:\tlearn: 0.2070694\ttotal: 1.05s\tremaining: 11.3s\n",
      "17:\tlearn: 0.2017362\ttotal: 1.12s\tremaining: 11.3s\n",
      "18:\tlearn: 0.1966613\ttotal: 1.18s\tremaining: 11.2s\n",
      "19:\tlearn: 0.1912730\ttotal: 1.24s\tremaining: 11.1s\n",
      "20:\tlearn: 0.1865882\ttotal: 1.31s\tremaining: 11.2s\n",
      "21:\tlearn: 0.1834601\ttotal: 1.38s\tremaining: 11.2s\n",
      "22:\tlearn: 0.1799821\ttotal: 1.44s\tremaining: 11.1s\n",
      "23:\tlearn: 0.1776982\ttotal: 1.48s\tremaining: 10.9s\n",
      "24:\tlearn: 0.1754990\ttotal: 1.53s\tremaining: 10.7s\n",
      "25:\tlearn: 0.1733098\ttotal: 1.6s\tremaining: 10.7s\n",
      "26:\tlearn: 0.1708654\ttotal: 1.67s\tremaining: 10.7s\n",
      "27:\tlearn: 0.1686777\ttotal: 1.73s\tremaining: 10.6s\n",
      "28:\tlearn: 0.1672650\ttotal: 1.79s\tremaining: 10.6s\n",
      "29:\tlearn: 0.1660640\ttotal: 1.85s\tremaining: 10.5s\n",
      "30:\tlearn: 0.1645897\ttotal: 1.92s\tremaining: 10.5s\n",
      "31:\tlearn: 0.1636260\ttotal: 1.97s\tremaining: 10.3s\n",
      "32:\tlearn: 0.1621360\ttotal: 2.04s\tremaining: 10.3s\n",
      "33:\tlearn: 0.1609235\ttotal: 2.11s\tremaining: 10.3s\n",
      "34:\tlearn: 0.1600191\ttotal: 2.17s\tremaining: 10.2s\n",
      "35:\tlearn: 0.1593229\ttotal: 2.23s\tremaining: 10.1s\n",
      "36:\tlearn: 0.1584774\ttotal: 2.3s\tremaining: 10.1s\n",
      "37:\tlearn: 0.1576992\ttotal: 2.38s\tremaining: 10.1s\n",
      "38:\tlearn: 0.1570546\ttotal: 2.46s\tremaining: 10.1s\n",
      "39:\tlearn: 0.1565360\ttotal: 2.53s\tremaining: 10.1s\n",
      "40:\tlearn: 0.1559517\ttotal: 2.62s\tremaining: 10.2s\n",
      "41:\tlearn: 0.1554916\ttotal: 2.68s\tremaining: 10.1s\n",
      "42:\tlearn: 0.1551297\ttotal: 2.73s\tremaining: 9.96s\n",
      "43:\tlearn: 0.1546790\ttotal: 2.8s\tremaining: 9.92s\n",
      "44:\tlearn: 0.1543189\ttotal: 2.88s\tremaining: 9.93s\n",
      "45:\tlearn: 0.1539258\ttotal: 2.96s\tremaining: 9.93s\n",
      "46:\tlearn: 0.1535167\ttotal: 3.07s\tremaining: 10s\n",
      "47:\tlearn: 0.1531856\ttotal: 3.16s\tremaining: 10s\n",
      "48:\tlearn: 0.1527936\ttotal: 3.28s\tremaining: 10.1s\n",
      "49:\tlearn: 0.1525650\ttotal: 3.38s\tremaining: 10.1s\n",
      "50:\tlearn: 0.1523054\ttotal: 3.49s\tremaining: 10.2s\n",
      "51:\tlearn: 0.1520316\ttotal: 3.6s\tremaining: 10.3s\n",
      "52:\tlearn: 0.1517860\ttotal: 3.7s\tremaining: 10.3s\n",
      "53:\tlearn: 0.1515223\ttotal: 3.81s\tremaining: 10.3s\n",
      "54:\tlearn: 0.1513129\ttotal: 3.88s\tremaining: 10.2s\n",
      "55:\tlearn: 0.1510779\ttotal: 3.95s\tremaining: 10.2s\n",
      "56:\tlearn: 0.1508194\ttotal: 4.07s\tremaining: 10.2s\n",
      "57:\tlearn: 0.1506406\ttotal: 4.15s\tremaining: 10.2s\n",
      "58:\tlearn: 0.1504943\ttotal: 4.22s\tremaining: 10.1s\n",
      "59:\tlearn: 0.1503390\ttotal: 4.31s\tremaining: 10.1s\n",
      "60:\tlearn: 0.1501174\ttotal: 4.37s\tremaining: 9.96s\n",
      "61:\tlearn: 0.1499573\ttotal: 4.44s\tremaining: 9.88s\n",
      "62:\tlearn: 0.1498315\ttotal: 4.51s\tremaining: 9.82s\n",
      "63:\tlearn: 0.1496632\ttotal: 4.57s\tremaining: 9.72s\n",
      "64:\tlearn: 0.1494929\ttotal: 4.63s\tremaining: 9.61s\n",
      "65:\tlearn: 0.1493674\ttotal: 4.72s\tremaining: 9.59s\n",
      "66:\tlearn: 0.1491935\ttotal: 4.82s\tremaining: 9.57s\n",
      "67:\tlearn: 0.1490682\ttotal: 4.96s\tremaining: 9.64s\n",
      "68:\tlearn: 0.1489258\ttotal: 5.05s\tremaining: 9.59s\n",
      "69:\tlearn: 0.1487929\ttotal: 5.12s\tremaining: 9.52s\n",
      "70:\tlearn: 0.1487156\ttotal: 5.23s\tremaining: 9.5s\n",
      "71:\tlearn: 0.1486197\ttotal: 5.3s\tremaining: 9.43s\n",
      "72:\tlearn: 0.1484449\ttotal: 5.39s\tremaining: 9.38s\n",
      "73:\tlearn: 0.1483447\ttotal: 5.51s\tremaining: 9.38s\n",
      "74:\tlearn: 0.1482466\ttotal: 5.63s\tremaining: 9.38s\n",
      "75:\tlearn: 0.1481281\ttotal: 5.71s\tremaining: 9.31s\n",
      "76:\tlearn: 0.1480287\ttotal: 5.79s\tremaining: 9.26s\n",
      "77:\tlearn: 0.1479403\ttotal: 5.87s\tremaining: 9.18s\n",
      "78:\tlearn: 0.1478201\ttotal: 5.92s\tremaining: 9.06s\n",
      "79:\tlearn: 0.1476996\ttotal: 5.97s\tremaining: 8.95s\n",
      "80:\tlearn: 0.1476044\ttotal: 6.03s\tremaining: 8.85s\n",
      "81:\tlearn: 0.1475250\ttotal: 6.12s\tremaining: 8.8s\n",
      "82:\tlearn: 0.1474503\ttotal: 6.2s\tremaining: 8.73s\n",
      "83:\tlearn: 0.1473523\ttotal: 6.27s\tremaining: 8.66s\n",
      "84:\tlearn: 0.1472554\ttotal: 6.36s\tremaining: 8.6s\n",
      "85:\tlearn: 0.1471949\ttotal: 6.42s\tremaining: 8.52s\n",
      "86:\tlearn: 0.1470767\ttotal: 6.51s\tremaining: 8.45s\n",
      "87:\tlearn: 0.1469820\ttotal: 6.57s\tremaining: 8.37s\n",
      "88:\tlearn: 0.1469034\ttotal: 6.63s\tremaining: 8.27s\n",
      "89:\tlearn: 0.1468252\ttotal: 6.68s\tremaining: 8.17s\n",
      "90:\tlearn: 0.1467427\ttotal: 6.73s\tremaining: 8.06s\n",
      "91:\tlearn: 0.1466478\ttotal: 6.8s\tremaining: 7.98s\n",
      "92:\tlearn: 0.1465616\ttotal: 6.85s\tremaining: 7.88s\n",
      "93:\tlearn: 0.1464983\ttotal: 6.91s\tremaining: 7.79s\n",
      "94:\tlearn: 0.1464381\ttotal: 6.97s\tremaining: 7.7s\n",
      "95:\tlearn: 0.1463889\ttotal: 7.02s\tremaining: 7.61s\n",
      "96:\tlearn: 0.1463063\ttotal: 7.09s\tremaining: 7.53s\n",
      "97:\tlearn: 0.1462336\ttotal: 7.14s\tremaining: 7.43s\n",
      "98:\tlearn: 0.1461695\ttotal: 7.21s\tremaining: 7.36s\n",
      "99:\tlearn: 0.1461161\ttotal: 7.3s\tremaining: 7.3s\n",
      "100:\tlearn: 0.1460491\ttotal: 7.39s\tremaining: 7.25s\n",
      "101:\tlearn: 0.1459850\ttotal: 7.51s\tremaining: 7.21s\n",
      "102:\tlearn: 0.1459338\ttotal: 7.58s\tremaining: 7.14s\n",
      "103:\tlearn: 0.1458801\ttotal: 7.67s\tremaining: 7.08s\n",
      "104:\tlearn: 0.1457972\ttotal: 7.79s\tremaining: 7.05s\n",
      "105:\tlearn: 0.1457370\ttotal: 7.86s\tremaining: 6.97s\n",
      "106:\tlearn: 0.1456683\ttotal: 7.92s\tremaining: 6.88s\n",
      "107:\tlearn: 0.1456240\ttotal: 7.99s\tremaining: 6.8s\n",
      "108:\tlearn: 0.1455733\ttotal: 8.11s\tremaining: 6.77s\n",
      "109:\tlearn: 0.1455259\ttotal: 8.2s\tremaining: 6.71s\n",
      "110:\tlearn: 0.1454727\ttotal: 8.32s\tremaining: 6.67s\n",
      "111:\tlearn: 0.1454235\ttotal: 8.4s\tremaining: 6.6s\n",
      "112:\tlearn: 0.1453804\ttotal: 8.52s\tremaining: 6.56s\n",
      "113:\tlearn: 0.1453078\ttotal: 8.61s\tremaining: 6.49s\n",
      "114:\tlearn: 0.1452578\ttotal: 8.71s\tremaining: 6.44s\n",
      "115:\tlearn: 0.1452088\ttotal: 8.82s\tremaining: 6.39s\n",
      "116:\tlearn: 0.1451516\ttotal: 8.91s\tremaining: 6.32s\n",
      "117:\tlearn: 0.1451046\ttotal: 8.98s\tremaining: 6.24s\n",
      "118:\tlearn: 0.1450505\ttotal: 9.04s\tremaining: 6.15s\n",
      "119:\tlearn: 0.1449842\ttotal: 9.1s\tremaining: 6.07s\n",
      "120:\tlearn: 0.1449275\ttotal: 9.19s\tremaining: 6s\n",
      "121:\tlearn: 0.1448771\ttotal: 9.28s\tremaining: 5.93s\n",
      "122:\tlearn: 0.1448332\ttotal: 9.38s\tremaining: 5.87s\n",
      "123:\tlearn: 0.1447901\ttotal: 9.45s\tremaining: 5.79s\n",
      "124:\tlearn: 0.1447533\ttotal: 9.52s\tremaining: 5.71s\n",
      "125:\tlearn: 0.1447145\ttotal: 9.61s\tremaining: 5.64s\n",
      "126:\tlearn: 0.1446775\ttotal: 9.68s\tremaining: 5.56s\n",
      "127:\tlearn: 0.1446400\ttotal: 9.78s\tremaining: 5.5s\n",
      "128:\tlearn: 0.1445646\ttotal: 9.89s\tremaining: 5.44s\n",
      "129:\tlearn: 0.1444929\ttotal: 10s\tremaining: 5.39s\n",
      "130:\tlearn: 0.1444573\ttotal: 10.1s\tremaining: 5.31s\n",
      "131:\tlearn: 0.1444196\ttotal: 10.2s\tremaining: 5.24s\n",
      "132:\tlearn: 0.1443744\ttotal: 10.2s\tremaining: 5.16s\n",
      "133:\tlearn: 0.1443442\ttotal: 10.3s\tremaining: 5.08s\n",
      "134:\tlearn: 0.1442979\ttotal: 10.4s\tremaining: 4.99s\n",
      "135:\tlearn: 0.1442571\ttotal: 10.4s\tremaining: 4.91s\n",
      "136:\tlearn: 0.1442120\ttotal: 10.5s\tremaining: 4.83s\n",
      "137:\tlearn: 0.1441644\ttotal: 10.6s\tremaining: 4.75s\n",
      "138:\tlearn: 0.1441315\ttotal: 10.6s\tremaining: 4.67s\n",
      "139:\tlearn: 0.1441009\ttotal: 10.7s\tremaining: 4.6s\n",
      "140:\tlearn: 0.1440558\ttotal: 10.8s\tremaining: 4.53s\n",
      "141:\tlearn: 0.1440083\ttotal: 10.9s\tremaining: 4.45s\n",
      "142:\tlearn: 0.1439621\ttotal: 11s\tremaining: 4.37s\n",
      "143:\tlearn: 0.1439270\ttotal: 11s\tremaining: 4.29s\n",
      "144:\tlearn: 0.1438834\ttotal: 11.1s\tremaining: 4.21s\n",
      "145:\tlearn: 0.1438348\ttotal: 11.2s\tremaining: 4.13s\n",
      "146:\tlearn: 0.1437893\ttotal: 11.2s\tremaining: 4.05s\n",
      "147:\tlearn: 0.1437562\ttotal: 11.3s\tremaining: 3.97s\n",
      "148:\tlearn: 0.1437017\ttotal: 11.4s\tremaining: 3.89s\n",
      "149:\tlearn: 0.1436711\ttotal: 11.4s\tremaining: 3.8s\n",
      "150:\tlearn: 0.1436421\ttotal: 11.5s\tremaining: 3.72s\n",
      "151:\tlearn: 0.1436154\ttotal: 11.5s\tremaining: 3.64s\n",
      "152:\tlearn: 0.1435790\ttotal: 11.6s\tremaining: 3.56s\n",
      "153:\tlearn: 0.1435375\ttotal: 11.7s\tremaining: 3.49s\n",
      "154:\tlearn: 0.1435000\ttotal: 11.8s\tremaining: 3.42s\n",
      "155:\tlearn: 0.1434628\ttotal: 11.8s\tremaining: 3.34s\n",
      "156:\tlearn: 0.1434312\ttotal: 11.9s\tremaining: 3.26s\n",
      "157:\tlearn: 0.1433849\ttotal: 12s\tremaining: 3.19s\n",
      "158:\tlearn: 0.1433453\ttotal: 12s\tremaining: 3.1s\n",
      "159:\tlearn: 0.1433085\ttotal: 12.1s\tremaining: 3.02s\n",
      "160:\tlearn: 0.1432522\ttotal: 12.1s\tremaining: 2.94s\n",
      "161:\tlearn: 0.1432195\ttotal: 12.2s\tremaining: 2.87s\n",
      "162:\tlearn: 0.1431952\ttotal: 12.3s\tremaining: 2.79s\n",
      "163:\tlearn: 0.1431456\ttotal: 12.3s\tremaining: 2.71s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.1431186\ttotal: 12.4s\tremaining: 2.63s\n",
      "165:\tlearn: 0.1430636\ttotal: 12.5s\tremaining: 2.56s\n",
      "166:\tlearn: 0.1430347\ttotal: 12.6s\tremaining: 2.48s\n",
      "167:\tlearn: 0.1430069\ttotal: 12.6s\tremaining: 2.4s\n",
      "168:\tlearn: 0.1429777\ttotal: 12.7s\tremaining: 2.33s\n",
      "169:\tlearn: 0.1429469\ttotal: 12.7s\tremaining: 2.25s\n",
      "170:\tlearn: 0.1428958\ttotal: 12.8s\tremaining: 2.17s\n",
      "171:\tlearn: 0.1428705\ttotal: 12.8s\tremaining: 2.09s\n",
      "172:\tlearn: 0.1428390\ttotal: 12.9s\tremaining: 2.01s\n",
      "173:\tlearn: 0.1428100\ttotal: 13s\tremaining: 1.94s\n",
      "174:\tlearn: 0.1427760\ttotal: 13s\tremaining: 1.86s\n",
      "175:\tlearn: 0.1427356\ttotal: 13.1s\tremaining: 1.78s\n",
      "176:\tlearn: 0.1427035\ttotal: 13.1s\tremaining: 1.7s\n",
      "177:\tlearn: 0.1426722\ttotal: 13.2s\tremaining: 1.63s\n",
      "178:\tlearn: 0.1426284\ttotal: 13.2s\tremaining: 1.55s\n",
      "179:\tlearn: 0.1426019\ttotal: 13.3s\tremaining: 1.48s\n",
      "180:\tlearn: 0.1425656\ttotal: 13.3s\tremaining: 1.4s\n",
      "181:\tlearn: 0.1425292\ttotal: 13.4s\tremaining: 1.32s\n",
      "182:\tlearn: 0.1424967\ttotal: 13.4s\tremaining: 1.25s\n",
      "183:\tlearn: 0.1424690\ttotal: 13.5s\tremaining: 1.17s\n",
      "184:\tlearn: 0.1424410\ttotal: 13.5s\tremaining: 1.1s\n",
      "185:\tlearn: 0.1424097\ttotal: 13.6s\tremaining: 1.02s\n",
      "186:\tlearn: 0.1423835\ttotal: 13.6s\tremaining: 948ms\n",
      "187:\tlearn: 0.1423405\ttotal: 13.7s\tremaining: 874ms\n",
      "188:\tlearn: 0.1423116\ttotal: 13.7s\tremaining: 800ms\n",
      "189:\tlearn: 0.1422793\ttotal: 13.8s\tremaining: 726ms\n",
      "190:\tlearn: 0.1422526\ttotal: 13.8s\tremaining: 652ms\n",
      "191:\tlearn: 0.1422309\ttotal: 13.9s\tremaining: 579ms\n",
      "192:\tlearn: 0.1421874\ttotal: 13.9s\tremaining: 506ms\n",
      "193:\tlearn: 0.1421558\ttotal: 14s\tremaining: 433ms\n",
      "194:\tlearn: 0.1421331\ttotal: 14.1s\tremaining: 360ms\n",
      "195:\tlearn: 0.1421024\ttotal: 14.1s\tremaining: 288ms\n",
      "196:\tlearn: 0.1420776\ttotal: 14.2s\tremaining: 216ms\n",
      "197:\tlearn: 0.1420565\ttotal: 14.2s\tremaining: 144ms\n",
      "198:\tlearn: 0.1420201\ttotal: 14.3s\tremaining: 71.7ms\n",
      "199:\tlearn: 0.1419964\ttotal: 14.3s\tremaining: 0us\n",
      "[CV]  learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5, total=  14.9s\n",
      "[CV] learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6145906\ttotal: 64.5ms\tremaining: 12.8s\n",
      "1:\tlearn: 0.5553650\ttotal: 115ms\tremaining: 11.4s\n",
      "2:\tlearn: 0.5035677\ttotal: 164ms\tremaining: 10.8s\n",
      "3:\tlearn: 0.4588398\ttotal: 221ms\tremaining: 10.8s\n",
      "4:\tlearn: 0.4188513\ttotal: 273ms\tremaining: 10.6s\n",
      "5:\tlearn: 0.3851877\ttotal: 340ms\tremaining: 11s\n",
      "6:\tlearn: 0.3557263\ttotal: 422ms\tremaining: 11.6s\n",
      "7:\tlearn: 0.3313005\ttotal: 492ms\tremaining: 11.8s\n",
      "8:\tlearn: 0.3096980\ttotal: 575ms\tremaining: 12.2s\n",
      "9:\tlearn: 0.2897513\ttotal: 635ms\tremaining: 12.1s\n",
      "10:\tlearn: 0.2741472\ttotal: 691ms\tremaining: 11.9s\n",
      "11:\tlearn: 0.2576382\ttotal: 763ms\tremaining: 11.9s\n",
      "12:\tlearn: 0.2453828\ttotal: 818ms\tremaining: 11.8s\n",
      "13:\tlearn: 0.2350366\ttotal: 871ms\tremaining: 11.6s\n",
      "14:\tlearn: 0.2243441\ttotal: 925ms\tremaining: 11.4s\n",
      "15:\tlearn: 0.2169332\ttotal: 977ms\tremaining: 11.2s\n",
      "16:\tlearn: 0.2100353\ttotal: 1.03s\tremaining: 11.1s\n",
      "17:\tlearn: 0.2044225\ttotal: 1.09s\tremaining: 11.1s\n",
      "18:\tlearn: 0.1991453\ttotal: 1.15s\tremaining: 10.9s\n",
      "19:\tlearn: 0.1948445\ttotal: 1.2s\tremaining: 10.8s\n",
      "20:\tlearn: 0.1894695\ttotal: 1.27s\tremaining: 10.8s\n",
      "21:\tlearn: 0.1848794\ttotal: 1.34s\tremaining: 10.8s\n",
      "22:\tlearn: 0.1808887\ttotal: 1.4s\tremaining: 10.8s\n",
      "23:\tlearn: 0.1778762\ttotal: 1.47s\tremaining: 10.8s\n",
      "24:\tlearn: 0.1749602\ttotal: 1.54s\tremaining: 10.8s\n",
      "25:\tlearn: 0.1723191\ttotal: 1.59s\tremaining: 10.6s\n",
      "26:\tlearn: 0.1707043\ttotal: 1.64s\tremaining: 10.5s\n",
      "27:\tlearn: 0.1686157\ttotal: 1.7s\tremaining: 10.4s\n",
      "28:\tlearn: 0.1668751\ttotal: 1.77s\tremaining: 10.4s\n",
      "29:\tlearn: 0.1652130\ttotal: 1.82s\tremaining: 10.3s\n",
      "30:\tlearn: 0.1635653\ttotal: 1.88s\tremaining: 10.2s\n",
      "31:\tlearn: 0.1625664\ttotal: 1.95s\tremaining: 10.2s\n",
      "32:\tlearn: 0.1613003\ttotal: 2.02s\tremaining: 10.2s\n",
      "33:\tlearn: 0.1606071\ttotal: 2.08s\tremaining: 10.2s\n",
      "34:\tlearn: 0.1596280\ttotal: 2.15s\tremaining: 10.1s\n",
      "35:\tlearn: 0.1587222\ttotal: 2.22s\tremaining: 10.1s\n",
      "36:\tlearn: 0.1579217\ttotal: 2.29s\tremaining: 10.1s\n",
      "37:\tlearn: 0.1571946\ttotal: 2.34s\tremaining: 9.99s\n",
      "38:\tlearn: 0.1565233\ttotal: 2.4s\tremaining: 9.93s\n",
      "39:\tlearn: 0.1559868\ttotal: 2.47s\tremaining: 9.87s\n",
      "40:\tlearn: 0.1554956\ttotal: 2.52s\tremaining: 9.78s\n",
      "41:\tlearn: 0.1551844\ttotal: 2.56s\tremaining: 9.65s\n",
      "42:\tlearn: 0.1546658\ttotal: 2.62s\tremaining: 9.58s\n",
      "43:\tlearn: 0.1542653\ttotal: 2.7s\tremaining: 9.57s\n",
      "44:\tlearn: 0.1538559\ttotal: 2.78s\tremaining: 9.57s\n",
      "45:\tlearn: 0.1535419\ttotal: 2.87s\tremaining: 9.62s\n",
      "46:\tlearn: 0.1531778\ttotal: 2.96s\tremaining: 9.63s\n",
      "47:\tlearn: 0.1528379\ttotal: 3.02s\tremaining: 9.57s\n",
      "48:\tlearn: 0.1525260\ttotal: 3.08s\tremaining: 9.49s\n",
      "49:\tlearn: 0.1523116\ttotal: 3.13s\tremaining: 9.41s\n",
      "50:\tlearn: 0.1520770\ttotal: 3.22s\tremaining: 9.4s\n",
      "51:\tlearn: 0.1518887\ttotal: 3.27s\tremaining: 9.31s\n",
      "52:\tlearn: 0.1515688\ttotal: 3.34s\tremaining: 9.27s\n",
      "53:\tlearn: 0.1513036\ttotal: 3.43s\tremaining: 9.27s\n",
      "54:\tlearn: 0.1511479\ttotal: 3.5s\tremaining: 9.22s\n",
      "55:\tlearn: 0.1509161\ttotal: 3.58s\tremaining: 9.22s\n",
      "56:\tlearn: 0.1507708\ttotal: 3.65s\tremaining: 9.17s\n",
      "57:\tlearn: 0.1505628\ttotal: 3.73s\tremaining: 9.14s\n",
      "58:\tlearn: 0.1503573\ttotal: 3.79s\tremaining: 9.05s\n",
      "59:\tlearn: 0.1501532\ttotal: 3.85s\tremaining: 8.98s\n",
      "60:\tlearn: 0.1500334\ttotal: 3.9s\tremaining: 8.9s\n",
      "61:\tlearn: 0.1499054\ttotal: 3.96s\tremaining: 8.8s\n",
      "62:\tlearn: 0.1497060\ttotal: 4.01s\tremaining: 8.73s\n",
      "63:\tlearn: 0.1495579\ttotal: 4.08s\tremaining: 8.66s\n",
      "64:\tlearn: 0.1494125\ttotal: 4.14s\tremaining: 8.6s\n",
      "65:\tlearn: 0.1492391\ttotal: 4.2s\tremaining: 8.53s\n",
      "66:\tlearn: 0.1491045\ttotal: 4.25s\tremaining: 8.45s\n",
      "67:\tlearn: 0.1489991\ttotal: 4.32s\tremaining: 8.39s\n",
      "68:\tlearn: 0.1488743\ttotal: 4.39s\tremaining: 8.34s\n",
      "69:\tlearn: 0.1487357\ttotal: 4.47s\tremaining: 8.3s\n",
      "70:\tlearn: 0.1485886\ttotal: 4.56s\tremaining: 8.29s\n",
      "71:\tlearn: 0.1485131\ttotal: 4.63s\tremaining: 8.23s\n",
      "72:\tlearn: 0.1484177\ttotal: 4.72s\tremaining: 8.21s\n",
      "73:\tlearn: 0.1483347\ttotal: 4.79s\tremaining: 8.16s\n",
      "74:\tlearn: 0.1482049\ttotal: 4.87s\tremaining: 8.12s\n",
      "75:\tlearn: 0.1481094\ttotal: 4.93s\tremaining: 8.04s\n",
      "76:\tlearn: 0.1480298\ttotal: 5.01s\tremaining: 8.01s\n",
      "77:\tlearn: 0.1479561\ttotal: 5.08s\tremaining: 7.95s\n",
      "78:\tlearn: 0.1478817\ttotal: 5.16s\tremaining: 7.89s\n",
      "79:\tlearn: 0.1478096\ttotal: 5.22s\tremaining: 7.83s\n",
      "80:\tlearn: 0.1476822\ttotal: 5.3s\tremaining: 7.79s\n",
      "81:\tlearn: 0.1475506\ttotal: 5.37s\tremaining: 7.73s\n",
      "82:\tlearn: 0.1474640\ttotal: 5.45s\tremaining: 7.68s\n",
      "83:\tlearn: 0.1473653\ttotal: 5.51s\tremaining: 7.61s\n",
      "84:\tlearn: 0.1473009\ttotal: 5.56s\tremaining: 7.52s\n",
      "85:\tlearn: 0.1472441\ttotal: 5.61s\tremaining: 7.44s\n",
      "86:\tlearn: 0.1471771\ttotal: 5.66s\tremaining: 7.36s\n",
      "87:\tlearn: 0.1470892\ttotal: 5.73s\tremaining: 7.29s\n",
      "88:\tlearn: 0.1470335\ttotal: 5.78s\tremaining: 7.2s\n",
      "89:\tlearn: 0.1469540\ttotal: 5.82s\tremaining: 7.12s\n",
      "90:\tlearn: 0.1468756\ttotal: 5.88s\tremaining: 7.04s\n",
      "91:\tlearn: 0.1467621\ttotal: 5.94s\tremaining: 6.97s\n",
      "92:\tlearn: 0.1466966\ttotal: 6s\tremaining: 6.91s\n",
      "93:\tlearn: 0.1466336\ttotal: 6.07s\tremaining: 6.85s\n",
      "94:\tlearn: 0.1465672\ttotal: 6.14s\tremaining: 6.78s\n",
      "95:\tlearn: 0.1465007\ttotal: 6.22s\tremaining: 6.74s\n",
      "96:\tlearn: 0.1463911\ttotal: 6.27s\tremaining: 6.66s\n",
      "97:\tlearn: 0.1462932\ttotal: 6.32s\tremaining: 6.58s\n",
      "98:\tlearn: 0.1462251\ttotal: 6.37s\tremaining: 6.5s\n",
      "99:\tlearn: 0.1461571\ttotal: 6.42s\tremaining: 6.42s\n",
      "100:\tlearn: 0.1460922\ttotal: 6.48s\tremaining: 6.35s\n",
      "101:\tlearn: 0.1460428\ttotal: 6.52s\tremaining: 6.27s\n",
      "102:\tlearn: 0.1459938\ttotal: 6.57s\tremaining: 6.18s\n",
      "103:\tlearn: 0.1459163\ttotal: 6.62s\tremaining: 6.11s\n",
      "104:\tlearn: 0.1458512\ttotal: 6.67s\tremaining: 6.04s\n",
      "105:\tlearn: 0.1457894\ttotal: 6.72s\tremaining: 5.96s\n",
      "106:\tlearn: 0.1457182\ttotal: 6.77s\tremaining: 5.88s\n",
      "107:\tlearn: 0.1456526\ttotal: 6.83s\tremaining: 5.82s\n",
      "108:\tlearn: 0.1455850\ttotal: 6.9s\tremaining: 5.76s\n",
      "109:\tlearn: 0.1455377\ttotal: 6.96s\tremaining: 5.69s\n",
      "110:\tlearn: 0.1454917\ttotal: 7.01s\tremaining: 5.62s\n",
      "111:\tlearn: 0.1454484\ttotal: 7.07s\tremaining: 5.55s\n",
      "112:\tlearn: 0.1453890\ttotal: 7.12s\tremaining: 5.48s\n",
      "113:\tlearn: 0.1453379\ttotal: 7.17s\tremaining: 5.41s\n",
      "114:\tlearn: 0.1452919\ttotal: 7.21s\tremaining: 5.33s\n",
      "115:\tlearn: 0.1452497\ttotal: 7.26s\tremaining: 5.26s\n",
      "116:\tlearn: 0.1452092\ttotal: 7.32s\tremaining: 5.19s\n",
      "117:\tlearn: 0.1451659\ttotal: 7.37s\tremaining: 5.12s\n",
      "118:\tlearn: 0.1451146\ttotal: 7.41s\tremaining: 5.05s\n",
      "119:\tlearn: 0.1450554\ttotal: 7.46s\tremaining: 4.97s\n",
      "120:\tlearn: 0.1449858\ttotal: 7.51s\tremaining: 4.9s\n",
      "121:\tlearn: 0.1448989\ttotal: 7.56s\tremaining: 4.83s\n",
      "122:\tlearn: 0.1448406\ttotal: 7.62s\tremaining: 4.77s\n",
      "123:\tlearn: 0.1448059\ttotal: 7.67s\tremaining: 4.7s\n",
      "124:\tlearn: 0.1447572\ttotal: 7.71s\tremaining: 4.63s\n",
      "125:\tlearn: 0.1447086\ttotal: 7.76s\tremaining: 4.56s\n",
      "126:\tlearn: 0.1446611\ttotal: 7.82s\tremaining: 4.5s\n",
      "127:\tlearn: 0.1446050\ttotal: 7.88s\tremaining: 4.43s\n",
      "128:\tlearn: 0.1445566\ttotal: 7.92s\tremaining: 4.36s\n",
      "129:\tlearn: 0.1445190\ttotal: 7.97s\tremaining: 4.29s\n",
      "130:\tlearn: 0.1444687\ttotal: 8.02s\tremaining: 4.22s\n",
      "131:\tlearn: 0.1444148\ttotal: 8.08s\tremaining: 4.16s\n",
      "132:\tlearn: 0.1443697\ttotal: 8.14s\tremaining: 4.1s\n",
      "133:\tlearn: 0.1443268\ttotal: 8.2s\tremaining: 4.04s\n",
      "134:\tlearn: 0.1442940\ttotal: 8.27s\tremaining: 3.98s\n",
      "135:\tlearn: 0.1442445\ttotal: 8.36s\tremaining: 3.93s\n",
      "136:\tlearn: 0.1442077\ttotal: 8.46s\tremaining: 3.89s\n",
      "137:\tlearn: 0.1441697\ttotal: 8.51s\tremaining: 3.82s\n",
      "138:\tlearn: 0.1441170\ttotal: 8.6s\tremaining: 3.77s\n",
      "139:\tlearn: 0.1440771\ttotal: 8.66s\tremaining: 3.71s\n",
      "140:\tlearn: 0.1440278\ttotal: 8.71s\tremaining: 3.64s\n",
      "141:\tlearn: 0.1439729\ttotal: 8.76s\tremaining: 3.58s\n",
      "142:\tlearn: 0.1439401\ttotal: 8.8s\tremaining: 3.51s\n",
      "143:\tlearn: 0.1438927\ttotal: 8.87s\tremaining: 3.45s\n",
      "144:\tlearn: 0.1438574\ttotal: 8.92s\tremaining: 3.38s\n",
      "145:\tlearn: 0.1438205\ttotal: 8.98s\tremaining: 3.32s\n",
      "146:\tlearn: 0.1437840\ttotal: 9.03s\tremaining: 3.25s\n",
      "147:\tlearn: 0.1437484\ttotal: 9.1s\tremaining: 3.2s\n",
      "148:\tlearn: 0.1437130\ttotal: 9.16s\tremaining: 3.13s\n",
      "149:\tlearn: 0.1436708\ttotal: 9.22s\tremaining: 3.07s\n",
      "150:\tlearn: 0.1436406\ttotal: 9.29s\tremaining: 3.01s\n",
      "151:\tlearn: 0.1435839\ttotal: 9.36s\tremaining: 2.96s\n",
      "152:\tlearn: 0.1435497\ttotal: 9.41s\tremaining: 2.89s\n",
      "153:\tlearn: 0.1435136\ttotal: 9.46s\tremaining: 2.83s\n",
      "154:\tlearn: 0.1434443\ttotal: 9.52s\tremaining: 2.76s\n",
      "155:\tlearn: 0.1434095\ttotal: 9.58s\tremaining: 2.7s\n",
      "156:\tlearn: 0.1433788\ttotal: 9.64s\tremaining: 2.64s\n",
      "157:\tlearn: 0.1433354\ttotal: 9.69s\tremaining: 2.58s\n",
      "158:\tlearn: 0.1432876\ttotal: 9.75s\tremaining: 2.51s\n",
      "159:\tlearn: 0.1432545\ttotal: 9.82s\tremaining: 2.45s\n",
      "160:\tlearn: 0.1431993\ttotal: 9.88s\tremaining: 2.39s\n",
      "161:\tlearn: 0.1431722\ttotal: 9.91s\tremaining: 2.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162:\tlearn: 0.1431455\ttotal: 9.97s\tremaining: 2.26s\n",
      "163:\tlearn: 0.1431140\ttotal: 10s\tremaining: 2.2s\n",
      "164:\tlearn: 0.1430722\ttotal: 10.1s\tremaining: 2.14s\n",
      "165:\tlearn: 0.1430368\ttotal: 10.1s\tremaining: 2.08s\n",
      "166:\tlearn: 0.1430071\ttotal: 10.2s\tremaining: 2.01s\n",
      "167:\tlearn: 0.1429627\ttotal: 10.2s\tremaining: 1.95s\n",
      "168:\tlearn: 0.1429206\ttotal: 10.3s\tremaining: 1.89s\n",
      "169:\tlearn: 0.1428903\ttotal: 10.3s\tremaining: 1.82s\n",
      "170:\tlearn: 0.1428676\ttotal: 10.4s\tremaining: 1.76s\n",
      "171:\tlearn: 0.1428339\ttotal: 10.5s\tremaining: 1.7s\n",
      "172:\tlearn: 0.1428035\ttotal: 10.5s\tremaining: 1.64s\n",
      "173:\tlearn: 0.1427625\ttotal: 10.6s\tremaining: 1.58s\n",
      "174:\tlearn: 0.1427362\ttotal: 10.6s\tremaining: 1.52s\n",
      "175:\tlearn: 0.1426982\ttotal: 10.7s\tremaining: 1.46s\n",
      "176:\tlearn: 0.1426680\ttotal: 10.7s\tremaining: 1.4s\n",
      "177:\tlearn: 0.1426297\ttotal: 10.8s\tremaining: 1.33s\n",
      "178:\tlearn: 0.1425953\ttotal: 10.8s\tremaining: 1.27s\n",
      "179:\tlearn: 0.1425725\ttotal: 10.9s\tremaining: 1.21s\n",
      "180:\tlearn: 0.1425425\ttotal: 11s\tremaining: 1.15s\n",
      "181:\tlearn: 0.1425165\ttotal: 11s\tremaining: 1.09s\n",
      "182:\tlearn: 0.1424880\ttotal: 11.1s\tremaining: 1.03s\n",
      "183:\tlearn: 0.1424646\ttotal: 11.2s\tremaining: 973ms\n",
      "184:\tlearn: 0.1424103\ttotal: 11.3s\tremaining: 913ms\n",
      "185:\tlearn: 0.1423873\ttotal: 11.3s\tremaining: 853ms\n",
      "186:\tlearn: 0.1423621\ttotal: 11.4s\tremaining: 793ms\n",
      "187:\tlearn: 0.1423181\ttotal: 11.5s\tremaining: 733ms\n",
      "188:\tlearn: 0.1422627\ttotal: 11.5s\tremaining: 672ms\n",
      "189:\tlearn: 0.1422259\ttotal: 11.6s\tremaining: 612ms\n",
      "190:\tlearn: 0.1422032\ttotal: 11.7s\tremaining: 552ms\n",
      "191:\tlearn: 0.1421747\ttotal: 11.8s\tremaining: 490ms\n",
      "192:\tlearn: 0.1421411\ttotal: 11.8s\tremaining: 429ms\n",
      "193:\tlearn: 0.1421021\ttotal: 11.9s\tremaining: 369ms\n",
      "194:\tlearn: 0.1420799\ttotal: 12s\tremaining: 307ms\n",
      "195:\tlearn: 0.1420569\ttotal: 12.1s\tremaining: 246ms\n",
      "196:\tlearn: 0.1420166\ttotal: 12.1s\tremaining: 185ms\n",
      "197:\tlearn: 0.1419899\ttotal: 12.2s\tremaining: 123ms\n",
      "198:\tlearn: 0.1419635\ttotal: 12.3s\tremaining: 61.7ms\n",
      "199:\tlearn: 0.1419364\ttotal: 12.3s\tremaining: 0us\n",
      "[CV]  learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5, total=  12.8s\n",
      "[CV] learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5 ......\n",
      "0:\tlearn: 0.6145224\ttotal: 86.8ms\tremaining: 17.3s\n",
      "1:\tlearn: 0.5553312\ttotal: 138ms\tremaining: 13.6s\n",
      "2:\tlearn: 0.5027650\ttotal: 185ms\tremaining: 12.1s\n",
      "3:\tlearn: 0.4581391\ttotal: 234ms\tremaining: 11.5s\n",
      "4:\tlearn: 0.4196954\ttotal: 281ms\tremaining: 10.9s\n",
      "5:\tlearn: 0.3867245\ttotal: 343ms\tremaining: 11.1s\n",
      "6:\tlearn: 0.3534321\ttotal: 413ms\tremaining: 11.4s\n",
      "7:\tlearn: 0.3295030\ttotal: 459ms\tremaining: 11s\n",
      "8:\tlearn: 0.3088684\ttotal: 510ms\tremaining: 10.8s\n",
      "9:\tlearn: 0.2909882\ttotal: 560ms\tremaining: 10.6s\n",
      "10:\tlearn: 0.2749343\ttotal: 612ms\tremaining: 10.5s\n",
      "11:\tlearn: 0.2582799\ttotal: 692ms\tremaining: 10.8s\n",
      "12:\tlearn: 0.2457040\ttotal: 751ms\tremaining: 10.8s\n",
      "13:\tlearn: 0.2333449\ttotal: 820ms\tremaining: 10.9s\n",
      "14:\tlearn: 0.2248735\ttotal: 877ms\tremaining: 10.8s\n",
      "15:\tlearn: 0.2174529\ttotal: 930ms\tremaining: 10.7s\n",
      "16:\tlearn: 0.2104572\ttotal: 989ms\tremaining: 10.6s\n",
      "17:\tlearn: 0.2035547\ttotal: 1.06s\tremaining: 10.7s\n",
      "18:\tlearn: 0.1985985\ttotal: 1.12s\tremaining: 10.6s\n",
      "19:\tlearn: 0.1932788\ttotal: 1.17s\tremaining: 10.6s\n",
      "20:\tlearn: 0.1882001\ttotal: 1.23s\tremaining: 10.5s\n",
      "21:\tlearn: 0.1838791\ttotal: 1.3s\tremaining: 10.5s\n",
      "22:\tlearn: 0.1803925\ttotal: 1.39s\tremaining: 10.7s\n",
      "23:\tlearn: 0.1774438\ttotal: 1.46s\tremaining: 10.7s\n",
      "24:\tlearn: 0.1746407\ttotal: 1.55s\tremaining: 10.8s\n",
      "25:\tlearn: 0.1725386\ttotal: 1.62s\tremaining: 10.8s\n",
      "26:\tlearn: 0.1701730\ttotal: 1.71s\tremaining: 10.9s\n",
      "27:\tlearn: 0.1682562\ttotal: 1.78s\tremaining: 10.9s\n",
      "28:\tlearn: 0.1668790\ttotal: 1.85s\tremaining: 10.9s\n",
      "29:\tlearn: 0.1651417\ttotal: 1.91s\tremaining: 10.8s\n",
      "30:\tlearn: 0.1637242\ttotal: 1.97s\tremaining: 10.7s\n",
      "31:\tlearn: 0.1627617\ttotal: 2.03s\tremaining: 10.7s\n",
      "32:\tlearn: 0.1616349\ttotal: 2.11s\tremaining: 10.7s\n",
      "33:\tlearn: 0.1606664\ttotal: 2.18s\tremaining: 10.6s\n",
      "34:\tlearn: 0.1597025\ttotal: 2.26s\tremaining: 10.6s\n",
      "35:\tlearn: 0.1588419\ttotal: 2.35s\tremaining: 10.7s\n",
      "36:\tlearn: 0.1581273\ttotal: 2.42s\tremaining: 10.7s\n",
      "37:\tlearn: 0.1573958\ttotal: 2.49s\tremaining: 10.6s\n",
      "38:\tlearn: 0.1566519\ttotal: 2.56s\tremaining: 10.6s\n",
      "39:\tlearn: 0.1559993\ttotal: 2.63s\tremaining: 10.5s\n",
      "40:\tlearn: 0.1554886\ttotal: 2.7s\tremaining: 10.5s\n",
      "41:\tlearn: 0.1549534\ttotal: 2.76s\tremaining: 10.4s\n",
      "42:\tlearn: 0.1544793\ttotal: 2.82s\tremaining: 10.3s\n",
      "43:\tlearn: 0.1540802\ttotal: 2.88s\tremaining: 10.2s\n",
      "44:\tlearn: 0.1537215\ttotal: 2.93s\tremaining: 10.1s\n",
      "45:\tlearn: 0.1533070\ttotal: 3.01s\tremaining: 10.1s\n",
      "46:\tlearn: 0.1529968\ttotal: 3.06s\tremaining: 9.95s\n",
      "47:\tlearn: 0.1526655\ttotal: 3.11s\tremaining: 9.86s\n",
      "48:\tlearn: 0.1524008\ttotal: 3.16s\tremaining: 9.75s\n",
      "49:\tlearn: 0.1521616\ttotal: 3.23s\tremaining: 9.71s\n",
      "50:\tlearn: 0.1519113\ttotal: 3.32s\tremaining: 9.69s\n",
      "51:\tlearn: 0.1516620\ttotal: 3.37s\tremaining: 9.58s\n",
      "52:\tlearn: 0.1513945\ttotal: 3.43s\tremaining: 9.51s\n",
      "53:\tlearn: 0.1511403\ttotal: 3.5s\tremaining: 9.46s\n",
      "54:\tlearn: 0.1508984\ttotal: 3.59s\tremaining: 9.45s\n",
      "55:\tlearn: 0.1507067\ttotal: 3.67s\tremaining: 9.42s\n",
      "56:\tlearn: 0.1505246\ttotal: 3.73s\tremaining: 9.35s\n",
      "57:\tlearn: 0.1503061\ttotal: 3.78s\tremaining: 9.26s\n",
      "58:\tlearn: 0.1501593\ttotal: 3.84s\tremaining: 9.17s\n",
      "59:\tlearn: 0.1500065\ttotal: 3.89s\tremaining: 9.07s\n",
      "60:\tlearn: 0.1498763\ttotal: 3.94s\tremaining: 8.97s\n",
      "61:\tlearn: 0.1497175\ttotal: 3.99s\tremaining: 8.89s\n",
      "62:\tlearn: 0.1495152\ttotal: 4.06s\tremaining: 8.82s\n",
      "63:\tlearn: 0.1493343\ttotal: 4.14s\tremaining: 8.79s\n",
      "64:\tlearn: 0.1492114\ttotal: 4.21s\tremaining: 8.75s\n",
      "65:\tlearn: 0.1490902\ttotal: 4.29s\tremaining: 8.71s\n",
      "66:\tlearn: 0.1489759\ttotal: 4.38s\tremaining: 8.69s\n",
      "67:\tlearn: 0.1488688\ttotal: 4.44s\tremaining: 8.62s\n",
      "68:\tlearn: 0.1486920\ttotal: 4.53s\tremaining: 8.59s\n",
      "69:\tlearn: 0.1485652\ttotal: 4.62s\tremaining: 8.58s\n",
      "70:\tlearn: 0.1484477\ttotal: 4.69s\tremaining: 8.53s\n",
      "71:\tlearn: 0.1483200\ttotal: 4.76s\tremaining: 8.47s\n",
      "72:\tlearn: 0.1482275\ttotal: 4.83s\tremaining: 8.4s\n",
      "73:\tlearn: 0.1480900\ttotal: 4.92s\tremaining: 8.38s\n",
      "74:\tlearn: 0.1480083\ttotal: 5s\tremaining: 8.33s\n",
      "75:\tlearn: 0.1479069\ttotal: 5.07s\tremaining: 8.27s\n",
      "76:\tlearn: 0.1478332\ttotal: 5.12s\tremaining: 8.18s\n",
      "77:\tlearn: 0.1477655\ttotal: 5.17s\tremaining: 8.09s\n",
      "78:\tlearn: 0.1476844\ttotal: 5.24s\tremaining: 8.02s\n",
      "79:\tlearn: 0.1476194\ttotal: 5.33s\tremaining: 8s\n",
      "80:\tlearn: 0.1475223\ttotal: 5.4s\tremaining: 7.93s\n",
      "81:\tlearn: 0.1474478\ttotal: 5.47s\tremaining: 7.87s\n",
      "82:\tlearn: 0.1473747\ttotal: 5.54s\tremaining: 7.81s\n",
      "83:\tlearn: 0.1473029\ttotal: 5.6s\tremaining: 7.73s\n",
      "84:\tlearn: 0.1472342\ttotal: 5.69s\tremaining: 7.69s\n",
      "85:\tlearn: 0.1471673\ttotal: 5.77s\tremaining: 7.65s\n",
      "86:\tlearn: 0.1471037\ttotal: 5.83s\tremaining: 7.58s\n",
      "87:\tlearn: 0.1470139\ttotal: 5.91s\tremaining: 7.53s\n",
      "88:\tlearn: 0.1469615\ttotal: 5.99s\tremaining: 7.47s\n",
      "89:\tlearn: 0.1468623\ttotal: 6.07s\tremaining: 7.42s\n",
      "90:\tlearn: 0.1467990\ttotal: 6.14s\tremaining: 7.36s\n",
      "91:\tlearn: 0.1466887\ttotal: 6.21s\tremaining: 7.29s\n",
      "92:\tlearn: 0.1466185\ttotal: 6.29s\tremaining: 7.24s\n",
      "93:\tlearn: 0.1464999\ttotal: 6.36s\tremaining: 7.18s\n",
      "94:\tlearn: 0.1464204\ttotal: 6.45s\tremaining: 7.13s\n",
      "95:\tlearn: 0.1463288\ttotal: 6.51s\tremaining: 7.05s\n",
      "96:\tlearn: 0.1462766\ttotal: 6.57s\tremaining: 6.98s\n",
      "97:\tlearn: 0.1462187\ttotal: 6.63s\tremaining: 6.91s\n",
      "98:\tlearn: 0.1461609\ttotal: 6.72s\tremaining: 6.86s\n",
      "99:\tlearn: 0.1461080\ttotal: 6.78s\tremaining: 6.78s\n",
      "100:\tlearn: 0.1460419\ttotal: 6.84s\tremaining: 6.7s\n",
      "101:\tlearn: 0.1459791\ttotal: 6.91s\tremaining: 6.64s\n",
      "102:\tlearn: 0.1458890\ttotal: 6.98s\tremaining: 6.57s\n",
      "103:\tlearn: 0.1458380\ttotal: 7.05s\tremaining: 6.51s\n",
      "104:\tlearn: 0.1457930\ttotal: 7.1s\tremaining: 6.42s\n",
      "105:\tlearn: 0.1457342\ttotal: 7.17s\tremaining: 6.36s\n",
      "106:\tlearn: 0.1456751\ttotal: 7.23s\tremaining: 6.28s\n",
      "107:\tlearn: 0.1455951\ttotal: 7.29s\tremaining: 6.21s\n",
      "108:\tlearn: 0.1455230\ttotal: 7.38s\tremaining: 6.16s\n",
      "109:\tlearn: 0.1454782\ttotal: 7.44s\tremaining: 6.09s\n",
      "110:\tlearn: 0.1454311\ttotal: 7.5s\tremaining: 6.01s\n",
      "111:\tlearn: 0.1453842\ttotal: 7.58s\tremaining: 5.95s\n",
      "112:\tlearn: 0.1453352\ttotal: 7.64s\tremaining: 5.88s\n",
      "113:\tlearn: 0.1452865\ttotal: 7.74s\tremaining: 5.84s\n",
      "114:\tlearn: 0.1452227\ttotal: 7.79s\tremaining: 5.76s\n",
      "115:\tlearn: 0.1451667\ttotal: 7.87s\tremaining: 5.7s\n",
      "116:\tlearn: 0.1451281\ttotal: 7.93s\tremaining: 5.63s\n",
      "117:\tlearn: 0.1450733\ttotal: 8.02s\tremaining: 5.57s\n",
      "118:\tlearn: 0.1450257\ttotal: 8.09s\tremaining: 5.51s\n",
      "119:\tlearn: 0.1449845\ttotal: 8.15s\tremaining: 5.43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120:\tlearn: 0.1449314\ttotal: 8.23s\tremaining: 5.38s\n",
      "121:\tlearn: 0.1448881\ttotal: 8.3s\tremaining: 5.31s\n",
      "122:\tlearn: 0.1448330\ttotal: 8.38s\tremaining: 5.25s\n",
      "123:\tlearn: 0.1447700\ttotal: 8.46s\tremaining: 5.19s\n",
      "124:\tlearn: 0.1447039\ttotal: 8.54s\tremaining: 5.12s\n",
      "125:\tlearn: 0.1446067\ttotal: 8.6s\tremaining: 5.05s\n",
      "126:\tlearn: 0.1445610\ttotal: 8.67s\tremaining: 4.98s\n",
      "127:\tlearn: 0.1444995\ttotal: 8.75s\tremaining: 4.92s\n",
      "128:\tlearn: 0.1444641\ttotal: 8.83s\tremaining: 4.86s\n",
      "129:\tlearn: 0.1444065\ttotal: 8.89s\tremaining: 4.79s\n",
      "130:\tlearn: 0.1443608\ttotal: 8.96s\tremaining: 4.72s\n",
      "131:\tlearn: 0.1443120\ttotal: 9.02s\tremaining: 4.65s\n",
      "132:\tlearn: 0.1442747\ttotal: 9.08s\tremaining: 4.58s\n",
      "133:\tlearn: 0.1442141\ttotal: 9.14s\tremaining: 4.5s\n",
      "134:\tlearn: 0.1441603\ttotal: 9.19s\tremaining: 4.42s\n",
      "135:\tlearn: 0.1441143\ttotal: 9.23s\tremaining: 4.34s\n",
      "136:\tlearn: 0.1440791\ttotal: 9.29s\tremaining: 4.27s\n",
      "137:\tlearn: 0.1440371\ttotal: 9.34s\tremaining: 4.2s\n",
      "138:\tlearn: 0.1440028\ttotal: 9.4s\tremaining: 4.12s\n",
      "139:\tlearn: 0.1439592\ttotal: 9.45s\tremaining: 4.05s\n",
      "140:\tlearn: 0.1439220\ttotal: 9.51s\tremaining: 3.98s\n",
      "141:\tlearn: 0.1438734\ttotal: 9.56s\tremaining: 3.91s\n",
      "142:\tlearn: 0.1438152\ttotal: 9.63s\tremaining: 3.84s\n",
      "143:\tlearn: 0.1437674\ttotal: 9.72s\tremaining: 3.78s\n",
      "144:\tlearn: 0.1437083\ttotal: 9.78s\tremaining: 3.71s\n",
      "145:\tlearn: 0.1436693\ttotal: 9.83s\tremaining: 3.64s\n",
      "146:\tlearn: 0.1436357\ttotal: 9.88s\tremaining: 3.56s\n",
      "147:\tlearn: 0.1436006\ttotal: 9.93s\tremaining: 3.49s\n",
      "148:\tlearn: 0.1435346\ttotal: 9.98s\tremaining: 3.42s\n",
      "149:\tlearn: 0.1435019\ttotal: 10s\tremaining: 3.35s\n",
      "150:\tlearn: 0.1434628\ttotal: 10.1s\tremaining: 3.28s\n",
      "151:\tlearn: 0.1434262\ttotal: 10.2s\tremaining: 3.21s\n",
      "152:\tlearn: 0.1433970\ttotal: 10.2s\tremaining: 3.13s\n",
      "153:\tlearn: 0.1433678\ttotal: 10.3s\tremaining: 3.06s\n",
      "154:\tlearn: 0.1433038\ttotal: 10.3s\tremaining: 2.99s\n",
      "155:\tlearn: 0.1432730\ttotal: 10.4s\tremaining: 2.93s\n",
      "156:\tlearn: 0.1432237\ttotal: 10.4s\tremaining: 2.85s\n",
      "157:\tlearn: 0.1431771\ttotal: 10.5s\tremaining: 2.79s\n",
      "158:\tlearn: 0.1431390\ttotal: 10.5s\tremaining: 2.71s\n",
      "159:\tlearn: 0.1431062\ttotal: 10.6s\tremaining: 2.64s\n",
      "160:\tlearn: 0.1430756\ttotal: 10.6s\tremaining: 2.57s\n",
      "161:\tlearn: 0.1430499\ttotal: 10.7s\tremaining: 2.5s\n",
      "162:\tlearn: 0.1430142\ttotal: 10.7s\tremaining: 2.43s\n",
      "163:\tlearn: 0.1429822\ttotal: 10.8s\tremaining: 2.36s\n",
      "164:\tlearn: 0.1429324\ttotal: 10.8s\tremaining: 2.29s\n",
      "165:\tlearn: 0.1429049\ttotal: 10.9s\tremaining: 2.22s\n",
      "166:\tlearn: 0.1428524\ttotal: 10.9s\tremaining: 2.16s\n",
      "167:\tlearn: 0.1428192\ttotal: 11s\tremaining: 2.09s\n",
      "168:\tlearn: 0.1427894\ttotal: 11s\tremaining: 2.02s\n",
      "169:\tlearn: 0.1427511\ttotal: 11.1s\tremaining: 1.95s\n",
      "170:\tlearn: 0.1427199\ttotal: 11.1s\tremaining: 1.89s\n",
      "171:\tlearn: 0.1426814\ttotal: 11.2s\tremaining: 1.82s\n",
      "172:\tlearn: 0.1426528\ttotal: 11.2s\tremaining: 1.75s\n",
      "173:\tlearn: 0.1426076\ttotal: 11.3s\tremaining: 1.68s\n",
      "174:\tlearn: 0.1425833\ttotal: 11.3s\tremaining: 1.62s\n",
      "175:\tlearn: 0.1425543\ttotal: 11.4s\tremaining: 1.55s\n",
      "176:\tlearn: 0.1425190\ttotal: 11.4s\tremaining: 1.49s\n",
      "177:\tlearn: 0.1424930\ttotal: 11.5s\tremaining: 1.42s\n",
      "178:\tlearn: 0.1424525\ttotal: 11.5s\tremaining: 1.35s\n",
      "179:\tlearn: 0.1424128\ttotal: 11.6s\tremaining: 1.29s\n",
      "180:\tlearn: 0.1423734\ttotal: 11.7s\tremaining: 1.22s\n",
      "181:\tlearn: 0.1423488\ttotal: 11.7s\tremaining: 1.16s\n",
      "182:\tlearn: 0.1423205\ttotal: 11.8s\tremaining: 1.09s\n",
      "183:\tlearn: 0.1422796\ttotal: 11.9s\tremaining: 1.03s\n",
      "184:\tlearn: 0.1422444\ttotal: 11.9s\tremaining: 968ms\n",
      "185:\tlearn: 0.1422051\ttotal: 12s\tremaining: 904ms\n",
      "186:\tlearn: 0.1421698\ttotal: 12.1s\tremaining: 839ms\n",
      "187:\tlearn: 0.1421478\ttotal: 12.1s\tremaining: 775ms\n",
      "188:\tlearn: 0.1421257\ttotal: 12.2s\tremaining: 711ms\n",
      "189:\tlearn: 0.1420885\ttotal: 12.3s\tremaining: 646ms\n",
      "190:\tlearn: 0.1420650\ttotal: 12.3s\tremaining: 581ms\n",
      "191:\tlearn: 0.1420370\ttotal: 12.4s\tremaining: 516ms\n",
      "192:\tlearn: 0.1420133\ttotal: 12.5s\tremaining: 452ms\n",
      "193:\tlearn: 0.1419819\ttotal: 12.5s\tremaining: 388ms\n",
      "194:\tlearn: 0.1419555\ttotal: 12.6s\tremaining: 323ms\n",
      "195:\tlearn: 0.1419200\ttotal: 12.7s\tremaining: 258ms\n",
      "196:\tlearn: 0.1418991\ttotal: 12.7s\tremaining: 194ms\n",
      "197:\tlearn: 0.1418606\ttotal: 12.8s\tremaining: 129ms\n",
      "198:\tlearn: 0.1418361\ttotal: 12.9s\tremaining: 64.6ms\n",
      "199:\tlearn: 0.1418107\ttotal: 12.9s\tremaining: 0us\n",
      "[CV]  learning_rate=0.05, l2_leaf_reg=1, iterations=200, depth=5, total=  13.4s\n",
      "[CV] learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4 .........\n",
      "0:\tlearn: 0.1664811\ttotal: 83.4ms\tremaining: 16.6s\n",
      "1:\tlearn: 0.1567440\ttotal: 156ms\tremaining: 15.4s\n",
      "2:\tlearn: 0.1539154\ttotal: 216ms\tremaining: 14.2s\n",
      "3:\tlearn: 0.1513539\ttotal: 274ms\tremaining: 13.4s\n",
      "4:\tlearn: 0.1498146\ttotal: 346ms\tremaining: 13.5s\n",
      "5:\tlearn: 0.1488211\ttotal: 418ms\tremaining: 13.5s\n",
      "6:\tlearn: 0.1476656\ttotal: 483ms\tremaining: 13.3s\n",
      "7:\tlearn: 0.1470523\ttotal: 536ms\tremaining: 12.9s\n",
      "8:\tlearn: 0.1465592\ttotal: 602ms\tremaining: 12.8s\n",
      "9:\tlearn: 0.1462213\ttotal: 664ms\tremaining: 12.6s\n",
      "10:\tlearn: 0.1457622\ttotal: 716ms\tremaining: 12.3s\n",
      "11:\tlearn: 0.1452361\ttotal: 801ms\tremaining: 12.5s\n",
      "12:\tlearn: 0.1448018\ttotal: 859ms\tremaining: 12.4s\n",
      "13:\tlearn: 0.1443285\ttotal: 921ms\tremaining: 12.2s\n",
      "14:\tlearn: 0.1440676\ttotal: 965ms\tremaining: 11.9s\n",
      "15:\tlearn: 0.1437951\ttotal: 1.01s\tremaining: 11.6s\n",
      "16:\tlearn: 0.1435642\ttotal: 1.06s\tremaining: 11.5s\n",
      "17:\tlearn: 0.1432527\ttotal: 1.12s\tremaining: 11.3s\n",
      "18:\tlearn: 0.1429789\ttotal: 1.17s\tremaining: 11.1s\n",
      "19:\tlearn: 0.1427184\ttotal: 1.22s\tremaining: 11s\n",
      "20:\tlearn: 0.1423966\ttotal: 1.28s\tremaining: 10.9s\n",
      "21:\tlearn: 0.1421527\ttotal: 1.33s\tremaining: 10.8s\n",
      "22:\tlearn: 0.1418294\ttotal: 1.39s\tremaining: 10.7s\n",
      "23:\tlearn: 0.1414597\ttotal: 1.46s\tremaining: 10.7s\n",
      "24:\tlearn: 0.1411664\ttotal: 1.52s\tremaining: 10.6s\n",
      "25:\tlearn: 0.1408999\ttotal: 1.58s\tremaining: 10.6s\n",
      "26:\tlearn: 0.1407384\ttotal: 1.65s\tremaining: 10.5s\n",
      "27:\tlearn: 0.1405876\ttotal: 1.71s\tremaining: 10.5s\n",
      "28:\tlearn: 0.1402667\ttotal: 1.78s\tremaining: 10.5s\n",
      "29:\tlearn: 0.1400033\ttotal: 1.84s\tremaining: 10.4s\n",
      "30:\tlearn: 0.1397608\ttotal: 1.9s\tremaining: 10.4s\n",
      "31:\tlearn: 0.1395987\ttotal: 1.96s\tremaining: 10.3s\n",
      "32:\tlearn: 0.1394701\ttotal: 2.04s\tremaining: 10.3s\n",
      "33:\tlearn: 0.1393277\ttotal: 2.1s\tremaining: 10.2s\n",
      "34:\tlearn: 0.1391923\ttotal: 2.17s\tremaining: 10.2s\n",
      "35:\tlearn: 0.1390205\ttotal: 2.22s\tremaining: 10.1s\n",
      "36:\tlearn: 0.1389009\ttotal: 2.27s\tremaining: 10s\n",
      "37:\tlearn: 0.1387567\ttotal: 2.33s\tremaining: 9.96s\n",
      "38:\tlearn: 0.1385763\ttotal: 2.39s\tremaining: 9.88s\n",
      "39:\tlearn: 0.1384111\ttotal: 2.44s\tremaining: 9.77s\n",
      "40:\tlearn: 0.1382480\ttotal: 2.5s\tremaining: 9.7s\n",
      "41:\tlearn: 0.1381268\ttotal: 2.56s\tremaining: 9.62s\n",
      "42:\tlearn: 0.1380366\ttotal: 2.6s\tremaining: 9.5s\n",
      "43:\tlearn: 0.1379397\ttotal: 2.64s\tremaining: 9.37s\n",
      "44:\tlearn: 0.1378073\ttotal: 2.71s\tremaining: 9.33s\n",
      "45:\tlearn: 0.1376371\ttotal: 2.76s\tremaining: 9.24s\n",
      "46:\tlearn: 0.1375164\ttotal: 2.8s\tremaining: 9.12s\n",
      "47:\tlearn: 0.1373801\ttotal: 2.85s\tremaining: 9.02s\n",
      "48:\tlearn: 0.1372841\ttotal: 2.91s\tremaining: 8.97s\n",
      "49:\tlearn: 0.1370990\ttotal: 2.96s\tremaining: 8.89s\n",
      "50:\tlearn: 0.1369229\ttotal: 3.03s\tremaining: 8.84s\n",
      "51:\tlearn: 0.1368213\ttotal: 3.08s\tremaining: 8.78s\n",
      "52:\tlearn: 0.1367142\ttotal: 3.13s\tremaining: 8.68s\n",
      "53:\tlearn: 0.1365980\ttotal: 3.18s\tremaining: 8.61s\n",
      "54:\tlearn: 0.1365141\ttotal: 3.23s\tremaining: 8.51s\n",
      "55:\tlearn: 0.1364255\ttotal: 3.27s\tremaining: 8.41s\n",
      "56:\tlearn: 0.1362843\ttotal: 3.33s\tremaining: 8.36s\n",
      "57:\tlearn: 0.1361786\ttotal: 3.38s\tremaining: 8.28s\n",
      "58:\tlearn: 0.1360270\ttotal: 3.42s\tremaining: 8.18s\n",
      "59:\tlearn: 0.1359212\ttotal: 3.47s\tremaining: 8.09s\n",
      "60:\tlearn: 0.1358306\ttotal: 3.51s\tremaining: 7.99s\n",
      "61:\tlearn: 0.1357224\ttotal: 3.55s\tremaining: 7.91s\n",
      "62:\tlearn: 0.1356417\ttotal: 3.6s\tremaining: 7.83s\n",
      "63:\tlearn: 0.1355391\ttotal: 3.67s\tremaining: 7.8s\n",
      "64:\tlearn: 0.1354322\ttotal: 3.72s\tremaining: 7.72s\n",
      "65:\tlearn: 0.1353382\ttotal: 3.76s\tremaining: 7.64s\n",
      "66:\tlearn: 0.1352136\ttotal: 3.82s\tremaining: 7.58s\n",
      "67:\tlearn: 0.1351008\ttotal: 3.87s\tremaining: 7.51s\n",
      "68:\tlearn: 0.1349910\ttotal: 3.92s\tremaining: 7.45s\n",
      "69:\tlearn: 0.1348760\ttotal: 3.98s\tremaining: 7.39s\n",
      "70:\tlearn: 0.1347753\ttotal: 4.02s\tremaining: 7.31s\n",
      "71:\tlearn: 0.1346711\ttotal: 4.08s\tremaining: 7.25s\n",
      "72:\tlearn: 0.1345745\ttotal: 4.12s\tremaining: 7.16s\n",
      "73:\tlearn: 0.1344853\ttotal: 4.16s\tremaining: 7.09s\n",
      "74:\tlearn: 0.1343661\ttotal: 4.2s\tremaining: 7s\n",
      "75:\tlearn: 0.1342749\ttotal: 4.26s\tremaining: 6.95s\n",
      "76:\tlearn: 0.1341670\ttotal: 4.31s\tremaining: 6.89s\n",
      "77:\tlearn: 0.1340927\ttotal: 4.36s\tremaining: 6.82s\n",
      "78:\tlearn: 0.1340231\ttotal: 4.41s\tremaining: 6.75s\n",
      "79:\tlearn: 0.1339599\ttotal: 4.45s\tremaining: 6.68s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80:\tlearn: 0.1338576\ttotal: 4.51s\tremaining: 6.63s\n",
      "81:\tlearn: 0.1337871\ttotal: 4.57s\tremaining: 6.57s\n",
      "82:\tlearn: 0.1336840\ttotal: 4.62s\tremaining: 6.51s\n",
      "83:\tlearn: 0.1336108\ttotal: 4.67s\tremaining: 6.45s\n",
      "84:\tlearn: 0.1335395\ttotal: 4.73s\tremaining: 6.4s\n",
      "85:\tlearn: 0.1334540\ttotal: 4.79s\tremaining: 6.35s\n",
      "86:\tlearn: 0.1333590\ttotal: 4.84s\tremaining: 6.29s\n",
      "87:\tlearn: 0.1332856\ttotal: 4.9s\tremaining: 6.24s\n",
      "88:\tlearn: 0.1331859\ttotal: 4.96s\tremaining: 6.19s\n",
      "89:\tlearn: 0.1330861\ttotal: 5.02s\tremaining: 6.13s\n",
      "90:\tlearn: 0.1330115\ttotal: 5.09s\tremaining: 6.1s\n",
      "91:\tlearn: 0.1329353\ttotal: 5.17s\tremaining: 6.06s\n",
      "92:\tlearn: 0.1328767\ttotal: 5.24s\tremaining: 6.03s\n",
      "93:\tlearn: 0.1327852\ttotal: 5.3s\tremaining: 5.98s\n",
      "94:\tlearn: 0.1326959\ttotal: 5.38s\tremaining: 5.94s\n",
      "95:\tlearn: 0.1326284\ttotal: 5.45s\tremaining: 5.91s\n",
      "96:\tlearn: 0.1325630\ttotal: 5.53s\tremaining: 5.87s\n",
      "97:\tlearn: 0.1324587\ttotal: 5.59s\tremaining: 5.81s\n",
      "98:\tlearn: 0.1323543\ttotal: 5.66s\tremaining: 5.77s\n",
      "99:\tlearn: 0.1322384\ttotal: 5.72s\tremaining: 5.72s\n",
      "100:\tlearn: 0.1321356\ttotal: 5.79s\tremaining: 5.67s\n",
      "101:\tlearn: 0.1320499\ttotal: 5.87s\tremaining: 5.64s\n",
      "102:\tlearn: 0.1319825\ttotal: 5.94s\tremaining: 5.6s\n",
      "103:\tlearn: 0.1318917\ttotal: 6s\tremaining: 5.53s\n",
      "104:\tlearn: 0.1318082\ttotal: 6.06s\tremaining: 5.49s\n",
      "105:\tlearn: 0.1317277\ttotal: 6.11s\tremaining: 5.42s\n",
      "106:\tlearn: 0.1316601\ttotal: 6.16s\tremaining: 5.36s\n",
      "107:\tlearn: 0.1315705\ttotal: 6.2s\tremaining: 5.28s\n",
      "108:\tlearn: 0.1314806\ttotal: 6.25s\tremaining: 5.22s\n",
      "109:\tlearn: 0.1314154\ttotal: 6.3s\tremaining: 5.15s\n",
      "110:\tlearn: 0.1313125\ttotal: 6.35s\tremaining: 5.09s\n",
      "111:\tlearn: 0.1312447\ttotal: 6.42s\tremaining: 5.04s\n",
      "112:\tlearn: 0.1311907\ttotal: 6.49s\tremaining: 5s\n",
      "113:\tlearn: 0.1311257\ttotal: 6.56s\tremaining: 4.95s\n",
      "114:\tlearn: 0.1310735\ttotal: 6.62s\tremaining: 4.9s\n",
      "115:\tlearn: 0.1309809\ttotal: 6.69s\tremaining: 4.84s\n",
      "116:\tlearn: 0.1309073\ttotal: 6.75s\tremaining: 4.79s\n",
      "117:\tlearn: 0.1307910\ttotal: 6.84s\tremaining: 4.76s\n",
      "118:\tlearn: 0.1307140\ttotal: 6.91s\tremaining: 4.7s\n",
      "119:\tlearn: 0.1306134\ttotal: 6.97s\tremaining: 4.65s\n",
      "120:\tlearn: 0.1305278\ttotal: 7.05s\tremaining: 4.6s\n",
      "121:\tlearn: 0.1304662\ttotal: 7.14s\tremaining: 4.57s\n",
      "122:\tlearn: 0.1303885\ttotal: 7.2s\tremaining: 4.51s\n",
      "123:\tlearn: 0.1303361\ttotal: 7.27s\tremaining: 4.46s\n",
      "124:\tlearn: 0.1302630\ttotal: 7.34s\tremaining: 4.41s\n",
      "125:\tlearn: 0.1301920\ttotal: 7.41s\tremaining: 4.35s\n",
      "126:\tlearn: 0.1301254\ttotal: 7.49s\tremaining: 4.3s\n",
      "127:\tlearn: 0.1300743\ttotal: 7.55s\tremaining: 4.25s\n",
      "128:\tlearn: 0.1299975\ttotal: 7.62s\tremaining: 4.19s\n",
      "129:\tlearn: 0.1299252\ttotal: 7.69s\tremaining: 4.14s\n",
      "130:\tlearn: 0.1298511\ttotal: 7.75s\tremaining: 4.08s\n",
      "131:\tlearn: 0.1297926\ttotal: 7.84s\tremaining: 4.04s\n",
      "132:\tlearn: 0.1297218\ttotal: 7.9s\tremaining: 3.98s\n",
      "133:\tlearn: 0.1296781\ttotal: 7.97s\tremaining: 3.92s\n",
      "134:\tlearn: 0.1296053\ttotal: 8.03s\tremaining: 3.87s\n",
      "135:\tlearn: 0.1295478\ttotal: 8.11s\tremaining: 3.82s\n",
      "136:\tlearn: 0.1294742\ttotal: 8.18s\tremaining: 3.76s\n",
      "137:\tlearn: 0.1294039\ttotal: 8.23s\tremaining: 3.7s\n",
      "138:\tlearn: 0.1293477\ttotal: 8.28s\tremaining: 3.63s\n",
      "139:\tlearn: 0.1293017\ttotal: 8.33s\tremaining: 3.57s\n",
      "140:\tlearn: 0.1292300\ttotal: 8.37s\tremaining: 3.5s\n",
      "141:\tlearn: 0.1291666\ttotal: 8.42s\tremaining: 3.44s\n",
      "142:\tlearn: 0.1291107\ttotal: 8.48s\tremaining: 3.38s\n",
      "143:\tlearn: 0.1290615\ttotal: 8.52s\tremaining: 3.31s\n",
      "144:\tlearn: 0.1289831\ttotal: 8.57s\tremaining: 3.25s\n",
      "145:\tlearn: 0.1289132\ttotal: 8.64s\tremaining: 3.2s\n",
      "146:\tlearn: 0.1288399\ttotal: 8.7s\tremaining: 3.13s\n",
      "147:\tlearn: 0.1287985\ttotal: 8.77s\tremaining: 3.08s\n",
      "148:\tlearn: 0.1287060\ttotal: 8.84s\tremaining: 3.03s\n",
      "149:\tlearn: 0.1286262\ttotal: 8.9s\tremaining: 2.97s\n",
      "150:\tlearn: 0.1285557\ttotal: 8.97s\tremaining: 2.91s\n",
      "151:\tlearn: 0.1284771\ttotal: 9.03s\tremaining: 2.85s\n",
      "152:\tlearn: 0.1284229\ttotal: 9.11s\tremaining: 2.8s\n",
      "153:\tlearn: 0.1283328\ttotal: 9.15s\tremaining: 2.73s\n",
      "154:\tlearn: 0.1282490\ttotal: 9.19s\tremaining: 2.67s\n",
      "155:\tlearn: 0.1281799\ttotal: 9.24s\tremaining: 2.6s\n",
      "156:\tlearn: 0.1281235\ttotal: 9.29s\tremaining: 2.54s\n",
      "157:\tlearn: 0.1280378\ttotal: 9.34s\tremaining: 2.48s\n",
      "158:\tlearn: 0.1279702\ttotal: 9.4s\tremaining: 2.42s\n",
      "159:\tlearn: 0.1279106\ttotal: 9.45s\tremaining: 2.36s\n",
      "160:\tlearn: 0.1278352\ttotal: 9.5s\tremaining: 2.3s\n",
      "161:\tlearn: 0.1277687\ttotal: 9.55s\tremaining: 2.24s\n",
      "162:\tlearn: 0.1277066\ttotal: 9.63s\tremaining: 2.19s\n",
      "163:\tlearn: 0.1276300\ttotal: 9.68s\tremaining: 2.12s\n",
      "164:\tlearn: 0.1275651\ttotal: 9.72s\tremaining: 2.06s\n",
      "165:\tlearn: 0.1274959\ttotal: 9.77s\tremaining: 2s\n",
      "166:\tlearn: 0.1274321\ttotal: 9.84s\tremaining: 1.94s\n",
      "167:\tlearn: 0.1273689\ttotal: 9.88s\tremaining: 1.88s\n",
      "168:\tlearn: 0.1272918\ttotal: 9.93s\tremaining: 1.82s\n",
      "169:\tlearn: 0.1272390\ttotal: 9.97s\tremaining: 1.76s\n",
      "170:\tlearn: 0.1271663\ttotal: 10s\tremaining: 1.7s\n",
      "171:\tlearn: 0.1271162\ttotal: 10.1s\tremaining: 1.64s\n",
      "172:\tlearn: 0.1270610\ttotal: 10.2s\tremaining: 1.59s\n",
      "173:\tlearn: 0.1270192\ttotal: 10.2s\tremaining: 1.53s\n",
      "174:\tlearn: 0.1269475\ttotal: 10.3s\tremaining: 1.47s\n",
      "175:\tlearn: 0.1268918\ttotal: 10.4s\tremaining: 1.41s\n",
      "176:\tlearn: 0.1268226\ttotal: 10.4s\tremaining: 1.35s\n",
      "177:\tlearn: 0.1267528\ttotal: 10.5s\tremaining: 1.3s\n",
      "178:\tlearn: 0.1266582\ttotal: 10.6s\tremaining: 1.24s\n",
      "179:\tlearn: 0.1266180\ttotal: 10.6s\tremaining: 1.18s\n",
      "180:\tlearn: 0.1265493\ttotal: 10.7s\tremaining: 1.12s\n",
      "181:\tlearn: 0.1264930\ttotal: 10.8s\tremaining: 1.06s\n",
      "182:\tlearn: 0.1264315\ttotal: 10.8s\tremaining: 1s\n",
      "183:\tlearn: 0.1263614\ttotal: 10.9s\tremaining: 945ms\n",
      "184:\tlearn: 0.1262981\ttotal: 10.9s\tremaining: 885ms\n",
      "185:\tlearn: 0.1262339\ttotal: 11s\tremaining: 826ms\n",
      "186:\tlearn: 0.1261746\ttotal: 11s\tremaining: 768ms\n",
      "187:\tlearn: 0.1261223\ttotal: 11.1s\tremaining: 709ms\n",
      "188:\tlearn: 0.1260913\ttotal: 11.1s\tremaining: 649ms\n",
      "189:\tlearn: 0.1260316\ttotal: 11.2s\tremaining: 589ms\n",
      "190:\tlearn: 0.1259757\ttotal: 11.2s\tremaining: 530ms\n",
      "191:\tlearn: 0.1259299\ttotal: 11.3s\tremaining: 470ms\n",
      "192:\tlearn: 0.1258834\ttotal: 11.3s\tremaining: 411ms\n",
      "193:\tlearn: 0.1258277\ttotal: 11.4s\tremaining: 353ms\n",
      "194:\tlearn: 0.1257724\ttotal: 11.5s\tremaining: 294ms\n",
      "195:\tlearn: 0.1257078\ttotal: 11.5s\tremaining: 235ms\n",
      "196:\tlearn: 0.1256556\ttotal: 11.6s\tremaining: 176ms\n",
      "197:\tlearn: 0.1256157\ttotal: 11.6s\tremaining: 118ms\n",
      "198:\tlearn: 0.1255557\ttotal: 11.7s\tremaining: 58.9ms\n",
      "199:\tlearn: 0.1255019\ttotal: 11.8s\tremaining: 0us\n",
      "[CV]  learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4, total=  12.3s\n",
      "[CV] learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4 .........\n",
      "0:\tlearn: 0.1664160\ttotal: 71.4ms\tremaining: 14.2s\n",
      "1:\tlearn: 0.1566104\ttotal: 127ms\tremaining: 12.6s\n",
      "2:\tlearn: 0.1537316\ttotal: 173ms\tremaining: 11.3s\n",
      "3:\tlearn: 0.1518026\ttotal: 216ms\tremaining: 10.6s\n",
      "4:\tlearn: 0.1502783\ttotal: 272ms\tremaining: 10.6s\n",
      "5:\tlearn: 0.1488270\ttotal: 348ms\tremaining: 11.2s\n",
      "6:\tlearn: 0.1481753\ttotal: 414ms\tremaining: 11.4s\n",
      "7:\tlearn: 0.1474064\ttotal: 470ms\tremaining: 11.3s\n",
      "8:\tlearn: 0.1467902\ttotal: 526ms\tremaining: 11.2s\n",
      "9:\tlearn: 0.1461976\ttotal: 582ms\tremaining: 11.1s\n",
      "10:\tlearn: 0.1456559\ttotal: 638ms\tremaining: 11s\n",
      "11:\tlearn: 0.1452540\ttotal: 694ms\tremaining: 10.9s\n",
      "12:\tlearn: 0.1448248\ttotal: 746ms\tremaining: 10.7s\n",
      "13:\tlearn: 0.1444372\ttotal: 805ms\tremaining: 10.7s\n",
      "14:\tlearn: 0.1441315\ttotal: 856ms\tremaining: 10.6s\n",
      "15:\tlearn: 0.1438036\ttotal: 906ms\tremaining: 10.4s\n",
      "16:\tlearn: 0.1434291\ttotal: 956ms\tremaining: 10.3s\n",
      "17:\tlearn: 0.1431358\ttotal: 1.02s\tremaining: 10.3s\n",
      "18:\tlearn: 0.1428609\ttotal: 1.07s\tremaining: 10.2s\n",
      "19:\tlearn: 0.1426823\ttotal: 1.13s\tremaining: 10.2s\n",
      "20:\tlearn: 0.1423268\ttotal: 1.18s\tremaining: 10s\n",
      "21:\tlearn: 0.1421007\ttotal: 1.22s\tremaining: 9.9s\n",
      "22:\tlearn: 0.1418950\ttotal: 1.3s\tremaining: 9.99s\n",
      "23:\tlearn: 0.1417206\ttotal: 1.36s\tremaining: 9.99s\n",
      "24:\tlearn: 0.1413660\ttotal: 1.43s\tremaining: 10s\n",
      "25:\tlearn: 0.1411719\ttotal: 1.49s\tremaining: 9.94s\n",
      "26:\tlearn: 0.1409853\ttotal: 1.54s\tremaining: 9.86s\n",
      "27:\tlearn: 0.1407876\ttotal: 1.58s\tremaining: 9.74s\n",
      "28:\tlearn: 0.1406261\ttotal: 1.64s\tremaining: 9.69s\n",
      "29:\tlearn: 0.1404458\ttotal: 1.71s\tremaining: 9.71s\n",
      "30:\tlearn: 0.1402641\ttotal: 1.78s\tremaining: 9.69s\n",
      "31:\tlearn: 0.1400642\ttotal: 1.82s\tremaining: 9.58s\n",
      "32:\tlearn: 0.1399424\ttotal: 1.88s\tremaining: 9.51s\n",
      "33:\tlearn: 0.1398068\ttotal: 1.96s\tremaining: 9.55s\n",
      "34:\tlearn: 0.1396168\ttotal: 2.02s\tremaining: 9.52s\n",
      "35:\tlearn: 0.1393437\ttotal: 2.09s\tremaining: 9.51s\n",
      "36:\tlearn: 0.1392114\ttotal: 2.15s\tremaining: 9.5s\n",
      "37:\tlearn: 0.1389895\ttotal: 2.21s\tremaining: 9.45s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38:\tlearn: 0.1387754\ttotal: 2.3s\tremaining: 9.48s\n",
      "39:\tlearn: 0.1386435\ttotal: 2.38s\tremaining: 9.52s\n",
      "40:\tlearn: 0.1384689\ttotal: 2.44s\tremaining: 9.45s\n",
      "41:\tlearn: 0.1383237\ttotal: 2.49s\tremaining: 9.36s\n",
      "42:\tlearn: 0.1381770\ttotal: 2.55s\tremaining: 9.32s\n",
      "43:\tlearn: 0.1380339\ttotal: 2.62s\tremaining: 9.28s\n",
      "44:\tlearn: 0.1377930\ttotal: 2.71s\tremaining: 9.32s\n",
      "45:\tlearn: 0.1376230\ttotal: 2.77s\tremaining: 9.27s\n",
      "46:\tlearn: 0.1374991\ttotal: 2.84s\tremaining: 9.25s\n",
      "47:\tlearn: 0.1373725\ttotal: 2.9s\tremaining: 9.18s\n",
      "48:\tlearn: 0.1372755\ttotal: 2.97s\tremaining: 9.15s\n",
      "49:\tlearn: 0.1371615\ttotal: 3.04s\tremaining: 9.12s\n",
      "50:\tlearn: 0.1370343\ttotal: 3.1s\tremaining: 9.05s\n",
      "51:\tlearn: 0.1369365\ttotal: 3.15s\tremaining: 8.96s\n",
      "52:\tlearn: 0.1368047\ttotal: 3.2s\tremaining: 8.88s\n",
      "53:\tlearn: 0.1367184\ttotal: 3.29s\tremaining: 8.88s\n",
      "54:\tlearn: 0.1366009\ttotal: 3.34s\tremaining: 8.82s\n",
      "55:\tlearn: 0.1364845\ttotal: 3.4s\tremaining: 8.74s\n",
      "56:\tlearn: 0.1363663\ttotal: 3.46s\tremaining: 8.69s\n",
      "57:\tlearn: 0.1362835\ttotal: 3.52s\tremaining: 8.63s\n",
      "58:\tlearn: 0.1361631\ttotal: 3.58s\tremaining: 8.56s\n",
      "59:\tlearn: 0.1360905\ttotal: 3.64s\tremaining: 8.5s\n",
      "60:\tlearn: 0.1359797\ttotal: 3.7s\tremaining: 8.44s\n",
      "61:\tlearn: 0.1358608\ttotal: 3.76s\tremaining: 8.38s\n",
      "62:\tlearn: 0.1357413\ttotal: 3.81s\tremaining: 8.29s\n",
      "63:\tlearn: 0.1355974\ttotal: 3.87s\tremaining: 8.22s\n",
      "64:\tlearn: 0.1354790\ttotal: 3.92s\tremaining: 8.15s\n",
      "65:\tlearn: 0.1353564\ttotal: 3.98s\tremaining: 8.07s\n",
      "66:\tlearn: 0.1352331\ttotal: 4.03s\tremaining: 8s\n",
      "67:\tlearn: 0.1350808\ttotal: 4.08s\tremaining: 7.93s\n",
      "68:\tlearn: 0.1349705\ttotal: 4.13s\tremaining: 7.84s\n",
      "69:\tlearn: 0.1348567\ttotal: 4.18s\tremaining: 7.77s\n",
      "70:\tlearn: 0.1347557\ttotal: 4.25s\tremaining: 7.71s\n",
      "71:\tlearn: 0.1346438\ttotal: 4.3s\tremaining: 7.65s\n",
      "72:\tlearn: 0.1345545\ttotal: 4.37s\tremaining: 7.6s\n",
      "73:\tlearn: 0.1344576\ttotal: 4.42s\tremaining: 7.53s\n",
      "74:\tlearn: 0.1343603\ttotal: 4.46s\tremaining: 7.44s\n",
      "75:\tlearn: 0.1342641\ttotal: 4.51s\tremaining: 7.37s\n",
      "76:\tlearn: 0.1341779\ttotal: 4.58s\tremaining: 7.31s\n",
      "77:\tlearn: 0.1340898\ttotal: 4.63s\tremaining: 7.24s\n",
      "78:\tlearn: 0.1339852\ttotal: 4.68s\tremaining: 7.17s\n",
      "79:\tlearn: 0.1338945\ttotal: 4.73s\tremaining: 7.09s\n",
      "80:\tlearn: 0.1338134\ttotal: 4.77s\tremaining: 7s\n",
      "81:\tlearn: 0.1337259\ttotal: 4.83s\tremaining: 6.95s\n",
      "82:\tlearn: 0.1336353\ttotal: 4.88s\tremaining: 6.88s\n",
      "83:\tlearn: 0.1335517\ttotal: 4.93s\tremaining: 6.81s\n",
      "84:\tlearn: 0.1334387\ttotal: 4.98s\tremaining: 6.73s\n",
      "85:\tlearn: 0.1333638\ttotal: 5.02s\tremaining: 6.65s\n",
      "86:\tlearn: 0.1332921\ttotal: 5.07s\tremaining: 6.58s\n",
      "87:\tlearn: 0.1331841\ttotal: 5.12s\tremaining: 6.51s\n",
      "88:\tlearn: 0.1331137\ttotal: 5.17s\tremaining: 6.45s\n",
      "89:\tlearn: 0.1330547\ttotal: 5.22s\tremaining: 6.38s\n",
      "90:\tlearn: 0.1329391\ttotal: 5.26s\tremaining: 6.31s\n",
      "91:\tlearn: 0.1328639\ttotal: 5.32s\tremaining: 6.24s\n",
      "92:\tlearn: 0.1327816\ttotal: 5.37s\tremaining: 6.17s\n",
      "93:\tlearn: 0.1327174\ttotal: 5.42s\tremaining: 6.11s\n",
      "94:\tlearn: 0.1326441\ttotal: 5.47s\tremaining: 6.04s\n",
      "95:\tlearn: 0.1325729\ttotal: 5.51s\tremaining: 5.97s\n",
      "96:\tlearn: 0.1324887\ttotal: 5.57s\tremaining: 5.91s\n",
      "97:\tlearn: 0.1324115\ttotal: 5.61s\tremaining: 5.84s\n",
      "98:\tlearn: 0.1323307\ttotal: 5.67s\tremaining: 5.78s\n",
      "99:\tlearn: 0.1322629\ttotal: 5.72s\tremaining: 5.72s\n",
      "100:\tlearn: 0.1321862\ttotal: 5.76s\tremaining: 5.64s\n",
      "101:\tlearn: 0.1321113\ttotal: 5.83s\tremaining: 5.61s\n",
      "102:\tlearn: 0.1320246\ttotal: 5.88s\tremaining: 5.54s\n",
      "103:\tlearn: 0.1319374\ttotal: 5.94s\tremaining: 5.48s\n",
      "104:\tlearn: 0.1318603\ttotal: 5.99s\tremaining: 5.42s\n",
      "105:\tlearn: 0.1317575\ttotal: 6.04s\tremaining: 5.36s\n",
      "106:\tlearn: 0.1316660\ttotal: 6.09s\tremaining: 5.3s\n",
      "107:\tlearn: 0.1315759\ttotal: 6.15s\tremaining: 5.24s\n",
      "108:\tlearn: 0.1315208\ttotal: 6.21s\tremaining: 5.18s\n",
      "109:\tlearn: 0.1314417\ttotal: 6.25s\tremaining: 5.12s\n",
      "110:\tlearn: 0.1313590\ttotal: 6.31s\tremaining: 5.06s\n",
      "111:\tlearn: 0.1312715\ttotal: 6.36s\tremaining: 5s\n",
      "112:\tlearn: 0.1311918\ttotal: 6.41s\tremaining: 4.93s\n",
      "113:\tlearn: 0.1311011\ttotal: 6.45s\tremaining: 4.87s\n",
      "114:\tlearn: 0.1310317\ttotal: 6.52s\tremaining: 4.82s\n",
      "115:\tlearn: 0.1309638\ttotal: 6.58s\tremaining: 4.76s\n",
      "116:\tlearn: 0.1308974\ttotal: 6.62s\tremaining: 4.7s\n",
      "117:\tlearn: 0.1308021\ttotal: 6.67s\tremaining: 4.64s\n",
      "118:\tlearn: 0.1307222\ttotal: 6.72s\tremaining: 4.57s\n",
      "119:\tlearn: 0.1306393\ttotal: 6.78s\tremaining: 4.52s\n",
      "120:\tlearn: 0.1305638\ttotal: 6.83s\tremaining: 4.46s\n",
      "121:\tlearn: 0.1304968\ttotal: 6.88s\tremaining: 4.4s\n",
      "122:\tlearn: 0.1303976\ttotal: 6.92s\tremaining: 4.33s\n",
      "123:\tlearn: 0.1303236\ttotal: 6.97s\tremaining: 4.27s\n",
      "124:\tlearn: 0.1302479\ttotal: 7.03s\tremaining: 4.22s\n",
      "125:\tlearn: 0.1301651\ttotal: 7.09s\tremaining: 4.16s\n",
      "126:\tlearn: 0.1300747\ttotal: 7.13s\tremaining: 4.1s\n",
      "127:\tlearn: 0.1300060\ttotal: 7.18s\tremaining: 4.04s\n",
      "128:\tlearn: 0.1299347\ttotal: 7.23s\tremaining: 3.98s\n",
      "129:\tlearn: 0.1298413\ttotal: 7.29s\tremaining: 3.93s\n",
      "130:\tlearn: 0.1297446\ttotal: 7.35s\tremaining: 3.87s\n",
      "131:\tlearn: 0.1296710\ttotal: 7.4s\tremaining: 3.81s\n",
      "132:\tlearn: 0.1296050\ttotal: 7.44s\tremaining: 3.75s\n",
      "133:\tlearn: 0.1295455\ttotal: 7.49s\tremaining: 3.69s\n",
      "134:\tlearn: 0.1294839\ttotal: 7.55s\tremaining: 3.64s\n",
      "135:\tlearn: 0.1294122\ttotal: 7.61s\tremaining: 3.58s\n",
      "136:\tlearn: 0.1293494\ttotal: 7.66s\tremaining: 3.52s\n",
      "137:\tlearn: 0.1293006\ttotal: 7.7s\tremaining: 3.46s\n",
      "138:\tlearn: 0.1292136\ttotal: 7.76s\tremaining: 3.4s\n",
      "139:\tlearn: 0.1291512\ttotal: 7.82s\tremaining: 3.35s\n",
      "140:\tlearn: 0.1291169\ttotal: 7.88s\tremaining: 3.3s\n",
      "141:\tlearn: 0.1290353\ttotal: 7.93s\tremaining: 3.24s\n",
      "142:\tlearn: 0.1289476\ttotal: 7.99s\tremaining: 3.18s\n",
      "143:\tlearn: 0.1288807\ttotal: 8.03s\tremaining: 3.12s\n",
      "144:\tlearn: 0.1287748\ttotal: 8.08s\tremaining: 3.06s\n",
      "145:\tlearn: 0.1287236\ttotal: 8.14s\tremaining: 3.01s\n",
      "146:\tlearn: 0.1286622\ttotal: 8.19s\tremaining: 2.95s\n",
      "147:\tlearn: 0.1286010\ttotal: 8.24s\tremaining: 2.89s\n",
      "148:\tlearn: 0.1285539\ttotal: 8.3s\tremaining: 2.84s\n",
      "149:\tlearn: 0.1285074\ttotal: 8.35s\tremaining: 2.78s\n",
      "150:\tlearn: 0.1284629\ttotal: 8.4s\tremaining: 2.73s\n",
      "151:\tlearn: 0.1284001\ttotal: 8.46s\tremaining: 2.67s\n",
      "152:\tlearn: 0.1283368\ttotal: 8.52s\tremaining: 2.62s\n",
      "153:\tlearn: 0.1282615\ttotal: 8.56s\tremaining: 2.56s\n",
      "154:\tlearn: 0.1282053\ttotal: 8.62s\tremaining: 2.5s\n",
      "155:\tlearn: 0.1281265\ttotal: 8.66s\tremaining: 2.44s\n",
      "156:\tlearn: 0.1280597\ttotal: 8.72s\tremaining: 2.39s\n",
      "157:\tlearn: 0.1280001\ttotal: 8.77s\tremaining: 2.33s\n",
      "158:\tlearn: 0.1279183\ttotal: 8.82s\tremaining: 2.27s\n",
      "159:\tlearn: 0.1278611\ttotal: 8.88s\tremaining: 2.22s\n",
      "160:\tlearn: 0.1278229\ttotal: 8.94s\tremaining: 2.17s\n",
      "161:\tlearn: 0.1277679\ttotal: 9s\tremaining: 2.11s\n",
      "162:\tlearn: 0.1277063\ttotal: 9.05s\tremaining: 2.06s\n",
      "163:\tlearn: 0.1276543\ttotal: 9.13s\tremaining: 2s\n",
      "164:\tlearn: 0.1275701\ttotal: 9.2s\tremaining: 1.95s\n",
      "165:\tlearn: 0.1275268\ttotal: 9.27s\tremaining: 1.9s\n",
      "166:\tlearn: 0.1274669\ttotal: 9.33s\tremaining: 1.84s\n",
      "167:\tlearn: 0.1274025\ttotal: 9.4s\tremaining: 1.79s\n",
      "168:\tlearn: 0.1273461\ttotal: 9.46s\tremaining: 1.74s\n",
      "169:\tlearn: 0.1272801\ttotal: 9.53s\tremaining: 1.68s\n",
      "170:\tlearn: 0.1272242\ttotal: 9.62s\tremaining: 1.63s\n",
      "171:\tlearn: 0.1271836\ttotal: 9.7s\tremaining: 1.58s\n",
      "172:\tlearn: 0.1271335\ttotal: 9.78s\tremaining: 1.53s\n",
      "173:\tlearn: 0.1270806\ttotal: 9.86s\tremaining: 1.47s\n",
      "174:\tlearn: 0.1270184\ttotal: 9.93s\tremaining: 1.42s\n",
      "175:\tlearn: 0.1269552\ttotal: 10s\tremaining: 1.36s\n",
      "176:\tlearn: 0.1268978\ttotal: 10.1s\tremaining: 1.31s\n",
      "177:\tlearn: 0.1268488\ttotal: 10.2s\tremaining: 1.25s\n",
      "178:\tlearn: 0.1267789\ttotal: 10.2s\tremaining: 1.2s\n",
      "179:\tlearn: 0.1267122\ttotal: 10.3s\tremaining: 1.14s\n",
      "180:\tlearn: 0.1266534\ttotal: 10.3s\tremaining: 1.08s\n",
      "181:\tlearn: 0.1266045\ttotal: 10.4s\tremaining: 1.03s\n",
      "182:\tlearn: 0.1265545\ttotal: 10.5s\tremaining: 976ms\n",
      "183:\tlearn: 0.1265053\ttotal: 10.6s\tremaining: 919ms\n",
      "184:\tlearn: 0.1264550\ttotal: 10.6s\tremaining: 863ms\n",
      "185:\tlearn: 0.1264041\ttotal: 10.7s\tremaining: 807ms\n",
      "186:\tlearn: 0.1263274\ttotal: 10.8s\tremaining: 750ms\n",
      "187:\tlearn: 0.1262682\ttotal: 10.9s\tremaining: 694ms\n",
      "188:\tlearn: 0.1262101\ttotal: 10.9s\tremaining: 637ms\n",
      "189:\tlearn: 0.1261370\ttotal: 11s\tremaining: 580ms\n",
      "190:\tlearn: 0.1260773\ttotal: 11.1s\tremaining: 522ms\n",
      "191:\tlearn: 0.1260336\ttotal: 11.1s\tremaining: 464ms\n",
      "192:\tlearn: 0.1259734\ttotal: 11.2s\tremaining: 407ms\n",
      "193:\tlearn: 0.1259210\ttotal: 11.3s\tremaining: 349ms\n",
      "194:\tlearn: 0.1258763\ttotal: 11.3s\tremaining: 291ms\n",
      "195:\tlearn: 0.1258331\ttotal: 11.4s\tremaining: 233ms\n",
      "196:\tlearn: 0.1257778\ttotal: 11.5s\tremaining: 175ms\n",
      "197:\tlearn: 0.1257248\ttotal: 11.6s\tremaining: 117ms\n",
      "198:\tlearn: 0.1256697\ttotal: 11.6s\tremaining: 58.5ms\n",
      "199:\tlearn: 0.1256093\ttotal: 11.7s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4, total=  12.2s\n",
      "[CV] learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4 .........\n",
      "0:\tlearn: 0.1663747\ttotal: 71.4ms\tremaining: 14.2s\n",
      "1:\tlearn: 0.1565049\ttotal: 147ms\tremaining: 14.5s\n",
      "2:\tlearn: 0.1537246\ttotal: 204ms\tremaining: 13.4s\n",
      "3:\tlearn: 0.1514873\ttotal: 270ms\tremaining: 13.3s\n",
      "4:\tlearn: 0.1497059\ttotal: 334ms\tremaining: 13s\n",
      "5:\tlearn: 0.1487846\ttotal: 395ms\tremaining: 12.8s\n",
      "6:\tlearn: 0.1480720\ttotal: 447ms\tremaining: 12.3s\n",
      "7:\tlearn: 0.1472258\ttotal: 507ms\tremaining: 12.2s\n",
      "8:\tlearn: 0.1465331\ttotal: 580ms\tremaining: 12.3s\n",
      "9:\tlearn: 0.1459208\ttotal: 634ms\tremaining: 12s\n",
      "10:\tlearn: 0.1454708\ttotal: 692ms\tremaining: 11.9s\n",
      "11:\tlearn: 0.1446656\ttotal: 767ms\tremaining: 12s\n",
      "12:\tlearn: 0.1443454\ttotal: 861ms\tremaining: 12.4s\n",
      "13:\tlearn: 0.1438001\ttotal: 922ms\tremaining: 12.2s\n",
      "14:\tlearn: 0.1435036\ttotal: 967ms\tremaining: 11.9s\n",
      "15:\tlearn: 0.1431650\ttotal: 1.03s\tremaining: 11.8s\n",
      "16:\tlearn: 0.1429151\ttotal: 1.08s\tremaining: 11.7s\n",
      "17:\tlearn: 0.1425296\ttotal: 1.14s\tremaining: 11.5s\n",
      "18:\tlearn: 0.1421512\ttotal: 1.21s\tremaining: 11.5s\n",
      "19:\tlearn: 0.1418883\ttotal: 1.26s\tremaining: 11.3s\n",
      "20:\tlearn: 0.1416238\ttotal: 1.31s\tremaining: 11.2s\n",
      "21:\tlearn: 0.1413866\ttotal: 1.36s\tremaining: 11s\n",
      "22:\tlearn: 0.1411104\ttotal: 1.43s\tremaining: 11s\n",
      "23:\tlearn: 0.1408084\ttotal: 1.49s\tremaining: 10.9s\n",
      "24:\tlearn: 0.1406373\ttotal: 1.56s\tremaining: 10.9s\n",
      "25:\tlearn: 0.1403929\ttotal: 1.61s\tremaining: 10.8s\n",
      "26:\tlearn: 0.1401708\ttotal: 1.67s\tremaining: 10.7s\n",
      "27:\tlearn: 0.1399746\ttotal: 1.72s\tremaining: 10.6s\n",
      "28:\tlearn: 0.1397186\ttotal: 1.78s\tremaining: 10.5s\n",
      "29:\tlearn: 0.1394529\ttotal: 1.84s\tremaining: 10.5s\n",
      "30:\tlearn: 0.1393238\ttotal: 1.9s\tremaining: 10.3s\n",
      "31:\tlearn: 0.1391374\ttotal: 1.96s\tremaining: 10.3s\n",
      "32:\tlearn: 0.1389941\ttotal: 2s\tremaining: 10.1s\n",
      "33:\tlearn: 0.1387980\ttotal: 2.06s\tremaining: 10.1s\n",
      "34:\tlearn: 0.1386532\ttotal: 2.11s\tremaining: 9.95s\n",
      "35:\tlearn: 0.1385162\ttotal: 2.16s\tremaining: 9.85s\n",
      "36:\tlearn: 0.1383765\ttotal: 2.21s\tremaining: 9.75s\n",
      "37:\tlearn: 0.1381887\ttotal: 2.27s\tremaining: 9.66s\n",
      "38:\tlearn: 0.1380644\ttotal: 2.32s\tremaining: 9.59s\n",
      "39:\tlearn: 0.1379476\ttotal: 2.38s\tremaining: 9.51s\n",
      "40:\tlearn: 0.1378341\ttotal: 2.44s\tremaining: 9.46s\n",
      "41:\tlearn: 0.1376593\ttotal: 2.49s\tremaining: 9.36s\n",
      "42:\tlearn: 0.1375360\ttotal: 2.54s\tremaining: 9.27s\n",
      "43:\tlearn: 0.1373833\ttotal: 2.59s\tremaining: 9.18s\n",
      "44:\tlearn: 0.1372467\ttotal: 2.65s\tremaining: 9.13s\n",
      "45:\tlearn: 0.1371360\ttotal: 2.71s\tremaining: 9.06s\n",
      "46:\tlearn: 0.1370374\ttotal: 2.75s\tremaining: 8.96s\n",
      "47:\tlearn: 0.1368874\ttotal: 2.81s\tremaining: 8.88s\n",
      "48:\tlearn: 0.1367618\ttotal: 2.85s\tremaining: 8.79s\n",
      "49:\tlearn: 0.1366661\ttotal: 2.91s\tremaining: 8.73s\n",
      "50:\tlearn: 0.1365283\ttotal: 2.97s\tremaining: 8.68s\n",
      "51:\tlearn: 0.1363979\ttotal: 3.01s\tremaining: 8.58s\n",
      "52:\tlearn: 0.1362715\ttotal: 3.07s\tremaining: 8.5s\n",
      "53:\tlearn: 0.1361388\ttotal: 3.12s\tremaining: 8.44s\n",
      "54:\tlearn: 0.1359521\ttotal: 3.17s\tremaining: 8.36s\n",
      "55:\tlearn: 0.1358383\ttotal: 3.25s\tremaining: 8.34s\n",
      "56:\tlearn: 0.1357182\ttotal: 3.32s\tremaining: 8.33s\n",
      "57:\tlearn: 0.1356159\ttotal: 3.37s\tremaining: 8.26s\n",
      "58:\tlearn: 0.1355059\ttotal: 3.44s\tremaining: 8.21s\n",
      "59:\tlearn: 0.1354043\ttotal: 3.5s\tremaining: 8.16s\n",
      "60:\tlearn: 0.1352971\ttotal: 3.55s\tremaining: 8.1s\n",
      "61:\tlearn: 0.1351720\ttotal: 3.61s\tremaining: 8.03s\n",
      "62:\tlearn: 0.1350640\ttotal: 3.66s\tremaining: 7.95s\n",
      "63:\tlearn: 0.1349479\ttotal: 3.72s\tremaining: 7.9s\n",
      "64:\tlearn: 0.1348189\ttotal: 3.77s\tremaining: 7.82s\n",
      "65:\tlearn: 0.1346932\ttotal: 3.83s\tremaining: 7.78s\n",
      "66:\tlearn: 0.1345841\ttotal: 3.89s\tremaining: 7.72s\n",
      "67:\tlearn: 0.1344715\ttotal: 3.94s\tremaining: 7.64s\n",
      "68:\tlearn: 0.1343968\ttotal: 3.99s\tremaining: 7.57s\n",
      "69:\tlearn: 0.1342981\ttotal: 4.04s\tremaining: 7.49s\n",
      "70:\tlearn: 0.1341910\ttotal: 4.08s\tremaining: 7.42s\n",
      "71:\tlearn: 0.1341029\ttotal: 4.13s\tremaining: 7.34s\n",
      "72:\tlearn: 0.1340188\ttotal: 4.18s\tremaining: 7.27s\n",
      "73:\tlearn: 0.1339097\ttotal: 4.23s\tremaining: 7.2s\n",
      "74:\tlearn: 0.1337835\ttotal: 4.28s\tremaining: 7.13s\n",
      "75:\tlearn: 0.1336924\ttotal: 4.33s\tremaining: 7.06s\n",
      "76:\tlearn: 0.1335970\ttotal: 4.38s\tremaining: 7s\n",
      "77:\tlearn: 0.1334911\ttotal: 4.45s\tremaining: 6.96s\n",
      "78:\tlearn: 0.1333883\ttotal: 4.5s\tremaining: 6.9s\n",
      "79:\tlearn: 0.1333099\ttotal: 4.56s\tremaining: 6.84s\n",
      "80:\tlearn: 0.1332458\ttotal: 4.62s\tremaining: 6.78s\n",
      "81:\tlearn: 0.1331462\ttotal: 4.67s\tremaining: 6.72s\n",
      "82:\tlearn: 0.1330504\ttotal: 4.73s\tremaining: 6.67s\n",
      "83:\tlearn: 0.1329791\ttotal: 4.79s\tremaining: 6.61s\n",
      "84:\tlearn: 0.1328867\ttotal: 4.83s\tremaining: 6.53s\n",
      "85:\tlearn: 0.1328078\ttotal: 4.88s\tremaining: 6.47s\n",
      "86:\tlearn: 0.1327225\ttotal: 4.94s\tremaining: 6.42s\n",
      "87:\tlearn: 0.1326481\ttotal: 4.99s\tremaining: 6.35s\n",
      "88:\tlearn: 0.1325749\ttotal: 5.04s\tremaining: 6.28s\n",
      "89:\tlearn: 0.1324898\ttotal: 5.11s\tremaining: 6.24s\n",
      "90:\tlearn: 0.1324339\ttotal: 5.16s\tremaining: 6.18s\n",
      "91:\tlearn: 0.1323466\ttotal: 5.21s\tremaining: 6.12s\n",
      "92:\tlearn: 0.1322696\ttotal: 5.26s\tremaining: 6.05s\n",
      "93:\tlearn: 0.1321782\ttotal: 5.31s\tremaining: 5.98s\n",
      "94:\tlearn: 0.1320944\ttotal: 5.37s\tremaining: 5.93s\n",
      "95:\tlearn: 0.1320255\ttotal: 5.43s\tremaining: 5.88s\n",
      "96:\tlearn: 0.1319270\ttotal: 5.47s\tremaining: 5.81s\n",
      "97:\tlearn: 0.1318595\ttotal: 5.53s\tremaining: 5.76s\n",
      "98:\tlearn: 0.1317589\ttotal: 5.6s\tremaining: 5.71s\n",
      "99:\tlearn: 0.1316731\ttotal: 5.64s\tremaining: 5.64s\n",
      "100:\tlearn: 0.1316134\ttotal: 5.7s\tremaining: 5.58s\n",
      "101:\tlearn: 0.1315248\ttotal: 5.74s\tremaining: 5.51s\n",
      "102:\tlearn: 0.1314501\ttotal: 5.79s\tremaining: 5.46s\n",
      "103:\tlearn: 0.1313554\ttotal: 5.84s\tremaining: 5.39s\n",
      "104:\tlearn: 0.1312489\ttotal: 5.89s\tremaining: 5.33s\n",
      "105:\tlearn: 0.1311932\ttotal: 5.95s\tremaining: 5.27s\n",
      "106:\tlearn: 0.1311301\ttotal: 6s\tremaining: 5.21s\n",
      "107:\tlearn: 0.1310502\ttotal: 6.04s\tremaining: 5.14s\n",
      "108:\tlearn: 0.1309293\ttotal: 6.1s\tremaining: 5.09s\n",
      "109:\tlearn: 0.1308380\ttotal: 6.15s\tremaining: 5.03s\n",
      "110:\tlearn: 0.1307763\ttotal: 6.21s\tremaining: 4.98s\n",
      "111:\tlearn: 0.1306999\ttotal: 6.25s\tremaining: 4.92s\n",
      "112:\tlearn: 0.1306176\ttotal: 6.31s\tremaining: 4.86s\n",
      "113:\tlearn: 0.1305508\ttotal: 6.35s\tremaining: 4.79s\n",
      "114:\tlearn: 0.1304863\ttotal: 6.42s\tremaining: 4.75s\n",
      "115:\tlearn: 0.1304068\ttotal: 6.47s\tremaining: 4.69s\n",
      "116:\tlearn: 0.1303458\ttotal: 6.53s\tremaining: 4.63s\n",
      "117:\tlearn: 0.1302620\ttotal: 6.58s\tremaining: 4.57s\n",
      "118:\tlearn: 0.1301956\ttotal: 6.62s\tremaining: 4.5s\n",
      "119:\tlearn: 0.1301370\ttotal: 6.68s\tremaining: 4.45s\n",
      "120:\tlearn: 0.1300439\ttotal: 6.73s\tremaining: 4.39s\n",
      "121:\tlearn: 0.1299950\ttotal: 6.77s\tremaining: 4.33s\n",
      "122:\tlearn: 0.1299240\ttotal: 6.82s\tremaining: 4.27s\n",
      "123:\tlearn: 0.1298647\ttotal: 6.87s\tremaining: 4.21s\n",
      "124:\tlearn: 0.1297940\ttotal: 6.94s\tremaining: 4.16s\n",
      "125:\tlearn: 0.1297213\ttotal: 6.99s\tremaining: 4.11s\n",
      "126:\tlearn: 0.1296503\ttotal: 7.04s\tremaining: 4.05s\n",
      "127:\tlearn: 0.1295791\ttotal: 7.09s\tremaining: 3.99s\n",
      "128:\tlearn: 0.1295256\ttotal: 7.14s\tremaining: 3.93s\n",
      "129:\tlearn: 0.1294372\ttotal: 7.2s\tremaining: 3.88s\n",
      "130:\tlearn: 0.1293607\ttotal: 7.25s\tremaining: 3.82s\n",
      "131:\tlearn: 0.1293106\ttotal: 7.32s\tremaining: 3.77s\n",
      "132:\tlearn: 0.1292514\ttotal: 7.38s\tremaining: 3.72s\n",
      "133:\tlearn: 0.1291961\ttotal: 7.44s\tremaining: 3.66s\n",
      "134:\tlearn: 0.1291142\ttotal: 7.48s\tremaining: 3.6s\n",
      "135:\tlearn: 0.1290322\ttotal: 7.52s\tremaining: 3.54s\n",
      "136:\tlearn: 0.1289685\ttotal: 7.58s\tremaining: 3.48s\n",
      "137:\tlearn: 0.1288849\ttotal: 7.63s\tremaining: 3.43s\n",
      "138:\tlearn: 0.1288126\ttotal: 7.68s\tremaining: 3.37s\n",
      "139:\tlearn: 0.1287442\ttotal: 7.73s\tremaining: 3.31s\n",
      "140:\tlearn: 0.1286598\ttotal: 7.78s\tremaining: 3.25s\n",
      "141:\tlearn: 0.1285507\ttotal: 7.83s\tremaining: 3.2s\n",
      "142:\tlearn: 0.1284962\ttotal: 7.89s\tremaining: 3.15s\n",
      "143:\tlearn: 0.1284333\ttotal: 7.94s\tremaining: 3.09s\n",
      "144:\tlearn: 0.1283592\ttotal: 8s\tremaining: 3.03s\n",
      "145:\tlearn: 0.1282774\ttotal: 8.05s\tremaining: 2.98s\n",
      "146:\tlearn: 0.1282151\ttotal: 8.11s\tremaining: 2.92s\n",
      "147:\tlearn: 0.1281637\ttotal: 8.17s\tremaining: 2.87s\n",
      "148:\tlearn: 0.1280933\ttotal: 8.21s\tremaining: 2.81s\n",
      "149:\tlearn: 0.1280134\ttotal: 8.26s\tremaining: 2.75s\n",
      "150:\tlearn: 0.1279443\ttotal: 8.33s\tremaining: 2.7s\n",
      "151:\tlearn: 0.1278982\ttotal: 8.39s\tremaining: 2.65s\n",
      "152:\tlearn: 0.1278505\ttotal: 8.46s\tremaining: 2.6s\n",
      "153:\tlearn: 0.1277827\ttotal: 8.53s\tremaining: 2.55s\n",
      "154:\tlearn: 0.1277155\ttotal: 8.59s\tremaining: 2.5s\n",
      "155:\tlearn: 0.1276382\ttotal: 8.66s\tremaining: 2.44s\n",
      "156:\tlearn: 0.1275747\ttotal: 8.74s\tremaining: 2.39s\n",
      "157:\tlearn: 0.1275175\ttotal: 8.81s\tremaining: 2.34s\n",
      "158:\tlearn: 0.1274709\ttotal: 8.88s\tremaining: 2.29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159:\tlearn: 0.1274126\ttotal: 8.97s\tremaining: 2.24s\n",
      "160:\tlearn: 0.1273394\ttotal: 9.03s\tremaining: 2.19s\n",
      "161:\tlearn: 0.1272778\ttotal: 9.09s\tremaining: 2.13s\n",
      "162:\tlearn: 0.1271963\ttotal: 9.16s\tremaining: 2.08s\n",
      "163:\tlearn: 0.1271469\ttotal: 9.23s\tremaining: 2.03s\n",
      "164:\tlearn: 0.1270792\ttotal: 9.3s\tremaining: 1.97s\n",
      "165:\tlearn: 0.1270250\ttotal: 9.38s\tremaining: 1.92s\n",
      "166:\tlearn: 0.1269511\ttotal: 9.45s\tremaining: 1.87s\n",
      "167:\tlearn: 0.1269012\ttotal: 9.52s\tremaining: 1.81s\n",
      "168:\tlearn: 0.1268515\ttotal: 9.6s\tremaining: 1.76s\n",
      "169:\tlearn: 0.1267760\ttotal: 9.65s\tremaining: 1.7s\n",
      "170:\tlearn: 0.1267149\ttotal: 9.72s\tremaining: 1.65s\n",
      "171:\tlearn: 0.1266485\ttotal: 9.8s\tremaining: 1.59s\n",
      "172:\tlearn: 0.1265771\ttotal: 9.88s\tremaining: 1.54s\n",
      "173:\tlearn: 0.1265240\ttotal: 9.95s\tremaining: 1.49s\n",
      "174:\tlearn: 0.1264746\ttotal: 10s\tremaining: 1.43s\n",
      "175:\tlearn: 0.1264259\ttotal: 10.1s\tremaining: 1.37s\n",
      "176:\tlearn: 0.1263858\ttotal: 10.1s\tremaining: 1.32s\n",
      "177:\tlearn: 0.1263284\ttotal: 10.2s\tremaining: 1.26s\n",
      "178:\tlearn: 0.1262610\ttotal: 10.3s\tremaining: 1.2s\n",
      "179:\tlearn: 0.1262019\ttotal: 10.3s\tremaining: 1.15s\n",
      "180:\tlearn: 0.1261407\ttotal: 10.4s\tremaining: 1.09s\n",
      "181:\tlearn: 0.1260911\ttotal: 10.4s\tremaining: 1.03s\n",
      "182:\tlearn: 0.1260328\ttotal: 10.5s\tremaining: 975ms\n",
      "183:\tlearn: 0.1259718\ttotal: 10.5s\tremaining: 917ms\n",
      "184:\tlearn: 0.1259195\ttotal: 10.6s\tremaining: 859ms\n",
      "185:\tlearn: 0.1258641\ttotal: 10.7s\tremaining: 803ms\n",
      "186:\tlearn: 0.1258008\ttotal: 10.7s\tremaining: 746ms\n",
      "187:\tlearn: 0.1257339\ttotal: 10.8s\tremaining: 688ms\n",
      "188:\tlearn: 0.1256759\ttotal: 10.8s\tremaining: 631ms\n",
      "189:\tlearn: 0.1256352\ttotal: 10.9s\tremaining: 574ms\n",
      "190:\tlearn: 0.1255702\ttotal: 11s\tremaining: 517ms\n",
      "191:\tlearn: 0.1255216\ttotal: 11s\tremaining: 460ms\n",
      "192:\tlearn: 0.1254848\ttotal: 11.1s\tremaining: 403ms\n",
      "193:\tlearn: 0.1254448\ttotal: 11.2s\tremaining: 346ms\n",
      "194:\tlearn: 0.1253809\ttotal: 11.2s\tremaining: 288ms\n",
      "195:\tlearn: 0.1253292\ttotal: 11.3s\tremaining: 231ms\n",
      "196:\tlearn: 0.1252794\ttotal: 11.4s\tremaining: 173ms\n",
      "197:\tlearn: 0.1252170\ttotal: 11.4s\tremaining: 115ms\n",
      "198:\tlearn: 0.1251578\ttotal: 11.5s\tremaining: 57.7ms\n",
      "199:\tlearn: 0.1251123\ttotal: 11.5s\tremaining: 0us\n",
      "[CV]  learning_rate=1, l2_leaf_reg=9, iterations=200, depth=4, total=  12.1s\n",
      "[CV] learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4 .......\n",
      "0:\tlearn: 0.5532918\ttotal: 68.7ms\tremaining: 34.3s\n",
      "1:\tlearn: 0.4523723\ttotal: 141ms\tremaining: 35.1s\n",
      "2:\tlearn: 0.3814123\ttotal: 203ms\tremaining: 33.6s\n",
      "3:\tlearn: 0.3266455\ttotal: 267ms\tremaining: 33s\n",
      "4:\tlearn: 0.2864931\ttotal: 334ms\tremaining: 33.1s\n",
      "5:\tlearn: 0.2551545\ttotal: 389ms\tremaining: 32s\n",
      "6:\tlearn: 0.2327570\ttotal: 450ms\tremaining: 31.7s\n",
      "7:\tlearn: 0.2169571\ttotal: 507ms\tremaining: 31.2s\n",
      "8:\tlearn: 0.2015102\ttotal: 595ms\tremaining: 32.5s\n",
      "9:\tlearn: 0.1899683\ttotal: 668ms\tremaining: 32.7s\n",
      "10:\tlearn: 0.1826868\ttotal: 721ms\tremaining: 32.1s\n",
      "11:\tlearn: 0.1763564\ttotal: 789ms\tremaining: 32.1s\n",
      "12:\tlearn: 0.1725491\ttotal: 852ms\tremaining: 31.9s\n",
      "13:\tlearn: 0.1686678\ttotal: 936ms\tremaining: 32.5s\n",
      "14:\tlearn: 0.1659384\ttotal: 1.01s\tremaining: 32.8s\n",
      "15:\tlearn: 0.1639134\ttotal: 1.09s\tremaining: 33.2s\n",
      "16:\tlearn: 0.1617837\ttotal: 1.17s\tremaining: 33.2s\n",
      "17:\tlearn: 0.1604060\ttotal: 1.22s\tremaining: 32.6s\n",
      "18:\tlearn: 0.1590799\ttotal: 1.26s\tremaining: 32s\n",
      "19:\tlearn: 0.1578123\ttotal: 1.34s\tremaining: 32.1s\n",
      "20:\tlearn: 0.1566503\ttotal: 1.44s\tremaining: 32.8s\n",
      "21:\tlearn: 0.1560463\ttotal: 1.5s\tremaining: 32.7s\n",
      "22:\tlearn: 0.1553647\ttotal: 1.58s\tremaining: 32.8s\n",
      "23:\tlearn: 0.1545744\ttotal: 1.67s\tremaining: 33.2s\n",
      "24:\tlearn: 0.1538799\ttotal: 1.78s\tremaining: 33.9s\n",
      "25:\tlearn: 0.1533085\ttotal: 1.87s\tremaining: 34.1s\n",
      "26:\tlearn: 0.1527255\ttotal: 1.94s\tremaining: 34.1s\n",
      "27:\tlearn: 0.1524089\ttotal: 2s\tremaining: 33.7s\n",
      "28:\tlearn: 0.1520447\ttotal: 2.07s\tremaining: 33.6s\n",
      "29:\tlearn: 0.1516076\ttotal: 2.16s\tremaining: 33.9s\n",
      "30:\tlearn: 0.1513342\ttotal: 2.22s\tremaining: 33.5s\n",
      "31:\tlearn: 0.1510702\ttotal: 2.29s\tremaining: 33.5s\n",
      "32:\tlearn: 0.1508230\ttotal: 2.37s\tremaining: 33.5s\n",
      "33:\tlearn: 0.1505570\ttotal: 2.47s\tremaining: 33.8s\n",
      "34:\tlearn: 0.1503716\ttotal: 2.54s\tremaining: 33.7s\n",
      "35:\tlearn: 0.1501134\ttotal: 2.6s\tremaining: 33.5s\n",
      "36:\tlearn: 0.1499485\ttotal: 2.67s\tremaining: 33.4s\n",
      "37:\tlearn: 0.1497930\ttotal: 2.72s\tremaining: 33.1s\n",
      "38:\tlearn: 0.1496297\ttotal: 2.78s\tremaining: 32.8s\n",
      "39:\tlearn: 0.1494038\ttotal: 2.85s\tremaining: 32.8s\n",
      "40:\tlearn: 0.1492646\ttotal: 2.91s\tremaining: 32.5s\n",
      "41:\tlearn: 0.1490485\ttotal: 2.96s\tremaining: 32.2s\n",
      "42:\tlearn: 0.1489124\ttotal: 3s\tremaining: 31.9s\n",
      "43:\tlearn: 0.1487984\ttotal: 3.07s\tremaining: 31.8s\n",
      "44:\tlearn: 0.1486519\ttotal: 3.13s\tremaining: 31.7s\n",
      "45:\tlearn: 0.1485220\ttotal: 3.19s\tremaining: 31.5s\n",
      "46:\tlearn: 0.1483547\ttotal: 3.25s\tremaining: 31.3s\n",
      "47:\tlearn: 0.1482205\ttotal: 3.31s\tremaining: 31.2s\n",
      "48:\tlearn: 0.1481208\ttotal: 3.37s\tremaining: 31s\n",
      "49:\tlearn: 0.1480041\ttotal: 3.42s\tremaining: 30.8s\n",
      "50:\tlearn: 0.1479032\ttotal: 3.46s\tremaining: 30.5s\n",
      "51:\tlearn: 0.1477805\ttotal: 3.52s\tremaining: 30.3s\n",
      "52:\tlearn: 0.1477031\ttotal: 3.58s\tremaining: 30.2s\n",
      "53:\tlearn: 0.1475686\ttotal: 3.63s\tremaining: 30s\n",
      "54:\tlearn: 0.1474690\ttotal: 3.69s\tremaining: 29.8s\n",
      "55:\tlearn: 0.1473190\ttotal: 3.75s\tremaining: 29.7s\n",
      "56:\tlearn: 0.1471724\ttotal: 3.81s\tremaining: 29.6s\n",
      "57:\tlearn: 0.1470534\ttotal: 3.88s\tremaining: 29.5s\n",
      "58:\tlearn: 0.1469374\ttotal: 3.95s\tremaining: 29.5s\n",
      "59:\tlearn: 0.1468516\ttotal: 4.02s\tremaining: 29.5s\n",
      "60:\tlearn: 0.1467616\ttotal: 4.07s\tremaining: 29.3s\n",
      "61:\tlearn: 0.1466544\ttotal: 4.13s\tremaining: 29.2s\n",
      "62:\tlearn: 0.1465855\ttotal: 4.19s\tremaining: 29.1s\n",
      "63:\tlearn: 0.1464744\ttotal: 4.27s\tremaining: 29.1s\n",
      "64:\tlearn: 0.1464040\ttotal: 4.32s\tremaining: 28.9s\n",
      "65:\tlearn: 0.1463159\ttotal: 4.39s\tremaining: 28.9s\n",
      "66:\tlearn: 0.1462328\ttotal: 4.44s\tremaining: 28.7s\n",
      "67:\tlearn: 0.1461721\ttotal: 4.51s\tremaining: 28.6s\n",
      "68:\tlearn: 0.1460967\ttotal: 4.57s\tremaining: 28.5s\n",
      "69:\tlearn: 0.1459826\ttotal: 4.63s\tremaining: 28.5s\n",
      "70:\tlearn: 0.1458726\ttotal: 4.71s\tremaining: 28.5s\n",
      "71:\tlearn: 0.1457760\ttotal: 4.77s\tremaining: 28.4s\n",
      "72:\tlearn: 0.1456922\ttotal: 4.83s\tremaining: 28.3s\n",
      "73:\tlearn: 0.1456297\ttotal: 4.88s\tremaining: 28.1s\n",
      "74:\tlearn: 0.1455390\ttotal: 4.95s\tremaining: 28s\n",
      "75:\tlearn: 0.1454806\ttotal: 5.01s\tremaining: 28s\n",
      "76:\tlearn: 0.1453995\ttotal: 5.07s\tremaining: 27.8s\n",
      "77:\tlearn: 0.1453318\ttotal: 5.14s\tremaining: 27.8s\n",
      "78:\tlearn: 0.1452741\ttotal: 5.21s\tremaining: 27.8s\n",
      "79:\tlearn: 0.1452161\ttotal: 5.26s\tremaining: 27.6s\n",
      "80:\tlearn: 0.1451722\ttotal: 5.33s\tremaining: 27.5s\n",
      "81:\tlearn: 0.1450930\ttotal: 5.39s\tremaining: 27.5s\n",
      "82:\tlearn: 0.1449771\ttotal: 5.46s\tremaining: 27.4s\n",
      "83:\tlearn: 0.1448986\ttotal: 5.52s\tremaining: 27.3s\n",
      "84:\tlearn: 0.1448435\ttotal: 5.56s\tremaining: 27.2s\n",
      "85:\tlearn: 0.1447998\ttotal: 5.62s\tremaining: 27.1s\n",
      "86:\tlearn: 0.1447543\ttotal: 5.68s\tremaining: 27s\n",
      "87:\tlearn: 0.1446816\ttotal: 5.74s\tremaining: 26.9s\n",
      "88:\tlearn: 0.1446409\ttotal: 5.79s\tremaining: 26.7s\n",
      "89:\tlearn: 0.1445822\ttotal: 5.83s\tremaining: 26.6s\n",
      "90:\tlearn: 0.1445349\ttotal: 5.88s\tremaining: 26.4s\n",
      "91:\tlearn: 0.1444466\ttotal: 5.95s\tremaining: 26.4s\n",
      "92:\tlearn: 0.1444013\ttotal: 6s\tremaining: 26.3s\n",
      "93:\tlearn: 0.1443298\ttotal: 6.06s\tremaining: 26.2s\n",
      "94:\tlearn: 0.1442804\ttotal: 6.11s\tremaining: 26s\n",
      "95:\tlearn: 0.1442173\ttotal: 6.16s\tremaining: 25.9s\n",
      "96:\tlearn: 0.1441792\ttotal: 6.21s\tremaining: 25.8s\n",
      "97:\tlearn: 0.1441154\ttotal: 6.26s\tremaining: 25.7s\n",
      "98:\tlearn: 0.1440226\ttotal: 6.33s\tremaining: 25.7s\n",
      "99:\tlearn: 0.1439855\ttotal: 6.39s\tremaining: 25.5s\n",
      "100:\tlearn: 0.1439366\ttotal: 6.43s\tremaining: 25.4s\n",
      "101:\tlearn: 0.1438486\ttotal: 6.5s\tremaining: 25.4s\n",
      "102:\tlearn: 0.1437973\ttotal: 6.54s\tremaining: 25.2s\n",
      "103:\tlearn: 0.1437228\ttotal: 6.61s\tremaining: 25.2s\n",
      "104:\tlearn: 0.1436651\ttotal: 6.68s\tremaining: 25.1s\n",
      "105:\tlearn: 0.1436275\ttotal: 6.74s\tremaining: 25s\n",
      "106:\tlearn: 0.1435692\ttotal: 6.79s\tremaining: 24.9s\n",
      "107:\tlearn: 0.1435188\ttotal: 6.85s\tremaining: 24.9s\n",
      "108:\tlearn: 0.1434858\ttotal: 6.89s\tremaining: 24.7s\n",
      "109:\tlearn: 0.1434436\ttotal: 6.95s\tremaining: 24.7s\n",
      "110:\tlearn: 0.1434047\ttotal: 7.01s\tremaining: 24.6s\n",
      "111:\tlearn: 0.1433587\ttotal: 7.07s\tremaining: 24.5s\n",
      "112:\tlearn: 0.1433147\ttotal: 7.12s\tremaining: 24.4s\n",
      "113:\tlearn: 0.1432632\ttotal: 7.17s\tremaining: 24.3s\n",
      "114:\tlearn: 0.1432021\ttotal: 7.22s\tremaining: 24.2s\n",
      "115:\tlearn: 0.1431649\ttotal: 7.3s\tremaining: 24.2s\n",
      "116:\tlearn: 0.1431311\ttotal: 7.4s\tremaining: 24.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117:\tlearn: 0.1430938\ttotal: 7.51s\tremaining: 24.3s\n",
      "118:\tlearn: 0.1430491\ttotal: 7.62s\tremaining: 24.4s\n",
      "119:\tlearn: 0.1429773\ttotal: 7.73s\tremaining: 24.5s\n",
      "120:\tlearn: 0.1429278\ttotal: 7.83s\tremaining: 24.5s\n",
      "121:\tlearn: 0.1428915\ttotal: 7.93s\tremaining: 24.6s\n",
      "122:\tlearn: 0.1428538\ttotal: 8.03s\tremaining: 24.6s\n",
      "123:\tlearn: 0.1428138\ttotal: 8.1s\tremaining: 24.6s\n",
      "124:\tlearn: 0.1427702\ttotal: 8.18s\tremaining: 24.5s\n",
      "125:\tlearn: 0.1427274\ttotal: 8.25s\tremaining: 24.5s\n",
      "126:\tlearn: 0.1426869\ttotal: 8.36s\tremaining: 24.6s\n",
      "127:\tlearn: 0.1426241\ttotal: 8.42s\tremaining: 24.5s\n",
      "128:\tlearn: 0.1425867\ttotal: 8.48s\tremaining: 24.4s\n",
      "129:\tlearn: 0.1425453\ttotal: 8.54s\tremaining: 24.3s\n",
      "130:\tlearn: 0.1424742\ttotal: 8.61s\tremaining: 24.2s\n",
      "131:\tlearn: 0.1424478\ttotal: 8.68s\tremaining: 24.2s\n",
      "132:\tlearn: 0.1424048\ttotal: 8.77s\tremaining: 24.2s\n",
      "133:\tlearn: 0.1423459\ttotal: 8.83s\tremaining: 24.1s\n",
      "134:\tlearn: 0.1423185\ttotal: 8.89s\tremaining: 24s\n",
      "135:\tlearn: 0.1422739\ttotal: 8.97s\tremaining: 24s\n",
      "136:\tlearn: 0.1422349\ttotal: 9.03s\tremaining: 23.9s\n",
      "137:\tlearn: 0.1421969\ttotal: 9.12s\tremaining: 23.9s\n",
      "138:\tlearn: 0.1421650\ttotal: 9.22s\tremaining: 23.9s\n",
      "139:\tlearn: 0.1421224\ttotal: 9.3s\tremaining: 23.9s\n",
      "140:\tlearn: 0.1420958\ttotal: 9.38s\tremaining: 23.9s\n",
      "141:\tlearn: 0.1420582\ttotal: 9.47s\tremaining: 23.9s\n",
      "142:\tlearn: 0.1420275\ttotal: 9.55s\tremaining: 23.8s\n",
      "143:\tlearn: 0.1419802\ttotal: 9.62s\tremaining: 23.8s\n",
      "144:\tlearn: 0.1419467\ttotal: 9.68s\tremaining: 23.7s\n",
      "145:\tlearn: 0.1419156\ttotal: 9.73s\tremaining: 23.6s\n",
      "146:\tlearn: 0.1418846\ttotal: 9.77s\tremaining: 23.5s\n",
      "147:\tlearn: 0.1418331\ttotal: 9.84s\tremaining: 23.4s\n",
      "148:\tlearn: 0.1417839\ttotal: 9.92s\tremaining: 23.4s\n",
      "149:\tlearn: 0.1417332\ttotal: 9.98s\tremaining: 23.3s\n",
      "150:\tlearn: 0.1416703\ttotal: 10s\tremaining: 23.2s\n",
      "151:\tlearn: 0.1416342\ttotal: 10.1s\tremaining: 23.1s\n",
      "152:\tlearn: 0.1415797\ttotal: 10.1s\tremaining: 23s\n",
      "153:\tlearn: 0.1415431\ttotal: 10.2s\tremaining: 22.9s\n",
      "154:\tlearn: 0.1415106\ttotal: 10.3s\tremaining: 22.9s\n",
      "155:\tlearn: 0.1414829\ttotal: 10.3s\tremaining: 22.8s\n",
      "156:\tlearn: 0.1414304\ttotal: 10.4s\tremaining: 22.7s\n",
      "157:\tlearn: 0.1413939\ttotal: 10.4s\tremaining: 22.6s\n",
      "158:\tlearn: 0.1413664\ttotal: 10.5s\tremaining: 22.5s\n",
      "159:\tlearn: 0.1413316\ttotal: 10.5s\tremaining: 22.4s\n",
      "160:\tlearn: 0.1412841\ttotal: 10.6s\tremaining: 22.3s\n",
      "161:\tlearn: 0.1412563\ttotal: 10.7s\tremaining: 22.3s\n",
      "162:\tlearn: 0.1412293\ttotal: 10.7s\tremaining: 22.2s\n",
      "163:\tlearn: 0.1411856\ttotal: 10.8s\tremaining: 22.1s\n",
      "164:\tlearn: 0.1411483\ttotal: 10.8s\tremaining: 22s\n",
      "165:\tlearn: 0.1411227\ttotal: 10.9s\tremaining: 21.9s\n",
      "166:\tlearn: 0.1410889\ttotal: 10.9s\tremaining: 21.8s\n",
      "167:\tlearn: 0.1410511\ttotal: 11s\tremaining: 21.7s\n",
      "168:\tlearn: 0.1410261\ttotal: 11s\tremaining: 21.6s\n",
      "169:\tlearn: 0.1410067\ttotal: 11.1s\tremaining: 21.6s\n",
      "170:\tlearn: 0.1409780\ttotal: 11.1s\tremaining: 21.4s\n",
      "171:\tlearn: 0.1409406\ttotal: 11.2s\tremaining: 21.4s\n",
      "172:\tlearn: 0.1408775\ttotal: 11.3s\tremaining: 21.3s\n",
      "173:\tlearn: 0.1408407\ttotal: 11.3s\tremaining: 21.2s\n",
      "174:\tlearn: 0.1407895\ttotal: 11.4s\tremaining: 21.1s\n",
      "175:\tlearn: 0.1407686\ttotal: 11.4s\tremaining: 21.1s\n",
      "176:\tlearn: 0.1407443\ttotal: 11.5s\tremaining: 21s\n",
      "177:\tlearn: 0.1407046\ttotal: 11.5s\tremaining: 20.9s\n",
      "178:\tlearn: 0.1406664\ttotal: 11.6s\tremaining: 20.8s\n",
      "179:\tlearn: 0.1406352\ttotal: 11.6s\tremaining: 20.7s\n",
      "180:\tlearn: 0.1406154\ttotal: 11.7s\tremaining: 20.6s\n",
      "181:\tlearn: 0.1405705\ttotal: 11.8s\tremaining: 20.5s\n",
      "182:\tlearn: 0.1405338\ttotal: 11.8s\tremaining: 20.5s\n",
      "183:\tlearn: 0.1405029\ttotal: 11.9s\tremaining: 20.4s\n",
      "184:\tlearn: 0.1404801\ttotal: 12s\tremaining: 20.4s\n",
      "185:\tlearn: 0.1404260\ttotal: 12s\tremaining: 20.3s\n",
      "186:\tlearn: 0.1403983\ttotal: 12.1s\tremaining: 20.2s\n",
      "187:\tlearn: 0.1403576\ttotal: 12.1s\tremaining: 20.1s\n",
      "188:\tlearn: 0.1403362\ttotal: 12.2s\tremaining: 20.1s\n",
      "189:\tlearn: 0.1403051\ttotal: 12.3s\tremaining: 20s\n",
      "190:\tlearn: 0.1402854\ttotal: 12.3s\tremaining: 19.9s\n",
      "191:\tlearn: 0.1402340\ttotal: 12.4s\tremaining: 19.8s\n",
      "192:\tlearn: 0.1401969\ttotal: 12.4s\tremaining: 19.8s\n",
      "193:\tlearn: 0.1401715\ttotal: 12.5s\tremaining: 19.7s\n",
      "194:\tlearn: 0.1401455\ttotal: 12.5s\tremaining: 19.6s\n",
      "195:\tlearn: 0.1401168\ttotal: 12.6s\tremaining: 19.5s\n",
      "196:\tlearn: 0.1400981\ttotal: 12.6s\tremaining: 19.4s\n",
      "197:\tlearn: 0.1400643\ttotal: 12.7s\tremaining: 19.3s\n",
      "198:\tlearn: 0.1400331\ttotal: 12.7s\tremaining: 19.3s\n",
      "199:\tlearn: 0.1400077\ttotal: 12.8s\tremaining: 19.2s\n",
      "200:\tlearn: 0.1399699\ttotal: 12.9s\tremaining: 19.1s\n",
      "201:\tlearn: 0.1399360\ttotal: 12.9s\tremaining: 19.1s\n",
      "202:\tlearn: 0.1399105\ttotal: 13s\tremaining: 19s\n",
      "203:\tlearn: 0.1398743\ttotal: 13s\tremaining: 18.9s\n",
      "204:\tlearn: 0.1398507\ttotal: 13.1s\tremaining: 18.8s\n",
      "205:\tlearn: 0.1398281\ttotal: 13.1s\tremaining: 18.7s\n",
      "206:\tlearn: 0.1397968\ttotal: 13.2s\tremaining: 18.7s\n",
      "207:\tlearn: 0.1397776\ttotal: 13.2s\tremaining: 18.6s\n",
      "208:\tlearn: 0.1397276\ttotal: 13.3s\tremaining: 18.5s\n",
      "209:\tlearn: 0.1396992\ttotal: 13.3s\tremaining: 18.4s\n",
      "210:\tlearn: 0.1396636\ttotal: 13.4s\tremaining: 18.4s\n",
      "211:\tlearn: 0.1396393\ttotal: 13.5s\tremaining: 18.3s\n",
      "212:\tlearn: 0.1396173\ttotal: 13.5s\tremaining: 18.2s\n",
      "213:\tlearn: 0.1395936\ttotal: 13.6s\tremaining: 18.1s\n",
      "214:\tlearn: 0.1395733\ttotal: 13.6s\tremaining: 18.1s\n",
      "215:\tlearn: 0.1395503\ttotal: 13.7s\tremaining: 18s\n",
      "216:\tlearn: 0.1395283\ttotal: 13.7s\tremaining: 17.9s\n",
      "217:\tlearn: 0.1394918\ttotal: 13.8s\tremaining: 17.9s\n",
      "218:\tlearn: 0.1394620\ttotal: 13.9s\tremaining: 17.8s\n",
      "219:\tlearn: 0.1394392\ttotal: 13.9s\tremaining: 17.7s\n",
      "220:\tlearn: 0.1394134\ttotal: 14s\tremaining: 17.6s\n",
      "221:\tlearn: 0.1393933\ttotal: 14s\tremaining: 17.6s\n",
      "222:\tlearn: 0.1393685\ttotal: 14.1s\tremaining: 17.5s\n",
      "223:\tlearn: 0.1393495\ttotal: 14.1s\tremaining: 17.4s\n",
      "224:\tlearn: 0.1393062\ttotal: 14.2s\tremaining: 17.3s\n",
      "225:\tlearn: 0.1392719\ttotal: 14.2s\tremaining: 17.2s\n",
      "226:\tlearn: 0.1392448\ttotal: 14.3s\tremaining: 17.1s\n",
      "227:\tlearn: 0.1392176\ttotal: 14.3s\tremaining: 17.1s\n",
      "228:\tlearn: 0.1391936\ttotal: 14.4s\tremaining: 17s\n",
      "229:\tlearn: 0.1391696\ttotal: 14.4s\tremaining: 16.9s\n",
      "230:\tlearn: 0.1391450\ttotal: 14.5s\tremaining: 16.9s\n",
      "231:\tlearn: 0.1391278\ttotal: 14.5s\tremaining: 16.8s\n",
      "232:\tlearn: 0.1390987\ttotal: 14.6s\tremaining: 16.7s\n",
      "233:\tlearn: 0.1390793\ttotal: 14.6s\tremaining: 16.6s\n",
      "234:\tlearn: 0.1390479\ttotal: 14.7s\tremaining: 16.6s\n",
      "235:\tlearn: 0.1390278\ttotal: 14.7s\tremaining: 16.5s\n",
      "236:\tlearn: 0.1390007\ttotal: 14.8s\tremaining: 16.4s\n",
      "237:\tlearn: 0.1389675\ttotal: 14.8s\tremaining: 16.3s\n",
      "238:\tlearn: 0.1389458\ttotal: 14.9s\tremaining: 16.3s\n",
      "239:\tlearn: 0.1389226\ttotal: 14.9s\tremaining: 16.2s\n",
      "240:\tlearn: 0.1388811\ttotal: 15s\tremaining: 16.1s\n",
      "241:\tlearn: 0.1388589\ttotal: 15.1s\tremaining: 16.1s\n",
      "242:\tlearn: 0.1388317\ttotal: 15.1s\tremaining: 16s\n",
      "243:\tlearn: 0.1387885\ttotal: 15.2s\tremaining: 15.9s\n",
      "244:\tlearn: 0.1387625\ttotal: 15.2s\tremaining: 15.9s\n",
      "245:\tlearn: 0.1387285\ttotal: 15.3s\tremaining: 15.8s\n",
      "246:\tlearn: 0.1386948\ttotal: 15.3s\tremaining: 15.7s\n",
      "247:\tlearn: 0.1386735\ttotal: 15.4s\tremaining: 15.7s\n",
      "248:\tlearn: 0.1386431\ttotal: 15.5s\tremaining: 15.6s\n",
      "249:\tlearn: 0.1386231\ttotal: 15.5s\tremaining: 15.5s\n",
      "250:\tlearn: 0.1385961\ttotal: 15.6s\tremaining: 15.5s\n",
      "251:\tlearn: 0.1385818\ttotal: 15.6s\tremaining: 15.4s\n",
      "252:\tlearn: 0.1385551\ttotal: 15.7s\tremaining: 15.3s\n",
      "253:\tlearn: 0.1385329\ttotal: 15.7s\tremaining: 15.2s\n",
      "254:\tlearn: 0.1385016\ttotal: 15.8s\tremaining: 15.2s\n",
      "255:\tlearn: 0.1384819\ttotal: 15.9s\tremaining: 15.1s\n",
      "256:\tlearn: 0.1384600\ttotal: 15.9s\tremaining: 15s\n",
      "257:\tlearn: 0.1384415\ttotal: 16s\tremaining: 15s\n",
      "258:\tlearn: 0.1384154\ttotal: 16s\tremaining: 14.9s\n",
      "259:\tlearn: 0.1383887\ttotal: 16.1s\tremaining: 14.8s\n",
      "260:\tlearn: 0.1383643\ttotal: 16.1s\tremaining: 14.8s\n",
      "261:\tlearn: 0.1383414\ttotal: 16.2s\tremaining: 14.7s\n",
      "262:\tlearn: 0.1383071\ttotal: 16.3s\tremaining: 14.6s\n",
      "263:\tlearn: 0.1382800\ttotal: 16.3s\tremaining: 14.6s\n",
      "264:\tlearn: 0.1382650\ttotal: 16.4s\tremaining: 14.5s\n",
      "265:\tlearn: 0.1382401\ttotal: 16.4s\tremaining: 14.4s\n",
      "266:\tlearn: 0.1382123\ttotal: 16.5s\tremaining: 14.4s\n",
      "267:\tlearn: 0.1381937\ttotal: 16.5s\tremaining: 14.3s\n",
      "268:\tlearn: 0.1381720\ttotal: 16.6s\tremaining: 14.2s\n",
      "269:\tlearn: 0.1381518\ttotal: 16.6s\tremaining: 14.2s\n",
      "270:\tlearn: 0.1381364\ttotal: 16.7s\tremaining: 14.1s\n",
      "271:\tlearn: 0.1381195\ttotal: 16.7s\tremaining: 14s\n",
      "272:\tlearn: 0.1380927\ttotal: 16.8s\tremaining: 14s\n",
      "273:\tlearn: 0.1380542\ttotal: 16.9s\tremaining: 13.9s\n",
      "274:\tlearn: 0.1380332\ttotal: 16.9s\tremaining: 13.8s\n",
      "275:\tlearn: 0.1380131\ttotal: 17s\tremaining: 13.8s\n",
      "276:\tlearn: 0.1379890\ttotal: 17s\tremaining: 13.7s\n",
      "277:\tlearn: 0.1379705\ttotal: 17.1s\tremaining: 13.7s\n",
      "278:\tlearn: 0.1379452\ttotal: 17.1s\tremaining: 13.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279:\tlearn: 0.1379130\ttotal: 17.2s\tremaining: 13.5s\n",
      "280:\tlearn: 0.1378904\ttotal: 17.2s\tremaining: 13.4s\n",
      "281:\tlearn: 0.1378720\ttotal: 17.3s\tremaining: 13.4s\n",
      "282:\tlearn: 0.1378539\ttotal: 17.4s\tremaining: 13.3s\n",
      "283:\tlearn: 0.1378384\ttotal: 17.4s\tremaining: 13.3s\n",
      "284:\tlearn: 0.1378141\ttotal: 17.5s\tremaining: 13.2s\n",
      "285:\tlearn: 0.1377921\ttotal: 17.5s\tremaining: 13.1s\n",
      "286:\tlearn: 0.1377738\ttotal: 17.6s\tremaining: 13s\n",
      "287:\tlearn: 0.1377557\ttotal: 17.6s\tremaining: 13s\n",
      "288:\tlearn: 0.1377356\ttotal: 17.7s\tremaining: 12.9s\n",
      "289:\tlearn: 0.1377176\ttotal: 17.7s\tremaining: 12.8s\n",
      "290:\tlearn: 0.1377006\ttotal: 17.8s\tremaining: 12.8s\n",
      "291:\tlearn: 0.1376799\ttotal: 17.8s\tremaining: 12.7s\n",
      "292:\tlearn: 0.1376540\ttotal: 17.9s\tremaining: 12.6s\n",
      "293:\tlearn: 0.1376220\ttotal: 17.9s\tremaining: 12.6s\n",
      "294:\tlearn: 0.1376067\ttotal: 18s\tremaining: 12.5s\n",
      "295:\tlearn: 0.1375887\ttotal: 18s\tremaining: 12.4s\n",
      "296:\tlearn: 0.1375654\ttotal: 18.1s\tremaining: 12.4s\n",
      "297:\tlearn: 0.1375413\ttotal: 18.1s\tremaining: 12.3s\n",
      "298:\tlearn: 0.1375217\ttotal: 18.2s\tremaining: 12.2s\n",
      "299:\tlearn: 0.1374920\ttotal: 18.2s\tremaining: 12.2s\n",
      "300:\tlearn: 0.1374760\ttotal: 18.3s\tremaining: 12.1s\n",
      "301:\tlearn: 0.1374537\ttotal: 18.4s\tremaining: 12s\n",
      "302:\tlearn: 0.1374142\ttotal: 18.4s\tremaining: 12s\n",
      "303:\tlearn: 0.1373904\ttotal: 18.5s\tremaining: 11.9s\n",
      "304:\tlearn: 0.1373715\ttotal: 18.5s\tremaining: 11.8s\n",
      "305:\tlearn: 0.1373504\ttotal: 18.6s\tremaining: 11.8s\n",
      "306:\tlearn: 0.1373331\ttotal: 18.6s\tremaining: 11.7s\n",
      "307:\tlearn: 0.1373134\ttotal: 18.6s\tremaining: 11.6s\n",
      "308:\tlearn: 0.1372881\ttotal: 18.7s\tremaining: 11.6s\n",
      "309:\tlearn: 0.1372624\ttotal: 18.8s\tremaining: 11.5s\n",
      "310:\tlearn: 0.1372498\ttotal: 18.8s\tremaining: 11.4s\n",
      "311:\tlearn: 0.1372324\ttotal: 18.9s\tremaining: 11.4s\n",
      "312:\tlearn: 0.1372113\ttotal: 18.9s\tremaining: 11.3s\n",
      "313:\tlearn: 0.1371905\ttotal: 19s\tremaining: 11.2s\n",
      "314:\tlearn: 0.1371683\ttotal: 19s\tremaining: 11.2s\n",
      "315:\tlearn: 0.1371536\ttotal: 19.1s\tremaining: 11.1s\n",
      "316:\tlearn: 0.1371368\ttotal: 19.1s\tremaining: 11s\n",
      "317:\tlearn: 0.1371211\ttotal: 19.2s\tremaining: 11s\n",
      "318:\tlearn: 0.1370979\ttotal: 19.2s\tremaining: 10.9s\n",
      "319:\tlearn: 0.1370866\ttotal: 19.3s\tremaining: 10.8s\n",
      "320:\tlearn: 0.1370718\ttotal: 19.3s\tremaining: 10.8s\n",
      "321:\tlearn: 0.1370430\ttotal: 19.4s\tremaining: 10.7s\n",
      "322:\tlearn: 0.1370237\ttotal: 19.4s\tremaining: 10.7s\n",
      "323:\tlearn: 0.1370071\ttotal: 19.5s\tremaining: 10.6s\n",
      "324:\tlearn: 0.1369838\ttotal: 19.6s\tremaining: 10.5s\n",
      "325:\tlearn: 0.1369614\ttotal: 19.6s\tremaining: 10.5s\n",
      "326:\tlearn: 0.1369426\ttotal: 19.7s\tremaining: 10.4s\n",
      "327:\tlearn: 0.1369213\ttotal: 19.7s\tremaining: 10.3s\n",
      "328:\tlearn: 0.1368988\ttotal: 19.8s\tremaining: 10.3s\n",
      "329:\tlearn: 0.1368780\ttotal: 19.8s\tremaining: 10.2s\n",
      "330:\tlearn: 0.1368617\ttotal: 19.9s\tremaining: 10.2s\n",
      "331:\tlearn: 0.1368418\ttotal: 19.9s\tremaining: 10.1s\n",
      "332:\tlearn: 0.1368263\ttotal: 20s\tremaining: 10s\n",
      "333:\tlearn: 0.1368097\ttotal: 20.1s\tremaining: 9.97s\n",
      "334:\tlearn: 0.1367851\ttotal: 20.1s\tremaining: 9.9s\n",
      "335:\tlearn: 0.1367625\ttotal: 20.2s\tremaining: 9.84s\n",
      "336:\tlearn: 0.1367323\ttotal: 20.2s\tremaining: 9.78s\n",
      "337:\tlearn: 0.1367202\ttotal: 20.3s\tremaining: 9.71s\n",
      "338:\tlearn: 0.1366986\ttotal: 20.3s\tremaining: 9.64s\n",
      "339:\tlearn: 0.1366806\ttotal: 20.4s\tremaining: 9.58s\n",
      "340:\tlearn: 0.1366565\ttotal: 20.4s\tremaining: 9.53s\n",
      "341:\tlearn: 0.1366421\ttotal: 20.5s\tremaining: 9.46s\n",
      "342:\tlearn: 0.1366278\ttotal: 20.5s\tremaining: 9.4s\n",
      "343:\tlearn: 0.1366132\ttotal: 20.6s\tremaining: 9.34s\n",
      "344:\tlearn: 0.1365945\ttotal: 20.6s\tremaining: 9.27s\n",
      "345:\tlearn: 0.1365783\ttotal: 20.7s\tremaining: 9.22s\n",
      "346:\tlearn: 0.1365593\ttotal: 20.8s\tremaining: 9.16s\n",
      "347:\tlearn: 0.1365420\ttotal: 20.8s\tremaining: 9.11s\n",
      "348:\tlearn: 0.1365209\ttotal: 20.9s\tremaining: 9.04s\n",
      "349:\tlearn: 0.1365055\ttotal: 20.9s\tremaining: 8.98s\n",
      "350:\tlearn: 0.1364905\ttotal: 21s\tremaining: 8.92s\n",
      "351:\tlearn: 0.1364720\ttotal: 21.1s\tremaining: 8.85s\n",
      "352:\tlearn: 0.1364474\ttotal: 21.1s\tremaining: 8.79s\n",
      "353:\tlearn: 0.1364244\ttotal: 21.2s\tremaining: 8.73s\n",
      "354:\tlearn: 0.1364018\ttotal: 21.2s\tremaining: 8.67s\n",
      "355:\tlearn: 0.1363788\ttotal: 21.3s\tremaining: 8.62s\n",
      "356:\tlearn: 0.1363597\ttotal: 21.4s\tremaining: 8.56s\n",
      "357:\tlearn: 0.1363373\ttotal: 21.4s\tremaining: 8.49s\n",
      "358:\tlearn: 0.1363130\ttotal: 21.5s\tremaining: 8.43s\n",
      "359:\tlearn: 0.1362956\ttotal: 21.5s\tremaining: 8.37s\n",
      "360:\tlearn: 0.1362738\ttotal: 21.6s\tremaining: 8.31s\n",
      "361:\tlearn: 0.1362597\ttotal: 21.6s\tremaining: 8.25s\n",
      "362:\tlearn: 0.1362402\ttotal: 21.7s\tremaining: 8.19s\n",
      "363:\tlearn: 0.1362205\ttotal: 21.7s\tremaining: 8.12s\n",
      "364:\tlearn: 0.1362056\ttotal: 21.8s\tremaining: 8.05s\n",
      "365:\tlearn: 0.1361859\ttotal: 21.8s\tremaining: 7.99s\n",
      "366:\tlearn: 0.1361763\ttotal: 21.9s\tremaining: 7.93s\n",
      "367:\tlearn: 0.1361533\ttotal: 21.9s\tremaining: 7.87s\n",
      "368:\tlearn: 0.1361399\ttotal: 22s\tremaining: 7.81s\n",
      "369:\tlearn: 0.1361259\ttotal: 22.1s\tremaining: 7.75s\n",
      "370:\tlearn: 0.1361083\ttotal: 22.1s\tremaining: 7.69s\n",
      "371:\tlearn: 0.1360935\ttotal: 22.2s\tremaining: 7.63s\n",
      "372:\tlearn: 0.1360723\ttotal: 22.2s\tremaining: 7.57s\n",
      "373:\tlearn: 0.1360567\ttotal: 22.3s\tremaining: 7.51s\n",
      "374:\tlearn: 0.1360433\ttotal: 22.3s\tremaining: 7.45s\n",
      "375:\tlearn: 0.1360258\ttotal: 22.4s\tremaining: 7.39s\n",
      "376:\tlearn: 0.1360055\ttotal: 22.4s\tremaining: 7.32s\n",
      "377:\tlearn: 0.1359838\ttotal: 22.5s\tremaining: 7.26s\n",
      "378:\tlearn: 0.1359610\ttotal: 22.5s\tremaining: 7.2s\n",
      "379:\tlearn: 0.1359437\ttotal: 22.6s\tremaining: 7.14s\n",
      "380:\tlearn: 0.1359259\ttotal: 22.7s\tremaining: 7.08s\n",
      "381:\tlearn: 0.1359146\ttotal: 22.7s\tremaining: 7.02s\n",
      "382:\tlearn: 0.1358960\ttotal: 22.8s\tremaining: 6.96s\n",
      "383:\tlearn: 0.1358830\ttotal: 22.8s\tremaining: 6.89s\n",
      "384:\tlearn: 0.1358712\ttotal: 22.9s\tremaining: 6.84s\n",
      "385:\tlearn: 0.1358521\ttotal: 23s\tremaining: 6.78s\n",
      "386:\tlearn: 0.1358358\ttotal: 23s\tremaining: 6.72s\n",
      "387:\tlearn: 0.1358158\ttotal: 23.1s\tremaining: 6.66s\n",
      "388:\tlearn: 0.1357879\ttotal: 23.1s\tremaining: 6.6s\n",
      "389:\tlearn: 0.1357700\ttotal: 23.2s\tremaining: 6.54s\n",
      "390:\tlearn: 0.1357531\ttotal: 23.2s\tremaining: 6.48s\n",
      "391:\tlearn: 0.1357370\ttotal: 23.3s\tremaining: 6.42s\n",
      "392:\tlearn: 0.1357201\ttotal: 23.4s\tremaining: 6.37s\n",
      "393:\tlearn: 0.1357019\ttotal: 23.4s\tremaining: 6.31s\n",
      "394:\tlearn: 0.1356864\ttotal: 23.5s\tremaining: 6.25s\n",
      "395:\tlearn: 0.1356708\ttotal: 23.6s\tremaining: 6.2s\n",
      "396:\tlearn: 0.1356591\ttotal: 23.7s\tremaining: 6.14s\n",
      "397:\tlearn: 0.1356381\ttotal: 23.8s\tremaining: 6.09s\n",
      "398:\tlearn: 0.1356210\ttotal: 23.8s\tremaining: 6.03s\n",
      "399:\tlearn: 0.1356031\ttotal: 23.9s\tremaining: 5.97s\n",
      "400:\tlearn: 0.1355884\ttotal: 24s\tremaining: 5.92s\n",
      "401:\tlearn: 0.1355705\ttotal: 24s\tremaining: 5.86s\n",
      "402:\tlearn: 0.1355575\ttotal: 24.1s\tremaining: 5.81s\n",
      "403:\tlearn: 0.1355415\ttotal: 24.2s\tremaining: 5.75s\n",
      "404:\tlearn: 0.1355231\ttotal: 24.3s\tremaining: 5.69s\n",
      "405:\tlearn: 0.1355063\ttotal: 24.3s\tremaining: 5.64s\n",
      "406:\tlearn: 0.1354957\ttotal: 24.4s\tremaining: 5.57s\n",
      "407:\tlearn: 0.1354804\ttotal: 24.5s\tremaining: 5.51s\n",
      "408:\tlearn: 0.1354674\ttotal: 24.5s\tremaining: 5.45s\n",
      "409:\tlearn: 0.1354553\ttotal: 24.6s\tremaining: 5.39s\n",
      "410:\tlearn: 0.1354354\ttotal: 24.6s\tremaining: 5.33s\n",
      "411:\tlearn: 0.1354176\ttotal: 24.7s\tremaining: 5.27s\n",
      "412:\tlearn: 0.1354029\ttotal: 24.7s\tremaining: 5.21s\n",
      "413:\tlearn: 0.1353831\ttotal: 24.8s\tremaining: 5.14s\n",
      "414:\tlearn: 0.1353669\ttotal: 24.8s\tremaining: 5.08s\n",
      "415:\tlearn: 0.1353553\ttotal: 24.9s\tremaining: 5.02s\n",
      "416:\tlearn: 0.1353363\ttotal: 24.9s\tremaining: 4.96s\n",
      "417:\tlearn: 0.1353236\ttotal: 25s\tremaining: 4.9s\n",
      "418:\tlearn: 0.1353107\ttotal: 25.1s\tremaining: 4.84s\n",
      "419:\tlearn: 0.1352920\ttotal: 25.1s\tremaining: 4.78s\n",
      "420:\tlearn: 0.1352730\ttotal: 25.2s\tremaining: 4.72s\n",
      "421:\tlearn: 0.1352571\ttotal: 25.2s\tremaining: 4.66s\n",
      "422:\tlearn: 0.1352448\ttotal: 25.3s\tremaining: 4.61s\n",
      "423:\tlearn: 0.1352238\ttotal: 25.4s\tremaining: 4.54s\n",
      "424:\tlearn: 0.1352120\ttotal: 25.4s\tremaining: 4.48s\n",
      "425:\tlearn: 0.1351877\ttotal: 25.5s\tremaining: 4.42s\n",
      "426:\tlearn: 0.1351716\ttotal: 25.5s\tremaining: 4.37s\n",
      "427:\tlearn: 0.1351537\ttotal: 25.6s\tremaining: 4.31s\n",
      "428:\tlearn: 0.1351413\ttotal: 25.7s\tremaining: 4.26s\n",
      "429:\tlearn: 0.1351117\ttotal: 25.8s\tremaining: 4.2s\n",
      "430:\tlearn: 0.1350988\ttotal: 25.9s\tremaining: 4.14s\n",
      "431:\tlearn: 0.1350777\ttotal: 25.9s\tremaining: 4.08s\n",
      "432:\tlearn: 0.1350638\ttotal: 26s\tremaining: 4.03s\n",
      "433:\tlearn: 0.1350518\ttotal: 26.1s\tremaining: 3.97s\n",
      "434:\tlearn: 0.1350371\ttotal: 26.2s\tremaining: 3.91s\n",
      "435:\tlearn: 0.1350243\ttotal: 26.3s\tremaining: 3.85s\n",
      "436:\tlearn: 0.1350095\ttotal: 26.3s\tremaining: 3.79s\n",
      "437:\tlearn: 0.1349914\ttotal: 26.4s\tremaining: 3.73s\n",
      "438:\tlearn: 0.1349750\ttotal: 26.4s\tremaining: 3.67s\n",
      "439:\tlearn: 0.1349578\ttotal: 26.5s\tremaining: 3.61s\n",
      "440:\tlearn: 0.1349407\ttotal: 26.5s\tremaining: 3.55s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441:\tlearn: 0.1349260\ttotal: 26.6s\tremaining: 3.49s\n",
      "442:\tlearn: 0.1349133\ttotal: 26.7s\tremaining: 3.43s\n",
      "443:\tlearn: 0.1348986\ttotal: 26.7s\tremaining: 3.37s\n",
      "444:\tlearn: 0.1348827\ttotal: 26.8s\tremaining: 3.31s\n",
      "445:\tlearn: 0.1348696\ttotal: 26.9s\tremaining: 3.25s\n",
      "446:\tlearn: 0.1348562\ttotal: 26.9s\tremaining: 3.19s\n",
      "447:\tlearn: 0.1348317\ttotal: 27s\tremaining: 3.13s\n",
      "448:\tlearn: 0.1348179\ttotal: 27.1s\tremaining: 3.07s\n",
      "449:\tlearn: 0.1348012\ttotal: 27.1s\tremaining: 3.01s\n",
      "450:\tlearn: 0.1347910\ttotal: 27.2s\tremaining: 2.95s\n",
      "451:\tlearn: 0.1347747\ttotal: 27.2s\tremaining: 2.89s\n",
      "452:\tlearn: 0.1347570\ttotal: 27.3s\tremaining: 2.83s\n",
      "453:\tlearn: 0.1347393\ttotal: 27.3s\tremaining: 2.77s\n",
      "454:\tlearn: 0.1347211\ttotal: 27.4s\tremaining: 2.71s\n",
      "455:\tlearn: 0.1347082\ttotal: 27.5s\tremaining: 2.65s\n",
      "456:\tlearn: 0.1346950\ttotal: 27.5s\tremaining: 2.59s\n",
      "457:\tlearn: 0.1346810\ttotal: 27.6s\tremaining: 2.53s\n",
      "458:\tlearn: 0.1346684\ttotal: 27.6s\tremaining: 2.47s\n",
      "459:\tlearn: 0.1346486\ttotal: 27.7s\tremaining: 2.41s\n",
      "460:\tlearn: 0.1346337\ttotal: 27.7s\tremaining: 2.35s\n",
      "461:\tlearn: 0.1346181\ttotal: 27.8s\tremaining: 2.28s\n",
      "462:\tlearn: 0.1346010\ttotal: 27.8s\tremaining: 2.23s\n",
      "463:\tlearn: 0.1345816\ttotal: 27.9s\tremaining: 2.17s\n",
      "464:\tlearn: 0.1345642\ttotal: 28s\tremaining: 2.1s\n",
      "465:\tlearn: 0.1345474\ttotal: 28s\tremaining: 2.04s\n",
      "466:\tlearn: 0.1345334\ttotal: 28.1s\tremaining: 1.98s\n",
      "467:\tlearn: 0.1345160\ttotal: 28.1s\tremaining: 1.92s\n",
      "468:\tlearn: 0.1345050\ttotal: 28.2s\tremaining: 1.86s\n",
      "469:\tlearn: 0.1344936\ttotal: 28.2s\tremaining: 1.8s\n",
      "470:\tlearn: 0.1344781\ttotal: 28.3s\tremaining: 1.74s\n",
      "471:\tlearn: 0.1344651\ttotal: 28.3s\tremaining: 1.68s\n",
      "472:\tlearn: 0.1344507\ttotal: 28.4s\tremaining: 1.62s\n",
      "473:\tlearn: 0.1344417\ttotal: 28.4s\tremaining: 1.56s\n",
      "474:\tlearn: 0.1344257\ttotal: 28.5s\tremaining: 1.5s\n",
      "475:\tlearn: 0.1344091\ttotal: 28.6s\tremaining: 1.44s\n",
      "476:\tlearn: 0.1343964\ttotal: 28.6s\tremaining: 1.38s\n",
      "477:\tlearn: 0.1343784\ttotal: 28.7s\tremaining: 1.32s\n",
      "478:\tlearn: 0.1343650\ttotal: 28.7s\tremaining: 1.26s\n",
      "479:\tlearn: 0.1343410\ttotal: 28.8s\tremaining: 1.2s\n",
      "480:\tlearn: 0.1343272\ttotal: 28.8s\tremaining: 1.14s\n",
      "481:\tlearn: 0.1343152\ttotal: 28.9s\tremaining: 1.08s\n",
      "482:\tlearn: 0.1342972\ttotal: 29s\tremaining: 1.02s\n",
      "483:\tlearn: 0.1342835\ttotal: 29s\tremaining: 959ms\n",
      "484:\tlearn: 0.1342674\ttotal: 29.1s\tremaining: 899ms\n",
      "485:\tlearn: 0.1342509\ttotal: 29.1s\tremaining: 838ms\n",
      "486:\tlearn: 0.1342382\ttotal: 29.2s\tremaining: 779ms\n",
      "487:\tlearn: 0.1342217\ttotal: 29.2s\tremaining: 719ms\n",
      "488:\tlearn: 0.1341991\ttotal: 29.3s\tremaining: 659ms\n",
      "489:\tlearn: 0.1341857\ttotal: 29.4s\tremaining: 599ms\n",
      "490:\tlearn: 0.1341704\ttotal: 29.4s\tremaining: 539ms\n",
      "491:\tlearn: 0.1341460\ttotal: 29.5s\tremaining: 479ms\n",
      "492:\tlearn: 0.1341323\ttotal: 29.6s\tremaining: 420ms\n",
      "493:\tlearn: 0.1341177\ttotal: 29.6s\tremaining: 360ms\n",
      "494:\tlearn: 0.1340921\ttotal: 29.7s\tremaining: 300ms\n",
      "495:\tlearn: 0.1340769\ttotal: 29.7s\tremaining: 240ms\n",
      "496:\tlearn: 0.1340611\ttotal: 29.8s\tremaining: 180ms\n",
      "497:\tlearn: 0.1340506\ttotal: 29.8s\tremaining: 120ms\n",
      "498:\tlearn: 0.1340404\ttotal: 29.9s\tremaining: 60ms\n",
      "499:\tlearn: 0.1340250\ttotal: 30s\tremaining: 0us\n",
      "[CV]  learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4, total=  30.6s\n",
      "[CV] learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4 .......\n",
      "0:\tlearn: 0.5531661\ttotal: 70.2ms\tremaining: 35s\n",
      "1:\tlearn: 0.4522009\ttotal: 136ms\tremaining: 34s\n",
      "2:\tlearn: 0.3813172\ttotal: 192ms\tremaining: 31.8s\n",
      "3:\tlearn: 0.3279210\ttotal: 250ms\tremaining: 31s\n",
      "4:\tlearn: 0.2875931\ttotal: 309ms\tremaining: 30.5s\n",
      "5:\tlearn: 0.2557125\ttotal: 393ms\tremaining: 32.3s\n",
      "6:\tlearn: 0.2323468\ttotal: 454ms\tremaining: 32s\n",
      "7:\tlearn: 0.2142511\ttotal: 512ms\tremaining: 31.5s\n",
      "8:\tlearn: 0.2019613\ttotal: 577ms\tremaining: 31.5s\n",
      "9:\tlearn: 0.1928645\ttotal: 637ms\tremaining: 31.2s\n",
      "10:\tlearn: 0.1833730\ttotal: 710ms\tremaining: 31.6s\n",
      "11:\tlearn: 0.1783083\ttotal: 776ms\tremaining: 31.6s\n",
      "12:\tlearn: 0.1739069\ttotal: 837ms\tremaining: 31.3s\n",
      "13:\tlearn: 0.1692865\ttotal: 901ms\tremaining: 31.3s\n",
      "14:\tlearn: 0.1660867\ttotal: 966ms\tremaining: 31.2s\n",
      "15:\tlearn: 0.1631484\ttotal: 1.04s\tremaining: 31.5s\n",
      "16:\tlearn: 0.1613978\ttotal: 1.1s\tremaining: 31.3s\n",
      "17:\tlearn: 0.1597922\ttotal: 1.17s\tremaining: 31.2s\n",
      "18:\tlearn: 0.1587338\ttotal: 1.22s\tremaining: 30.9s\n",
      "19:\tlearn: 0.1573991\ttotal: 1.3s\tremaining: 31.2s\n",
      "20:\tlearn: 0.1562582\ttotal: 1.38s\tremaining: 31.5s\n",
      "21:\tlearn: 0.1554487\ttotal: 1.45s\tremaining: 31.5s\n",
      "22:\tlearn: 0.1548271\ttotal: 1.5s\tremaining: 31.1s\n",
      "23:\tlearn: 0.1543506\ttotal: 1.55s\tremaining: 30.8s\n",
      "24:\tlearn: 0.1539974\ttotal: 1.6s\tremaining: 30.4s\n",
      "25:\tlearn: 0.1533490\ttotal: 1.67s\tremaining: 30.5s\n",
      "26:\tlearn: 0.1529097\ttotal: 1.74s\tremaining: 30.5s\n",
      "27:\tlearn: 0.1525201\ttotal: 1.81s\tremaining: 30.6s\n",
      "28:\tlearn: 0.1520077\ttotal: 1.87s\tremaining: 30.4s\n",
      "29:\tlearn: 0.1516308\ttotal: 1.93s\tremaining: 30.3s\n",
      "30:\tlearn: 0.1512385\ttotal: 2s\tremaining: 30.2s\n",
      "31:\tlearn: 0.1508367\ttotal: 2.06s\tremaining: 30.1s\n",
      "32:\tlearn: 0.1506164\ttotal: 2.11s\tremaining: 29.9s\n",
      "33:\tlearn: 0.1504328\ttotal: 2.16s\tremaining: 29.7s\n",
      "34:\tlearn: 0.1501511\ttotal: 2.22s\tremaining: 29.5s\n",
      "35:\tlearn: 0.1499255\ttotal: 2.29s\tremaining: 29.5s\n",
      "36:\tlearn: 0.1497814\ttotal: 2.35s\tremaining: 29.4s\n",
      "37:\tlearn: 0.1495642\ttotal: 2.42s\tremaining: 29.4s\n",
      "38:\tlearn: 0.1493794\ttotal: 2.47s\tremaining: 29.2s\n",
      "39:\tlearn: 0.1492014\ttotal: 2.53s\tremaining: 29.1s\n",
      "40:\tlearn: 0.1490724\ttotal: 2.58s\tremaining: 28.9s\n",
      "41:\tlearn: 0.1489191\ttotal: 2.64s\tremaining: 28.8s\n",
      "42:\tlearn: 0.1487709\ttotal: 2.7s\tremaining: 28.7s\n",
      "43:\tlearn: 0.1486347\ttotal: 2.77s\tremaining: 28.7s\n",
      "44:\tlearn: 0.1484930\ttotal: 2.83s\tremaining: 28.6s\n",
      "45:\tlearn: 0.1483811\ttotal: 2.88s\tremaining: 28.4s\n",
      "46:\tlearn: 0.1482585\ttotal: 2.93s\tremaining: 28.2s\n",
      "47:\tlearn: 0.1480495\ttotal: 2.99s\tremaining: 28.2s\n",
      "48:\tlearn: 0.1478405\ttotal: 3.06s\tremaining: 28.2s\n",
      "49:\tlearn: 0.1477346\ttotal: 3.12s\tremaining: 28.1s\n",
      "50:\tlearn: 0.1476378\ttotal: 3.17s\tremaining: 28s\n",
      "51:\tlearn: 0.1475507\ttotal: 3.23s\tremaining: 27.8s\n",
      "52:\tlearn: 0.1474048\ttotal: 3.29s\tremaining: 27.8s\n",
      "53:\tlearn: 0.1472649\ttotal: 3.34s\tremaining: 27.6s\n",
      "54:\tlearn: 0.1471507\ttotal: 3.39s\tremaining: 27.4s\n",
      "55:\tlearn: 0.1470238\ttotal: 3.45s\tremaining: 27.4s\n",
      "56:\tlearn: 0.1469055\ttotal: 3.52s\tremaining: 27.3s\n",
      "57:\tlearn: 0.1468273\ttotal: 3.57s\tremaining: 27.2s\n",
      "58:\tlearn: 0.1467069\ttotal: 3.64s\tremaining: 27.2s\n",
      "59:\tlearn: 0.1466050\ttotal: 3.71s\tremaining: 27.2s\n",
      "60:\tlearn: 0.1465347\ttotal: 3.77s\tremaining: 27.1s\n",
      "61:\tlearn: 0.1464554\ttotal: 3.83s\tremaining: 27.1s\n",
      "62:\tlearn: 0.1463669\ttotal: 3.88s\tremaining: 26.9s\n",
      "63:\tlearn: 0.1462772\ttotal: 3.94s\tremaining: 26.8s\n",
      "64:\tlearn: 0.1462076\ttotal: 4s\tremaining: 26.8s\n",
      "65:\tlearn: 0.1460512\ttotal: 4.05s\tremaining: 26.6s\n",
      "66:\tlearn: 0.1459993\ttotal: 4.09s\tremaining: 26.5s\n",
      "67:\tlearn: 0.1458947\ttotal: 4.15s\tremaining: 26.4s\n",
      "68:\tlearn: 0.1458103\ttotal: 4.22s\tremaining: 26.3s\n",
      "69:\tlearn: 0.1457012\ttotal: 4.27s\tremaining: 26.2s\n",
      "70:\tlearn: 0.1456372\ttotal: 4.32s\tremaining: 26.1s\n",
      "71:\tlearn: 0.1455815\ttotal: 4.38s\tremaining: 26s\n",
      "72:\tlearn: 0.1454766\ttotal: 4.45s\tremaining: 26s\n",
      "73:\tlearn: 0.1454164\ttotal: 4.5s\tremaining: 25.9s\n",
      "74:\tlearn: 0.1453566\ttotal: 4.56s\tremaining: 25.9s\n",
      "75:\tlearn: 0.1452502\ttotal: 4.62s\tremaining: 25.8s\n",
      "76:\tlearn: 0.1451256\ttotal: 4.68s\tremaining: 25.7s\n",
      "77:\tlearn: 0.1450553\ttotal: 4.73s\tremaining: 25.6s\n",
      "78:\tlearn: 0.1449421\ttotal: 4.78s\tremaining: 25.5s\n",
      "79:\tlearn: 0.1448758\ttotal: 4.85s\tremaining: 25.5s\n",
      "80:\tlearn: 0.1448026\ttotal: 4.92s\tremaining: 25.4s\n",
      "81:\tlearn: 0.1447539\ttotal: 4.97s\tremaining: 25.3s\n",
      "82:\tlearn: 0.1447044\ttotal: 5.01s\tremaining: 25.2s\n",
      "83:\tlearn: 0.1446423\ttotal: 5.07s\tremaining: 25.1s\n",
      "84:\tlearn: 0.1445725\ttotal: 5.12s\tremaining: 25s\n",
      "85:\tlearn: 0.1445126\ttotal: 5.17s\tremaining: 24.9s\n",
      "86:\tlearn: 0.1444464\ttotal: 5.24s\tremaining: 24.9s\n",
      "87:\tlearn: 0.1443617\ttotal: 5.29s\tremaining: 24.8s\n",
      "88:\tlearn: 0.1443122\ttotal: 5.35s\tremaining: 24.7s\n",
      "89:\tlearn: 0.1442702\ttotal: 5.4s\tremaining: 24.6s\n",
      "90:\tlearn: 0.1442081\ttotal: 5.45s\tremaining: 24.5s\n",
      "91:\tlearn: 0.1441374\ttotal: 5.5s\tremaining: 24.4s\n",
      "92:\tlearn: 0.1440946\ttotal: 5.57s\tremaining: 24.4s\n",
      "93:\tlearn: 0.1440478\ttotal: 5.63s\tremaining: 24.3s\n",
      "94:\tlearn: 0.1439949\ttotal: 5.69s\tremaining: 24.3s\n",
      "95:\tlearn: 0.1439107\ttotal: 5.75s\tremaining: 24.2s\n",
      "96:\tlearn: 0.1438526\ttotal: 5.82s\tremaining: 24.2s\n",
      "97:\tlearn: 0.1438051\ttotal: 5.88s\tremaining: 24.1s\n",
      "98:\tlearn: 0.1437371\ttotal: 5.95s\tremaining: 24.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99:\tlearn: 0.1436895\ttotal: 6.01s\tremaining: 24s\n",
      "100:\tlearn: 0.1436492\ttotal: 6.05s\tremaining: 23.9s\n",
      "101:\tlearn: 0.1435939\ttotal: 6.11s\tremaining: 23.9s\n",
      "102:\tlearn: 0.1435594\ttotal: 6.16s\tremaining: 23.8s\n",
      "103:\tlearn: 0.1435004\ttotal: 6.21s\tremaining: 23.6s\n",
      "104:\tlearn: 0.1434622\ttotal: 6.27s\tremaining: 23.6s\n",
      "105:\tlearn: 0.1434170\ttotal: 6.32s\tremaining: 23.5s\n",
      "106:\tlearn: 0.1433526\ttotal: 6.37s\tremaining: 23.4s\n",
      "107:\tlearn: 0.1432505\ttotal: 6.43s\tremaining: 23.3s\n",
      "108:\tlearn: 0.1431971\ttotal: 6.49s\tremaining: 23.3s\n",
      "109:\tlearn: 0.1431536\ttotal: 6.55s\tremaining: 23.2s\n",
      "110:\tlearn: 0.1431215\ttotal: 6.62s\tremaining: 23.2s\n",
      "111:\tlearn: 0.1430631\ttotal: 6.67s\tremaining: 23.1s\n",
      "112:\tlearn: 0.1430120\ttotal: 6.72s\tremaining: 23s\n",
      "113:\tlearn: 0.1429380\ttotal: 6.79s\tremaining: 23s\n",
      "114:\tlearn: 0.1429019\ttotal: 6.84s\tremaining: 22.9s\n",
      "115:\tlearn: 0.1428676\ttotal: 6.91s\tremaining: 22.9s\n",
      "116:\tlearn: 0.1428174\ttotal: 6.98s\tremaining: 22.8s\n",
      "117:\tlearn: 0.1427725\ttotal: 7.04s\tremaining: 22.8s\n",
      "118:\tlearn: 0.1427429\ttotal: 7.08s\tremaining: 22.7s\n",
      "119:\tlearn: 0.1427087\ttotal: 7.13s\tremaining: 22.6s\n",
      "120:\tlearn: 0.1426634\ttotal: 7.2s\tremaining: 22.5s\n",
      "121:\tlearn: 0.1426348\ttotal: 7.26s\tremaining: 22.5s\n",
      "122:\tlearn: 0.1425864\ttotal: 7.34s\tremaining: 22.5s\n",
      "123:\tlearn: 0.1425556\ttotal: 7.41s\tremaining: 22.5s\n",
      "124:\tlearn: 0.1424989\ttotal: 7.49s\tremaining: 22.5s\n",
      "125:\tlearn: 0.1424449\ttotal: 7.57s\tremaining: 22.5s\n",
      "126:\tlearn: 0.1423879\ttotal: 7.64s\tremaining: 22.4s\n",
      "127:\tlearn: 0.1423278\ttotal: 7.71s\tremaining: 22.4s\n",
      "128:\tlearn: 0.1422953\ttotal: 7.77s\tremaining: 22.3s\n",
      "129:\tlearn: 0.1422547\ttotal: 7.84s\tremaining: 22.3s\n",
      "130:\tlearn: 0.1422203\ttotal: 7.92s\tremaining: 22.3s\n",
      "131:\tlearn: 0.1421766\ttotal: 8.01s\tremaining: 22.3s\n",
      "132:\tlearn: 0.1421438\ttotal: 8.08s\tremaining: 22.3s\n",
      "133:\tlearn: 0.1420965\ttotal: 8.15s\tremaining: 22.3s\n",
      "134:\tlearn: 0.1420614\ttotal: 8.22s\tremaining: 22.2s\n",
      "135:\tlearn: 0.1419983\ttotal: 8.31s\tremaining: 22.3s\n",
      "136:\tlearn: 0.1419642\ttotal: 8.38s\tremaining: 22.2s\n",
      "137:\tlearn: 0.1419239\ttotal: 8.45s\tremaining: 22.2s\n",
      "138:\tlearn: 0.1418919\ttotal: 8.52s\tremaining: 22.1s\n",
      "139:\tlearn: 0.1418609\ttotal: 8.62s\tremaining: 22.2s\n",
      "140:\tlearn: 0.1418203\ttotal: 8.69s\tremaining: 22.1s\n",
      "141:\tlearn: 0.1417690\ttotal: 8.76s\tremaining: 22.1s\n",
      "142:\tlearn: 0.1417188\ttotal: 8.83s\tremaining: 22s\n",
      "143:\tlearn: 0.1416499\ttotal: 8.89s\tremaining: 22s\n",
      "144:\tlearn: 0.1416112\ttotal: 8.98s\tremaining: 22s\n",
      "145:\tlearn: 0.1415878\ttotal: 9.06s\tremaining: 22s\n",
      "146:\tlearn: 0.1415396\ttotal: 9.13s\tremaining: 21.9s\n",
      "147:\tlearn: 0.1414994\ttotal: 9.19s\tremaining: 21.9s\n",
      "148:\tlearn: 0.1414658\ttotal: 9.26s\tremaining: 21.8s\n",
      "149:\tlearn: 0.1414382\ttotal: 9.32s\tremaining: 21.8s\n",
      "150:\tlearn: 0.1414103\ttotal: 9.39s\tremaining: 21.7s\n",
      "151:\tlearn: 0.1413612\ttotal: 9.45s\tremaining: 21.6s\n",
      "152:\tlearn: 0.1413241\ttotal: 9.51s\tremaining: 21.6s\n",
      "153:\tlearn: 0.1412562\ttotal: 9.57s\tremaining: 21.5s\n",
      "154:\tlearn: 0.1412275\ttotal: 9.63s\tremaining: 21.4s\n",
      "155:\tlearn: 0.1411988\ttotal: 9.72s\tremaining: 21.4s\n",
      "156:\tlearn: 0.1411540\ttotal: 9.8s\tremaining: 21.4s\n",
      "157:\tlearn: 0.1411316\ttotal: 9.86s\tremaining: 21.3s\n",
      "158:\tlearn: 0.1410956\ttotal: 9.92s\tremaining: 21.3s\n",
      "159:\tlearn: 0.1410493\ttotal: 9.99s\tremaining: 21.2s\n",
      "160:\tlearn: 0.1410202\ttotal: 10s\tremaining: 21.2s\n",
      "161:\tlearn: 0.1409654\ttotal: 10.1s\tremaining: 21.1s\n",
      "162:\tlearn: 0.1409350\ttotal: 10.2s\tremaining: 21.1s\n",
      "163:\tlearn: 0.1408967\ttotal: 10.3s\tremaining: 21s\n",
      "164:\tlearn: 0.1408486\ttotal: 10.3s\tremaining: 20.9s\n",
      "165:\tlearn: 0.1408256\ttotal: 10.4s\tremaining: 20.9s\n",
      "166:\tlearn: 0.1408022\ttotal: 10.5s\tremaining: 20.9s\n",
      "167:\tlearn: 0.1407750\ttotal: 10.5s\tremaining: 20.8s\n",
      "168:\tlearn: 0.1407450\ttotal: 10.6s\tremaining: 20.8s\n",
      "169:\tlearn: 0.1406964\ttotal: 10.7s\tremaining: 20.7s\n",
      "170:\tlearn: 0.1406706\ttotal: 10.7s\tremaining: 20.7s\n",
      "171:\tlearn: 0.1406234\ttotal: 10.8s\tremaining: 20.6s\n",
      "172:\tlearn: 0.1405923\ttotal: 10.9s\tremaining: 20.6s\n",
      "173:\tlearn: 0.1405591\ttotal: 11s\tremaining: 20.5s\n",
      "174:\tlearn: 0.1405136\ttotal: 11s\tremaining: 20.4s\n",
      "175:\tlearn: 0.1404622\ttotal: 11.1s\tremaining: 20.4s\n",
      "176:\tlearn: 0.1404373\ttotal: 11.1s\tremaining: 20.3s\n",
      "177:\tlearn: 0.1404095\ttotal: 11.2s\tremaining: 20.3s\n",
      "178:\tlearn: 0.1403801\ttotal: 11.3s\tremaining: 20.2s\n",
      "179:\tlearn: 0.1403372\ttotal: 11.3s\tremaining: 20.1s\n",
      "180:\tlearn: 0.1403144\ttotal: 11.4s\tremaining: 20s\n",
      "181:\tlearn: 0.1402721\ttotal: 11.4s\tremaining: 20s\n",
      "182:\tlearn: 0.1402403\ttotal: 11.5s\tremaining: 19.9s\n",
      "183:\tlearn: 0.1402164\ttotal: 11.6s\tremaining: 19.9s\n",
      "184:\tlearn: 0.1401869\ttotal: 11.6s\tremaining: 19.8s\n",
      "185:\tlearn: 0.1401605\ttotal: 11.7s\tremaining: 19.8s\n",
      "186:\tlearn: 0.1401353\ttotal: 11.8s\tremaining: 19.7s\n",
      "187:\tlearn: 0.1400958\ttotal: 11.8s\tremaining: 19.6s\n",
      "188:\tlearn: 0.1400471\ttotal: 11.9s\tremaining: 19.6s\n",
      "189:\tlearn: 0.1400100\ttotal: 11.9s\tremaining: 19.5s\n",
      "190:\tlearn: 0.1399865\ttotal: 12s\tremaining: 19.4s\n",
      "191:\tlearn: 0.1399531\ttotal: 12.1s\tremaining: 19.3s\n",
      "192:\tlearn: 0.1399125\ttotal: 12.1s\tremaining: 19.2s\n",
      "193:\tlearn: 0.1398810\ttotal: 12.2s\tremaining: 19.2s\n",
      "194:\tlearn: 0.1398420\ttotal: 12.2s\tremaining: 19.1s\n",
      "195:\tlearn: 0.1398139\ttotal: 12.3s\tremaining: 19.1s\n",
      "196:\tlearn: 0.1397864\ttotal: 12.3s\tremaining: 19s\n",
      "197:\tlearn: 0.1397619\ttotal: 12.4s\tremaining: 18.9s\n",
      "198:\tlearn: 0.1397381\ttotal: 12.4s\tremaining: 18.8s\n",
      "199:\tlearn: 0.1397117\ttotal: 12.5s\tremaining: 18.7s\n",
      "200:\tlearn: 0.1396852\ttotal: 12.6s\tremaining: 18.7s\n",
      "201:\tlearn: 0.1396647\ttotal: 12.6s\tremaining: 18.6s\n",
      "202:\tlearn: 0.1396434\ttotal: 12.7s\tremaining: 18.6s\n",
      "203:\tlearn: 0.1396217\ttotal: 12.8s\tremaining: 18.5s\n",
      "204:\tlearn: 0.1395862\ttotal: 12.8s\tremaining: 18.4s\n",
      "205:\tlearn: 0.1395660\ttotal: 12.9s\tremaining: 18.4s\n",
      "206:\tlearn: 0.1395352\ttotal: 13s\tremaining: 18.3s\n",
      "207:\tlearn: 0.1395038\ttotal: 13s\tremaining: 18.3s\n",
      "208:\tlearn: 0.1394814\ttotal: 13.1s\tremaining: 18.2s\n",
      "209:\tlearn: 0.1394466\ttotal: 13.1s\tremaining: 18.1s\n",
      "210:\tlearn: 0.1394215\ttotal: 13.2s\tremaining: 18.1s\n",
      "211:\tlearn: 0.1393924\ttotal: 13.3s\tremaining: 18.1s\n",
      "212:\tlearn: 0.1393641\ttotal: 13.4s\tremaining: 18s\n",
      "213:\tlearn: 0.1393396\ttotal: 13.5s\tremaining: 18s\n",
      "214:\tlearn: 0.1393228\ttotal: 13.5s\tremaining: 18s\n",
      "215:\tlearn: 0.1392993\ttotal: 13.6s\tremaining: 17.9s\n",
      "216:\tlearn: 0.1392667\ttotal: 13.7s\tremaining: 17.8s\n",
      "217:\tlearn: 0.1392433\ttotal: 13.8s\tremaining: 17.8s\n",
      "218:\tlearn: 0.1392220\ttotal: 13.8s\tremaining: 17.7s\n",
      "219:\tlearn: 0.1391915\ttotal: 13.9s\tremaining: 17.7s\n",
      "220:\tlearn: 0.1391602\ttotal: 13.9s\tremaining: 17.6s\n",
      "221:\tlearn: 0.1391230\ttotal: 14s\tremaining: 17.5s\n",
      "222:\tlearn: 0.1390930\ttotal: 14.1s\tremaining: 17.5s\n",
      "223:\tlearn: 0.1390732\ttotal: 14.1s\tremaining: 17.4s\n",
      "224:\tlearn: 0.1390461\ttotal: 14.2s\tremaining: 17.4s\n",
      "225:\tlearn: 0.1390256\ttotal: 14.3s\tremaining: 17.3s\n",
      "226:\tlearn: 0.1389993\ttotal: 14.3s\tremaining: 17.2s\n",
      "227:\tlearn: 0.1389659\ttotal: 14.4s\tremaining: 17.2s\n",
      "228:\tlearn: 0.1389437\ttotal: 14.5s\tremaining: 17.1s\n",
      "229:\tlearn: 0.1389112\ttotal: 14.5s\tremaining: 17.1s\n",
      "230:\tlearn: 0.1388718\ttotal: 14.6s\tremaining: 17s\n",
      "231:\tlearn: 0.1388438\ttotal: 14.7s\tremaining: 16.9s\n",
      "232:\tlearn: 0.1388126\ttotal: 14.7s\tremaining: 16.9s\n",
      "233:\tlearn: 0.1387891\ttotal: 14.8s\tremaining: 16.8s\n",
      "234:\tlearn: 0.1387715\ttotal: 14.9s\tremaining: 16.8s\n",
      "235:\tlearn: 0.1387406\ttotal: 14.9s\tremaining: 16.7s\n",
      "236:\tlearn: 0.1387140\ttotal: 15s\tremaining: 16.6s\n",
      "237:\tlearn: 0.1386872\ttotal: 15.1s\tremaining: 16.6s\n",
      "238:\tlearn: 0.1386729\ttotal: 15.2s\tremaining: 16.6s\n",
      "239:\tlearn: 0.1386499\ttotal: 15.2s\tremaining: 16.5s\n",
      "240:\tlearn: 0.1386139\ttotal: 15.3s\tremaining: 16.4s\n",
      "241:\tlearn: 0.1385873\ttotal: 15.4s\tremaining: 16.4s\n",
      "242:\tlearn: 0.1385518\ttotal: 15.4s\tremaining: 16.3s\n",
      "243:\tlearn: 0.1385270\ttotal: 15.5s\tremaining: 16.2s\n",
      "244:\tlearn: 0.1385074\ttotal: 15.5s\tremaining: 16.2s\n",
      "245:\tlearn: 0.1384850\ttotal: 15.6s\tremaining: 16.1s\n",
      "246:\tlearn: 0.1384593\ttotal: 15.7s\tremaining: 16s\n",
      "247:\tlearn: 0.1384287\ttotal: 15.7s\tremaining: 16s\n",
      "248:\tlearn: 0.1384021\ttotal: 15.8s\tremaining: 15.9s\n",
      "249:\tlearn: 0.1383818\ttotal: 15.8s\tremaining: 15.8s\n",
      "250:\tlearn: 0.1383583\ttotal: 15.9s\tremaining: 15.8s\n",
      "251:\tlearn: 0.1383297\ttotal: 16s\tremaining: 15.7s\n",
      "252:\tlearn: 0.1383098\ttotal: 16s\tremaining: 15.6s\n",
      "253:\tlearn: 0.1382850\ttotal: 16.1s\tremaining: 15.6s\n",
      "254:\tlearn: 0.1382617\ttotal: 16.1s\tremaining: 15.5s\n",
      "255:\tlearn: 0.1382378\ttotal: 16.2s\tremaining: 15.4s\n",
      "256:\tlearn: 0.1382151\ttotal: 16.3s\tremaining: 15.4s\n",
      "257:\tlearn: 0.1381841\ttotal: 16.3s\tremaining: 15.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258:\tlearn: 0.1381635\ttotal: 16.4s\tremaining: 15.2s\n",
      "259:\tlearn: 0.1381402\ttotal: 16.4s\tremaining: 15.2s\n",
      "260:\tlearn: 0.1381204\ttotal: 16.5s\tremaining: 15.1s\n",
      "261:\tlearn: 0.1380970\ttotal: 16.5s\tremaining: 15s\n",
      "262:\tlearn: 0.1380646\ttotal: 16.6s\tremaining: 14.9s\n",
      "263:\tlearn: 0.1380502\ttotal: 16.6s\tremaining: 14.9s\n",
      "264:\tlearn: 0.1380324\ttotal: 16.7s\tremaining: 14.8s\n",
      "265:\tlearn: 0.1380170\ttotal: 16.7s\tremaining: 14.7s\n",
      "266:\tlearn: 0.1379949\ttotal: 16.8s\tremaining: 14.7s\n",
      "267:\tlearn: 0.1379811\ttotal: 16.9s\tremaining: 14.6s\n",
      "268:\tlearn: 0.1379632\ttotal: 16.9s\tremaining: 14.5s\n",
      "269:\tlearn: 0.1379403\ttotal: 17s\tremaining: 14.5s\n",
      "270:\tlearn: 0.1379179\ttotal: 17s\tremaining: 14.4s\n",
      "271:\tlearn: 0.1378947\ttotal: 17.1s\tremaining: 14.3s\n",
      "272:\tlearn: 0.1378652\ttotal: 17.2s\tremaining: 14.3s\n",
      "273:\tlearn: 0.1378371\ttotal: 17.2s\tremaining: 14.2s\n",
      "274:\tlearn: 0.1378132\ttotal: 17.3s\tremaining: 14.1s\n",
      "275:\tlearn: 0.1377942\ttotal: 17.3s\tremaining: 14.1s\n",
      "276:\tlearn: 0.1377761\ttotal: 17.4s\tremaining: 14s\n",
      "277:\tlearn: 0.1377559\ttotal: 17.4s\tremaining: 13.9s\n",
      "278:\tlearn: 0.1377292\ttotal: 17.5s\tremaining: 13.8s\n",
      "279:\tlearn: 0.1377033\ttotal: 17.6s\tremaining: 13.8s\n",
      "280:\tlearn: 0.1376857\ttotal: 17.6s\tremaining: 13.7s\n",
      "281:\tlearn: 0.1376647\ttotal: 17.7s\tremaining: 13.7s\n",
      "282:\tlearn: 0.1376409\ttotal: 17.7s\tremaining: 13.6s\n",
      "283:\tlearn: 0.1376128\ttotal: 17.8s\tremaining: 13.5s\n",
      "284:\tlearn: 0.1375994\ttotal: 17.8s\tremaining: 13.4s\n",
      "285:\tlearn: 0.1375788\ttotal: 17.9s\tremaining: 13.4s\n",
      "286:\tlearn: 0.1375615\ttotal: 17.9s\tremaining: 13.3s\n",
      "287:\tlearn: 0.1375459\ttotal: 18s\tremaining: 13.2s\n",
      "288:\tlearn: 0.1375180\ttotal: 18s\tremaining: 13.2s\n",
      "289:\tlearn: 0.1374977\ttotal: 18.1s\tremaining: 13.1s\n",
      "290:\tlearn: 0.1374637\ttotal: 18.2s\tremaining: 13s\n",
      "291:\tlearn: 0.1374440\ttotal: 18.2s\tremaining: 13s\n",
      "292:\tlearn: 0.1374175\ttotal: 18.3s\tremaining: 12.9s\n",
      "293:\tlearn: 0.1373983\ttotal: 18.3s\tremaining: 12.8s\n",
      "294:\tlearn: 0.1373835\ttotal: 18.4s\tremaining: 12.8s\n",
      "295:\tlearn: 0.1373661\ttotal: 18.4s\tremaining: 12.7s\n",
      "296:\tlearn: 0.1373460\ttotal: 18.5s\tremaining: 12.6s\n",
      "297:\tlearn: 0.1373209\ttotal: 18.6s\tremaining: 12.6s\n",
      "298:\tlearn: 0.1372908\ttotal: 18.6s\tremaining: 12.5s\n",
      "299:\tlearn: 0.1372739\ttotal: 18.7s\tremaining: 12.5s\n",
      "300:\tlearn: 0.1372557\ttotal: 18.7s\tremaining: 12.4s\n",
      "301:\tlearn: 0.1372341\ttotal: 18.8s\tremaining: 12.3s\n",
      "302:\tlearn: 0.1372157\ttotal: 18.8s\tremaining: 12.3s\n",
      "303:\tlearn: 0.1371962\ttotal: 18.9s\tremaining: 12.2s\n",
      "304:\tlearn: 0.1371787\ttotal: 19s\tremaining: 12.1s\n",
      "305:\tlearn: 0.1371566\ttotal: 19s\tremaining: 12.1s\n",
      "306:\tlearn: 0.1371346\ttotal: 19.1s\tremaining: 12s\n",
      "307:\tlearn: 0.1371188\ttotal: 19.2s\tremaining: 12s\n",
      "308:\tlearn: 0.1370913\ttotal: 19.2s\tremaining: 11.9s\n",
      "309:\tlearn: 0.1370729\ttotal: 19.3s\tremaining: 11.8s\n",
      "310:\tlearn: 0.1370495\ttotal: 19.4s\tremaining: 11.8s\n",
      "311:\tlearn: 0.1370293\ttotal: 19.4s\tremaining: 11.7s\n",
      "312:\tlearn: 0.1370135\ttotal: 19.5s\tremaining: 11.6s\n",
      "313:\tlearn: 0.1369901\ttotal: 19.6s\tremaining: 11.6s\n",
      "314:\tlearn: 0.1369730\ttotal: 19.7s\tremaining: 11.5s\n",
      "315:\tlearn: 0.1369508\ttotal: 19.7s\tremaining: 11.5s\n",
      "316:\tlearn: 0.1369252\ttotal: 19.8s\tremaining: 11.4s\n",
      "317:\tlearn: 0.1368999\ttotal: 19.9s\tremaining: 11.4s\n",
      "318:\tlearn: 0.1368688\ttotal: 19.9s\tremaining: 11.3s\n",
      "319:\tlearn: 0.1368558\ttotal: 20s\tremaining: 11.3s\n",
      "320:\tlearn: 0.1368338\ttotal: 20.1s\tremaining: 11.2s\n",
      "321:\tlearn: 0.1368154\ttotal: 20.1s\tremaining: 11.1s\n",
      "322:\tlearn: 0.1367970\ttotal: 20.2s\tremaining: 11.1s\n",
      "323:\tlearn: 0.1367793\ttotal: 20.2s\tremaining: 11s\n",
      "324:\tlearn: 0.1367596\ttotal: 20.3s\tremaining: 10.9s\n",
      "325:\tlearn: 0.1367417\ttotal: 20.4s\tremaining: 10.9s\n",
      "326:\tlearn: 0.1367181\ttotal: 20.4s\tremaining: 10.8s\n",
      "327:\tlearn: 0.1366962\ttotal: 20.5s\tremaining: 10.7s\n",
      "328:\tlearn: 0.1366795\ttotal: 20.5s\tremaining: 10.7s\n",
      "329:\tlearn: 0.1366625\ttotal: 20.6s\tremaining: 10.6s\n",
      "330:\tlearn: 0.1366426\ttotal: 20.7s\tremaining: 10.6s\n",
      "331:\tlearn: 0.1366174\ttotal: 20.8s\tremaining: 10.5s\n",
      "332:\tlearn: 0.1366031\ttotal: 20.8s\tremaining: 10.4s\n",
      "333:\tlearn: 0.1365848\ttotal: 20.9s\tremaining: 10.4s\n",
      "334:\tlearn: 0.1365677\ttotal: 20.9s\tremaining: 10.3s\n",
      "335:\tlearn: 0.1365435\ttotal: 21s\tremaining: 10.2s\n",
      "336:\tlearn: 0.1365255\ttotal: 21.1s\tremaining: 10.2s\n",
      "337:\tlearn: 0.1365118\ttotal: 21.1s\tremaining: 10.1s\n",
      "338:\tlearn: 0.1364978\ttotal: 21.2s\tremaining: 10.1s\n",
      "339:\tlearn: 0.1364793\ttotal: 21.3s\tremaining: 10s\n",
      "340:\tlearn: 0.1364623\ttotal: 21.3s\tremaining: 9.94s\n",
      "341:\tlearn: 0.1364460\ttotal: 21.4s\tremaining: 9.89s\n",
      "342:\tlearn: 0.1364275\ttotal: 21.5s\tremaining: 9.83s\n",
      "343:\tlearn: 0.1364127\ttotal: 21.5s\tremaining: 9.76s\n",
      "344:\tlearn: 0.1363914\ttotal: 21.6s\tremaining: 9.69s\n",
      "345:\tlearn: 0.1363774\ttotal: 21.6s\tremaining: 9.62s\n",
      "346:\tlearn: 0.1363553\ttotal: 21.7s\tremaining: 9.56s\n",
      "347:\tlearn: 0.1363351\ttotal: 21.7s\tremaining: 9.49s\n",
      "348:\tlearn: 0.1363184\ttotal: 21.8s\tremaining: 9.44s\n",
      "349:\tlearn: 0.1362995\ttotal: 21.9s\tremaining: 9.37s\n",
      "350:\tlearn: 0.1362663\ttotal: 21.9s\tremaining: 9.31s\n",
      "351:\tlearn: 0.1362474\ttotal: 22s\tremaining: 9.24s\n",
      "352:\tlearn: 0.1362337\ttotal: 22s\tremaining: 9.18s\n",
      "353:\tlearn: 0.1362118\ttotal: 22.1s\tremaining: 9.11s\n",
      "354:\tlearn: 0.1361978\ttotal: 22.2s\tremaining: 9.05s\n",
      "355:\tlearn: 0.1361811\ttotal: 22.2s\tremaining: 8.99s\n",
      "356:\tlearn: 0.1361635\ttotal: 22.3s\tremaining: 8.93s\n",
      "357:\tlearn: 0.1361429\ttotal: 22.4s\tremaining: 8.87s\n",
      "358:\tlearn: 0.1361216\ttotal: 22.4s\tremaining: 8.81s\n",
      "359:\tlearn: 0.1360988\ttotal: 22.5s\tremaining: 8.74s\n",
      "360:\tlearn: 0.1360758\ttotal: 22.5s\tremaining: 8.68s\n",
      "361:\tlearn: 0.1360642\ttotal: 22.6s\tremaining: 8.62s\n",
      "362:\tlearn: 0.1360464\ttotal: 22.7s\tremaining: 8.55s\n",
      "363:\tlearn: 0.1360283\ttotal: 22.7s\tremaining: 8.48s\n",
      "364:\tlearn: 0.1360127\ttotal: 22.8s\tremaining: 8.42s\n",
      "365:\tlearn: 0.1359860\ttotal: 22.8s\tremaining: 8.36s\n",
      "366:\tlearn: 0.1359722\ttotal: 22.9s\tremaining: 8.31s\n",
      "367:\tlearn: 0.1359557\ttotal: 23s\tremaining: 8.24s\n",
      "368:\tlearn: 0.1359403\ttotal: 23.1s\tremaining: 8.19s\n",
      "369:\tlearn: 0.1359242\ttotal: 23.1s\tremaining: 8.13s\n",
      "370:\tlearn: 0.1359110\ttotal: 23.2s\tremaining: 8.07s\n",
      "371:\tlearn: 0.1358905\ttotal: 23.3s\tremaining: 8s\n",
      "372:\tlearn: 0.1358796\ttotal: 23.3s\tremaining: 7.95s\n",
      "373:\tlearn: 0.1358584\ttotal: 23.4s\tremaining: 7.89s\n",
      "374:\tlearn: 0.1358433\ttotal: 23.5s\tremaining: 7.83s\n",
      "375:\tlearn: 0.1358230\ttotal: 23.5s\tremaining: 7.76s\n",
      "376:\tlearn: 0.1358038\ttotal: 23.6s\tremaining: 7.71s\n",
      "377:\tlearn: 0.1357877\ttotal: 23.7s\tremaining: 7.64s\n",
      "378:\tlearn: 0.1357685\ttotal: 23.8s\tremaining: 7.58s\n",
      "379:\tlearn: 0.1357556\ttotal: 23.8s\tremaining: 7.53s\n",
      "380:\tlearn: 0.1357373\ttotal: 23.9s\tremaining: 7.46s\n",
      "381:\tlearn: 0.1357232\ttotal: 23.9s\tremaining: 7.39s\n",
      "382:\tlearn: 0.1357120\ttotal: 24s\tremaining: 7.33s\n",
      "383:\tlearn: 0.1356904\ttotal: 24.1s\tremaining: 7.27s\n",
      "384:\tlearn: 0.1356758\ttotal: 24.1s\tremaining: 7.21s\n",
      "385:\tlearn: 0.1356559\ttotal: 24.2s\tremaining: 7.14s\n",
      "386:\tlearn: 0.1356375\ttotal: 24.3s\tremaining: 7.09s\n",
      "387:\tlearn: 0.1356209\ttotal: 24.3s\tremaining: 7.02s\n",
      "388:\tlearn: 0.1356081\ttotal: 24.4s\tremaining: 6.96s\n",
      "389:\tlearn: 0.1355871\ttotal: 24.5s\tremaining: 6.9s\n",
      "390:\tlearn: 0.1355697\ttotal: 24.5s\tremaining: 6.84s\n",
      "391:\tlearn: 0.1355558\ttotal: 24.6s\tremaining: 6.78s\n",
      "392:\tlearn: 0.1355425\ttotal: 24.7s\tremaining: 6.72s\n",
      "393:\tlearn: 0.1355231\ttotal: 24.7s\tremaining: 6.66s\n",
      "394:\tlearn: 0.1355088\ttotal: 24.8s\tremaining: 6.6s\n",
      "395:\tlearn: 0.1354930\ttotal: 24.9s\tremaining: 6.54s\n",
      "396:\tlearn: 0.1354685\ttotal: 25s\tremaining: 6.47s\n",
      "397:\tlearn: 0.1354545\ttotal: 25s\tremaining: 6.41s\n",
      "398:\tlearn: 0.1354388\ttotal: 25.1s\tremaining: 6.35s\n",
      "399:\tlearn: 0.1354174\ttotal: 25.2s\tremaining: 6.29s\n",
      "400:\tlearn: 0.1354050\ttotal: 25.2s\tremaining: 6.23s\n",
      "401:\tlearn: 0.1353875\ttotal: 25.3s\tremaining: 6.17s\n",
      "402:\tlearn: 0.1353678\ttotal: 25.4s\tremaining: 6.1s\n",
      "403:\tlearn: 0.1353475\ttotal: 25.4s\tremaining: 6.04s\n",
      "404:\tlearn: 0.1353291\ttotal: 25.5s\tremaining: 5.98s\n",
      "405:\tlearn: 0.1353109\ttotal: 25.6s\tremaining: 5.93s\n",
      "406:\tlearn: 0.1352933\ttotal: 25.7s\tremaining: 5.87s\n",
      "407:\tlearn: 0.1352748\ttotal: 25.7s\tremaining: 5.8s\n",
      "408:\tlearn: 0.1352628\ttotal: 25.8s\tremaining: 5.74s\n",
      "409:\tlearn: 0.1352395\ttotal: 25.9s\tremaining: 5.68s\n",
      "410:\tlearn: 0.1352239\ttotal: 25.9s\tremaining: 5.62s\n",
      "411:\tlearn: 0.1352078\ttotal: 26s\tremaining: 5.56s\n",
      "412:\tlearn: 0.1351938\ttotal: 26.1s\tremaining: 5.5s\n",
      "413:\tlearn: 0.1351782\ttotal: 26.2s\tremaining: 5.44s\n",
      "414:\tlearn: 0.1351584\ttotal: 26.3s\tremaining: 5.38s\n",
      "415:\tlearn: 0.1351363\ttotal: 26.3s\tremaining: 5.32s\n",
      "416:\tlearn: 0.1351121\ttotal: 26.4s\tremaining: 5.25s\n",
      "417:\tlearn: 0.1350987\ttotal: 26.5s\tremaining: 5.19s\n",
      "418:\tlearn: 0.1350837\ttotal: 26.5s\tremaining: 5.13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419:\tlearn: 0.1350696\ttotal: 26.6s\tremaining: 5.07s\n",
      "420:\tlearn: 0.1350572\ttotal: 26.7s\tremaining: 5s\n",
      "421:\tlearn: 0.1350380\ttotal: 26.7s\tremaining: 4.94s\n",
      "422:\tlearn: 0.1350172\ttotal: 26.8s\tremaining: 4.88s\n",
      "423:\tlearn: 0.1350050\ttotal: 26.9s\tremaining: 4.82s\n",
      "424:\tlearn: 0.1349877\ttotal: 27s\tremaining: 4.76s\n",
      "425:\tlearn: 0.1349742\ttotal: 27s\tremaining: 4.7s\n",
      "426:\tlearn: 0.1349494\ttotal: 27.1s\tremaining: 4.63s\n",
      "427:\tlearn: 0.1349350\ttotal: 27.2s\tremaining: 4.57s\n",
      "428:\tlearn: 0.1349228\ttotal: 27.2s\tremaining: 4.51s\n",
      "429:\tlearn: 0.1349046\ttotal: 27.3s\tremaining: 4.45s\n",
      "430:\tlearn: 0.1348775\ttotal: 27.4s\tremaining: 4.39s\n",
      "431:\tlearn: 0.1348651\ttotal: 27.5s\tremaining: 4.33s\n",
      "432:\tlearn: 0.1348468\ttotal: 27.6s\tremaining: 4.26s\n",
      "433:\tlearn: 0.1348341\ttotal: 27.6s\tremaining: 4.2s\n",
      "434:\tlearn: 0.1348185\ttotal: 27.7s\tremaining: 4.14s\n",
      "435:\tlearn: 0.1348069\ttotal: 27.8s\tremaining: 4.08s\n",
      "436:\tlearn: 0.1347904\ttotal: 27.8s\tremaining: 4.01s\n",
      "437:\tlearn: 0.1347732\ttotal: 27.9s\tremaining: 3.95s\n",
      "438:\tlearn: 0.1347546\ttotal: 28s\tremaining: 3.89s\n",
      "439:\tlearn: 0.1347387\ttotal: 28.1s\tremaining: 3.83s\n",
      "440:\tlearn: 0.1347221\ttotal: 28.2s\tremaining: 3.77s\n",
      "441:\tlearn: 0.1347016\ttotal: 28.2s\tremaining: 3.7s\n",
      "442:\tlearn: 0.1346871\ttotal: 28.3s\tremaining: 3.64s\n",
      "443:\tlearn: 0.1346663\ttotal: 28.4s\tremaining: 3.58s\n",
      "444:\tlearn: 0.1346505\ttotal: 28.4s\tremaining: 3.51s\n",
      "445:\tlearn: 0.1346332\ttotal: 28.5s\tremaining: 3.45s\n",
      "446:\tlearn: 0.1346155\ttotal: 28.6s\tremaining: 3.39s\n",
      "447:\tlearn: 0.1346014\ttotal: 28.7s\tremaining: 3.33s\n",
      "448:\tlearn: 0.1345831\ttotal: 28.8s\tremaining: 3.27s\n",
      "449:\tlearn: 0.1345638\ttotal: 28.8s\tremaining: 3.2s\n",
      "450:\tlearn: 0.1345509\ttotal: 28.9s\tremaining: 3.14s\n",
      "451:\tlearn: 0.1345411\ttotal: 29s\tremaining: 3.08s\n",
      "452:\tlearn: 0.1345241\ttotal: 29.1s\tremaining: 3.01s\n",
      "453:\tlearn: 0.1345107\ttotal: 29.1s\tremaining: 2.95s\n",
      "454:\tlearn: 0.1344970\ttotal: 29.2s\tremaining: 2.89s\n",
      "455:\tlearn: 0.1344800\ttotal: 29.3s\tremaining: 2.82s\n",
      "456:\tlearn: 0.1344611\ttotal: 29.3s\tremaining: 2.76s\n",
      "457:\tlearn: 0.1344475\ttotal: 29.4s\tremaining: 2.7s\n",
      "458:\tlearn: 0.1344286\ttotal: 29.5s\tremaining: 2.63s\n",
      "459:\tlearn: 0.1344120\ttotal: 29.6s\tremaining: 2.57s\n",
      "460:\tlearn: 0.1344009\ttotal: 29.6s\tremaining: 2.51s\n",
      "461:\tlearn: 0.1343891\ttotal: 29.7s\tremaining: 2.44s\n",
      "462:\tlearn: 0.1343740\ttotal: 29.8s\tremaining: 2.38s\n",
      "463:\tlearn: 0.1343592\ttotal: 29.8s\tremaining: 2.31s\n",
      "464:\tlearn: 0.1343432\ttotal: 29.9s\tremaining: 2.25s\n",
      "465:\tlearn: 0.1343315\ttotal: 30s\tremaining: 2.19s\n",
      "466:\tlearn: 0.1343173\ttotal: 30.1s\tremaining: 2.12s\n",
      "467:\tlearn: 0.1343016\ttotal: 30.1s\tremaining: 2.06s\n",
      "468:\tlearn: 0.1342854\ttotal: 30.2s\tremaining: 2s\n",
      "469:\tlearn: 0.1342735\ttotal: 30.3s\tremaining: 1.93s\n",
      "470:\tlearn: 0.1342609\ttotal: 30.4s\tremaining: 1.87s\n",
      "471:\tlearn: 0.1342477\ttotal: 30.4s\tremaining: 1.8s\n",
      "472:\tlearn: 0.1342265\ttotal: 30.5s\tremaining: 1.74s\n",
      "473:\tlearn: 0.1342108\ttotal: 30.6s\tremaining: 1.68s\n",
      "474:\tlearn: 0.1341993\ttotal: 30.7s\tremaining: 1.61s\n",
      "475:\tlearn: 0.1341842\ttotal: 30.8s\tremaining: 1.55s\n",
      "476:\tlearn: 0.1341682\ttotal: 30.8s\tremaining: 1.49s\n",
      "477:\tlearn: 0.1341538\ttotal: 30.9s\tremaining: 1.42s\n",
      "478:\tlearn: 0.1341359\ttotal: 31s\tremaining: 1.36s\n",
      "479:\tlearn: 0.1341203\ttotal: 31.1s\tremaining: 1.29s\n",
      "480:\tlearn: 0.1341076\ttotal: 31.1s\tremaining: 1.23s\n",
      "481:\tlearn: 0.1340942\ttotal: 31.2s\tremaining: 1.16s\n",
      "482:\tlearn: 0.1340768\ttotal: 31.2s\tremaining: 1.1s\n",
      "483:\tlearn: 0.1340627\ttotal: 31.3s\tremaining: 1.03s\n",
      "484:\tlearn: 0.1340477\ttotal: 31.4s\tremaining: 970ms\n",
      "485:\tlearn: 0.1340371\ttotal: 31.4s\tremaining: 905ms\n",
      "486:\tlearn: 0.1340131\ttotal: 31.5s\tremaining: 840ms\n",
      "487:\tlearn: 0.1340006\ttotal: 31.5s\tremaining: 775ms\n",
      "488:\tlearn: 0.1339829\ttotal: 31.6s\tremaining: 711ms\n",
      "489:\tlearn: 0.1339722\ttotal: 31.7s\tremaining: 646ms\n",
      "490:\tlearn: 0.1339602\ttotal: 31.7s\tremaining: 582ms\n",
      "491:\tlearn: 0.1339433\ttotal: 31.8s\tremaining: 517ms\n",
      "492:\tlearn: 0.1339310\ttotal: 31.9s\tremaining: 453ms\n",
      "493:\tlearn: 0.1339148\ttotal: 32s\tremaining: 388ms\n",
      "494:\tlearn: 0.1338936\ttotal: 32s\tremaining: 324ms\n",
      "495:\tlearn: 0.1338775\ttotal: 32.1s\tremaining: 259ms\n",
      "496:\tlearn: 0.1338636\ttotal: 32.2s\tremaining: 194ms\n",
      "497:\tlearn: 0.1338517\ttotal: 32.3s\tremaining: 130ms\n",
      "498:\tlearn: 0.1338353\ttotal: 32.3s\tremaining: 64.8ms\n",
      "499:\tlearn: 0.1338207\ttotal: 32.4s\tremaining: 0us\n",
      "[CV]  learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4, total=  33.0s\n",
      "[CV] learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4 .......\n",
      "0:\tlearn: 0.5531566\ttotal: 76.7ms\tremaining: 38.3s\n",
      "1:\tlearn: 0.4521906\ttotal: 166ms\tremaining: 41.4s\n",
      "2:\tlearn: 0.3813284\ttotal: 248ms\tremaining: 41.2s\n",
      "3:\tlearn: 0.3279782\ttotal: 330ms\tremaining: 41s\n",
      "4:\tlearn: 0.2875603\ttotal: 403ms\tremaining: 39.9s\n",
      "5:\tlearn: 0.2557313\ttotal: 462ms\tremaining: 38s\n",
      "6:\tlearn: 0.2322677\ttotal: 548ms\tremaining: 38.6s\n",
      "7:\tlearn: 0.2141646\ttotal: 631ms\tremaining: 38.8s\n",
      "8:\tlearn: 0.2018531\ttotal: 696ms\tremaining: 38s\n",
      "9:\tlearn: 0.1927664\ttotal: 760ms\tremaining: 37.2s\n",
      "10:\tlearn: 0.1861789\ttotal: 830ms\tremaining: 36.9s\n",
      "11:\tlearn: 0.1783088\ttotal: 923ms\tremaining: 37.5s\n",
      "12:\tlearn: 0.1726281\ttotal: 1s\tremaining: 37.5s\n",
      "13:\tlearn: 0.1681992\ttotal: 1.08s\tremaining: 37.6s\n",
      "14:\tlearn: 0.1650432\ttotal: 1.16s\tremaining: 37.5s\n",
      "15:\tlearn: 0.1626414\ttotal: 1.25s\tremaining: 37.9s\n",
      "16:\tlearn: 0.1605920\ttotal: 1.34s\tremaining: 38s\n",
      "17:\tlearn: 0.1591611\ttotal: 1.4s\tremaining: 37.5s\n",
      "18:\tlearn: 0.1578376\ttotal: 1.48s\tremaining: 37.5s\n",
      "19:\tlearn: 0.1566915\ttotal: 1.58s\tremaining: 37.9s\n",
      "20:\tlearn: 0.1555551\ttotal: 1.66s\tremaining: 38s\n",
      "21:\tlearn: 0.1547080\ttotal: 1.74s\tremaining: 37.9s\n",
      "22:\tlearn: 0.1539414\ttotal: 1.83s\tremaining: 37.9s\n",
      "23:\tlearn: 0.1535067\ttotal: 1.9s\tremaining: 37.7s\n",
      "24:\tlearn: 0.1530623\ttotal: 1.98s\tremaining: 37.6s\n",
      "25:\tlearn: 0.1526691\ttotal: 2.07s\tremaining: 37.7s\n",
      "26:\tlearn: 0.1522654\ttotal: 2.15s\tremaining: 37.6s\n",
      "27:\tlearn: 0.1518665\ttotal: 2.22s\tremaining: 37.5s\n",
      "28:\tlearn: 0.1516138\ttotal: 2.3s\tremaining: 37.4s\n",
      "29:\tlearn: 0.1512843\ttotal: 2.38s\tremaining: 37.3s\n",
      "30:\tlearn: 0.1510113\ttotal: 2.45s\tremaining: 37s\n",
      "31:\tlearn: 0.1507860\ttotal: 2.52s\tremaining: 36.8s\n",
      "32:\tlearn: 0.1505486\ttotal: 2.62s\tremaining: 37.1s\n",
      "33:\tlearn: 0.1503572\ttotal: 2.69s\tremaining: 36.9s\n",
      "34:\tlearn: 0.1501132\ttotal: 2.76s\tremaining: 36.7s\n",
      "35:\tlearn: 0.1499281\ttotal: 2.82s\tremaining: 36.4s\n",
      "36:\tlearn: 0.1497521\ttotal: 2.89s\tremaining: 36.2s\n",
      "37:\tlearn: 0.1494811\ttotal: 2.98s\tremaining: 36.3s\n",
      "38:\tlearn: 0.1492779\ttotal: 3.07s\tremaining: 36.3s\n",
      "39:\tlearn: 0.1489769\ttotal: 3.16s\tremaining: 36.3s\n",
      "40:\tlearn: 0.1488339\ttotal: 3.23s\tremaining: 36.2s\n",
      "41:\tlearn: 0.1486775\ttotal: 3.33s\tremaining: 36.3s\n",
      "42:\tlearn: 0.1485265\ttotal: 3.41s\tremaining: 36.2s\n",
      "43:\tlearn: 0.1483769\ttotal: 3.48s\tremaining: 36.1s\n",
      "44:\tlearn: 0.1481752\ttotal: 3.55s\tremaining: 35.9s\n",
      "45:\tlearn: 0.1480643\ttotal: 3.64s\tremaining: 35.9s\n",
      "46:\tlearn: 0.1479668\ttotal: 3.71s\tremaining: 35.8s\n",
      "47:\tlearn: 0.1477700\ttotal: 3.8s\tremaining: 35.7s\n",
      "48:\tlearn: 0.1476421\ttotal: 3.87s\tremaining: 35.6s\n",
      "49:\tlearn: 0.1475388\ttotal: 3.95s\tremaining: 35.6s\n",
      "50:\tlearn: 0.1474412\ttotal: 4.02s\tremaining: 35.4s\n",
      "51:\tlearn: 0.1473240\ttotal: 4.08s\tremaining: 35.2s\n",
      "52:\tlearn: 0.1472073\ttotal: 4.16s\tremaining: 35.1s\n",
      "53:\tlearn: 0.1470913\ttotal: 4.23s\tremaining: 34.9s\n",
      "54:\tlearn: 0.1469122\ttotal: 4.33s\tremaining: 35s\n",
      "55:\tlearn: 0.1468214\ttotal: 4.4s\tremaining: 34.9s\n",
      "56:\tlearn: 0.1467282\ttotal: 4.46s\tremaining: 34.7s\n",
      "57:\tlearn: 0.1466316\ttotal: 4.51s\tremaining: 34.4s\n",
      "58:\tlearn: 0.1465357\ttotal: 4.59s\tremaining: 34.3s\n",
      "59:\tlearn: 0.1464598\ttotal: 4.66s\tremaining: 34.2s\n",
      "60:\tlearn: 0.1463739\ttotal: 4.73s\tremaining: 34s\n",
      "61:\tlearn: 0.1462868\ttotal: 4.79s\tremaining: 33.9s\n",
      "62:\tlearn: 0.1462176\ttotal: 4.86s\tremaining: 33.7s\n",
      "63:\tlearn: 0.1461307\ttotal: 4.93s\tremaining: 33.6s\n",
      "64:\tlearn: 0.1459933\ttotal: 5.02s\tremaining: 33.6s\n",
      "65:\tlearn: 0.1459315\ttotal: 5.1s\tremaining: 33.5s\n",
      "66:\tlearn: 0.1458565\ttotal: 5.16s\tremaining: 33.4s\n",
      "67:\tlearn: 0.1457804\ttotal: 5.23s\tremaining: 33.2s\n",
      "68:\tlearn: 0.1456842\ttotal: 5.32s\tremaining: 33.2s\n",
      "69:\tlearn: 0.1456283\ttotal: 5.39s\tremaining: 33.1s\n",
      "70:\tlearn: 0.1455473\ttotal: 5.47s\tremaining: 33.1s\n",
      "71:\tlearn: 0.1454696\ttotal: 5.54s\tremaining: 32.9s\n",
      "72:\tlearn: 0.1454127\ttotal: 5.61s\tremaining: 32.8s\n",
      "73:\tlearn: 0.1453260\ttotal: 5.71s\tremaining: 32.9s\n",
      "74:\tlearn: 0.1452548\ttotal: 5.79s\tremaining: 32.8s\n",
      "75:\tlearn: 0.1451520\ttotal: 5.86s\tremaining: 32.7s\n",
      "76:\tlearn: 0.1450938\ttotal: 5.91s\tremaining: 32.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77:\tlearn: 0.1450108\ttotal: 5.98s\tremaining: 32.4s\n",
      "78:\tlearn: 0.1449300\ttotal: 6.08s\tremaining: 32.4s\n",
      "79:\tlearn: 0.1448764\ttotal: 6.14s\tremaining: 32.3s\n",
      "80:\tlearn: 0.1448216\ttotal: 6.22s\tremaining: 32.2s\n",
      "81:\tlearn: 0.1447057\ttotal: 6.29s\tremaining: 32.1s\n",
      "82:\tlearn: 0.1446284\ttotal: 6.36s\tremaining: 31.9s\n",
      "83:\tlearn: 0.1445775\ttotal: 6.43s\tremaining: 31.9s\n",
      "84:\tlearn: 0.1445274\ttotal: 6.51s\tremaining: 31.8s\n",
      "85:\tlearn: 0.1444685\ttotal: 6.6s\tremaining: 31.8s\n",
      "86:\tlearn: 0.1444236\ttotal: 6.67s\tremaining: 31.7s\n",
      "87:\tlearn: 0.1443658\ttotal: 6.76s\tremaining: 31.7s\n",
      "88:\tlearn: 0.1443067\ttotal: 6.82s\tremaining: 31.5s\n",
      "89:\tlearn: 0.1442629\ttotal: 6.89s\tremaining: 31.4s\n",
      "90:\tlearn: 0.1441793\ttotal: 6.96s\tremaining: 31.3s\n",
      "91:\tlearn: 0.1441087\ttotal: 7.02s\tremaining: 31.1s\n",
      "92:\tlearn: 0.1440264\ttotal: 7.12s\tremaining: 31.2s\n",
      "93:\tlearn: 0.1439667\ttotal: 7.2s\tremaining: 31.1s\n",
      "94:\tlearn: 0.1439264\ttotal: 7.28s\tremaining: 31s\n",
      "95:\tlearn: 0.1438810\ttotal: 7.34s\tremaining: 30.9s\n",
      "96:\tlearn: 0.1438336\ttotal: 7.41s\tremaining: 30.8s\n",
      "97:\tlearn: 0.1437962\ttotal: 7.48s\tremaining: 30.7s\n",
      "98:\tlearn: 0.1437529\ttotal: 7.55s\tremaining: 30.6s\n",
      "99:\tlearn: 0.1437077\ttotal: 7.63s\tremaining: 30.5s\n",
      "100:\tlearn: 0.1436690\ttotal: 7.68s\tremaining: 30.3s\n",
      "101:\tlearn: 0.1435989\ttotal: 7.74s\tremaining: 30.2s\n",
      "102:\tlearn: 0.1435568\ttotal: 7.83s\tremaining: 30.2s\n",
      "103:\tlearn: 0.1434713\ttotal: 7.88s\tremaining: 30s\n",
      "104:\tlearn: 0.1434366\ttotal: 7.94s\tremaining: 29.9s\n",
      "105:\tlearn: 0.1433943\ttotal: 7.99s\tremaining: 29.7s\n",
      "106:\tlearn: 0.1433576\ttotal: 8.04s\tremaining: 29.5s\n",
      "107:\tlearn: 0.1433170\ttotal: 8.09s\tremaining: 29.4s\n",
      "108:\tlearn: 0.1432780\ttotal: 8.17s\tremaining: 29.3s\n",
      "109:\tlearn: 0.1431950\ttotal: 8.24s\tremaining: 29.2s\n",
      "110:\tlearn: 0.1431189\ttotal: 8.31s\tremaining: 29.1s\n",
      "111:\tlearn: 0.1430560\ttotal: 8.37s\tremaining: 29s\n",
      "112:\tlearn: 0.1429786\ttotal: 8.43s\tremaining: 28.9s\n",
      "113:\tlearn: 0.1429365\ttotal: 8.5s\tremaining: 28.8s\n",
      "114:\tlearn: 0.1429048\ttotal: 8.55s\tremaining: 28.6s\n",
      "115:\tlearn: 0.1428524\ttotal: 8.62s\tremaining: 28.5s\n",
      "116:\tlearn: 0.1428172\ttotal: 8.68s\tremaining: 28.4s\n",
      "117:\tlearn: 0.1427726\ttotal: 8.75s\tremaining: 28.3s\n",
      "118:\tlearn: 0.1427305\ttotal: 8.84s\tremaining: 28.3s\n",
      "119:\tlearn: 0.1426861\ttotal: 8.93s\tremaining: 28.3s\n",
      "120:\tlearn: 0.1426130\ttotal: 9s\tremaining: 28.2s\n",
      "121:\tlearn: 0.1425752\ttotal: 9.07s\tremaining: 28.1s\n",
      "122:\tlearn: 0.1425262\ttotal: 9.16s\tremaining: 28.1s\n",
      "123:\tlearn: 0.1424804\ttotal: 9.23s\tremaining: 28s\n",
      "124:\tlearn: 0.1424453\ttotal: 9.29s\tremaining: 27.9s\n",
      "125:\tlearn: 0.1424061\ttotal: 9.37s\tremaining: 27.8s\n",
      "126:\tlearn: 0.1423728\ttotal: 9.43s\tremaining: 27.7s\n",
      "127:\tlearn: 0.1423349\ttotal: 9.51s\tremaining: 27.6s\n",
      "128:\tlearn: 0.1422990\ttotal: 9.59s\tremaining: 27.6s\n",
      "129:\tlearn: 0.1422719\ttotal: 9.64s\tremaining: 27.4s\n",
      "130:\tlearn: 0.1422332\ttotal: 9.71s\tremaining: 27.4s\n",
      "131:\tlearn: 0.1421792\ttotal: 9.77s\tremaining: 27.2s\n",
      "132:\tlearn: 0.1421382\ttotal: 9.87s\tremaining: 27.2s\n",
      "133:\tlearn: 0.1420934\ttotal: 9.96s\tremaining: 27.2s\n",
      "134:\tlearn: 0.1420386\ttotal: 10s\tremaining: 27.1s\n",
      "135:\tlearn: 0.1419931\ttotal: 10.1s\tremaining: 27s\n",
      "136:\tlearn: 0.1419242\ttotal: 10.2s\tremaining: 27s\n",
      "137:\tlearn: 0.1418898\ttotal: 10.3s\tremaining: 26.9s\n",
      "138:\tlearn: 0.1418431\ttotal: 10.3s\tremaining: 26.8s\n",
      "139:\tlearn: 0.1417951\ttotal: 10.4s\tremaining: 26.8s\n",
      "140:\tlearn: 0.1417546\ttotal: 10.5s\tremaining: 26.6s\n",
      "141:\tlearn: 0.1417196\ttotal: 10.5s\tremaining: 26.6s\n",
      "142:\tlearn: 0.1416893\ttotal: 10.6s\tremaining: 26.5s\n",
      "143:\tlearn: 0.1416544\ttotal: 10.7s\tremaining: 26.4s\n",
      "144:\tlearn: 0.1416185\ttotal: 10.7s\tremaining: 26.3s\n",
      "145:\tlearn: 0.1415936\ttotal: 10.8s\tremaining: 26.1s\n",
      "146:\tlearn: 0.1415531\ttotal: 10.9s\tremaining: 26.1s\n",
      "147:\tlearn: 0.1415246\ttotal: 10.9s\tremaining: 26s\n",
      "148:\tlearn: 0.1414918\ttotal: 11s\tremaining: 25.9s\n",
      "149:\tlearn: 0.1414599\ttotal: 11s\tremaining: 25.8s\n",
      "150:\tlearn: 0.1414316\ttotal: 11.1s\tremaining: 25.7s\n",
      "151:\tlearn: 0.1414024\ttotal: 11.2s\tremaining: 25.6s\n",
      "152:\tlearn: 0.1413762\ttotal: 11.3s\tremaining: 25.5s\n",
      "153:\tlearn: 0.1413286\ttotal: 11.3s\tremaining: 25.4s\n",
      "154:\tlearn: 0.1413041\ttotal: 11.4s\tremaining: 25.3s\n",
      "155:\tlearn: 0.1412559\ttotal: 11.4s\tremaining: 25.2s\n",
      "156:\tlearn: 0.1412245\ttotal: 11.5s\tremaining: 25.1s\n",
      "157:\tlearn: 0.1411851\ttotal: 11.6s\tremaining: 25.1s\n",
      "158:\tlearn: 0.1411530\ttotal: 11.6s\tremaining: 25s\n",
      "159:\tlearn: 0.1411101\ttotal: 11.7s\tremaining: 24.8s\n",
      "160:\tlearn: 0.1410462\ttotal: 11.8s\tremaining: 24.7s\n",
      "161:\tlearn: 0.1410127\ttotal: 11.8s\tremaining: 24.7s\n",
      "162:\tlearn: 0.1409803\ttotal: 11.9s\tremaining: 24.6s\n",
      "163:\tlearn: 0.1409448\ttotal: 12s\tremaining: 24.5s\n",
      "164:\tlearn: 0.1409093\ttotal: 12s\tremaining: 24.5s\n",
      "165:\tlearn: 0.1408817\ttotal: 12.1s\tremaining: 24.4s\n",
      "166:\tlearn: 0.1408401\ttotal: 12.2s\tremaining: 24.2s\n",
      "167:\tlearn: 0.1408018\ttotal: 12.2s\tremaining: 24.1s\n",
      "168:\tlearn: 0.1407703\ttotal: 12.3s\tremaining: 24.1s\n",
      "169:\tlearn: 0.1407268\ttotal: 12.4s\tremaining: 24s\n",
      "170:\tlearn: 0.1406994\ttotal: 12.4s\tremaining: 23.9s\n",
      "171:\tlearn: 0.1406669\ttotal: 12.5s\tremaining: 23.8s\n",
      "172:\tlearn: 0.1406368\ttotal: 12.6s\tremaining: 23.8s\n",
      "173:\tlearn: 0.1405976\ttotal: 12.6s\tremaining: 23.7s\n",
      "174:\tlearn: 0.1405518\ttotal: 12.7s\tremaining: 23.6s\n",
      "175:\tlearn: 0.1405058\ttotal: 12.8s\tremaining: 23.5s\n",
      "176:\tlearn: 0.1404633\ttotal: 12.8s\tremaining: 23.4s\n",
      "177:\tlearn: 0.1404163\ttotal: 12.9s\tremaining: 23.4s\n",
      "178:\tlearn: 0.1403791\ttotal: 13s\tremaining: 23.2s\n",
      "179:\tlearn: 0.1403506\ttotal: 13s\tremaining: 23.2s\n",
      "180:\tlearn: 0.1403192\ttotal: 13.1s\tremaining: 23.1s\n",
      "181:\tlearn: 0.1402968\ttotal: 13.2s\tremaining: 23s\n",
      "182:\tlearn: 0.1402689\ttotal: 13.2s\tremaining: 22.9s\n",
      "183:\tlearn: 0.1402218\ttotal: 13.3s\tremaining: 22.8s\n",
      "184:\tlearn: 0.1401965\ttotal: 13.4s\tremaining: 22.8s\n",
      "185:\tlearn: 0.1401616\ttotal: 13.4s\tremaining: 22.7s\n",
      "186:\tlearn: 0.1401260\ttotal: 13.5s\tremaining: 22.6s\n",
      "187:\tlearn: 0.1400962\ttotal: 13.5s\tremaining: 22.5s\n",
      "188:\tlearn: 0.1400695\ttotal: 13.6s\tremaining: 22.4s\n",
      "189:\tlearn: 0.1400417\ttotal: 13.7s\tremaining: 22.3s\n",
      "190:\tlearn: 0.1400127\ttotal: 13.8s\tremaining: 22.3s\n",
      "191:\tlearn: 0.1399853\ttotal: 13.8s\tremaining: 22.2s\n",
      "192:\tlearn: 0.1399522\ttotal: 13.9s\tremaining: 22.1s\n",
      "193:\tlearn: 0.1399226\ttotal: 14s\tremaining: 22s\n",
      "194:\tlearn: 0.1398892\ttotal: 14s\tremaining: 22s\n",
      "195:\tlearn: 0.1398645\ttotal: 14.1s\tremaining: 21.9s\n",
      "196:\tlearn: 0.1398196\ttotal: 14.2s\tremaining: 21.8s\n",
      "197:\tlearn: 0.1397983\ttotal: 14.2s\tremaining: 21.7s\n",
      "198:\tlearn: 0.1397776\ttotal: 14.3s\tremaining: 21.6s\n",
      "199:\tlearn: 0.1397465\ttotal: 14.4s\tremaining: 21.5s\n",
      "200:\tlearn: 0.1397184\ttotal: 14.4s\tremaining: 21.5s\n",
      "201:\tlearn: 0.1396880\ttotal: 14.5s\tremaining: 21.4s\n",
      "202:\tlearn: 0.1396550\ttotal: 14.6s\tremaining: 21.3s\n",
      "203:\tlearn: 0.1396263\ttotal: 14.6s\tremaining: 21.2s\n",
      "204:\tlearn: 0.1395954\ttotal: 14.7s\tremaining: 21.1s\n",
      "205:\tlearn: 0.1395761\ttotal: 14.7s\tremaining: 21s\n",
      "206:\tlearn: 0.1395539\ttotal: 14.8s\tremaining: 20.9s\n",
      "207:\tlearn: 0.1395157\ttotal: 14.9s\tremaining: 20.9s\n",
      "208:\tlearn: 0.1394859\ttotal: 14.9s\tremaining: 20.8s\n",
      "209:\tlearn: 0.1394634\ttotal: 15s\tremaining: 20.7s\n",
      "210:\tlearn: 0.1394355\ttotal: 15.1s\tremaining: 20.6s\n",
      "211:\tlearn: 0.1394148\ttotal: 15.1s\tremaining: 20.6s\n",
      "212:\tlearn: 0.1393781\ttotal: 15.2s\tremaining: 20.5s\n",
      "213:\tlearn: 0.1393430\ttotal: 15.2s\tremaining: 20.4s\n",
      "214:\tlearn: 0.1393212\ttotal: 15.3s\tremaining: 20.3s\n",
      "215:\tlearn: 0.1392937\ttotal: 15.3s\tremaining: 20.2s\n",
      "216:\tlearn: 0.1392786\ttotal: 15.4s\tremaining: 20.1s\n",
      "217:\tlearn: 0.1392193\ttotal: 15.5s\tremaining: 20s\n",
      "218:\tlearn: 0.1391963\ttotal: 15.5s\tremaining: 19.9s\n",
      "219:\tlearn: 0.1391692\ttotal: 15.6s\tremaining: 19.8s\n",
      "220:\tlearn: 0.1391472\ttotal: 15.6s\tremaining: 19.7s\n",
      "221:\tlearn: 0.1391214\ttotal: 15.7s\tremaining: 19.7s\n",
      "222:\tlearn: 0.1390925\ttotal: 15.8s\tremaining: 19.6s\n",
      "223:\tlearn: 0.1390722\ttotal: 15.8s\tremaining: 19.5s\n",
      "224:\tlearn: 0.1390516\ttotal: 15.9s\tremaining: 19.4s\n",
      "225:\tlearn: 0.1390251\ttotal: 16s\tremaining: 19.3s\n",
      "226:\tlearn: 0.1389921\ttotal: 16s\tremaining: 19.3s\n",
      "227:\tlearn: 0.1389657\ttotal: 16.1s\tremaining: 19.2s\n",
      "228:\tlearn: 0.1389246\ttotal: 16.2s\tremaining: 19.1s\n",
      "229:\tlearn: 0.1388938\ttotal: 16.2s\tremaining: 19.1s\n",
      "230:\tlearn: 0.1388673\ttotal: 16.3s\tremaining: 19s\n",
      "231:\tlearn: 0.1388483\ttotal: 16.4s\tremaining: 18.9s\n",
      "232:\tlearn: 0.1388204\ttotal: 16.5s\tremaining: 18.9s\n",
      "233:\tlearn: 0.1387871\ttotal: 16.5s\tremaining: 18.8s\n",
      "234:\tlearn: 0.1387601\ttotal: 16.6s\tremaining: 18.7s\n",
      "235:\tlearn: 0.1387398\ttotal: 16.7s\tremaining: 18.6s\n",
      "236:\tlearn: 0.1387200\ttotal: 16.7s\tremaining: 18.6s\n",
      "237:\tlearn: 0.1386983\ttotal: 16.8s\tremaining: 18.5s\n",
      "238:\tlearn: 0.1386715\ttotal: 16.9s\tremaining: 18.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239:\tlearn: 0.1386449\ttotal: 16.9s\tremaining: 18.3s\n",
      "240:\tlearn: 0.1386264\ttotal: 17s\tremaining: 18.3s\n",
      "241:\tlearn: 0.1385971\ttotal: 17s\tremaining: 18.2s\n",
      "242:\tlearn: 0.1385746\ttotal: 17.1s\tremaining: 18.1s\n",
      "243:\tlearn: 0.1385347\ttotal: 17.2s\tremaining: 18s\n",
      "244:\tlearn: 0.1385101\ttotal: 17.3s\tremaining: 18s\n",
      "245:\tlearn: 0.1384869\ttotal: 17.3s\tremaining: 17.9s\n",
      "246:\tlearn: 0.1384634\ttotal: 17.4s\tremaining: 17.8s\n",
      "247:\tlearn: 0.1384335\ttotal: 17.5s\tremaining: 17.7s\n",
      "248:\tlearn: 0.1384169\ttotal: 17.5s\tremaining: 17.7s\n",
      "249:\tlearn: 0.1383896\ttotal: 17.6s\tremaining: 17.6s\n",
      "250:\tlearn: 0.1383569\ttotal: 17.7s\tremaining: 17.5s\n",
      "251:\tlearn: 0.1383394\ttotal: 17.7s\tremaining: 17.4s\n",
      "252:\tlearn: 0.1383150\ttotal: 17.8s\tremaining: 17.4s\n",
      "253:\tlearn: 0.1382921\ttotal: 17.9s\tremaining: 17.3s\n",
      "254:\tlearn: 0.1382575\ttotal: 17.9s\tremaining: 17.2s\n",
      "255:\tlearn: 0.1382316\ttotal: 18s\tremaining: 17.2s\n",
      "256:\tlearn: 0.1382101\ttotal: 18.1s\tremaining: 17.1s\n",
      "257:\tlearn: 0.1381819\ttotal: 18.1s\tremaining: 17s\n",
      "258:\tlearn: 0.1381555\ttotal: 18.2s\tremaining: 16.9s\n",
      "259:\tlearn: 0.1381310\ttotal: 18.2s\tremaining: 16.8s\n",
      "260:\tlearn: 0.1381075\ttotal: 18.3s\tremaining: 16.8s\n",
      "261:\tlearn: 0.1380855\ttotal: 18.4s\tremaining: 16.7s\n",
      "262:\tlearn: 0.1380639\ttotal: 18.4s\tremaining: 16.6s\n",
      "263:\tlearn: 0.1380417\ttotal: 18.5s\tremaining: 16.6s\n",
      "264:\tlearn: 0.1380223\ttotal: 18.6s\tremaining: 16.5s\n",
      "265:\tlearn: 0.1379958\ttotal: 18.7s\tremaining: 16.5s\n",
      "266:\tlearn: 0.1379789\ttotal: 18.8s\tremaining: 16.4s\n",
      "267:\tlearn: 0.1379532\ttotal: 18.9s\tremaining: 16.3s\n",
      "268:\tlearn: 0.1379222\ttotal: 18.9s\tremaining: 16.3s\n",
      "269:\tlearn: 0.1379033\ttotal: 19s\tremaining: 16.2s\n",
      "270:\tlearn: 0.1378867\ttotal: 19s\tremaining: 16.1s\n",
      "271:\tlearn: 0.1378644\ttotal: 19.1s\tremaining: 16s\n",
      "272:\tlearn: 0.1378379\ttotal: 19.2s\tremaining: 15.9s\n",
      "273:\tlearn: 0.1378187\ttotal: 19.3s\tremaining: 15.9s\n",
      "274:\tlearn: 0.1377974\ttotal: 19.3s\tremaining: 15.8s\n",
      "275:\tlearn: 0.1377679\ttotal: 19.4s\tremaining: 15.7s\n",
      "276:\tlearn: 0.1377484\ttotal: 19.4s\tremaining: 15.6s\n",
      "277:\tlearn: 0.1377270\ttotal: 19.5s\tremaining: 15.6s\n",
      "278:\tlearn: 0.1376975\ttotal: 19.6s\tremaining: 15.5s\n",
      "279:\tlearn: 0.1376746\ttotal: 19.6s\tremaining: 15.4s\n",
      "280:\tlearn: 0.1376504\ttotal: 19.7s\tremaining: 15.4s\n",
      "281:\tlearn: 0.1376202\ttotal: 19.7s\tremaining: 15.3s\n",
      "282:\tlearn: 0.1376043\ttotal: 19.8s\tremaining: 15.2s\n",
      "283:\tlearn: 0.1375838\ttotal: 19.8s\tremaining: 15.1s\n",
      "284:\tlearn: 0.1375621\ttotal: 19.9s\tremaining: 15s\n",
      "285:\tlearn: 0.1375361\ttotal: 20s\tremaining: 15s\n",
      "286:\tlearn: 0.1375133\ttotal: 20s\tremaining: 14.9s\n",
      "287:\tlearn: 0.1374867\ttotal: 20.1s\tremaining: 14.8s\n",
      "288:\tlearn: 0.1374604\ttotal: 20.2s\tremaining: 14.7s\n",
      "289:\tlearn: 0.1374301\ttotal: 20.2s\tremaining: 14.6s\n",
      "290:\tlearn: 0.1374079\ttotal: 20.3s\tremaining: 14.6s\n",
      "291:\tlearn: 0.1373883\ttotal: 20.4s\tremaining: 14.5s\n",
      "292:\tlearn: 0.1373720\ttotal: 20.4s\tremaining: 14.4s\n",
      "293:\tlearn: 0.1373535\ttotal: 20.4s\tremaining: 14.3s\n",
      "294:\tlearn: 0.1373194\ttotal: 20.5s\tremaining: 14.2s\n",
      "295:\tlearn: 0.1372989\ttotal: 20.6s\tremaining: 14.2s\n",
      "296:\tlearn: 0.1372787\ttotal: 20.6s\tremaining: 14.1s\n",
      "297:\tlearn: 0.1372485\ttotal: 20.7s\tremaining: 14s\n",
      "298:\tlearn: 0.1372301\ttotal: 20.7s\tremaining: 13.9s\n",
      "299:\tlearn: 0.1372064\ttotal: 20.8s\tremaining: 13.9s\n",
      "300:\tlearn: 0.1371844\ttotal: 20.8s\tremaining: 13.8s\n",
      "301:\tlearn: 0.1371630\ttotal: 20.9s\tremaining: 13.7s\n",
      "302:\tlearn: 0.1371311\ttotal: 21s\tremaining: 13.6s\n",
      "303:\tlearn: 0.1371105\ttotal: 21s\tremaining: 13.5s\n",
      "304:\tlearn: 0.1370908\ttotal: 21.1s\tremaining: 13.5s\n",
      "305:\tlearn: 0.1370562\ttotal: 21.1s\tremaining: 13.4s\n",
      "306:\tlearn: 0.1370343\ttotal: 21.2s\tremaining: 13.3s\n",
      "307:\tlearn: 0.1370086\ttotal: 21.3s\tremaining: 13.3s\n",
      "308:\tlearn: 0.1369930\ttotal: 21.4s\tremaining: 13.2s\n",
      "309:\tlearn: 0.1369751\ttotal: 21.4s\tremaining: 13.1s\n",
      "310:\tlearn: 0.1369508\ttotal: 21.5s\tremaining: 13.1s\n",
      "311:\tlearn: 0.1369307\ttotal: 21.6s\tremaining: 13s\n",
      "312:\tlearn: 0.1369134\ttotal: 21.6s\tremaining: 12.9s\n",
      "313:\tlearn: 0.1368814\ttotal: 21.7s\tremaining: 12.8s\n",
      "314:\tlearn: 0.1368573\ttotal: 21.8s\tremaining: 12.8s\n",
      "315:\tlearn: 0.1368357\ttotal: 21.8s\tremaining: 12.7s\n",
      "316:\tlearn: 0.1368090\ttotal: 21.9s\tremaining: 12.6s\n",
      "317:\tlearn: 0.1367853\ttotal: 21.9s\tremaining: 12.5s\n",
      "318:\tlearn: 0.1367671\ttotal: 22s\tremaining: 12.5s\n",
      "319:\tlearn: 0.1367469\ttotal: 22s\tremaining: 12.4s\n",
      "320:\tlearn: 0.1367277\ttotal: 22.1s\tremaining: 12.3s\n",
      "321:\tlearn: 0.1367050\ttotal: 22.2s\tremaining: 12.3s\n",
      "322:\tlearn: 0.1366858\ttotal: 22.3s\tremaining: 12.2s\n",
      "323:\tlearn: 0.1366717\ttotal: 22.3s\tremaining: 12.1s\n",
      "324:\tlearn: 0.1366599\ttotal: 22.4s\tremaining: 12.1s\n",
      "325:\tlearn: 0.1366426\ttotal: 22.5s\tremaining: 12s\n",
      "326:\tlearn: 0.1366299\ttotal: 22.6s\tremaining: 11.9s\n",
      "327:\tlearn: 0.1366140\ttotal: 22.6s\tremaining: 11.9s\n",
      "328:\tlearn: 0.1366003\ttotal: 22.7s\tremaining: 11.8s\n",
      "329:\tlearn: 0.1365756\ttotal: 22.7s\tremaining: 11.7s\n",
      "330:\tlearn: 0.1365605\ttotal: 22.8s\tremaining: 11.6s\n",
      "331:\tlearn: 0.1365445\ttotal: 22.8s\tremaining: 11.6s\n",
      "332:\tlearn: 0.1365286\ttotal: 22.9s\tremaining: 11.5s\n",
      "333:\tlearn: 0.1365095\ttotal: 23s\tremaining: 11.4s\n",
      "334:\tlearn: 0.1364928\ttotal: 23s\tremaining: 11.3s\n",
      "335:\tlearn: 0.1364715\ttotal: 23.1s\tremaining: 11.3s\n",
      "336:\tlearn: 0.1364550\ttotal: 23.1s\tremaining: 11.2s\n",
      "337:\tlearn: 0.1364348\ttotal: 23.2s\tremaining: 11.1s\n",
      "338:\tlearn: 0.1364216\ttotal: 23.3s\tremaining: 11.1s\n",
      "339:\tlearn: 0.1364025\ttotal: 23.3s\tremaining: 11s\n",
      "340:\tlearn: 0.1363863\ttotal: 23.4s\tremaining: 10.9s\n",
      "341:\tlearn: 0.1363662\ttotal: 23.4s\tremaining: 10.8s\n",
      "342:\tlearn: 0.1363486\ttotal: 23.5s\tremaining: 10.8s\n",
      "343:\tlearn: 0.1363324\ttotal: 23.6s\tremaining: 10.7s\n",
      "344:\tlearn: 0.1363164\ttotal: 23.6s\tremaining: 10.6s\n",
      "345:\tlearn: 0.1362928\ttotal: 23.7s\tremaining: 10.5s\n",
      "346:\tlearn: 0.1362767\ttotal: 23.7s\tremaining: 10.5s\n",
      "347:\tlearn: 0.1362579\ttotal: 23.8s\tremaining: 10.4s\n",
      "348:\tlearn: 0.1362432\ttotal: 23.9s\tremaining: 10.3s\n",
      "349:\tlearn: 0.1362239\ttotal: 23.9s\tremaining: 10.3s\n",
      "350:\tlearn: 0.1362002\ttotal: 24s\tremaining: 10.2s\n",
      "351:\tlearn: 0.1361852\ttotal: 24s\tremaining: 10.1s\n",
      "352:\tlearn: 0.1361698\ttotal: 24.1s\tremaining: 10s\n",
      "353:\tlearn: 0.1361470\ttotal: 24.2s\tremaining: 9.96s\n",
      "354:\tlearn: 0.1361088\ttotal: 24.2s\tremaining: 9.88s\n",
      "355:\tlearn: 0.1360885\ttotal: 24.3s\tremaining: 9.81s\n",
      "356:\tlearn: 0.1360703\ttotal: 24.3s\tremaining: 9.74s\n",
      "357:\tlearn: 0.1360543\ttotal: 24.4s\tremaining: 9.67s\n",
      "358:\tlearn: 0.1360356\ttotal: 24.4s\tremaining: 9.6s\n",
      "359:\tlearn: 0.1360221\ttotal: 24.5s\tremaining: 9.52s\n",
      "360:\tlearn: 0.1359966\ttotal: 24.5s\tremaining: 9.45s\n",
      "361:\tlearn: 0.1359706\ttotal: 24.6s\tremaining: 9.38s\n",
      "362:\tlearn: 0.1359510\ttotal: 24.7s\tremaining: 9.32s\n",
      "363:\tlearn: 0.1359326\ttotal: 24.7s\tremaining: 9.24s\n",
      "364:\tlearn: 0.1359160\ttotal: 24.8s\tremaining: 9.17s\n",
      "365:\tlearn: 0.1358965\ttotal: 24.9s\tremaining: 9.1s\n",
      "366:\tlearn: 0.1358770\ttotal: 24.9s\tremaining: 9.03s\n",
      "367:\tlearn: 0.1358632\ttotal: 25s\tremaining: 8.97s\n",
      "368:\tlearn: 0.1358462\ttotal: 25.1s\tremaining: 8.9s\n",
      "369:\tlearn: 0.1358281\ttotal: 25.1s\tremaining: 8.83s\n",
      "370:\tlearn: 0.1358018\ttotal: 25.2s\tremaining: 8.76s\n",
      "371:\tlearn: 0.1357837\ttotal: 25.2s\tremaining: 8.69s\n",
      "372:\tlearn: 0.1357684\ttotal: 25.3s\tremaining: 8.62s\n",
      "373:\tlearn: 0.1357546\ttotal: 25.4s\tremaining: 8.55s\n",
      "374:\tlearn: 0.1357352\ttotal: 25.4s\tremaining: 8.48s\n",
      "375:\tlearn: 0.1357154\ttotal: 25.5s\tremaining: 8.41s\n",
      "376:\tlearn: 0.1356996\ttotal: 25.6s\tremaining: 8.34s\n",
      "377:\tlearn: 0.1356854\ttotal: 25.6s\tremaining: 8.27s\n",
      "378:\tlearn: 0.1356703\ttotal: 25.7s\tremaining: 8.19s\n",
      "379:\tlearn: 0.1356577\ttotal: 25.7s\tremaining: 8.12s\n",
      "380:\tlearn: 0.1356434\ttotal: 25.8s\tremaining: 8.05s\n",
      "381:\tlearn: 0.1356193\ttotal: 25.8s\tremaining: 7.98s\n",
      "382:\tlearn: 0.1356026\ttotal: 25.9s\tremaining: 7.91s\n",
      "383:\tlearn: 0.1355790\ttotal: 25.9s\tremaining: 7.83s\n",
      "384:\tlearn: 0.1355629\ttotal: 26s\tremaining: 7.76s\n",
      "385:\tlearn: 0.1355503\ttotal: 26s\tremaining: 7.69s\n",
      "386:\tlearn: 0.1355267\ttotal: 26.1s\tremaining: 7.62s\n",
      "387:\tlearn: 0.1355036\ttotal: 26.2s\tremaining: 7.55s\n",
      "388:\tlearn: 0.1354897\ttotal: 26.2s\tremaining: 7.48s\n",
      "389:\tlearn: 0.1354700\ttotal: 26.3s\tremaining: 7.41s\n",
      "390:\tlearn: 0.1354508\ttotal: 26.3s\tremaining: 7.34s\n",
      "391:\tlearn: 0.1354286\ttotal: 26.4s\tremaining: 7.27s\n",
      "392:\tlearn: 0.1354079\ttotal: 26.5s\tremaining: 7.2s\n",
      "393:\tlearn: 0.1353946\ttotal: 26.5s\tremaining: 7.13s\n",
      "394:\tlearn: 0.1353817\ttotal: 26.6s\tremaining: 7.07s\n",
      "395:\tlearn: 0.1353632\ttotal: 26.6s\tremaining: 6.99s\n",
      "396:\tlearn: 0.1353471\ttotal: 26.7s\tremaining: 6.92s\n",
      "397:\tlearn: 0.1353347\ttotal: 26.7s\tremaining: 6.85s\n",
      "398:\tlearn: 0.1353167\ttotal: 26.8s\tremaining: 6.78s\n",
      "399:\tlearn: 0.1353022\ttotal: 26.9s\tremaining: 6.71s\n",
      "400:\tlearn: 0.1352902\ttotal: 26.9s\tremaining: 6.64s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401:\tlearn: 0.1352702\ttotal: 27s\tremaining: 6.57s\n",
      "402:\tlearn: 0.1352516\ttotal: 27s\tremaining: 6.5s\n",
      "403:\tlearn: 0.1352282\ttotal: 27.1s\tremaining: 6.43s\n",
      "404:\tlearn: 0.1352106\ttotal: 27.1s\tremaining: 6.36s\n",
      "405:\tlearn: 0.1351934\ttotal: 27.2s\tremaining: 6.3s\n",
      "406:\tlearn: 0.1351798\ttotal: 27.3s\tremaining: 6.23s\n",
      "407:\tlearn: 0.1351582\ttotal: 27.3s\tremaining: 6.16s\n",
      "408:\tlearn: 0.1351452\ttotal: 27.4s\tremaining: 6.09s\n",
      "409:\tlearn: 0.1351348\ttotal: 27.4s\tremaining: 6.01s\n",
      "410:\tlearn: 0.1351202\ttotal: 27.5s\tremaining: 5.95s\n",
      "411:\tlearn: 0.1351020\ttotal: 27.5s\tremaining: 5.88s\n",
      "412:\tlearn: 0.1350798\ttotal: 27.6s\tremaining: 5.81s\n",
      "413:\tlearn: 0.1350586\ttotal: 27.7s\tremaining: 5.74s\n",
      "414:\tlearn: 0.1350465\ttotal: 27.7s\tremaining: 5.67s\n",
      "415:\tlearn: 0.1350301\ttotal: 27.8s\tremaining: 5.6s\n",
      "416:\tlearn: 0.1350156\ttotal: 27.8s\tremaining: 5.54s\n",
      "417:\tlearn: 0.1349983\ttotal: 27.9s\tremaining: 5.47s\n",
      "418:\tlearn: 0.1349822\ttotal: 27.9s\tremaining: 5.4s\n",
      "419:\tlearn: 0.1349650\ttotal: 28s\tremaining: 5.33s\n",
      "420:\tlearn: 0.1349497\ttotal: 28s\tremaining: 5.26s\n",
      "421:\tlearn: 0.1349336\ttotal: 28.1s\tremaining: 5.19s\n",
      "422:\tlearn: 0.1349191\ttotal: 28.1s\tremaining: 5.12s\n",
      "423:\tlearn: 0.1349058\ttotal: 28.2s\tremaining: 5.05s\n",
      "424:\tlearn: 0.1348901\ttotal: 28.3s\tremaining: 4.99s\n",
      "425:\tlearn: 0.1348812\ttotal: 28.3s\tremaining: 4.92s\n",
      "426:\tlearn: 0.1348659\ttotal: 28.4s\tremaining: 4.85s\n",
      "427:\tlearn: 0.1348514\ttotal: 28.4s\tremaining: 4.78s\n",
      "428:\tlearn: 0.1348393\ttotal: 28.5s\tremaining: 4.71s\n",
      "429:\tlearn: 0.1348235\ttotal: 28.5s\tremaining: 4.64s\n",
      "430:\tlearn: 0.1348055\ttotal: 28.6s\tremaining: 4.58s\n",
      "431:\tlearn: 0.1347901\ttotal: 28.6s\tremaining: 4.51s\n",
      "432:\tlearn: 0.1347744\ttotal: 28.7s\tremaining: 4.44s\n",
      "433:\tlearn: 0.1347632\ttotal: 28.7s\tremaining: 4.37s\n",
      "434:\tlearn: 0.1347486\ttotal: 28.8s\tremaining: 4.3s\n",
      "435:\tlearn: 0.1347341\ttotal: 28.9s\tremaining: 4.24s\n",
      "436:\tlearn: 0.1347214\ttotal: 28.9s\tremaining: 4.17s\n",
      "437:\tlearn: 0.1347115\ttotal: 29s\tremaining: 4.1s\n",
      "438:\tlearn: 0.1346938\ttotal: 29s\tremaining: 4.03s\n",
      "439:\tlearn: 0.1346792\ttotal: 29.1s\tremaining: 3.96s\n",
      "440:\tlearn: 0.1346631\ttotal: 29.1s\tremaining: 3.9s\n",
      "441:\tlearn: 0.1346431\ttotal: 29.2s\tremaining: 3.83s\n",
      "442:\tlearn: 0.1346281\ttotal: 29.2s\tremaining: 3.76s\n",
      "443:\tlearn: 0.1346041\ttotal: 29.3s\tremaining: 3.69s\n",
      "444:\tlearn: 0.1345902\ttotal: 29.4s\tremaining: 3.63s\n",
      "445:\tlearn: 0.1345762\ttotal: 29.4s\tremaining: 3.56s\n",
      "446:\tlearn: 0.1345586\ttotal: 29.5s\tremaining: 3.49s\n",
      "447:\tlearn: 0.1345446\ttotal: 29.5s\tremaining: 3.42s\n",
      "448:\tlearn: 0.1345246\ttotal: 29.6s\tremaining: 3.36s\n",
      "449:\tlearn: 0.1345070\ttotal: 29.6s\tremaining: 3.29s\n",
      "450:\tlearn: 0.1344957\ttotal: 29.7s\tremaining: 3.23s\n",
      "451:\tlearn: 0.1344810\ttotal: 29.7s\tremaining: 3.16s\n",
      "452:\tlearn: 0.1344693\ttotal: 29.8s\tremaining: 3.09s\n",
      "453:\tlearn: 0.1344493\ttotal: 29.8s\tremaining: 3.02s\n",
      "454:\tlearn: 0.1344319\ttotal: 29.9s\tremaining: 2.96s\n",
      "455:\tlearn: 0.1344151\ttotal: 30s\tremaining: 2.89s\n",
      "456:\tlearn: 0.1343928\ttotal: 30s\tremaining: 2.82s\n",
      "457:\tlearn: 0.1343826\ttotal: 30.1s\tremaining: 2.76s\n",
      "458:\tlearn: 0.1343685\ttotal: 30.1s\tremaining: 2.69s\n",
      "459:\tlearn: 0.1343555\ttotal: 30.2s\tremaining: 2.62s\n",
      "460:\tlearn: 0.1343451\ttotal: 30.3s\tremaining: 2.56s\n",
      "461:\tlearn: 0.1343328\ttotal: 30.3s\tremaining: 2.49s\n",
      "462:\tlearn: 0.1343178\ttotal: 30.4s\tremaining: 2.43s\n",
      "463:\tlearn: 0.1343063\ttotal: 30.4s\tremaining: 2.36s\n",
      "464:\tlearn: 0.1342904\ttotal: 30.5s\tremaining: 2.29s\n",
      "465:\tlearn: 0.1342746\ttotal: 30.5s\tremaining: 2.23s\n",
      "466:\tlearn: 0.1342578\ttotal: 30.6s\tremaining: 2.16s\n",
      "467:\tlearn: 0.1342438\ttotal: 30.7s\tremaining: 2.1s\n",
      "468:\tlearn: 0.1342296\ttotal: 30.7s\tremaining: 2.03s\n",
      "469:\tlearn: 0.1342041\ttotal: 30.8s\tremaining: 1.97s\n",
      "470:\tlearn: 0.1341894\ttotal: 30.9s\tremaining: 1.9s\n",
      "471:\tlearn: 0.1341716\ttotal: 30.9s\tremaining: 1.83s\n",
      "472:\tlearn: 0.1341609\ttotal: 31s\tremaining: 1.77s\n",
      "473:\tlearn: 0.1341478\ttotal: 31s\tremaining: 1.7s\n",
      "474:\tlearn: 0.1341316\ttotal: 31.1s\tremaining: 1.64s\n",
      "475:\tlearn: 0.1341173\ttotal: 31.2s\tremaining: 1.57s\n",
      "476:\tlearn: 0.1341047\ttotal: 31.2s\tremaining: 1.5s\n",
      "477:\tlearn: 0.1340909\ttotal: 31.3s\tremaining: 1.44s\n",
      "478:\tlearn: 0.1340742\ttotal: 31.3s\tremaining: 1.37s\n",
      "479:\tlearn: 0.1340461\ttotal: 31.4s\tremaining: 1.31s\n",
      "480:\tlearn: 0.1340327\ttotal: 31.5s\tremaining: 1.24s\n",
      "481:\tlearn: 0.1340190\ttotal: 31.5s\tremaining: 1.18s\n",
      "482:\tlearn: 0.1340070\ttotal: 31.6s\tremaining: 1.11s\n",
      "483:\tlearn: 0.1339929\ttotal: 31.7s\tremaining: 1.05s\n",
      "484:\tlearn: 0.1339827\ttotal: 31.8s\tremaining: 982ms\n",
      "485:\tlearn: 0.1339703\ttotal: 31.8s\tremaining: 916ms\n",
      "486:\tlearn: 0.1339547\ttotal: 31.9s\tremaining: 851ms\n",
      "487:\tlearn: 0.1339385\ttotal: 31.9s\tremaining: 785ms\n",
      "488:\tlearn: 0.1339239\ttotal: 32s\tremaining: 719ms\n",
      "489:\tlearn: 0.1339070\ttotal: 32s\tremaining: 654ms\n",
      "490:\tlearn: 0.1338925\ttotal: 32.1s\tremaining: 589ms\n",
      "491:\tlearn: 0.1338755\ttotal: 32.2s\tremaining: 524ms\n",
      "492:\tlearn: 0.1338610\ttotal: 32.3s\tremaining: 459ms\n",
      "493:\tlearn: 0.1338494\ttotal: 32.4s\tremaining: 394ms\n",
      "494:\tlearn: 0.1338314\ttotal: 32.5s\tremaining: 328ms\n",
      "495:\tlearn: 0.1338188\ttotal: 32.6s\tremaining: 263ms\n",
      "496:\tlearn: 0.1338057\ttotal: 32.6s\tremaining: 197ms\n",
      "497:\tlearn: 0.1337939\ttotal: 32.7s\tremaining: 131ms\n",
      "498:\tlearn: 0.1337775\ttotal: 32.8s\tremaining: 65.7ms\n",
      "499:\tlearn: 0.1337640\ttotal: 32.8s\tremaining: 0us\n",
      "[CV]  learning_rate=0.1, l2_leaf_reg=7, iterations=500, depth=4, total=  33.5s\n",
      "[CV] learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2 .....\n",
      "0:\tlearn: 0.6931457\ttotal: 75.3ms\tremaining: 7.45s\n",
      "1:\tlearn: 0.6931443\ttotal: 149ms\tremaining: 7.28s\n",
      "2:\tlearn: 0.6931428\ttotal: 214ms\tremaining: 6.93s\n",
      "3:\tlearn: 0.6931414\ttotal: 270ms\tremaining: 6.49s\n",
      "4:\tlearn: 0.6931399\ttotal: 341ms\tremaining: 6.48s\n",
      "5:\tlearn: 0.6931385\ttotal: 411ms\tremaining: 6.44s\n",
      "6:\tlearn: 0.6931370\ttotal: 478ms\tremaining: 6.35s\n",
      "7:\tlearn: 0.6931355\ttotal: 542ms\tremaining: 6.23s\n",
      "8:\tlearn: 0.6931341\ttotal: 613ms\tremaining: 6.2s\n",
      "9:\tlearn: 0.6931326\ttotal: 691ms\tremaining: 6.22s\n",
      "10:\tlearn: 0.6931312\ttotal: 749ms\tremaining: 6.06s\n",
      "11:\tlearn: 0.6931297\ttotal: 823ms\tremaining: 6.04s\n",
      "12:\tlearn: 0.6931283\ttotal: 903ms\tremaining: 6.04s\n",
      "13:\tlearn: 0.6931268\ttotal: 973ms\tremaining: 5.98s\n",
      "14:\tlearn: 0.6931254\ttotal: 1.04s\tremaining: 5.88s\n",
      "15:\tlearn: 0.6931239\ttotal: 1.1s\tremaining: 5.79s\n",
      "16:\tlearn: 0.6931224\ttotal: 1.16s\tremaining: 5.65s\n",
      "17:\tlearn: 0.6931210\ttotal: 1.23s\tremaining: 5.62s\n",
      "18:\tlearn: 0.6931195\ttotal: 1.29s\tremaining: 5.49s\n",
      "19:\tlearn: 0.6931181\ttotal: 1.35s\tremaining: 5.41s\n",
      "20:\tlearn: 0.6931167\ttotal: 1.41s\tremaining: 5.31s\n",
      "21:\tlearn: 0.6931152\ttotal: 1.48s\tremaining: 5.25s\n",
      "22:\tlearn: 0.6931136\ttotal: 1.56s\tremaining: 5.22s\n",
      "23:\tlearn: 0.6931122\ttotal: 1.62s\tremaining: 5.13s\n",
      "24:\tlearn: 0.6931107\ttotal: 1.68s\tremaining: 5.03s\n",
      "25:\tlearn: 0.6931092\ttotal: 1.75s\tremaining: 4.99s\n",
      "26:\tlearn: 0.6931077\ttotal: 1.82s\tremaining: 4.93s\n",
      "27:\tlearn: 0.6931063\ttotal: 1.9s\tremaining: 4.88s\n",
      "28:\tlearn: 0.6931048\ttotal: 1.97s\tremaining: 4.82s\n",
      "29:\tlearn: 0.6931033\ttotal: 2.04s\tremaining: 4.76s\n",
      "30:\tlearn: 0.6931018\ttotal: 2.1s\tremaining: 4.67s\n",
      "31:\tlearn: 0.6931004\ttotal: 2.15s\tremaining: 4.57s\n",
      "32:\tlearn: 0.6930989\ttotal: 2.22s\tremaining: 4.5s\n",
      "33:\tlearn: 0.6930973\ttotal: 2.29s\tremaining: 4.45s\n",
      "34:\tlearn: 0.6930958\ttotal: 2.36s\tremaining: 4.38s\n",
      "35:\tlearn: 0.6930944\ttotal: 2.42s\tremaining: 4.31s\n",
      "36:\tlearn: 0.6930929\ttotal: 2.49s\tremaining: 4.25s\n",
      "37:\tlearn: 0.6930915\ttotal: 2.55s\tremaining: 4.16s\n",
      "38:\tlearn: 0.6930900\ttotal: 2.62s\tremaining: 4.1s\n",
      "39:\tlearn: 0.6930886\ttotal: 2.69s\tremaining: 4.04s\n",
      "40:\tlearn: 0.6930871\ttotal: 2.75s\tremaining: 3.96s\n",
      "41:\tlearn: 0.6930856\ttotal: 2.82s\tremaining: 3.89s\n",
      "42:\tlearn: 0.6930841\ttotal: 2.89s\tremaining: 3.83s\n",
      "43:\tlearn: 0.6930827\ttotal: 2.97s\tremaining: 3.78s\n",
      "44:\tlearn: 0.6930812\ttotal: 3.04s\tremaining: 3.71s\n",
      "45:\tlearn: 0.6930797\ttotal: 3.11s\tremaining: 3.66s\n",
      "46:\tlearn: 0.6930783\ttotal: 3.17s\tremaining: 3.58s\n",
      "47:\tlearn: 0.6930768\ttotal: 3.25s\tremaining: 3.52s\n",
      "48:\tlearn: 0.6930753\ttotal: 3.31s\tremaining: 3.45s\n",
      "49:\tlearn: 0.6930738\ttotal: 3.38s\tremaining: 3.38s\n",
      "50:\tlearn: 0.6930724\ttotal: 3.45s\tremaining: 3.32s\n",
      "51:\tlearn: 0.6930710\ttotal: 3.52s\tremaining: 3.25s\n",
      "52:\tlearn: 0.6930695\ttotal: 3.6s\tremaining: 3.19s\n",
      "53:\tlearn: 0.6930679\ttotal: 3.68s\tremaining: 3.14s\n",
      "54:\tlearn: 0.6930665\ttotal: 3.75s\tremaining: 3.06s\n",
      "55:\tlearn: 0.6930650\ttotal: 3.81s\tremaining: 3s\n",
      "56:\tlearn: 0.6930636\ttotal: 3.88s\tremaining: 2.93s\n",
      "57:\tlearn: 0.6930620\ttotal: 3.96s\tremaining: 2.87s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58:\tlearn: 0.6930605\ttotal: 4.05s\tremaining: 2.81s\n",
      "59:\tlearn: 0.6930591\ttotal: 4.13s\tremaining: 2.75s\n",
      "60:\tlearn: 0.6930576\ttotal: 4.21s\tremaining: 2.69s\n",
      "61:\tlearn: 0.6930562\ttotal: 4.28s\tremaining: 2.62s\n",
      "62:\tlearn: 0.6930547\ttotal: 4.35s\tremaining: 2.56s\n",
      "63:\tlearn: 0.6930533\ttotal: 4.41s\tremaining: 2.48s\n",
      "64:\tlearn: 0.6930518\ttotal: 4.49s\tremaining: 2.42s\n",
      "65:\tlearn: 0.6930504\ttotal: 4.57s\tremaining: 2.35s\n",
      "66:\tlearn: 0.6930489\ttotal: 4.63s\tremaining: 2.28s\n",
      "67:\tlearn: 0.6930473\ttotal: 4.71s\tremaining: 2.22s\n",
      "68:\tlearn: 0.6930459\ttotal: 4.78s\tremaining: 2.15s\n",
      "69:\tlearn: 0.6930444\ttotal: 4.84s\tremaining: 2.07s\n",
      "70:\tlearn: 0.6930429\ttotal: 4.9s\tremaining: 2s\n",
      "71:\tlearn: 0.6930415\ttotal: 4.97s\tremaining: 1.93s\n",
      "72:\tlearn: 0.6930400\ttotal: 5.06s\tremaining: 1.87s\n",
      "73:\tlearn: 0.6930385\ttotal: 5.12s\tremaining: 1.8s\n",
      "74:\tlearn: 0.6930371\ttotal: 5.19s\tremaining: 1.73s\n",
      "75:\tlearn: 0.6930356\ttotal: 5.27s\tremaining: 1.66s\n",
      "76:\tlearn: 0.6930341\ttotal: 5.34s\tremaining: 1.6s\n",
      "77:\tlearn: 0.6930326\ttotal: 5.41s\tremaining: 1.53s\n",
      "78:\tlearn: 0.6930312\ttotal: 5.49s\tremaining: 1.46s\n",
      "79:\tlearn: 0.6930297\ttotal: 5.57s\tremaining: 1.39s\n",
      "80:\tlearn: 0.6930283\ttotal: 5.63s\tremaining: 1.32s\n",
      "81:\tlearn: 0.6930268\ttotal: 5.71s\tremaining: 1.25s\n",
      "82:\tlearn: 0.6930253\ttotal: 5.77s\tremaining: 1.18s\n",
      "83:\tlearn: 0.6930239\ttotal: 5.84s\tremaining: 1.11s\n",
      "84:\tlearn: 0.6930222\ttotal: 5.94s\tremaining: 1.05s\n",
      "85:\tlearn: 0.6930208\ttotal: 6s\tremaining: 977ms\n",
      "86:\tlearn: 0.6930192\ttotal: 6.09s\tremaining: 911ms\n",
      "87:\tlearn: 0.6930176\ttotal: 6.19s\tremaining: 844ms\n",
      "88:\tlearn: 0.6930161\ttotal: 6.26s\tremaining: 774ms\n",
      "89:\tlearn: 0.6930146\ttotal: 6.34s\tremaining: 704ms\n",
      "90:\tlearn: 0.6930132\ttotal: 6.41s\tremaining: 634ms\n",
      "91:\tlearn: 0.6930118\ttotal: 6.46s\tremaining: 562ms\n",
      "92:\tlearn: 0.6930103\ttotal: 6.54s\tremaining: 493ms\n",
      "93:\tlearn: 0.6930089\ttotal: 6.62s\tremaining: 423ms\n",
      "94:\tlearn: 0.6930074\ttotal: 6.69s\tremaining: 352ms\n",
      "95:\tlearn: 0.6930060\ttotal: 6.77s\tremaining: 282ms\n",
      "96:\tlearn: 0.6930045\ttotal: 6.87s\tremaining: 212ms\n",
      "97:\tlearn: 0.6930031\ttotal: 6.94s\tremaining: 142ms\n",
      "98:\tlearn: 0.6930015\ttotal: 7.04s\tremaining: 71.1ms\n",
      "99:\tlearn: 0.6930000\ttotal: 7.13s\tremaining: 0us\n",
      "[CV]  learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2, total=   7.7s\n",
      "[CV] learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2 .....\n",
      "0:\tlearn: 0.6931457\ttotal: 58.5ms\tremaining: 5.8s\n",
      "1:\tlearn: 0.6931443\ttotal: 114ms\tremaining: 5.57s\n",
      "2:\tlearn: 0.6931428\ttotal: 175ms\tremaining: 5.67s\n",
      "3:\tlearn: 0.6931413\ttotal: 235ms\tremaining: 5.65s\n",
      "4:\tlearn: 0.6931399\ttotal: 304ms\tremaining: 5.78s\n",
      "5:\tlearn: 0.6931384\ttotal: 371ms\tremaining: 5.8s\n",
      "6:\tlearn: 0.6931370\ttotal: 454ms\tremaining: 6.04s\n",
      "7:\tlearn: 0.6931355\ttotal: 525ms\tremaining: 6.04s\n",
      "8:\tlearn: 0.6931341\ttotal: 601ms\tremaining: 6.08s\n",
      "9:\tlearn: 0.6931326\ttotal: 670ms\tremaining: 6.03s\n",
      "10:\tlearn: 0.6931312\ttotal: 751ms\tremaining: 6.07s\n",
      "11:\tlearn: 0.6931297\ttotal: 857ms\tremaining: 6.29s\n",
      "12:\tlearn: 0.6931282\ttotal: 938ms\tremaining: 6.28s\n",
      "13:\tlearn: 0.6931268\ttotal: 1.01s\tremaining: 6.23s\n",
      "14:\tlearn: 0.6931253\ttotal: 1.08s\tremaining: 6.12s\n",
      "15:\tlearn: 0.6931239\ttotal: 1.16s\tremaining: 6.06s\n",
      "16:\tlearn: 0.6931224\ttotal: 1.23s\tremaining: 5.99s\n",
      "17:\tlearn: 0.6931210\ttotal: 1.3s\tremaining: 5.91s\n",
      "18:\tlearn: 0.6931195\ttotal: 1.36s\tremaining: 5.81s\n",
      "19:\tlearn: 0.6931180\ttotal: 1.43s\tremaining: 5.71s\n",
      "20:\tlearn: 0.6931166\ttotal: 1.51s\tremaining: 5.68s\n",
      "21:\tlearn: 0.6931151\ttotal: 1.56s\tremaining: 5.54s\n",
      "22:\tlearn: 0.6931137\ttotal: 1.62s\tremaining: 5.44s\n",
      "23:\tlearn: 0.6931123\ttotal: 1.69s\tremaining: 5.34s\n",
      "24:\tlearn: 0.6931108\ttotal: 1.74s\tremaining: 5.22s\n",
      "25:\tlearn: 0.6931094\ttotal: 1.8s\tremaining: 5.14s\n",
      "26:\tlearn: 0.6931079\ttotal: 1.86s\tremaining: 5.02s\n",
      "27:\tlearn: 0.6931065\ttotal: 1.94s\tremaining: 4.98s\n",
      "28:\tlearn: 0.6931049\ttotal: 2.02s\tremaining: 4.96s\n",
      "29:\tlearn: 0.6931034\ttotal: 2.1s\tremaining: 4.91s\n",
      "30:\tlearn: 0.6931019\ttotal: 2.17s\tremaining: 4.83s\n",
      "31:\tlearn: 0.6931005\ttotal: 2.24s\tremaining: 4.76s\n",
      "32:\tlearn: 0.6930988\ttotal: 2.32s\tremaining: 4.72s\n",
      "33:\tlearn: 0.6930974\ttotal: 2.4s\tremaining: 4.65s\n",
      "34:\tlearn: 0.6930959\ttotal: 2.48s\tremaining: 4.61s\n",
      "35:\tlearn: 0.6930944\ttotal: 2.55s\tremaining: 4.53s\n",
      "36:\tlearn: 0.6930930\ttotal: 2.62s\tremaining: 4.46s\n",
      "37:\tlearn: 0.6930915\ttotal: 2.69s\tremaining: 4.38s\n",
      "38:\tlearn: 0.6930900\ttotal: 2.75s\tremaining: 4.31s\n",
      "39:\tlearn: 0.6930885\ttotal: 2.82s\tremaining: 4.22s\n",
      "40:\tlearn: 0.6930869\ttotal: 2.9s\tremaining: 4.17s\n",
      "41:\tlearn: 0.6930854\ttotal: 2.97s\tremaining: 4.1s\n",
      "42:\tlearn: 0.6930840\ttotal: 3.04s\tremaining: 4.03s\n",
      "43:\tlearn: 0.6930825\ttotal: 3.11s\tremaining: 3.96s\n",
      "44:\tlearn: 0.6930811\ttotal: 3.17s\tremaining: 3.87s\n",
      "45:\tlearn: 0.6930795\ttotal: 3.23s\tremaining: 3.79s\n",
      "46:\tlearn: 0.6930781\ttotal: 3.3s\tremaining: 3.73s\n",
      "47:\tlearn: 0.6930766\ttotal: 3.36s\tremaining: 3.64s\n",
      "48:\tlearn: 0.6930751\ttotal: 3.43s\tremaining: 3.57s\n",
      "49:\tlearn: 0.6930737\ttotal: 3.5s\tremaining: 3.5s\n",
      "50:\tlearn: 0.6930723\ttotal: 3.57s\tremaining: 3.43s\n",
      "51:\tlearn: 0.6930708\ttotal: 3.64s\tremaining: 3.36s\n",
      "52:\tlearn: 0.6930694\ttotal: 3.7s\tremaining: 3.28s\n",
      "53:\tlearn: 0.6930678\ttotal: 3.77s\tremaining: 3.21s\n",
      "54:\tlearn: 0.6930663\ttotal: 3.82s\tremaining: 3.12s\n",
      "55:\tlearn: 0.6930649\ttotal: 3.88s\tremaining: 3.05s\n",
      "56:\tlearn: 0.6930633\ttotal: 3.96s\tremaining: 2.99s\n",
      "57:\tlearn: 0.6930618\ttotal: 4.05s\tremaining: 2.93s\n",
      "58:\tlearn: 0.6930604\ttotal: 4.12s\tremaining: 2.86s\n",
      "59:\tlearn: 0.6930589\ttotal: 4.18s\tremaining: 2.79s\n",
      "60:\tlearn: 0.6930575\ttotal: 4.26s\tremaining: 2.72s\n",
      "61:\tlearn: 0.6930560\ttotal: 4.35s\tremaining: 2.67s\n",
      "62:\tlearn: 0.6930545\ttotal: 4.43s\tremaining: 2.6s\n",
      "63:\tlearn: 0.6930531\ttotal: 4.51s\tremaining: 2.54s\n",
      "64:\tlearn: 0.6930516\ttotal: 4.58s\tremaining: 2.46s\n",
      "65:\tlearn: 0.6930502\ttotal: 4.67s\tremaining: 2.4s\n",
      "66:\tlearn: 0.6930487\ttotal: 4.74s\tremaining: 2.34s\n",
      "67:\tlearn: 0.6930471\ttotal: 4.83s\tremaining: 2.27s\n",
      "68:\tlearn: 0.6930456\ttotal: 4.91s\tremaining: 2.2s\n",
      "69:\tlearn: 0.6930442\ttotal: 4.99s\tremaining: 2.14s\n",
      "70:\tlearn: 0.6930426\ttotal: 5.07s\tremaining: 2.07s\n",
      "71:\tlearn: 0.6930412\ttotal: 5.15s\tremaining: 2s\n",
      "72:\tlearn: 0.6930397\ttotal: 5.21s\tremaining: 1.93s\n",
      "73:\tlearn: 0.6930382\ttotal: 5.29s\tremaining: 1.86s\n",
      "74:\tlearn: 0.6930366\ttotal: 5.37s\tremaining: 1.79s\n",
      "75:\tlearn: 0.6930352\ttotal: 5.44s\tremaining: 1.72s\n",
      "76:\tlearn: 0.6930337\ttotal: 5.5s\tremaining: 1.64s\n",
      "77:\tlearn: 0.6930321\ttotal: 5.57s\tremaining: 1.57s\n",
      "78:\tlearn: 0.6930307\ttotal: 5.62s\tremaining: 1.49s\n",
      "79:\tlearn: 0.6930292\ttotal: 5.69s\tremaining: 1.42s\n",
      "80:\tlearn: 0.6930277\ttotal: 5.76s\tremaining: 1.35s\n",
      "81:\tlearn: 0.6930263\ttotal: 5.81s\tremaining: 1.27s\n",
      "82:\tlearn: 0.6930248\ttotal: 5.89s\tremaining: 1.21s\n",
      "83:\tlearn: 0.6930234\ttotal: 5.96s\tremaining: 1.14s\n",
      "84:\tlearn: 0.6930218\ttotal: 6.04s\tremaining: 1.07s\n",
      "85:\tlearn: 0.6930204\ttotal: 6.1s\tremaining: 993ms\n",
      "86:\tlearn: 0.6930189\ttotal: 6.16s\tremaining: 921ms\n",
      "87:\tlearn: 0.6930175\ttotal: 6.23s\tremaining: 850ms\n",
      "88:\tlearn: 0.6930160\ttotal: 6.3s\tremaining: 779ms\n",
      "89:\tlearn: 0.6930146\ttotal: 6.37s\tremaining: 708ms\n",
      "90:\tlearn: 0.6930131\ttotal: 6.43s\tremaining: 636ms\n",
      "91:\tlearn: 0.6930117\ttotal: 6.5s\tremaining: 566ms\n",
      "92:\tlearn: 0.6930102\ttotal: 6.57s\tremaining: 494ms\n",
      "93:\tlearn: 0.6930087\ttotal: 6.64s\tremaining: 424ms\n",
      "94:\tlearn: 0.6930073\ttotal: 6.71s\tremaining: 353ms\n",
      "95:\tlearn: 0.6930058\ttotal: 6.78s\tremaining: 283ms\n",
      "96:\tlearn: 0.6930043\ttotal: 6.85s\tremaining: 212ms\n",
      "97:\tlearn: 0.6930028\ttotal: 6.92s\tremaining: 141ms\n",
      "98:\tlearn: 0.6930014\ttotal: 7s\tremaining: 70.7ms\n",
      "99:\tlearn: 0.6929998\ttotal: 7.07s\tremaining: 0us\n",
      "[CV]  learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2, total=   7.6s\n",
      "[CV] learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2 .....\n",
      "0:\tlearn: 0.6931457\ttotal: 68.1ms\tremaining: 6.74s\n",
      "1:\tlearn: 0.6931443\ttotal: 147ms\tremaining: 7.21s\n",
      "2:\tlearn: 0.6931428\ttotal: 217ms\tremaining: 7s\n",
      "3:\tlearn: 0.6931412\ttotal: 307ms\tremaining: 7.36s\n",
      "4:\tlearn: 0.6931398\ttotal: 380ms\tremaining: 7.22s\n",
      "5:\tlearn: 0.6931383\ttotal: 461ms\tremaining: 7.22s\n",
      "6:\tlearn: 0.6931368\ttotal: 534ms\tremaining: 7.09s\n",
      "7:\tlearn: 0.6931353\ttotal: 604ms\tremaining: 6.94s\n",
      "8:\tlearn: 0.6931338\ttotal: 670ms\tremaining: 6.77s\n",
      "9:\tlearn: 0.6931324\ttotal: 745ms\tremaining: 6.71s\n",
      "10:\tlearn: 0.6931308\ttotal: 839ms\tremaining: 6.79s\n",
      "11:\tlearn: 0.6931294\ttotal: 900ms\tremaining: 6.6s\n",
      "12:\tlearn: 0.6931279\ttotal: 964ms\tremaining: 6.45s\n",
      "13:\tlearn: 0.6931264\ttotal: 1.03s\tremaining: 6.32s\n",
      "14:\tlearn: 0.6931250\ttotal: 1.1s\tremaining: 6.26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:\tlearn: 0.6931235\ttotal: 1.18s\tremaining: 6.2s\n",
      "16:\tlearn: 0.6931221\ttotal: 1.26s\tremaining: 6.16s\n",
      "17:\tlearn: 0.6931206\ttotal: 1.33s\tremaining: 6.08s\n",
      "18:\tlearn: 0.6931192\ttotal: 1.4s\tremaining: 5.96s\n",
      "19:\tlearn: 0.6931177\ttotal: 1.47s\tremaining: 5.87s\n",
      "20:\tlearn: 0.6931163\ttotal: 1.53s\tremaining: 5.78s\n",
      "21:\tlearn: 0.6931148\ttotal: 1.6s\tremaining: 5.67s\n",
      "22:\tlearn: 0.6931133\ttotal: 1.67s\tremaining: 5.58s\n",
      "23:\tlearn: 0.6931119\ttotal: 1.73s\tremaining: 5.49s\n",
      "24:\tlearn: 0.6931104\ttotal: 1.81s\tremaining: 5.42s\n",
      "25:\tlearn: 0.6931089\ttotal: 1.88s\tremaining: 5.34s\n",
      "26:\tlearn: 0.6931075\ttotal: 1.94s\tremaining: 5.25s\n",
      "27:\tlearn: 0.6931060\ttotal: 2.02s\tremaining: 5.18s\n",
      "28:\tlearn: 0.6931044\ttotal: 2.1s\tremaining: 5.13s\n",
      "29:\tlearn: 0.6931030\ttotal: 2.16s\tremaining: 5.04s\n",
      "30:\tlearn: 0.6931015\ttotal: 2.23s\tremaining: 4.97s\n",
      "31:\tlearn: 0.6931000\ttotal: 2.29s\tremaining: 4.86s\n",
      "32:\tlearn: 0.6930985\ttotal: 2.35s\tremaining: 4.78s\n",
      "33:\tlearn: 0.6930970\ttotal: 2.42s\tremaining: 4.71s\n",
      "34:\tlearn: 0.6930956\ttotal: 2.5s\tremaining: 4.64s\n",
      "35:\tlearn: 0.6930941\ttotal: 2.56s\tremaining: 4.55s\n",
      "36:\tlearn: 0.6930927\ttotal: 2.62s\tremaining: 4.47s\n",
      "37:\tlearn: 0.6930912\ttotal: 2.69s\tremaining: 4.39s\n",
      "38:\tlearn: 0.6930897\ttotal: 2.77s\tremaining: 4.34s\n",
      "39:\tlearn: 0.6930882\ttotal: 2.84s\tremaining: 4.26s\n",
      "40:\tlearn: 0.6930867\ttotal: 2.91s\tremaining: 4.19s\n",
      "41:\tlearn: 0.6930852\ttotal: 2.98s\tremaining: 4.12s\n",
      "42:\tlearn: 0.6930838\ttotal: 3.05s\tremaining: 4.04s\n",
      "43:\tlearn: 0.6930823\ttotal: 3.11s\tremaining: 3.96s\n",
      "44:\tlearn: 0.6930808\ttotal: 3.18s\tremaining: 3.89s\n",
      "45:\tlearn: 0.6930794\ttotal: 3.24s\tremaining: 3.8s\n",
      "46:\tlearn: 0.6930779\ttotal: 3.31s\tremaining: 3.73s\n",
      "47:\tlearn: 0.6930764\ttotal: 3.39s\tremaining: 3.67s\n",
      "48:\tlearn: 0.6930749\ttotal: 3.47s\tremaining: 3.61s\n",
      "49:\tlearn: 0.6930735\ttotal: 3.54s\tremaining: 3.54s\n",
      "50:\tlearn: 0.6930720\ttotal: 3.62s\tremaining: 3.48s\n",
      "51:\tlearn: 0.6930705\ttotal: 3.68s\tremaining: 3.4s\n",
      "52:\tlearn: 0.6930690\ttotal: 3.74s\tremaining: 3.31s\n",
      "53:\tlearn: 0.6930676\ttotal: 3.8s\tremaining: 3.24s\n",
      "54:\tlearn: 0.6930661\ttotal: 3.86s\tremaining: 3.15s\n",
      "55:\tlearn: 0.6930647\ttotal: 3.92s\tremaining: 3.08s\n",
      "56:\tlearn: 0.6930632\ttotal: 4.01s\tremaining: 3.03s\n",
      "57:\tlearn: 0.6930617\ttotal: 4.09s\tremaining: 2.96s\n",
      "58:\tlearn: 0.6930603\ttotal: 4.17s\tremaining: 2.9s\n",
      "59:\tlearn: 0.6930588\ttotal: 4.24s\tremaining: 2.83s\n",
      "60:\tlearn: 0.6930574\ttotal: 4.32s\tremaining: 2.76s\n",
      "61:\tlearn: 0.6930559\ttotal: 4.39s\tremaining: 2.69s\n",
      "62:\tlearn: 0.6930544\ttotal: 4.47s\tremaining: 2.62s\n",
      "63:\tlearn: 0.6930529\ttotal: 4.54s\tremaining: 2.55s\n",
      "64:\tlearn: 0.6930515\ttotal: 4.61s\tremaining: 2.48s\n",
      "65:\tlearn: 0.6930499\ttotal: 4.67s\tremaining: 2.41s\n",
      "66:\tlearn: 0.6930485\ttotal: 4.73s\tremaining: 2.33s\n",
      "67:\tlearn: 0.6930470\ttotal: 4.81s\tremaining: 2.26s\n",
      "68:\tlearn: 0.6930455\ttotal: 4.88s\tremaining: 2.19s\n",
      "69:\tlearn: 0.6930440\ttotal: 4.95s\tremaining: 2.12s\n",
      "70:\tlearn: 0.6930425\ttotal: 5.02s\tremaining: 2.05s\n",
      "71:\tlearn: 0.6930411\ttotal: 5.09s\tremaining: 1.98s\n",
      "72:\tlearn: 0.6930396\ttotal: 5.19s\tremaining: 1.92s\n",
      "73:\tlearn: 0.6930381\ttotal: 5.25s\tremaining: 1.84s\n",
      "74:\tlearn: 0.6930367\ttotal: 5.33s\tremaining: 1.78s\n",
      "75:\tlearn: 0.6930352\ttotal: 5.42s\tremaining: 1.71s\n",
      "76:\tlearn: 0.6930337\ttotal: 5.5s\tremaining: 1.64s\n",
      "77:\tlearn: 0.6930322\ttotal: 5.59s\tremaining: 1.58s\n",
      "78:\tlearn: 0.6930308\ttotal: 5.65s\tremaining: 1.5s\n",
      "79:\tlearn: 0.6930293\ttotal: 5.7s\tremaining: 1.43s\n",
      "80:\tlearn: 0.6930279\ttotal: 5.78s\tremaining: 1.35s\n",
      "81:\tlearn: 0.6930264\ttotal: 5.86s\tremaining: 1.29s\n",
      "82:\tlearn: 0.6930249\ttotal: 5.93s\tremaining: 1.22s\n",
      "83:\tlearn: 0.6930235\ttotal: 6.01s\tremaining: 1.14s\n",
      "84:\tlearn: 0.6930220\ttotal: 6.09s\tremaining: 1.07s\n",
      "85:\tlearn: 0.6930205\ttotal: 6.16s\tremaining: 1s\n",
      "86:\tlearn: 0.6930190\ttotal: 6.24s\tremaining: 933ms\n",
      "87:\tlearn: 0.6930176\ttotal: 6.32s\tremaining: 861ms\n",
      "88:\tlearn: 0.6930161\ttotal: 6.38s\tremaining: 789ms\n",
      "89:\tlearn: 0.6930146\ttotal: 6.45s\tremaining: 716ms\n",
      "90:\tlearn: 0.6930132\ttotal: 6.52s\tremaining: 645ms\n",
      "91:\tlearn: 0.6930117\ttotal: 6.59s\tremaining: 573ms\n",
      "92:\tlearn: 0.6930102\ttotal: 6.65s\tremaining: 501ms\n",
      "93:\tlearn: 0.6930088\ttotal: 6.73s\tremaining: 429ms\n",
      "94:\tlearn: 0.6930073\ttotal: 6.8s\tremaining: 358ms\n",
      "95:\tlearn: 0.6930059\ttotal: 6.88s\tremaining: 287ms\n",
      "96:\tlearn: 0.6930044\ttotal: 6.95s\tremaining: 215ms\n",
      "97:\tlearn: 0.6930030\ttotal: 7.03s\tremaining: 143ms\n",
      "98:\tlearn: 0.6930015\ttotal: 7.11s\tremaining: 71.9ms\n",
      "99:\tlearn: 0.6930000\ttotal: 7.19s\tremaining: 0us\n",
      "[CV]  learning_rate=1e-06, l2_leaf_reg=9, iterations=100, depth=2, total=   7.7s\n",
      "[CV] learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5 ......\n",
      "0:\tlearn: 0.6767345\ttotal: 69.5ms\tremaining: 34.7s\n",
      "1:\tlearn: 0.6614608\ttotal: 147ms\tremaining: 36.6s\n",
      "2:\tlearn: 0.6477659\ttotal: 225ms\tremaining: 37.3s\n",
      "3:\tlearn: 0.6344505\ttotal: 295ms\tremaining: 36.6s\n",
      "4:\tlearn: 0.6211005\ttotal: 367ms\tremaining: 36.4s\n",
      "5:\tlearn: 0.6083231\ttotal: 433ms\tremaining: 35.6s\n",
      "6:\tlearn: 0.5957613\ttotal: 507ms\tremaining: 35.7s\n",
      "7:\tlearn: 0.5838749\ttotal: 584ms\tremaining: 35.9s\n",
      "8:\tlearn: 0.5724222\ttotal: 642ms\tremaining: 35s\n",
      "9:\tlearn: 0.5604724\ttotal: 708ms\tremaining: 34.7s\n",
      "10:\tlearn: 0.5496420\ttotal: 776ms\tremaining: 34.5s\n",
      "11:\tlearn: 0.5391540\ttotal: 842ms\tremaining: 34.3s\n",
      "12:\tlearn: 0.5277506\ttotal: 908ms\tremaining: 34s\n",
      "13:\tlearn: 0.5174229\ttotal: 977ms\tremaining: 33.9s\n",
      "14:\tlearn: 0.5073637\ttotal: 1.03s\tremaining: 33.3s\n",
      "15:\tlearn: 0.4980066\ttotal: 1.09s\tremaining: 32.9s\n",
      "16:\tlearn: 0.4888177\ttotal: 1.15s\tremaining: 32.6s\n",
      "17:\tlearn: 0.4800002\ttotal: 1.21s\tremaining: 32.5s\n",
      "18:\tlearn: 0.4713338\ttotal: 1.28s\tremaining: 32.3s\n",
      "19:\tlearn: 0.4630125\ttotal: 1.33s\tremaining: 31.9s\n",
      "20:\tlearn: 0.4549036\ttotal: 1.39s\tremaining: 31.7s\n",
      "21:\tlearn: 0.4467972\ttotal: 1.45s\tremaining: 31.5s\n",
      "22:\tlearn: 0.4392102\ttotal: 1.5s\tremaining: 31.2s\n",
      "23:\tlearn: 0.4316882\ttotal: 1.58s\tremaining: 31.4s\n",
      "24:\tlearn: 0.4244794\ttotal: 1.67s\tremaining: 31.7s\n",
      "25:\tlearn: 0.4166478\ttotal: 1.75s\tremaining: 31.9s\n",
      "26:\tlearn: 0.4099271\ttotal: 1.8s\tremaining: 31.6s\n",
      "27:\tlearn: 0.4028977\ttotal: 1.86s\tremaining: 31.4s\n",
      "28:\tlearn: 0.3960526\ttotal: 1.94s\tremaining: 31.5s\n",
      "29:\tlearn: 0.3897745\ttotal: 2s\tremaining: 31.4s\n",
      "30:\tlearn: 0.3829576\ttotal: 2.07s\tremaining: 31.3s\n",
      "31:\tlearn: 0.3771059\ttotal: 2.12s\tremaining: 31s\n",
      "32:\tlearn: 0.3711642\ttotal: 2.19s\tremaining: 30.9s\n",
      "33:\tlearn: 0.3654679\ttotal: 2.27s\tremaining: 31.1s\n",
      "34:\tlearn: 0.3598297\ttotal: 2.34s\tremaining: 31.1s\n",
      "35:\tlearn: 0.3543720\ttotal: 2.42s\tremaining: 31.3s\n",
      "36:\tlearn: 0.3492995\ttotal: 2.5s\tremaining: 31.3s\n",
      "37:\tlearn: 0.3443124\ttotal: 2.58s\tremaining: 31.3s\n",
      "38:\tlearn: 0.3385900\ttotal: 2.68s\tremaining: 31.7s\n",
      "39:\tlearn: 0.3340814\ttotal: 2.77s\tremaining: 31.9s\n",
      "40:\tlearn: 0.3289979\ttotal: 2.85s\tremaining: 31.9s\n",
      "41:\tlearn: 0.3244253\ttotal: 2.92s\tremaining: 31.9s\n",
      "42:\tlearn: 0.3202037\ttotal: 3.01s\tremaining: 32s\n",
      "43:\tlearn: 0.3153155\ttotal: 3.1s\tremaining: 32.1s\n",
      "44:\tlearn: 0.3106930\ttotal: 3.19s\tremaining: 32.3s\n",
      "45:\tlearn: 0.3064180\ttotal: 3.27s\tremaining: 32.3s\n",
      "46:\tlearn: 0.3027327\ttotal: 3.35s\tremaining: 32.3s\n",
      "47:\tlearn: 0.2990714\ttotal: 3.43s\tremaining: 32.3s\n",
      "48:\tlearn: 0.2953409\ttotal: 3.51s\tremaining: 32.3s\n",
      "49:\tlearn: 0.2917179\ttotal: 3.59s\tremaining: 32.3s\n",
      "50:\tlearn: 0.2883366\ttotal: 3.67s\tremaining: 32.3s\n",
      "51:\tlearn: 0.2851096\ttotal: 3.75s\tremaining: 32.3s\n",
      "52:\tlearn: 0.2820053\ttotal: 3.82s\tremaining: 32.3s\n",
      "53:\tlearn: 0.2786269\ttotal: 3.91s\tremaining: 32.3s\n",
      "54:\tlearn: 0.2751010\ttotal: 4s\tremaining: 32.4s\n",
      "55:\tlearn: 0.2716280\ttotal: 4.11s\tremaining: 32.6s\n",
      "56:\tlearn: 0.2688622\ttotal: 4.21s\tremaining: 32.7s\n",
      "57:\tlearn: 0.2660352\ttotal: 4.28s\tremaining: 32.6s\n",
      "58:\tlearn: 0.2632440\ttotal: 4.33s\tremaining: 32.4s\n",
      "59:\tlearn: 0.2606649\ttotal: 4.39s\tremaining: 32.2s\n",
      "60:\tlearn: 0.2582021\ttotal: 4.46s\tremaining: 32.1s\n",
      "61:\tlearn: 0.2556760\ttotal: 4.52s\tremaining: 32s\n",
      "62:\tlearn: 0.2533471\ttotal: 4.61s\tremaining: 32s\n",
      "63:\tlearn: 0.2511037\ttotal: 4.7s\tremaining: 32s\n",
      "64:\tlearn: 0.2485571\ttotal: 4.8s\tremaining: 32.1s\n",
      "65:\tlearn: 0.2463903\ttotal: 4.87s\tremaining: 32s\n",
      "66:\tlearn: 0.2437883\ttotal: 4.98s\tremaining: 32.2s\n",
      "67:\tlearn: 0.2416509\ttotal: 5.06s\tremaining: 32.2s\n",
      "68:\tlearn: 0.2396619\ttotal: 5.14s\tremaining: 32.1s\n",
      "69:\tlearn: 0.2377076\ttotal: 5.22s\tremaining: 32.1s\n",
      "70:\tlearn: 0.2358462\ttotal: 5.28s\tremaining: 31.9s\n",
      "71:\tlearn: 0.2340450\ttotal: 5.33s\tremaining: 31.7s\n",
      "72:\tlearn: 0.2322103\ttotal: 5.39s\tremaining: 31.5s\n",
      "73:\tlearn: 0.2300227\ttotal: 5.46s\tremaining: 31.4s\n",
      "74:\tlearn: 0.2280920\ttotal: 5.55s\tremaining: 31.5s\n",
      "75:\tlearn: 0.2264398\ttotal: 5.62s\tremaining: 31.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76:\tlearn: 0.2248063\ttotal: 5.68s\tremaining: 31.2s\n",
      "77:\tlearn: 0.2228086\ttotal: 5.75s\tremaining: 31.1s\n",
      "78:\tlearn: 0.2208717\ttotal: 5.84s\tremaining: 31.1s\n",
      "79:\tlearn: 0.2190355\ttotal: 5.92s\tremaining: 31.1s\n",
      "80:\tlearn: 0.2175398\ttotal: 5.98s\tremaining: 30.9s\n",
      "81:\tlearn: 0.2162038\ttotal: 6.03s\tremaining: 30.7s\n",
      "82:\tlearn: 0.2148837\ttotal: 6.08s\tremaining: 30.5s\n",
      "83:\tlearn: 0.2135046\ttotal: 6.14s\tremaining: 30.4s\n",
      "84:\tlearn: 0.2118537\ttotal: 6.22s\tremaining: 30.4s\n",
      "85:\tlearn: 0.2104519\ttotal: 6.29s\tremaining: 30.3s\n",
      "86:\tlearn: 0.2092253\ttotal: 6.34s\tremaining: 30.1s\n",
      "87:\tlearn: 0.2077489\ttotal: 6.41s\tremaining: 30s\n",
      "88:\tlearn: 0.2066708\ttotal: 6.47s\tremaining: 29.9s\n",
      "89:\tlearn: 0.2052579\ttotal: 6.55s\tremaining: 29.9s\n",
      "90:\tlearn: 0.2039053\ttotal: 6.64s\tremaining: 29.9s\n",
      "91:\tlearn: 0.2026297\ttotal: 6.72s\tremaining: 29.8s\n",
      "92:\tlearn: 0.2014064\ttotal: 6.8s\tremaining: 29.7s\n",
      "93:\tlearn: 0.2004456\ttotal: 6.87s\tremaining: 29.7s\n",
      "94:\tlearn: 0.1994778\ttotal: 6.94s\tremaining: 29.6s\n",
      "95:\tlearn: 0.1982925\ttotal: 7.01s\tremaining: 29.5s\n",
      "96:\tlearn: 0.1971422\ttotal: 7.08s\tremaining: 29.4s\n",
      "97:\tlearn: 0.1962414\ttotal: 7.14s\tremaining: 29.3s\n",
      "98:\tlearn: 0.1954033\ttotal: 7.19s\tremaining: 29.1s\n",
      "99:\tlearn: 0.1942998\ttotal: 7.27s\tremaining: 29.1s\n",
      "100:\tlearn: 0.1932558\ttotal: 7.36s\tremaining: 29.1s\n",
      "101:\tlearn: 0.1922228\ttotal: 7.42s\tremaining: 29s\n",
      "102:\tlearn: 0.1913836\ttotal: 7.48s\tremaining: 28.8s\n",
      "103:\tlearn: 0.1903946\ttotal: 7.55s\tremaining: 28.7s\n",
      "104:\tlearn: 0.1895021\ttotal: 7.62s\tremaining: 28.7s\n",
      "105:\tlearn: 0.1885917\ttotal: 7.75s\tremaining: 28.8s\n",
      "106:\tlearn: 0.1879338\ttotal: 7.89s\tremaining: 29s\n",
      "107:\tlearn: 0.1872206\ttotal: 7.96s\tremaining: 28.9s\n",
      "108:\tlearn: 0.1863698\ttotal: 8.04s\tremaining: 28.9s\n",
      "109:\tlearn: 0.1857031\ttotal: 8.13s\tremaining: 28.8s\n",
      "110:\tlearn: 0.1851220\ttotal: 8.21s\tremaining: 28.8s\n",
      "111:\tlearn: 0.1843410\ttotal: 8.3s\tremaining: 28.8s\n",
      "112:\tlearn: 0.1837837\ttotal: 8.42s\tremaining: 28.8s\n",
      "113:\tlearn: 0.1831890\ttotal: 8.52s\tremaining: 28.8s\n",
      "114:\tlearn: 0.1824260\ttotal: 8.59s\tremaining: 28.7s\n",
      "115:\tlearn: 0.1818752\ttotal: 8.64s\tremaining: 28.6s\n",
      "116:\tlearn: 0.1812732\ttotal: 8.72s\tremaining: 28.5s\n",
      "117:\tlearn: 0.1805589\ttotal: 8.79s\tremaining: 28.5s\n",
      "118:\tlearn: 0.1800642\ttotal: 8.85s\tremaining: 28.3s\n",
      "119:\tlearn: 0.1793838\ttotal: 8.93s\tremaining: 28.3s\n",
      "120:\tlearn: 0.1789057\ttotal: 8.98s\tremaining: 28.1s\n",
      "121:\tlearn: 0.1784480\ttotal: 9.04s\tremaining: 28s\n",
      "122:\tlearn: 0.1779374\ttotal: 9.12s\tremaining: 28s\n",
      "123:\tlearn: 0.1772836\ttotal: 9.2s\tremaining: 27.9s\n",
      "124:\tlearn: 0.1767076\ttotal: 9.28s\tremaining: 27.8s\n",
      "125:\tlearn: 0.1760837\ttotal: 9.35s\tremaining: 27.8s\n",
      "126:\tlearn: 0.1755344\ttotal: 9.43s\tremaining: 27.7s\n",
      "127:\tlearn: 0.1749674\ttotal: 9.5s\tremaining: 27.6s\n",
      "128:\tlearn: 0.1745782\ttotal: 9.55s\tremaining: 27.5s\n",
      "129:\tlearn: 0.1740267\ttotal: 9.63s\tremaining: 27.4s\n",
      "130:\tlearn: 0.1734969\ttotal: 9.72s\tremaining: 27.4s\n",
      "131:\tlearn: 0.1729886\ttotal: 9.82s\tremaining: 27.4s\n",
      "132:\tlearn: 0.1724844\ttotal: 9.9s\tremaining: 27.3s\n",
      "133:\tlearn: 0.1720164\ttotal: 9.98s\tremaining: 27.3s\n",
      "134:\tlearn: 0.1715328\ttotal: 10.1s\tremaining: 27.2s\n",
      "135:\tlearn: 0.1710995\ttotal: 10.2s\tremaining: 27.2s\n",
      "136:\tlearn: 0.1706493\ttotal: 10.3s\tremaining: 27.2s\n",
      "137:\tlearn: 0.1702299\ttotal: 10.3s\tremaining: 27.1s\n",
      "138:\tlearn: 0.1699340\ttotal: 10.4s\tremaining: 27.1s\n",
      "139:\tlearn: 0.1695309\ttotal: 10.5s\tremaining: 27.1s\n",
      "140:\tlearn: 0.1691148\ttotal: 10.6s\tremaining: 27s\n",
      "141:\tlearn: 0.1687664\ttotal: 10.7s\tremaining: 26.9s\n",
      "142:\tlearn: 0.1683806\ttotal: 10.8s\tremaining: 26.9s\n",
      "143:\tlearn: 0.1681053\ttotal: 10.8s\tremaining: 26.8s\n",
      "144:\tlearn: 0.1678113\ttotal: 10.9s\tremaining: 26.7s\n",
      "145:\tlearn: 0.1674727\ttotal: 11s\tremaining: 26.7s\n",
      "146:\tlearn: 0.1671469\ttotal: 11.1s\tremaining: 26.6s\n",
      "147:\tlearn: 0.1667822\ttotal: 11.2s\tremaining: 26.6s\n",
      "148:\tlearn: 0.1665014\ttotal: 11.3s\tremaining: 26.5s\n",
      "149:\tlearn: 0.1661718\ttotal: 11.3s\tremaining: 26.5s\n",
      "150:\tlearn: 0.1658230\ttotal: 11.4s\tremaining: 26.4s\n",
      "151:\tlearn: 0.1655146\ttotal: 11.5s\tremaining: 26.3s\n",
      "152:\tlearn: 0.1652147\ttotal: 11.6s\tremaining: 26.2s\n",
      "153:\tlearn: 0.1650002\ttotal: 11.6s\tremaining: 26.1s\n",
      "154:\tlearn: 0.1647188\ttotal: 11.7s\tremaining: 26s\n",
      "155:\tlearn: 0.1644195\ttotal: 11.8s\tremaining: 25.9s\n",
      "156:\tlearn: 0.1641997\ttotal: 11.8s\tremaining: 25.9s\n",
      "157:\tlearn: 0.1639217\ttotal: 11.9s\tremaining: 25.8s\n",
      "158:\tlearn: 0.1636326\ttotal: 12s\tremaining: 25.8s\n",
      "159:\tlearn: 0.1633800\ttotal: 12.1s\tremaining: 25.7s\n",
      "160:\tlearn: 0.1631202\ttotal: 12.2s\tremaining: 25.6s\n",
      "161:\tlearn: 0.1628506\ttotal: 12.3s\tremaining: 25.6s\n",
      "162:\tlearn: 0.1626002\ttotal: 12.4s\tremaining: 25.6s\n",
      "163:\tlearn: 0.1623572\ttotal: 12.4s\tremaining: 25.5s\n",
      "164:\tlearn: 0.1621622\ttotal: 12.5s\tremaining: 25.4s\n",
      "165:\tlearn: 0.1619267\ttotal: 12.6s\tremaining: 25.4s\n",
      "166:\tlearn: 0.1616909\ttotal: 12.7s\tremaining: 25.4s\n",
      "167:\tlearn: 0.1614620\ttotal: 12.8s\tremaining: 25.3s\n",
      "168:\tlearn: 0.1612635\ttotal: 12.9s\tremaining: 25.2s\n",
      "169:\tlearn: 0.1610306\ttotal: 13s\tremaining: 25.2s\n",
      "170:\tlearn: 0.1608181\ttotal: 13.1s\tremaining: 25.1s\n",
      "171:\tlearn: 0.1606092\ttotal: 13.1s\tremaining: 25.1s\n",
      "172:\tlearn: 0.1604158\ttotal: 13.2s\tremaining: 25s\n",
      "173:\tlearn: 0.1602439\ttotal: 13.3s\tremaining: 24.9s\n",
      "174:\tlearn: 0.1600748\ttotal: 13.4s\tremaining: 24.8s\n",
      "175:\tlearn: 0.1598920\ttotal: 13.4s\tremaining: 24.7s\n",
      "176:\tlearn: 0.1597533\ttotal: 13.5s\tremaining: 24.6s\n",
      "177:\tlearn: 0.1596151\ttotal: 13.5s\tremaining: 24.5s\n",
      "178:\tlearn: 0.1594045\ttotal: 13.6s\tremaining: 24.4s\n",
      "179:\tlearn: 0.1592051\ttotal: 13.7s\tremaining: 24.4s\n",
      "180:\tlearn: 0.1590229\ttotal: 13.8s\tremaining: 24.3s\n",
      "181:\tlearn: 0.1588622\ttotal: 13.9s\tremaining: 24.2s\n",
      "182:\tlearn: 0.1586980\ttotal: 13.9s\tremaining: 24.1s\n",
      "183:\tlearn: 0.1585720\ttotal: 14s\tremaining: 24.1s\n",
      "184:\tlearn: 0.1584151\ttotal: 14.1s\tremaining: 24s\n",
      "185:\tlearn: 0.1582570\ttotal: 14.1s\tremaining: 23.9s\n",
      "186:\tlearn: 0.1581048\ttotal: 14.2s\tremaining: 23.8s\n",
      "187:\tlearn: 0.1579627\ttotal: 14.3s\tremaining: 23.7s\n",
      "188:\tlearn: 0.1578188\ttotal: 14.4s\tremaining: 23.6s\n",
      "189:\tlearn: 0.1576851\ttotal: 14.4s\tremaining: 23.5s\n",
      "190:\tlearn: 0.1575858\ttotal: 14.5s\tremaining: 23.4s\n",
      "191:\tlearn: 0.1574293\ttotal: 14.5s\tremaining: 23.3s\n",
      "192:\tlearn: 0.1572856\ttotal: 14.6s\tremaining: 23.3s\n",
      "193:\tlearn: 0.1571964\ttotal: 14.7s\tremaining: 23.2s\n",
      "194:\tlearn: 0.1570657\ttotal: 14.8s\tremaining: 23.1s\n",
      "195:\tlearn: 0.1569299\ttotal: 14.8s\tremaining: 23s\n",
      "196:\tlearn: 0.1568225\ttotal: 14.9s\tremaining: 22.9s\n",
      "197:\tlearn: 0.1567108\ttotal: 15s\tremaining: 22.9s\n",
      "198:\tlearn: 0.1565913\ttotal: 15.1s\tremaining: 22.8s\n",
      "199:\tlearn: 0.1564708\ttotal: 15.1s\tremaining: 22.7s\n",
      "200:\tlearn: 0.1563451\ttotal: 15.2s\tremaining: 22.6s\n",
      "201:\tlearn: 0.1562346\ttotal: 15.3s\tremaining: 22.6s\n",
      "202:\tlearn: 0.1561274\ttotal: 15.4s\tremaining: 22.5s\n",
      "203:\tlearn: 0.1560115\ttotal: 15.5s\tremaining: 22.4s\n",
      "204:\tlearn: 0.1559012\ttotal: 15.5s\tremaining: 22.4s\n",
      "205:\tlearn: 0.1557953\ttotal: 15.6s\tremaining: 22.3s\n",
      "206:\tlearn: 0.1556938\ttotal: 15.7s\tremaining: 22.2s\n",
      "207:\tlearn: 0.1555860\ttotal: 15.8s\tremaining: 22.1s\n",
      "208:\tlearn: 0.1554937\ttotal: 15.8s\tremaining: 22s\n",
      "209:\tlearn: 0.1554010\ttotal: 15.9s\tremaining: 21.9s\n",
      "210:\tlearn: 0.1552957\ttotal: 16s\tremaining: 21.9s\n",
      "211:\tlearn: 0.1551897\ttotal: 16s\tremaining: 21.8s\n",
      "212:\tlearn: 0.1550921\ttotal: 16.1s\tremaining: 21.7s\n",
      "213:\tlearn: 0.1550046\ttotal: 16.2s\tremaining: 21.6s\n",
      "214:\tlearn: 0.1549009\ttotal: 16.3s\tremaining: 21.6s\n",
      "215:\tlearn: 0.1547915\ttotal: 16.3s\tremaining: 21.5s\n",
      "216:\tlearn: 0.1546941\ttotal: 16.4s\tremaining: 21.4s\n",
      "217:\tlearn: 0.1546039\ttotal: 16.5s\tremaining: 21.4s\n",
      "218:\tlearn: 0.1545150\ttotal: 16.6s\tremaining: 21.3s\n",
      "219:\tlearn: 0.1544318\ttotal: 16.7s\tremaining: 21.2s\n",
      "220:\tlearn: 0.1543498\ttotal: 16.7s\tremaining: 21.1s\n",
      "221:\tlearn: 0.1542421\ttotal: 16.8s\tremaining: 21s\n",
      "222:\tlearn: 0.1541586\ttotal: 16.9s\tremaining: 21s\n",
      "223:\tlearn: 0.1540657\ttotal: 16.9s\tremaining: 20.9s\n",
      "224:\tlearn: 0.1540029\ttotal: 17s\tremaining: 20.8s\n",
      "225:\tlearn: 0.1539299\ttotal: 17.1s\tremaining: 20.7s\n",
      "226:\tlearn: 0.1538536\ttotal: 17.1s\tremaining: 20.6s\n",
      "227:\tlearn: 0.1538041\ttotal: 17.2s\tremaining: 20.5s\n",
      "228:\tlearn: 0.1537349\ttotal: 17.3s\tremaining: 20.4s\n",
      "229:\tlearn: 0.1536553\ttotal: 17.3s\tremaining: 20.4s\n",
      "230:\tlearn: 0.1535736\ttotal: 17.4s\tremaining: 20.3s\n",
      "231:\tlearn: 0.1535037\ttotal: 17.5s\tremaining: 20.2s\n",
      "232:\tlearn: 0.1534326\ttotal: 17.6s\tremaining: 20.2s\n",
      "233:\tlearn: 0.1533588\ttotal: 17.7s\tremaining: 20.1s\n",
      "234:\tlearn: 0.1532771\ttotal: 17.8s\tremaining: 20s\n",
      "235:\tlearn: 0.1532162\ttotal: 17.8s\tremaining: 20s\n",
      "236:\tlearn: 0.1531482\ttotal: 17.9s\tremaining: 19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237:\tlearn: 0.1530855\ttotal: 18s\tremaining: 19.8s\n",
      "238:\tlearn: 0.1530338\ttotal: 18.1s\tremaining: 19.8s\n",
      "239:\tlearn: 0.1529737\ttotal: 18.2s\tremaining: 19.7s\n",
      "240:\tlearn: 0.1529161\ttotal: 18.3s\tremaining: 19.7s\n",
      "241:\tlearn: 0.1528584\ttotal: 18.4s\tremaining: 19.6s\n",
      "242:\tlearn: 0.1528103\ttotal: 18.5s\tremaining: 19.5s\n",
      "243:\tlearn: 0.1527574\ttotal: 18.5s\tremaining: 19.5s\n",
      "244:\tlearn: 0.1526823\ttotal: 18.6s\tremaining: 19.4s\n",
      "245:\tlearn: 0.1526186\ttotal: 18.7s\tremaining: 19.3s\n",
      "246:\tlearn: 0.1525563\ttotal: 18.8s\tremaining: 19.2s\n",
      "247:\tlearn: 0.1524893\ttotal: 18.9s\tremaining: 19.2s\n",
      "248:\tlearn: 0.1524093\ttotal: 19s\tremaining: 19.1s\n",
      "249:\tlearn: 0.1523490\ttotal: 19.1s\tremaining: 19.1s\n",
      "250:\tlearn: 0.1522943\ttotal: 19.1s\tremaining: 19s\n",
      "251:\tlearn: 0.1522493\ttotal: 19.2s\tremaining: 18.9s\n",
      "252:\tlearn: 0.1521881\ttotal: 19.3s\tremaining: 18.8s\n",
      "253:\tlearn: 0.1521301\ttotal: 19.4s\tremaining: 18.8s\n",
      "254:\tlearn: 0.1520783\ttotal: 19.5s\tremaining: 18.7s\n",
      "255:\tlearn: 0.1520299\ttotal: 19.5s\tremaining: 18.6s\n",
      "256:\tlearn: 0.1519789\ttotal: 19.6s\tremaining: 18.6s\n",
      "257:\tlearn: 0.1519352\ttotal: 19.7s\tremaining: 18.5s\n",
      "258:\tlearn: 0.1518852\ttotal: 19.8s\tremaining: 18.4s\n",
      "259:\tlearn: 0.1518472\ttotal: 19.9s\tremaining: 18.3s\n",
      "260:\tlearn: 0.1518144\ttotal: 20s\tremaining: 18.3s\n",
      "261:\tlearn: 0.1517660\ttotal: 20.1s\tremaining: 18.2s\n",
      "262:\tlearn: 0.1517157\ttotal: 20.1s\tremaining: 18.1s\n",
      "263:\tlearn: 0.1516631\ttotal: 20.2s\tremaining: 18.1s\n",
      "264:\tlearn: 0.1516158\ttotal: 20.3s\tremaining: 18s\n",
      "265:\tlearn: 0.1515625\ttotal: 20.4s\tremaining: 17.9s\n",
      "266:\tlearn: 0.1515210\ttotal: 20.5s\tremaining: 17.9s\n",
      "267:\tlearn: 0.1514688\ttotal: 20.6s\tremaining: 17.8s\n",
      "268:\tlearn: 0.1514160\ttotal: 20.7s\tremaining: 17.7s\n",
      "269:\tlearn: 0.1513649\ttotal: 20.7s\tremaining: 17.7s\n",
      "270:\tlearn: 0.1513285\ttotal: 20.8s\tremaining: 17.6s\n",
      "271:\tlearn: 0.1512851\ttotal: 20.9s\tremaining: 17.5s\n",
      "272:\tlearn: 0.1512324\ttotal: 21s\tremaining: 17.4s\n",
      "273:\tlearn: 0.1511882\ttotal: 21.1s\tremaining: 17.4s\n",
      "274:\tlearn: 0.1511475\ttotal: 21.2s\tremaining: 17.3s\n",
      "275:\tlearn: 0.1511154\ttotal: 21.3s\tremaining: 17.3s\n",
      "276:\tlearn: 0.1510605\ttotal: 21.4s\tremaining: 17.2s\n",
      "277:\tlearn: 0.1510169\ttotal: 21.5s\tremaining: 17.1s\n",
      "278:\tlearn: 0.1509729\ttotal: 21.6s\tremaining: 17.1s\n",
      "279:\tlearn: 0.1509346\ttotal: 21.6s\tremaining: 17s\n",
      "280:\tlearn: 0.1508977\ttotal: 21.7s\tremaining: 16.9s\n",
      "281:\tlearn: 0.1508570\ttotal: 21.8s\tremaining: 16.9s\n",
      "282:\tlearn: 0.1508213\ttotal: 21.9s\tremaining: 16.8s\n",
      "283:\tlearn: 0.1507745\ttotal: 22s\tremaining: 16.7s\n",
      "284:\tlearn: 0.1507462\ttotal: 22.1s\tremaining: 16.7s\n",
      "285:\tlearn: 0.1506996\ttotal: 22.2s\tremaining: 16.6s\n",
      "286:\tlearn: 0.1506709\ttotal: 22.2s\tremaining: 16.5s\n",
      "287:\tlearn: 0.1506374\ttotal: 22.3s\tremaining: 16.4s\n",
      "288:\tlearn: 0.1505853\ttotal: 22.4s\tremaining: 16.4s\n",
      "289:\tlearn: 0.1505540\ttotal: 22.5s\tremaining: 16.3s\n",
      "290:\tlearn: 0.1505164\ttotal: 22.6s\tremaining: 16.2s\n",
      "291:\tlearn: 0.1504866\ttotal: 22.7s\tremaining: 16.2s\n",
      "292:\tlearn: 0.1504397\ttotal: 22.8s\tremaining: 16.1s\n",
      "293:\tlearn: 0.1504006\ttotal: 22.9s\tremaining: 16s\n",
      "294:\tlearn: 0.1503502\ttotal: 23s\tremaining: 16s\n",
      "295:\tlearn: 0.1503181\ttotal: 23.1s\tremaining: 15.9s\n",
      "296:\tlearn: 0.1502709\ttotal: 23.2s\tremaining: 15.8s\n",
      "297:\tlearn: 0.1502369\ttotal: 23.2s\tremaining: 15.7s\n",
      "298:\tlearn: 0.1502044\ttotal: 23.3s\tremaining: 15.7s\n",
      "299:\tlearn: 0.1501687\ttotal: 23.4s\tremaining: 15.6s\n",
      "300:\tlearn: 0.1501366\ttotal: 23.5s\tremaining: 15.5s\n",
      "301:\tlearn: 0.1501053\ttotal: 23.6s\tremaining: 15.4s\n",
      "302:\tlearn: 0.1500774\ttotal: 23.6s\tremaining: 15.4s\n",
      "303:\tlearn: 0.1500511\ttotal: 23.7s\tremaining: 15.3s\n",
      "304:\tlearn: 0.1500062\ttotal: 23.8s\tremaining: 15.2s\n",
      "305:\tlearn: 0.1499739\ttotal: 23.9s\tremaining: 15.2s\n",
      "306:\tlearn: 0.1499423\ttotal: 24s\tremaining: 15.1s\n",
      "307:\tlearn: 0.1499179\ttotal: 24.1s\tremaining: 15s\n",
      "308:\tlearn: 0.1498759\ttotal: 24.2s\tremaining: 14.9s\n",
      "309:\tlearn: 0.1498366\ttotal: 24.3s\tremaining: 14.9s\n",
      "310:\tlearn: 0.1498006\ttotal: 24.4s\tremaining: 14.8s\n",
      "311:\tlearn: 0.1497789\ttotal: 24.4s\tremaining: 14.7s\n",
      "312:\tlearn: 0.1497516\ttotal: 24.5s\tremaining: 14.6s\n",
      "313:\tlearn: 0.1497215\ttotal: 24.6s\tremaining: 14.6s\n",
      "314:\tlearn: 0.1496970\ttotal: 24.7s\tremaining: 14.5s\n",
      "315:\tlearn: 0.1496608\ttotal: 24.8s\tremaining: 14.4s\n",
      "316:\tlearn: 0.1496356\ttotal: 24.9s\tremaining: 14.3s\n",
      "317:\tlearn: 0.1496072\ttotal: 24.9s\tremaining: 14.3s\n",
      "318:\tlearn: 0.1495719\ttotal: 25s\tremaining: 14.2s\n",
      "319:\tlearn: 0.1495330\ttotal: 25.1s\tremaining: 14.1s\n",
      "320:\tlearn: 0.1495013\ttotal: 25.2s\tremaining: 14s\n",
      "321:\tlearn: 0.1494771\ttotal: 25.3s\tremaining: 14s\n",
      "322:\tlearn: 0.1494432\ttotal: 25.4s\tremaining: 13.9s\n",
      "323:\tlearn: 0.1494077\ttotal: 25.4s\tremaining: 13.8s\n",
      "324:\tlearn: 0.1493755\ttotal: 25.5s\tremaining: 13.7s\n",
      "325:\tlearn: 0.1493520\ttotal: 25.6s\tremaining: 13.7s\n",
      "326:\tlearn: 0.1493297\ttotal: 25.7s\tremaining: 13.6s\n",
      "327:\tlearn: 0.1493108\ttotal: 25.8s\tremaining: 13.5s\n",
      "328:\tlearn: 0.1492814\ttotal: 25.8s\tremaining: 13.4s\n",
      "329:\tlearn: 0.1492537\ttotal: 25.9s\tremaining: 13.4s\n",
      "330:\tlearn: 0.1492266\ttotal: 26s\tremaining: 13.3s\n",
      "331:\tlearn: 0.1492084\ttotal: 26.1s\tremaining: 13.2s\n",
      "332:\tlearn: 0.1491811\ttotal: 26.1s\tremaining: 13.1s\n",
      "333:\tlearn: 0.1491522\ttotal: 26.2s\tremaining: 13s\n",
      "334:\tlearn: 0.1491209\ttotal: 26.3s\tremaining: 13s\n",
      "335:\tlearn: 0.1490979\ttotal: 26.4s\tremaining: 12.9s\n",
      "336:\tlearn: 0.1490766\ttotal: 26.4s\tremaining: 12.8s\n",
      "337:\tlearn: 0.1490443\ttotal: 26.5s\tremaining: 12.7s\n",
      "338:\tlearn: 0.1490236\ttotal: 26.6s\tremaining: 12.6s\n",
      "339:\tlearn: 0.1490032\ttotal: 26.6s\tremaining: 12.5s\n",
      "340:\tlearn: 0.1489715\ttotal: 26.7s\tremaining: 12.5s\n",
      "341:\tlearn: 0.1489526\ttotal: 26.8s\tremaining: 12.4s\n",
      "342:\tlearn: 0.1489278\ttotal: 26.8s\tremaining: 12.3s\n",
      "343:\tlearn: 0.1489068\ttotal: 26.9s\tremaining: 12.2s\n",
      "344:\tlearn: 0.1488858\ttotal: 27s\tremaining: 12.1s\n",
      "345:\tlearn: 0.1488645\ttotal: 27.1s\tremaining: 12.1s\n",
      "346:\tlearn: 0.1488358\ttotal: 27.2s\tremaining: 12s\n",
      "347:\tlearn: 0.1488125\ttotal: 27.3s\tremaining: 11.9s\n",
      "348:\tlearn: 0.1487908\ttotal: 27.4s\tremaining: 11.8s\n",
      "349:\tlearn: 0.1487686\ttotal: 27.5s\tremaining: 11.8s\n",
      "350:\tlearn: 0.1487478\ttotal: 27.5s\tremaining: 11.7s\n",
      "351:\tlearn: 0.1487286\ttotal: 27.6s\tremaining: 11.6s\n",
      "352:\tlearn: 0.1487081\ttotal: 27.7s\tremaining: 11.6s\n",
      "353:\tlearn: 0.1486767\ttotal: 27.8s\tremaining: 11.5s\n",
      "354:\tlearn: 0.1486534\ttotal: 27.9s\tremaining: 11.4s\n",
      "355:\tlearn: 0.1486294\ttotal: 28s\tremaining: 11.3s\n",
      "356:\tlearn: 0.1486087\ttotal: 28.1s\tremaining: 11.2s\n",
      "357:\tlearn: 0.1485791\ttotal: 28.2s\tremaining: 11.2s\n",
      "358:\tlearn: 0.1485616\ttotal: 28.2s\tremaining: 11.1s\n",
      "359:\tlearn: 0.1485373\ttotal: 28.3s\tremaining: 11s\n",
      "360:\tlearn: 0.1485112\ttotal: 28.4s\tremaining: 10.9s\n",
      "361:\tlearn: 0.1484811\ttotal: 28.5s\tremaining: 10.9s\n",
      "362:\tlearn: 0.1484543\ttotal: 28.6s\tremaining: 10.8s\n",
      "363:\tlearn: 0.1484240\ttotal: 28.7s\tremaining: 10.7s\n",
      "364:\tlearn: 0.1484047\ttotal: 28.8s\tremaining: 10.6s\n",
      "365:\tlearn: 0.1483804\ttotal: 28.8s\tremaining: 10.6s\n",
      "366:\tlearn: 0.1483466\ttotal: 28.9s\tremaining: 10.5s\n",
      "367:\tlearn: 0.1483254\ttotal: 29s\tremaining: 10.4s\n",
      "368:\tlearn: 0.1483070\ttotal: 29.1s\tremaining: 10.3s\n",
      "369:\tlearn: 0.1482903\ttotal: 29.2s\tremaining: 10.3s\n",
      "370:\tlearn: 0.1482657\ttotal: 29.3s\tremaining: 10.2s\n",
      "371:\tlearn: 0.1482450\ttotal: 29.3s\tremaining: 10.1s\n",
      "372:\tlearn: 0.1482262\ttotal: 29.4s\tremaining: 10s\n",
      "373:\tlearn: 0.1482039\ttotal: 29.4s\tremaining: 9.92s\n",
      "374:\tlearn: 0.1481856\ttotal: 29.5s\tremaining: 9.84s\n",
      "375:\tlearn: 0.1481654\ttotal: 29.6s\tremaining: 9.76s\n",
      "376:\tlearn: 0.1481471\ttotal: 29.6s\tremaining: 9.67s\n",
      "377:\tlearn: 0.1481279\ttotal: 29.7s\tremaining: 9.59s\n",
      "378:\tlearn: 0.1481075\ttotal: 29.8s\tremaining: 9.52s\n",
      "379:\tlearn: 0.1480904\ttotal: 29.9s\tremaining: 9.44s\n",
      "380:\tlearn: 0.1480736\ttotal: 30s\tremaining: 9.36s\n",
      "381:\tlearn: 0.1480463\ttotal: 30.1s\tremaining: 9.29s\n",
      "382:\tlearn: 0.1480315\ttotal: 30.2s\tremaining: 9.21s\n",
      "383:\tlearn: 0.1480161\ttotal: 30.2s\tremaining: 9.13s\n",
      "384:\tlearn: 0.1479963\ttotal: 30.3s\tremaining: 9.05s\n",
      "385:\tlearn: 0.1479808\ttotal: 30.4s\tremaining: 8.98s\n",
      "386:\tlearn: 0.1479533\ttotal: 30.5s\tremaining: 8.9s\n",
      "387:\tlearn: 0.1479289\ttotal: 30.6s\tremaining: 8.83s\n",
      "388:\tlearn: 0.1479097\ttotal: 30.7s\tremaining: 8.75s\n",
      "389:\tlearn: 0.1478926\ttotal: 30.7s\tremaining: 8.67s\n",
      "390:\tlearn: 0.1478718\ttotal: 30.8s\tremaining: 8.59s\n",
      "391:\tlearn: 0.1478532\ttotal: 30.9s\tremaining: 8.52s\n",
      "392:\tlearn: 0.1478297\ttotal: 31s\tremaining: 8.45s\n",
      "393:\tlearn: 0.1478104\ttotal: 31.1s\tremaining: 8.37s\n",
      "394:\tlearn: 0.1477889\ttotal: 31.2s\tremaining: 8.29s\n",
      "395:\tlearn: 0.1477735\ttotal: 31.3s\tremaining: 8.21s\n",
      "396:\tlearn: 0.1477544\ttotal: 31.3s\tremaining: 8.13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397:\tlearn: 0.1477421\ttotal: 31.4s\tremaining: 8.05s\n",
      "398:\tlearn: 0.1477261\ttotal: 31.5s\tremaining: 7.97s\n",
      "399:\tlearn: 0.1477136\ttotal: 31.6s\tremaining: 7.9s\n",
      "400:\tlearn: 0.1476920\ttotal: 31.7s\tremaining: 7.82s\n",
      "401:\tlearn: 0.1476789\ttotal: 31.7s\tremaining: 7.74s\n",
      "402:\tlearn: 0.1476617\ttotal: 31.8s\tremaining: 7.66s\n",
      "403:\tlearn: 0.1476446\ttotal: 31.9s\tremaining: 7.58s\n",
      "404:\tlearn: 0.1476251\ttotal: 32s\tremaining: 7.51s\n",
      "405:\tlearn: 0.1476108\ttotal: 32.1s\tremaining: 7.43s\n",
      "406:\tlearn: 0.1475856\ttotal: 32.2s\tremaining: 7.35s\n",
      "407:\tlearn: 0.1475721\ttotal: 32.3s\tremaining: 7.27s\n",
      "408:\tlearn: 0.1475591\ttotal: 32.3s\tremaining: 7.19s\n",
      "409:\tlearn: 0.1475468\ttotal: 32.4s\tremaining: 7.11s\n",
      "410:\tlearn: 0.1475331\ttotal: 32.5s\tremaining: 7.03s\n",
      "411:\tlearn: 0.1475075\ttotal: 32.6s\tremaining: 6.96s\n",
      "412:\tlearn: 0.1474909\ttotal: 32.7s\tremaining: 6.88s\n",
      "413:\tlearn: 0.1474731\ttotal: 32.8s\tremaining: 6.8s\n",
      "414:\tlearn: 0.1474600\ttotal: 32.8s\tremaining: 6.72s\n",
      "415:\tlearn: 0.1474421\ttotal: 32.9s\tremaining: 6.64s\n",
      "416:\tlearn: 0.1474287\ttotal: 33s\tremaining: 6.57s\n",
      "417:\tlearn: 0.1474127\ttotal: 33.1s\tremaining: 6.49s\n",
      "418:\tlearn: 0.1474006\ttotal: 33.1s\tremaining: 6.41s\n",
      "419:\tlearn: 0.1473793\ttotal: 33.2s\tremaining: 6.33s\n",
      "420:\tlearn: 0.1473640\ttotal: 33.3s\tremaining: 6.25s\n",
      "421:\tlearn: 0.1473517\ttotal: 33.4s\tremaining: 6.17s\n",
      "422:\tlearn: 0.1473362\ttotal: 33.5s\tremaining: 6.09s\n",
      "423:\tlearn: 0.1473127\ttotal: 33.6s\tremaining: 6.01s\n",
      "424:\tlearn: 0.1472925\ttotal: 33.6s\tremaining: 5.93s\n",
      "425:\tlearn: 0.1472680\ttotal: 33.7s\tremaining: 5.86s\n",
      "426:\tlearn: 0.1472534\ttotal: 33.8s\tremaining: 5.78s\n",
      "427:\tlearn: 0.1472336\ttotal: 33.9s\tremaining: 5.7s\n",
      "428:\tlearn: 0.1472195\ttotal: 33.9s\tremaining: 5.62s\n",
      "429:\tlearn: 0.1472072\ttotal: 34s\tremaining: 5.54s\n",
      "430:\tlearn: 0.1471899\ttotal: 34.1s\tremaining: 5.46s\n",
      "431:\tlearn: 0.1471773\ttotal: 34.2s\tremaining: 5.38s\n",
      "432:\tlearn: 0.1471629\ttotal: 34.3s\tremaining: 5.3s\n",
      "433:\tlearn: 0.1471495\ttotal: 34.4s\tremaining: 5.22s\n",
      "434:\tlearn: 0.1471368\ttotal: 34.4s\tremaining: 5.14s\n",
      "435:\tlearn: 0.1471230\ttotal: 34.5s\tremaining: 5.06s\n",
      "436:\tlearn: 0.1471102\ttotal: 34.6s\tremaining: 4.99s\n",
      "437:\tlearn: 0.1470988\ttotal: 34.7s\tremaining: 4.91s\n",
      "438:\tlearn: 0.1470869\ttotal: 34.8s\tremaining: 4.83s\n",
      "439:\tlearn: 0.1470734\ttotal: 34.8s\tremaining: 4.75s\n",
      "440:\tlearn: 0.1470595\ttotal: 34.9s\tremaining: 4.67s\n",
      "441:\tlearn: 0.1470488\ttotal: 35s\tremaining: 4.59s\n",
      "442:\tlearn: 0.1470299\ttotal: 35.1s\tremaining: 4.51s\n",
      "443:\tlearn: 0.1470123\ttotal: 35.1s\tremaining: 4.43s\n",
      "444:\tlearn: 0.1469949\ttotal: 35.2s\tremaining: 4.35s\n",
      "445:\tlearn: 0.1469758\ttotal: 35.3s\tremaining: 4.27s\n",
      "446:\tlearn: 0.1469589\ttotal: 35.4s\tremaining: 4.19s\n",
      "447:\tlearn: 0.1469441\ttotal: 35.5s\tremaining: 4.12s\n",
      "448:\tlearn: 0.1469311\ttotal: 35.6s\tremaining: 4.04s\n",
      "449:\tlearn: 0.1469032\ttotal: 35.6s\tremaining: 3.96s\n",
      "450:\tlearn: 0.1468866\ttotal: 35.7s\tremaining: 3.88s\n",
      "451:\tlearn: 0.1468758\ttotal: 35.8s\tremaining: 3.8s\n",
      "452:\tlearn: 0.1468633\ttotal: 35.9s\tremaining: 3.72s\n",
      "453:\tlearn: 0.1468475\ttotal: 36s\tremaining: 3.65s\n",
      "454:\tlearn: 0.1468343\ttotal: 36.1s\tremaining: 3.57s\n",
      "455:\tlearn: 0.1468185\ttotal: 36.2s\tremaining: 3.49s\n",
      "456:\tlearn: 0.1468070\ttotal: 36.2s\tremaining: 3.41s\n",
      "457:\tlearn: 0.1467966\ttotal: 36.3s\tremaining: 3.33s\n",
      "458:\tlearn: 0.1467828\ttotal: 36.4s\tremaining: 3.25s\n",
      "459:\tlearn: 0.1467718\ttotal: 36.5s\tremaining: 3.17s\n",
      "460:\tlearn: 0.1467619\ttotal: 36.6s\tremaining: 3.09s\n",
      "461:\tlearn: 0.1467455\ttotal: 36.7s\tremaining: 3.01s\n",
      "462:\tlearn: 0.1467291\ttotal: 36.7s\tremaining: 2.93s\n",
      "463:\tlearn: 0.1467199\ttotal: 36.8s\tremaining: 2.86s\n",
      "464:\tlearn: 0.1467010\ttotal: 36.9s\tremaining: 2.78s\n",
      "465:\tlearn: 0.1466828\ttotal: 37s\tremaining: 2.7s\n",
      "466:\tlearn: 0.1466680\ttotal: 37.1s\tremaining: 2.62s\n",
      "467:\tlearn: 0.1466545\ttotal: 37.2s\tremaining: 2.54s\n",
      "468:\tlearn: 0.1466396\ttotal: 37.3s\tremaining: 2.46s\n",
      "469:\tlearn: 0.1466263\ttotal: 37.3s\tremaining: 2.38s\n",
      "470:\tlearn: 0.1466155\ttotal: 37.4s\tremaining: 2.3s\n",
      "471:\tlearn: 0.1465971\ttotal: 37.5s\tremaining: 2.22s\n",
      "472:\tlearn: 0.1465818\ttotal: 37.6s\tremaining: 2.14s\n",
      "473:\tlearn: 0.1465716\ttotal: 37.6s\tremaining: 2.06s\n",
      "474:\tlearn: 0.1465603\ttotal: 37.7s\tremaining: 1.98s\n",
      "475:\tlearn: 0.1465502\ttotal: 37.8s\tremaining: 1.9s\n",
      "476:\tlearn: 0.1465346\ttotal: 37.9s\tremaining: 1.82s\n",
      "477:\tlearn: 0.1465216\ttotal: 38s\tremaining: 1.75s\n",
      "478:\tlearn: 0.1465076\ttotal: 38s\tremaining: 1.67s\n",
      "479:\tlearn: 0.1464912\ttotal: 38.1s\tremaining: 1.59s\n",
      "480:\tlearn: 0.1464802\ttotal: 38.2s\tremaining: 1.51s\n",
      "481:\tlearn: 0.1464686\ttotal: 38.3s\tremaining: 1.43s\n",
      "482:\tlearn: 0.1464495\ttotal: 38.4s\tremaining: 1.35s\n",
      "483:\tlearn: 0.1464396\ttotal: 38.4s\tremaining: 1.27s\n",
      "484:\tlearn: 0.1464268\ttotal: 38.5s\tremaining: 1.19s\n",
      "485:\tlearn: 0.1464138\ttotal: 38.6s\tremaining: 1.11s\n",
      "486:\tlearn: 0.1463987\ttotal: 38.7s\tremaining: 1.03s\n",
      "487:\tlearn: 0.1463831\ttotal: 38.8s\tremaining: 953ms\n",
      "488:\tlearn: 0.1463643\ttotal: 38.8s\tremaining: 874ms\n",
      "489:\tlearn: 0.1463524\ttotal: 38.9s\tremaining: 795ms\n",
      "490:\tlearn: 0.1463378\ttotal: 39s\tremaining: 715ms\n",
      "491:\tlearn: 0.1463243\ttotal: 39.1s\tremaining: 636ms\n",
      "492:\tlearn: 0.1463109\ttotal: 39.2s\tremaining: 556ms\n",
      "493:\tlearn: 0.1463010\ttotal: 39.3s\tremaining: 477ms\n",
      "494:\tlearn: 0.1462916\ttotal: 39.3s\tremaining: 397ms\n",
      "495:\tlearn: 0.1462764\ttotal: 39.4s\tremaining: 318ms\n",
      "496:\tlearn: 0.1462623\ttotal: 39.5s\tremaining: 238ms\n",
      "497:\tlearn: 0.1462516\ttotal: 39.6s\tremaining: 159ms\n",
      "498:\tlearn: 0.1462379\ttotal: 39.6s\tremaining: 79.4ms\n",
      "499:\tlearn: 0.1462259\ttotal: 39.7s\tremaining: 0us\n",
      "[CV]  learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5, total=  40.3s\n",
      "[CV] learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5 ......\n",
      "0:\tlearn: 0.6767396\ttotal: 91.8ms\tremaining: 45.8s\n",
      "1:\tlearn: 0.6614284\ttotal: 167ms\tremaining: 41.6s\n",
      "2:\tlearn: 0.6473085\ttotal: 242ms\tremaining: 40.1s\n",
      "3:\tlearn: 0.6340065\ttotal: 323ms\tremaining: 40s\n",
      "4:\tlearn: 0.6210823\ttotal: 400ms\tremaining: 39.6s\n",
      "5:\tlearn: 0.6086541\ttotal: 475ms\tremaining: 39.1s\n",
      "6:\tlearn: 0.5964269\ttotal: 558ms\tremaining: 39.3s\n",
      "7:\tlearn: 0.5844884\ttotal: 656ms\tremaining: 40.3s\n",
      "8:\tlearn: 0.5728669\ttotal: 746ms\tremaining: 40.7s\n",
      "9:\tlearn: 0.5616671\ttotal: 841ms\tremaining: 41.2s\n",
      "10:\tlearn: 0.5507512\ttotal: 917ms\tremaining: 40.8s\n",
      "11:\tlearn: 0.5401969\ttotal: 1.01s\tremaining: 41.1s\n",
      "12:\tlearn: 0.5296025\ttotal: 1.09s\tremaining: 40.8s\n",
      "13:\tlearn: 0.5195787\ttotal: 1.18s\tremaining: 40.8s\n",
      "14:\tlearn: 0.5099711\ttotal: 1.26s\tremaining: 40.8s\n",
      "15:\tlearn: 0.5000833\ttotal: 1.36s\tremaining: 41.1s\n",
      "16:\tlearn: 0.4895145\ttotal: 1.46s\tremaining: 41.3s\n",
      "17:\tlearn: 0.4805408\ttotal: 1.54s\tremaining: 41.2s\n",
      "18:\tlearn: 0.4716905\ttotal: 1.63s\tremaining: 41.2s\n",
      "19:\tlearn: 0.4634192\ttotal: 1.72s\tremaining: 41.4s\n",
      "20:\tlearn: 0.4553028\ttotal: 1.8s\tremaining: 41s\n",
      "21:\tlearn: 0.4471228\ttotal: 1.88s\tremaining: 40.9s\n",
      "22:\tlearn: 0.4392846\ttotal: 1.96s\tremaining: 40.7s\n",
      "23:\tlearn: 0.4308278\ttotal: 2.06s\tremaining: 40.9s\n",
      "24:\tlearn: 0.4236905\ttotal: 2.14s\tremaining: 40.7s\n",
      "25:\tlearn: 0.4167296\ttotal: 2.22s\tremaining: 40.5s\n",
      "26:\tlearn: 0.4098867\ttotal: 2.3s\tremaining: 40.2s\n",
      "27:\tlearn: 0.4022667\ttotal: 2.4s\tremaining: 40.6s\n",
      "28:\tlearn: 0.3959232\ttotal: 2.49s\tremaining: 40.4s\n",
      "29:\tlearn: 0.3893485\ttotal: 2.56s\tremaining: 40s\n",
      "30:\tlearn: 0.3826587\ttotal: 2.64s\tremaining: 40s\n",
      "31:\tlearn: 0.3768578\ttotal: 2.73s\tremaining: 39.9s\n",
      "32:\tlearn: 0.3710752\ttotal: 2.8s\tremaining: 39.6s\n",
      "33:\tlearn: 0.3655896\ttotal: 2.89s\tremaining: 39.6s\n",
      "34:\tlearn: 0.3598985\ttotal: 2.97s\tremaining: 39.5s\n",
      "35:\tlearn: 0.3546564\ttotal: 3.04s\tremaining: 39.2s\n",
      "36:\tlearn: 0.3489418\ttotal: 3.14s\tremaining: 39.3s\n",
      "37:\tlearn: 0.3437584\ttotal: 3.22s\tremaining: 39.2s\n",
      "38:\tlearn: 0.3390792\ttotal: 3.29s\tremaining: 38.9s\n",
      "39:\tlearn: 0.3342586\ttotal: 3.39s\tremaining: 39s\n",
      "40:\tlearn: 0.3298179\ttotal: 3.47s\tremaining: 38.9s\n",
      "41:\tlearn: 0.3252426\ttotal: 3.55s\tremaining: 38.7s\n",
      "42:\tlearn: 0.3209251\ttotal: 3.63s\tremaining: 38.6s\n",
      "43:\tlearn: 0.3167948\ttotal: 3.72s\tremaining: 38.6s\n",
      "44:\tlearn: 0.3127760\ttotal: 3.81s\tremaining: 38.6s\n",
      "45:\tlearn: 0.3089743\ttotal: 3.91s\tremaining: 38.6s\n",
      "46:\tlearn: 0.3052411\ttotal: 3.98s\tremaining: 38.4s\n",
      "47:\tlearn: 0.3008514\ttotal: 4.05s\tremaining: 38.2s\n",
      "48:\tlearn: 0.2972418\ttotal: 4.13s\tremaining: 38s\n",
      "49:\tlearn: 0.2936119\ttotal: 4.19s\tremaining: 37.7s\n",
      "50:\tlearn: 0.2902832\ttotal: 4.25s\tremaining: 37.4s\n",
      "51:\tlearn: 0.2868639\ttotal: 4.31s\tremaining: 37.2s\n",
      "52:\tlearn: 0.2837678\ttotal: 4.39s\tremaining: 37s\n",
      "53:\tlearn: 0.2807444\ttotal: 4.48s\tremaining: 37s\n",
      "54:\tlearn: 0.2769678\ttotal: 4.57s\tremaining: 37s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55:\tlearn: 0.2740568\ttotal: 4.65s\tremaining: 36.9s\n",
      "56:\tlearn: 0.2713071\ttotal: 4.73s\tremaining: 36.8s\n",
      "57:\tlearn: 0.2684173\ttotal: 4.83s\tremaining: 36.8s\n",
      "58:\tlearn: 0.2657990\ttotal: 4.91s\tremaining: 36.7s\n",
      "59:\tlearn: 0.2626003\ttotal: 5s\tremaining: 36.6s\n",
      "60:\tlearn: 0.2599567\ttotal: 5.07s\tremaining: 36.5s\n",
      "61:\tlearn: 0.2575421\ttotal: 5.16s\tremaining: 36.4s\n",
      "62:\tlearn: 0.2545893\ttotal: 5.25s\tremaining: 36.4s\n",
      "63:\tlearn: 0.2518913\ttotal: 5.33s\tremaining: 36.3s\n",
      "64:\tlearn: 0.2495889\ttotal: 5.41s\tremaining: 36.2s\n",
      "65:\tlearn: 0.2474702\ttotal: 5.49s\tremaining: 36.1s\n",
      "66:\tlearn: 0.2453522\ttotal: 5.57s\tremaining: 36s\n",
      "67:\tlearn: 0.2426950\ttotal: 5.66s\tremaining: 36s\n",
      "68:\tlearn: 0.2407068\ttotal: 5.74s\tremaining: 35.9s\n",
      "69:\tlearn: 0.2382477\ttotal: 5.83s\tremaining: 35.8s\n",
      "70:\tlearn: 0.2362967\ttotal: 5.93s\tremaining: 35.8s\n",
      "71:\tlearn: 0.2341267\ttotal: 6.01s\tremaining: 35.7s\n",
      "72:\tlearn: 0.2322837\ttotal: 6.09s\tremaining: 35.6s\n",
      "73:\tlearn: 0.2305261\ttotal: 6.19s\tremaining: 35.7s\n",
      "74:\tlearn: 0.2288868\ttotal: 6.29s\tremaining: 35.7s\n",
      "75:\tlearn: 0.2272712\ttotal: 6.37s\tremaining: 35.5s\n",
      "76:\tlearn: 0.2257203\ttotal: 6.44s\tremaining: 35.4s\n",
      "77:\tlearn: 0.2239661\ttotal: 6.53s\tremaining: 35.3s\n",
      "78:\tlearn: 0.2224174\ttotal: 6.62s\tremaining: 35.3s\n",
      "79:\tlearn: 0.2204762\ttotal: 6.71s\tremaining: 35.2s\n",
      "80:\tlearn: 0.2186647\ttotal: 6.81s\tremaining: 35.2s\n",
      "81:\tlearn: 0.2173365\ttotal: 6.89s\tremaining: 35.1s\n",
      "82:\tlearn: 0.2159731\ttotal: 6.99s\tremaining: 35.1s\n",
      "83:\tlearn: 0.2142281\ttotal: 7.05s\tremaining: 34.9s\n",
      "84:\tlearn: 0.2125015\ttotal: 7.14s\tremaining: 34.8s\n",
      "85:\tlearn: 0.2110853\ttotal: 7.23s\tremaining: 34.8s\n",
      "86:\tlearn: 0.2097939\ttotal: 7.32s\tremaining: 34.7s\n",
      "87:\tlearn: 0.2086033\ttotal: 7.39s\tremaining: 34.6s\n",
      "88:\tlearn: 0.2071745\ttotal: 7.48s\tremaining: 34.5s\n",
      "89:\tlearn: 0.2056987\ttotal: 7.57s\tremaining: 34.5s\n",
      "90:\tlearn: 0.2044529\ttotal: 7.69s\tremaining: 34.6s\n",
      "91:\tlearn: 0.2030675\ttotal: 7.78s\tremaining: 34.5s\n",
      "92:\tlearn: 0.2020606\ttotal: 7.85s\tremaining: 34.3s\n",
      "93:\tlearn: 0.2008162\ttotal: 7.94s\tremaining: 34.3s\n",
      "94:\tlearn: 0.1995231\ttotal: 8.04s\tremaining: 34.3s\n",
      "95:\tlearn: 0.1985824\ttotal: 8.12s\tremaining: 34.2s\n",
      "96:\tlearn: 0.1974204\ttotal: 8.21s\tremaining: 34.1s\n",
      "97:\tlearn: 0.1964757\ttotal: 8.29s\tremaining: 34s\n",
      "98:\tlearn: 0.1956032\ttotal: 8.38s\tremaining: 33.9s\n",
      "99:\tlearn: 0.1945447\ttotal: 8.47s\tremaining: 33.9s\n",
      "100:\tlearn: 0.1936967\ttotal: 8.56s\tremaining: 33.8s\n",
      "101:\tlearn: 0.1929374\ttotal: 8.64s\tremaining: 33.7s\n",
      "102:\tlearn: 0.1918760\ttotal: 8.75s\tremaining: 33.7s\n",
      "103:\tlearn: 0.1911286\ttotal: 8.84s\tremaining: 33.6s\n",
      "104:\tlearn: 0.1901419\ttotal: 8.92s\tremaining: 33.6s\n",
      "105:\tlearn: 0.1892233\ttotal: 9.02s\tremaining: 33.5s\n",
      "106:\tlearn: 0.1882783\ttotal: 9.13s\tremaining: 33.5s\n",
      "107:\tlearn: 0.1873951\ttotal: 9.22s\tremaining: 33.5s\n",
      "108:\tlearn: 0.1866818\ttotal: 9.3s\tremaining: 33.4s\n",
      "109:\tlearn: 0.1860401\ttotal: 9.38s\tremaining: 33.3s\n",
      "110:\tlearn: 0.1854091\ttotal: 9.47s\tremaining: 33.2s\n",
      "111:\tlearn: 0.1847463\ttotal: 9.55s\tremaining: 33.1s\n",
      "112:\tlearn: 0.1839719\ttotal: 9.64s\tremaining: 33s\n",
      "113:\tlearn: 0.1833787\ttotal: 9.71s\tremaining: 32.9s\n",
      "114:\tlearn: 0.1827664\ttotal: 9.8s\tremaining: 32.8s\n",
      "115:\tlearn: 0.1820089\ttotal: 9.88s\tremaining: 32.7s\n",
      "116:\tlearn: 0.1814964\ttotal: 9.96s\tremaining: 32.6s\n",
      "117:\tlearn: 0.1809722\ttotal: 10s\tremaining: 32.5s\n",
      "118:\tlearn: 0.1804680\ttotal: 10.1s\tremaining: 32.4s\n",
      "119:\tlearn: 0.1799697\ttotal: 10.2s\tremaining: 32.3s\n",
      "120:\tlearn: 0.1792894\ttotal: 10.3s\tremaining: 32.3s\n",
      "121:\tlearn: 0.1788178\ttotal: 10.4s\tremaining: 32.1s\n",
      "122:\tlearn: 0.1782573\ttotal: 10.4s\tremaining: 32s\n",
      "123:\tlearn: 0.1776170\ttotal: 10.5s\tremaining: 31.9s\n",
      "124:\tlearn: 0.1770648\ttotal: 10.6s\tremaining: 31.8s\n",
      "125:\tlearn: 0.1764416\ttotal: 10.7s\tremaining: 31.8s\n",
      "126:\tlearn: 0.1760498\ttotal: 10.8s\tremaining: 31.6s\n",
      "127:\tlearn: 0.1754480\ttotal: 10.9s\tremaining: 31.6s\n",
      "128:\tlearn: 0.1748839\ttotal: 10.9s\tremaining: 31.5s\n",
      "129:\tlearn: 0.1743312\ttotal: 11s\tremaining: 31.3s\n",
      "130:\tlearn: 0.1739359\ttotal: 11.1s\tremaining: 31.2s\n",
      "131:\tlearn: 0.1733969\ttotal: 11.1s\tremaining: 31.1s\n",
      "132:\tlearn: 0.1730018\ttotal: 11.2s\tremaining: 30.9s\n",
      "133:\tlearn: 0.1725098\ttotal: 11.3s\tremaining: 30.8s\n",
      "134:\tlearn: 0.1720382\ttotal: 11.4s\tremaining: 30.8s\n",
      "135:\tlearn: 0.1716094\ttotal: 11.4s\tremaining: 30.6s\n",
      "136:\tlearn: 0.1713214\ttotal: 11.5s\tremaining: 30.5s\n",
      "137:\tlearn: 0.1708541\ttotal: 11.6s\tremaining: 30.5s\n",
      "138:\tlearn: 0.1705273\ttotal: 11.7s\tremaining: 30.3s\n",
      "139:\tlearn: 0.1701002\ttotal: 11.8s\tremaining: 30.3s\n",
      "140:\tlearn: 0.1696574\ttotal: 11.8s\tremaining: 30.2s\n",
      "141:\tlearn: 0.1692307\ttotal: 11.9s\tremaining: 30.1s\n",
      "142:\tlearn: 0.1688544\ttotal: 12s\tremaining: 30s\n",
      "143:\tlearn: 0.1684718\ttotal: 12.1s\tremaining: 29.8s\n",
      "144:\tlearn: 0.1680995\ttotal: 12.1s\tremaining: 29.7s\n",
      "145:\tlearn: 0.1677131\ttotal: 12.2s\tremaining: 29.6s\n",
      "146:\tlearn: 0.1673808\ttotal: 12.3s\tremaining: 29.5s\n",
      "147:\tlearn: 0.1670281\ttotal: 12.3s\tremaining: 29.3s\n",
      "148:\tlearn: 0.1666859\ttotal: 12.4s\tremaining: 29.2s\n",
      "149:\tlearn: 0.1663321\ttotal: 12.5s\tremaining: 29.2s\n",
      "150:\tlearn: 0.1659979\ttotal: 12.6s\tremaining: 29.1s\n",
      "151:\tlearn: 0.1656806\ttotal: 12.7s\tremaining: 29s\n",
      "152:\tlearn: 0.1654554\ttotal: 12.7s\tremaining: 28.9s\n",
      "153:\tlearn: 0.1651747\ttotal: 12.8s\tremaining: 28.7s\n",
      "154:\tlearn: 0.1649319\ttotal: 12.8s\tremaining: 28.6s\n",
      "155:\tlearn: 0.1646478\ttotal: 12.9s\tremaining: 28.4s\n",
      "156:\tlearn: 0.1644321\ttotal: 13s\tremaining: 28.3s\n",
      "157:\tlearn: 0.1641300\ttotal: 13s\tremaining: 28.2s\n",
      "158:\tlearn: 0.1638607\ttotal: 13.1s\tremaining: 28.1s\n",
      "159:\tlearn: 0.1636251\ttotal: 13.2s\tremaining: 28s\n",
      "160:\tlearn: 0.1634367\ttotal: 13.2s\tremaining: 27.8s\n",
      "161:\tlearn: 0.1631747\ttotal: 13.3s\tremaining: 27.7s\n",
      "162:\tlearn: 0.1629101\ttotal: 13.4s\tremaining: 27.6s\n",
      "163:\tlearn: 0.1626502\ttotal: 13.4s\tremaining: 27.5s\n",
      "164:\tlearn: 0.1624024\ttotal: 13.5s\tremaining: 27.4s\n",
      "165:\tlearn: 0.1622209\ttotal: 13.6s\tremaining: 27.3s\n",
      "166:\tlearn: 0.1619757\ttotal: 13.7s\tremaining: 27.2s\n",
      "167:\tlearn: 0.1617393\ttotal: 13.7s\tremaining: 27.1s\n",
      "168:\tlearn: 0.1615810\ttotal: 13.8s\tremaining: 27s\n",
      "169:\tlearn: 0.1613507\ttotal: 13.8s\tremaining: 26.9s\n",
      "170:\tlearn: 0.1611378\ttotal: 13.9s\tremaining: 26.8s\n",
      "171:\tlearn: 0.1609448\ttotal: 14s\tremaining: 26.7s\n",
      "172:\tlearn: 0.1607223\ttotal: 14.1s\tremaining: 26.6s\n",
      "173:\tlearn: 0.1605048\ttotal: 14.2s\tremaining: 26.5s\n",
      "174:\tlearn: 0.1603056\ttotal: 14.2s\tremaining: 26.4s\n",
      "175:\tlearn: 0.1601008\ttotal: 14.3s\tremaining: 26.3s\n",
      "176:\tlearn: 0.1599230\ttotal: 14.4s\tremaining: 26.2s\n",
      "177:\tlearn: 0.1597246\ttotal: 14.4s\tremaining: 26.1s\n",
      "178:\tlearn: 0.1595533\ttotal: 14.5s\tremaining: 26s\n",
      "179:\tlearn: 0.1594230\ttotal: 14.6s\tremaining: 25.9s\n",
      "180:\tlearn: 0.1592482\ttotal: 14.7s\tremaining: 25.9s\n",
      "181:\tlearn: 0.1590807\ttotal: 14.7s\tremaining: 25.8s\n",
      "182:\tlearn: 0.1589034\ttotal: 14.8s\tremaining: 25.7s\n",
      "183:\tlearn: 0.1587275\ttotal: 14.9s\tremaining: 25.6s\n",
      "184:\tlearn: 0.1585509\ttotal: 15s\tremaining: 25.5s\n",
      "185:\tlearn: 0.1584053\ttotal: 15s\tremaining: 25.4s\n",
      "186:\tlearn: 0.1582535\ttotal: 15.1s\tremaining: 25.3s\n",
      "187:\tlearn: 0.1580999\ttotal: 15.2s\tremaining: 25.2s\n",
      "188:\tlearn: 0.1579351\ttotal: 15.2s\tremaining: 25.1s\n",
      "189:\tlearn: 0.1577999\ttotal: 15.3s\tremaining: 25s\n",
      "190:\tlearn: 0.1576611\ttotal: 15.4s\tremaining: 24.9s\n",
      "191:\tlearn: 0.1575188\ttotal: 15.5s\tremaining: 24.8s\n",
      "192:\tlearn: 0.1573752\ttotal: 15.5s\tremaining: 24.7s\n",
      "193:\tlearn: 0.1572473\ttotal: 15.6s\tremaining: 24.6s\n",
      "194:\tlearn: 0.1571058\ttotal: 15.7s\tremaining: 24.5s\n",
      "195:\tlearn: 0.1569829\ttotal: 15.8s\tremaining: 24.5s\n",
      "196:\tlearn: 0.1568538\ttotal: 15.9s\tremaining: 24.4s\n",
      "197:\tlearn: 0.1567204\ttotal: 15.9s\tremaining: 24.3s\n",
      "198:\tlearn: 0.1566097\ttotal: 16s\tremaining: 24.2s\n",
      "199:\tlearn: 0.1564803\ttotal: 16.1s\tremaining: 24.2s\n",
      "200:\tlearn: 0.1563662\ttotal: 16.2s\tremaining: 24.1s\n",
      "201:\tlearn: 0.1562786\ttotal: 16.3s\tremaining: 24s\n",
      "202:\tlearn: 0.1561688\ttotal: 16.3s\tremaining: 23.9s\n",
      "203:\tlearn: 0.1560556\ttotal: 16.4s\tremaining: 23.8s\n",
      "204:\tlearn: 0.1559446\ttotal: 16.5s\tremaining: 23.7s\n",
      "205:\tlearn: 0.1558446\ttotal: 16.6s\tremaining: 23.6s\n",
      "206:\tlearn: 0.1557430\ttotal: 16.6s\tremaining: 23.6s\n",
      "207:\tlearn: 0.1556195\ttotal: 16.7s\tremaining: 23.5s\n",
      "208:\tlearn: 0.1555160\ttotal: 16.8s\tremaining: 23.4s\n",
      "209:\tlearn: 0.1553959\ttotal: 16.9s\tremaining: 23.3s\n",
      "210:\tlearn: 0.1552923\ttotal: 16.9s\tremaining: 23.2s\n",
      "211:\tlearn: 0.1551943\ttotal: 17s\tremaining: 23.1s\n",
      "212:\tlearn: 0.1550686\ttotal: 17.1s\tremaining: 23s\n",
      "213:\tlearn: 0.1549947\ttotal: 17.1s\tremaining: 22.9s\n",
      "214:\tlearn: 0.1548919\ttotal: 17.2s\tremaining: 22.8s\n",
      "215:\tlearn: 0.1547939\ttotal: 17.3s\tremaining: 22.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216:\tlearn: 0.1547311\ttotal: 17.4s\tremaining: 22.6s\n",
      "217:\tlearn: 0.1546392\ttotal: 17.4s\tremaining: 22.5s\n",
      "218:\tlearn: 0.1545654\ttotal: 17.5s\tremaining: 22.5s\n",
      "219:\tlearn: 0.1544674\ttotal: 17.6s\tremaining: 22.4s\n",
      "220:\tlearn: 0.1543788\ttotal: 17.7s\tremaining: 22.3s\n",
      "221:\tlearn: 0.1542959\ttotal: 17.7s\tremaining: 22.2s\n",
      "222:\tlearn: 0.1541987\ttotal: 17.8s\tremaining: 22.1s\n",
      "223:\tlearn: 0.1541159\ttotal: 17.9s\tremaining: 22s\n",
      "224:\tlearn: 0.1540304\ttotal: 18s\tremaining: 21.9s\n",
      "225:\tlearn: 0.1539452\ttotal: 18s\tremaining: 21.8s\n",
      "226:\tlearn: 0.1538730\ttotal: 18.1s\tremaining: 21.7s\n",
      "227:\tlearn: 0.1538091\ttotal: 18.1s\tremaining: 21.6s\n",
      "228:\tlearn: 0.1537308\ttotal: 18.2s\tremaining: 21.5s\n",
      "229:\tlearn: 0.1536433\ttotal: 18.3s\tremaining: 21.5s\n",
      "230:\tlearn: 0.1535683\ttotal: 18.4s\tremaining: 21.4s\n",
      "231:\tlearn: 0.1534957\ttotal: 18.4s\tremaining: 21.3s\n",
      "232:\tlearn: 0.1534405\ttotal: 18.5s\tremaining: 21.2s\n",
      "233:\tlearn: 0.1533720\ttotal: 18.6s\tremaining: 21.1s\n",
      "234:\tlearn: 0.1533181\ttotal: 18.6s\tremaining: 21s\n",
      "235:\tlearn: 0.1532532\ttotal: 18.7s\tremaining: 20.9s\n",
      "236:\tlearn: 0.1531852\ttotal: 18.8s\tremaining: 20.8s\n",
      "237:\tlearn: 0.1531180\ttotal: 18.8s\tremaining: 20.7s\n",
      "238:\tlearn: 0.1530584\ttotal: 18.9s\tremaining: 20.6s\n",
      "239:\tlearn: 0.1529899\ttotal: 19s\tremaining: 20.6s\n",
      "240:\tlearn: 0.1529241\ttotal: 19s\tremaining: 20.5s\n",
      "241:\tlearn: 0.1528618\ttotal: 19.1s\tremaining: 20.4s\n",
      "242:\tlearn: 0.1527993\ttotal: 19.2s\tremaining: 20.3s\n",
      "243:\tlearn: 0.1527381\ttotal: 19.2s\tremaining: 20.2s\n",
      "244:\tlearn: 0.1526760\ttotal: 19.3s\tremaining: 20.1s\n",
      "245:\tlearn: 0.1526140\ttotal: 19.4s\tremaining: 20s\n",
      "246:\tlearn: 0.1525725\ttotal: 19.4s\tremaining: 19.9s\n",
      "247:\tlearn: 0.1525115\ttotal: 19.5s\tremaining: 19.8s\n",
      "248:\tlearn: 0.1524559\ttotal: 19.5s\tremaining: 19.7s\n",
      "249:\tlearn: 0.1524014\ttotal: 19.6s\tremaining: 19.6s\n",
      "250:\tlearn: 0.1523442\ttotal: 19.7s\tremaining: 19.6s\n",
      "251:\tlearn: 0.1522820\ttotal: 19.8s\tremaining: 19.5s\n",
      "252:\tlearn: 0.1522282\ttotal: 19.9s\tremaining: 19.4s\n",
      "253:\tlearn: 0.1521807\ttotal: 19.9s\tremaining: 19.3s\n",
      "254:\tlearn: 0.1521296\ttotal: 20s\tremaining: 19.2s\n",
      "255:\tlearn: 0.1520723\ttotal: 20.1s\tremaining: 19.2s\n",
      "256:\tlearn: 0.1520175\ttotal: 20.2s\tremaining: 19.1s\n",
      "257:\tlearn: 0.1519765\ttotal: 20.3s\tremaining: 19s\n",
      "258:\tlearn: 0.1519215\ttotal: 20.3s\tremaining: 18.9s\n",
      "259:\tlearn: 0.1518688\ttotal: 20.4s\tremaining: 18.8s\n",
      "260:\tlearn: 0.1518245\ttotal: 20.5s\tremaining: 18.8s\n",
      "261:\tlearn: 0.1517552\ttotal: 20.6s\tremaining: 18.7s\n",
      "262:\tlearn: 0.1517068\ttotal: 20.6s\tremaining: 18.6s\n",
      "263:\tlearn: 0.1516640\ttotal: 20.7s\tremaining: 18.5s\n",
      "264:\tlearn: 0.1516180\ttotal: 20.8s\tremaining: 18.4s\n",
      "265:\tlearn: 0.1515704\ttotal: 20.8s\tremaining: 18.3s\n",
      "266:\tlearn: 0.1515206\ttotal: 20.9s\tremaining: 18.2s\n",
      "267:\tlearn: 0.1514812\ttotal: 21s\tremaining: 18.2s\n",
      "268:\tlearn: 0.1514499\ttotal: 21s\tremaining: 18.1s\n",
      "269:\tlearn: 0.1514017\ttotal: 21.1s\tremaining: 18s\n",
      "270:\tlearn: 0.1513721\ttotal: 21.2s\tremaining: 17.9s\n",
      "271:\tlearn: 0.1513282\ttotal: 21.3s\tremaining: 17.8s\n",
      "272:\tlearn: 0.1512868\ttotal: 21.4s\tremaining: 17.8s\n",
      "273:\tlearn: 0.1512380\ttotal: 21.5s\tremaining: 17.7s\n",
      "274:\tlearn: 0.1511948\ttotal: 21.5s\tremaining: 17.6s\n",
      "275:\tlearn: 0.1511550\ttotal: 21.6s\tremaining: 17.6s\n",
      "276:\tlearn: 0.1511007\ttotal: 21.7s\tremaining: 17.5s\n",
      "277:\tlearn: 0.1510505\ttotal: 21.8s\tremaining: 17.4s\n",
      "278:\tlearn: 0.1510060\ttotal: 21.9s\tremaining: 17.3s\n",
      "279:\tlearn: 0.1509698\ttotal: 22s\tremaining: 17.3s\n",
      "280:\tlearn: 0.1509222\ttotal: 22.1s\tremaining: 17.2s\n",
      "281:\tlearn: 0.1508870\ttotal: 22.1s\tremaining: 17.1s\n",
      "282:\tlearn: 0.1508525\ttotal: 22.2s\tremaining: 17s\n",
      "283:\tlearn: 0.1508098\ttotal: 22.3s\tremaining: 16.9s\n",
      "284:\tlearn: 0.1507692\ttotal: 22.3s\tremaining: 16.9s\n",
      "285:\tlearn: 0.1507249\ttotal: 22.4s\tremaining: 16.8s\n",
      "286:\tlearn: 0.1506915\ttotal: 22.5s\tremaining: 16.7s\n",
      "287:\tlearn: 0.1506558\ttotal: 22.6s\tremaining: 16.6s\n",
      "288:\tlearn: 0.1506090\ttotal: 22.6s\tremaining: 16.5s\n",
      "289:\tlearn: 0.1505815\ttotal: 22.7s\tremaining: 16.4s\n",
      "290:\tlearn: 0.1505463\ttotal: 22.8s\tremaining: 16.4s\n",
      "291:\tlearn: 0.1505129\ttotal: 22.8s\tremaining: 16.3s\n",
      "292:\tlearn: 0.1504753\ttotal: 22.9s\tremaining: 16.2s\n",
      "293:\tlearn: 0.1504435\ttotal: 23s\tremaining: 16.1s\n",
      "294:\tlearn: 0.1504079\ttotal: 23.1s\tremaining: 16s\n",
      "295:\tlearn: 0.1503799\ttotal: 23.1s\tremaining: 15.9s\n",
      "296:\tlearn: 0.1503500\ttotal: 23.2s\tremaining: 15.9s\n",
      "297:\tlearn: 0.1503160\ttotal: 23.3s\tremaining: 15.8s\n",
      "298:\tlearn: 0.1502820\ttotal: 23.4s\tremaining: 15.7s\n",
      "299:\tlearn: 0.1502574\ttotal: 23.4s\tremaining: 15.6s\n",
      "300:\tlearn: 0.1502253\ttotal: 23.5s\tremaining: 15.5s\n",
      "301:\tlearn: 0.1502004\ttotal: 23.6s\tremaining: 15.4s\n",
      "302:\tlearn: 0.1501543\ttotal: 23.6s\tremaining: 15.4s\n",
      "303:\tlearn: 0.1501072\ttotal: 23.7s\tremaining: 15.3s\n",
      "304:\tlearn: 0.1500815\ttotal: 23.8s\tremaining: 15.2s\n",
      "305:\tlearn: 0.1500504\ttotal: 23.8s\tremaining: 15.1s\n",
      "306:\tlearn: 0.1500258\ttotal: 23.9s\tremaining: 15s\n",
      "307:\tlearn: 0.1500026\ttotal: 24s\tremaining: 14.9s\n",
      "308:\tlearn: 0.1499647\ttotal: 24s\tremaining: 14.9s\n",
      "309:\tlearn: 0.1499359\ttotal: 24.1s\tremaining: 14.8s\n",
      "310:\tlearn: 0.1499098\ttotal: 24.2s\tremaining: 14.7s\n",
      "311:\tlearn: 0.1498810\ttotal: 24.2s\tremaining: 14.6s\n",
      "312:\tlearn: 0.1498530\ttotal: 24.3s\tremaining: 14.5s\n",
      "313:\tlearn: 0.1498286\ttotal: 24.4s\tremaining: 14.4s\n",
      "314:\tlearn: 0.1498044\ttotal: 24.4s\tremaining: 14.4s\n",
      "315:\tlearn: 0.1497807\ttotal: 24.5s\tremaining: 14.3s\n",
      "316:\tlearn: 0.1497465\ttotal: 24.6s\tremaining: 14.2s\n",
      "317:\tlearn: 0.1497219\ttotal: 24.6s\tremaining: 14.1s\n",
      "318:\tlearn: 0.1496885\ttotal: 24.7s\tremaining: 14s\n",
      "319:\tlearn: 0.1496707\ttotal: 24.8s\tremaining: 13.9s\n",
      "320:\tlearn: 0.1496447\ttotal: 24.8s\tremaining: 13.8s\n",
      "321:\tlearn: 0.1495969\ttotal: 24.9s\tremaining: 13.8s\n",
      "322:\tlearn: 0.1495669\ttotal: 25s\tremaining: 13.7s\n",
      "323:\tlearn: 0.1495242\ttotal: 25s\tremaining: 13.6s\n",
      "324:\tlearn: 0.1495031\ttotal: 25.1s\tremaining: 13.5s\n",
      "325:\tlearn: 0.1494814\ttotal: 25.1s\tremaining: 13.4s\n",
      "326:\tlearn: 0.1494542\ttotal: 25.2s\tremaining: 13.3s\n",
      "327:\tlearn: 0.1494274\ttotal: 25.3s\tremaining: 13.3s\n",
      "328:\tlearn: 0.1494032\ttotal: 25.3s\tremaining: 13.2s\n",
      "329:\tlearn: 0.1493669\ttotal: 25.4s\tremaining: 13.1s\n",
      "330:\tlearn: 0.1493371\ttotal: 25.5s\tremaining: 13s\n",
      "331:\tlearn: 0.1493125\ttotal: 25.5s\tremaining: 12.9s\n",
      "332:\tlearn: 0.1492902\ttotal: 25.6s\tremaining: 12.8s\n",
      "333:\tlearn: 0.1492649\ttotal: 25.7s\tremaining: 12.8s\n",
      "334:\tlearn: 0.1492376\ttotal: 25.7s\tremaining: 12.7s\n",
      "335:\tlearn: 0.1492115\ttotal: 25.8s\tremaining: 12.6s\n",
      "336:\tlearn: 0.1491851\ttotal: 25.9s\tremaining: 12.5s\n",
      "337:\tlearn: 0.1491601\ttotal: 25.9s\tremaining: 12.4s\n",
      "338:\tlearn: 0.1491416\ttotal: 26s\tremaining: 12.3s\n",
      "339:\tlearn: 0.1491240\ttotal: 26.1s\tremaining: 12.3s\n",
      "340:\tlearn: 0.1491030\ttotal: 26.1s\tremaining: 12.2s\n",
      "341:\tlearn: 0.1490666\ttotal: 26.2s\tremaining: 12.1s\n",
      "342:\tlearn: 0.1490334\ttotal: 26.3s\tremaining: 12s\n",
      "343:\tlearn: 0.1489990\ttotal: 26.3s\tremaining: 11.9s\n",
      "344:\tlearn: 0.1489705\ttotal: 26.4s\tremaining: 11.9s\n",
      "345:\tlearn: 0.1489359\ttotal: 26.5s\tremaining: 11.8s\n",
      "346:\tlearn: 0.1489186\ttotal: 26.5s\tremaining: 11.7s\n",
      "347:\tlearn: 0.1488938\ttotal: 26.6s\tremaining: 11.6s\n",
      "348:\tlearn: 0.1488619\ttotal: 26.7s\tremaining: 11.6s\n",
      "349:\tlearn: 0.1488377\ttotal: 26.8s\tremaining: 11.5s\n",
      "350:\tlearn: 0.1488185\ttotal: 26.8s\tremaining: 11.4s\n",
      "351:\tlearn: 0.1487889\ttotal: 26.9s\tremaining: 11.3s\n",
      "352:\tlearn: 0.1487655\ttotal: 27s\tremaining: 11.2s\n",
      "353:\tlearn: 0.1487432\ttotal: 27.1s\tremaining: 11.2s\n",
      "354:\tlearn: 0.1487086\ttotal: 27.1s\tremaining: 11.1s\n",
      "355:\tlearn: 0.1486709\ttotal: 27.2s\tremaining: 11s\n",
      "356:\tlearn: 0.1486497\ttotal: 27.3s\tremaining: 10.9s\n",
      "357:\tlearn: 0.1486154\ttotal: 27.4s\tremaining: 10.9s\n",
      "358:\tlearn: 0.1485924\ttotal: 27.5s\tremaining: 10.8s\n",
      "359:\tlearn: 0.1485755\ttotal: 27.5s\tremaining: 10.7s\n",
      "360:\tlearn: 0.1485540\ttotal: 27.6s\tremaining: 10.6s\n",
      "361:\tlearn: 0.1485235\ttotal: 27.7s\tremaining: 10.5s\n",
      "362:\tlearn: 0.1484946\ttotal: 27.7s\tremaining: 10.5s\n",
      "363:\tlearn: 0.1484690\ttotal: 27.8s\tremaining: 10.4s\n",
      "364:\tlearn: 0.1484459\ttotal: 27.9s\tremaining: 10.3s\n",
      "365:\tlearn: 0.1484238\ttotal: 27.9s\tremaining: 10.2s\n",
      "366:\tlearn: 0.1484002\ttotal: 28s\tremaining: 10.1s\n",
      "367:\tlearn: 0.1483747\ttotal: 28s\tremaining: 10.1s\n",
      "368:\tlearn: 0.1483553\ttotal: 28.1s\tremaining: 9.98s\n",
      "369:\tlearn: 0.1483381\ttotal: 28.2s\tremaining: 9.9s\n",
      "370:\tlearn: 0.1483173\ttotal: 28.3s\tremaining: 9.82s\n",
      "371:\tlearn: 0.1482966\ttotal: 28.3s\tremaining: 9.75s\n",
      "372:\tlearn: 0.1482767\ttotal: 28.4s\tremaining: 9.67s\n",
      "373:\tlearn: 0.1482550\ttotal: 28.5s\tremaining: 9.59s\n",
      "374:\tlearn: 0.1482282\ttotal: 28.5s\tremaining: 9.51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375:\tlearn: 0.1482086\ttotal: 28.6s\tremaining: 9.44s\n",
      "376:\tlearn: 0.1481813\ttotal: 28.7s\tremaining: 9.36s\n",
      "377:\tlearn: 0.1481635\ttotal: 28.7s\tremaining: 9.28s\n",
      "378:\tlearn: 0.1481474\ttotal: 28.8s\tremaining: 9.2s\n",
      "379:\tlearn: 0.1481293\ttotal: 28.9s\tremaining: 9.12s\n",
      "380:\tlearn: 0.1481101\ttotal: 28.9s\tremaining: 9.04s\n",
      "381:\tlearn: 0.1480938\ttotal: 29s\tremaining: 8.96s\n",
      "382:\tlearn: 0.1480770\ttotal: 29.1s\tremaining: 8.88s\n",
      "383:\tlearn: 0.1480614\ttotal: 29.1s\tremaining: 8.79s\n",
      "384:\tlearn: 0.1480442\ttotal: 29.2s\tremaining: 8.72s\n",
      "385:\tlearn: 0.1480273\ttotal: 29.2s\tremaining: 8.64s\n",
      "386:\tlearn: 0.1479992\ttotal: 29.3s\tremaining: 8.56s\n",
      "387:\tlearn: 0.1479760\ttotal: 29.4s\tremaining: 8.48s\n",
      "388:\tlearn: 0.1479577\ttotal: 29.4s\tremaining: 8.4s\n",
      "389:\tlearn: 0.1479331\ttotal: 29.5s\tremaining: 8.32s\n",
      "390:\tlearn: 0.1479079\ttotal: 29.6s\tremaining: 8.24s\n",
      "391:\tlearn: 0.1478914\ttotal: 29.6s\tremaining: 8.16s\n",
      "392:\tlearn: 0.1478745\ttotal: 29.7s\tremaining: 8.09s\n",
      "393:\tlearn: 0.1478499\ttotal: 29.8s\tremaining: 8.01s\n",
      "394:\tlearn: 0.1478314\ttotal: 29.8s\tremaining: 7.93s\n",
      "395:\tlearn: 0.1478050\ttotal: 29.9s\tremaining: 7.85s\n",
      "396:\tlearn: 0.1477868\ttotal: 30s\tremaining: 7.77s\n",
      "397:\tlearn: 0.1477636\ttotal: 30s\tremaining: 7.69s\n",
      "398:\tlearn: 0.1477482\ttotal: 30.1s\tremaining: 7.61s\n",
      "399:\tlearn: 0.1477316\ttotal: 30.2s\tremaining: 7.54s\n",
      "400:\tlearn: 0.1477157\ttotal: 30.2s\tremaining: 7.46s\n",
      "401:\tlearn: 0.1476835\ttotal: 30.3s\tremaining: 7.38s\n",
      "402:\tlearn: 0.1476689\ttotal: 30.4s\tremaining: 7.3s\n",
      "403:\tlearn: 0.1476468\ttotal: 30.4s\tremaining: 7.23s\n",
      "404:\tlearn: 0.1476204\ttotal: 30.5s\tremaining: 7.15s\n",
      "405:\tlearn: 0.1475940\ttotal: 30.5s\tremaining: 7.07s\n",
      "406:\tlearn: 0.1475746\ttotal: 30.6s\tremaining: 6.99s\n",
      "407:\tlearn: 0.1475582\ttotal: 30.7s\tremaining: 6.92s\n",
      "408:\tlearn: 0.1475451\ttotal: 30.7s\tremaining: 6.84s\n",
      "409:\tlearn: 0.1475337\ttotal: 30.8s\tremaining: 6.76s\n",
      "410:\tlearn: 0.1475206\ttotal: 30.9s\tremaining: 6.69s\n",
      "411:\tlearn: 0.1475049\ttotal: 31s\tremaining: 6.61s\n",
      "412:\tlearn: 0.1474841\ttotal: 31s\tremaining: 6.54s\n",
      "413:\tlearn: 0.1474690\ttotal: 31.1s\tremaining: 6.46s\n",
      "414:\tlearn: 0.1474547\ttotal: 31.1s\tremaining: 6.38s\n",
      "415:\tlearn: 0.1474364\ttotal: 31.2s\tremaining: 6.3s\n",
      "416:\tlearn: 0.1474201\ttotal: 31.3s\tremaining: 6.23s\n",
      "417:\tlearn: 0.1474070\ttotal: 31.4s\tremaining: 6.15s\n",
      "418:\tlearn: 0.1473921\ttotal: 31.4s\tremaining: 6.07s\n",
      "419:\tlearn: 0.1473803\ttotal: 31.5s\tremaining: 5.99s\n",
      "420:\tlearn: 0.1473644\ttotal: 31.5s\tremaining: 5.92s\n",
      "421:\tlearn: 0.1473510\ttotal: 31.6s\tremaining: 5.84s\n",
      "422:\tlearn: 0.1473386\ttotal: 31.7s\tremaining: 5.76s\n",
      "423:\tlearn: 0.1473252\ttotal: 31.7s\tremaining: 5.69s\n",
      "424:\tlearn: 0.1473129\ttotal: 31.8s\tremaining: 5.62s\n",
      "425:\tlearn: 0.1472925\ttotal: 31.9s\tremaining: 5.54s\n",
      "426:\tlearn: 0.1472749\ttotal: 32s\tremaining: 5.46s\n",
      "427:\tlearn: 0.1472602\ttotal: 32.1s\tremaining: 5.39s\n",
      "428:\tlearn: 0.1472446\ttotal: 32.1s\tremaining: 5.32s\n",
      "429:\tlearn: 0.1472236\ttotal: 32.2s\tremaining: 5.24s\n",
      "430:\tlearn: 0.1472108\ttotal: 32.2s\tremaining: 5.16s\n",
      "431:\tlearn: 0.1471945\ttotal: 32.3s\tremaining: 5.08s\n",
      "432:\tlearn: 0.1471809\ttotal: 32.4s\tremaining: 5s\n",
      "433:\tlearn: 0.1471536\ttotal: 32.4s\tremaining: 4.93s\n",
      "434:\tlearn: 0.1471397\ttotal: 32.5s\tremaining: 4.86s\n",
      "435:\tlearn: 0.1471254\ttotal: 32.6s\tremaining: 4.78s\n",
      "436:\tlearn: 0.1471118\ttotal: 32.6s\tremaining: 4.7s\n",
      "437:\tlearn: 0.1470988\ttotal: 32.7s\tremaining: 4.63s\n",
      "438:\tlearn: 0.1470855\ttotal: 32.8s\tremaining: 4.55s\n",
      "439:\tlearn: 0.1470708\ttotal: 32.9s\tremaining: 4.48s\n",
      "440:\tlearn: 0.1470489\ttotal: 32.9s\tremaining: 4.4s\n",
      "441:\tlearn: 0.1470315\ttotal: 33s\tremaining: 4.33s\n",
      "442:\tlearn: 0.1470183\ttotal: 33s\tremaining: 4.25s\n",
      "443:\tlearn: 0.1470062\ttotal: 33.1s\tremaining: 4.17s\n",
      "444:\tlearn: 0.1469880\ttotal: 33.2s\tremaining: 4.1s\n",
      "445:\tlearn: 0.1469633\ttotal: 33.2s\tremaining: 4.02s\n",
      "446:\tlearn: 0.1469517\ttotal: 33.3s\tremaining: 3.94s\n",
      "447:\tlearn: 0.1469309\ttotal: 33.3s\tremaining: 3.87s\n",
      "448:\tlearn: 0.1469201\ttotal: 33.4s\tremaining: 3.79s\n",
      "449:\tlearn: 0.1469058\ttotal: 33.4s\tremaining: 3.71s\n",
      "450:\tlearn: 0.1468940\ttotal: 33.5s\tremaining: 3.64s\n",
      "451:\tlearn: 0.1468762\ttotal: 33.6s\tremaining: 3.57s\n",
      "452:\tlearn: 0.1468570\ttotal: 33.6s\tremaining: 3.49s\n",
      "453:\tlearn: 0.1468446\ttotal: 33.7s\tremaining: 3.41s\n",
      "454:\tlearn: 0.1468309\ttotal: 33.7s\tremaining: 3.34s\n",
      "455:\tlearn: 0.1468126\ttotal: 33.8s\tremaining: 3.26s\n",
      "456:\tlearn: 0.1467966\ttotal: 33.9s\tremaining: 3.19s\n",
      "457:\tlearn: 0.1467796\ttotal: 33.9s\tremaining: 3.11s\n",
      "458:\tlearn: 0.1467633\ttotal: 34s\tremaining: 3.04s\n",
      "459:\tlearn: 0.1467521\ttotal: 34.1s\tremaining: 2.96s\n",
      "460:\tlearn: 0.1467289\ttotal: 34.1s\tremaining: 2.89s\n",
      "461:\tlearn: 0.1467075\ttotal: 34.2s\tremaining: 2.81s\n",
      "462:\tlearn: 0.1466983\ttotal: 34.3s\tremaining: 2.74s\n",
      "463:\tlearn: 0.1466875\ttotal: 34.3s\tremaining: 2.66s\n",
      "464:\tlearn: 0.1466690\ttotal: 34.4s\tremaining: 2.59s\n",
      "465:\tlearn: 0.1466489\ttotal: 34.4s\tremaining: 2.51s\n",
      "466:\tlearn: 0.1466269\ttotal: 34.5s\tremaining: 2.44s\n",
      "467:\tlearn: 0.1466159\ttotal: 34.6s\tremaining: 2.36s\n",
      "468:\tlearn: 0.1466010\ttotal: 34.6s\tremaining: 2.29s\n",
      "469:\tlearn: 0.1465877\ttotal: 34.7s\tremaining: 2.21s\n",
      "470:\tlearn: 0.1465718\ttotal: 34.8s\tremaining: 2.14s\n",
      "471:\tlearn: 0.1465589\ttotal: 34.9s\tremaining: 2.07s\n",
      "472:\tlearn: 0.1465491\ttotal: 34.9s\tremaining: 1.99s\n",
      "473:\tlearn: 0.1465297\ttotal: 35s\tremaining: 1.92s\n",
      "474:\tlearn: 0.1465189\ttotal: 35s\tremaining: 1.84s\n",
      "475:\tlearn: 0.1465061\ttotal: 35.1s\tremaining: 1.77s\n",
      "476:\tlearn: 0.1464925\ttotal: 35.1s\tremaining: 1.69s\n",
      "477:\tlearn: 0.1464746\ttotal: 35.2s\tremaining: 1.62s\n",
      "478:\tlearn: 0.1464644\ttotal: 35.3s\tremaining: 1.55s\n",
      "479:\tlearn: 0.1464508\ttotal: 35.3s\tremaining: 1.47s\n",
      "480:\tlearn: 0.1464399\ttotal: 35.4s\tremaining: 1.4s\n",
      "481:\tlearn: 0.1464294\ttotal: 35.4s\tremaining: 1.32s\n",
      "482:\tlearn: 0.1464183\ttotal: 35.5s\tremaining: 1.25s\n",
      "483:\tlearn: 0.1464026\ttotal: 35.6s\tremaining: 1.18s\n",
      "484:\tlearn: 0.1463878\ttotal: 35.6s\tremaining: 1.1s\n",
      "485:\tlearn: 0.1463753\ttotal: 35.7s\tremaining: 1.03s\n",
      "486:\tlearn: 0.1463614\ttotal: 35.8s\tremaining: 955ms\n",
      "487:\tlearn: 0.1463502\ttotal: 35.8s\tremaining: 881ms\n",
      "488:\tlearn: 0.1463381\ttotal: 35.9s\tremaining: 807ms\n",
      "489:\tlearn: 0.1463229\ttotal: 35.9s\tremaining: 734ms\n",
      "490:\tlearn: 0.1463111\ttotal: 36s\tremaining: 660ms\n",
      "491:\tlearn: 0.1462972\ttotal: 36s\tremaining: 586ms\n",
      "492:\tlearn: 0.1462839\ttotal: 36.1s\tremaining: 513ms\n",
      "493:\tlearn: 0.1462723\ttotal: 36.2s\tremaining: 440ms\n",
      "494:\tlearn: 0.1462631\ttotal: 36.3s\tremaining: 366ms\n",
      "495:\tlearn: 0.1462443\ttotal: 36.4s\tremaining: 293ms\n",
      "496:\tlearn: 0.1462323\ttotal: 36.4s\tremaining: 220ms\n",
      "497:\tlearn: 0.1462239\ttotal: 36.5s\tremaining: 147ms\n",
      "498:\tlearn: 0.1462076\ttotal: 36.5s\tremaining: 73.2ms\n",
      "499:\tlearn: 0.1461971\ttotal: 36.6s\tremaining: 0us\n",
      "[CV]  learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5, total=  37.3s\n",
      "[CV] learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5 ......\n",
      "0:\tlearn: 0.6767236\ttotal: 78.7ms\tremaining: 39.3s\n",
      "1:\tlearn: 0.6614329\ttotal: 176ms\tremaining: 43.7s\n",
      "2:\tlearn: 0.6472916\ttotal: 234ms\tremaining: 38.7s\n",
      "3:\tlearn: 0.6337657\ttotal: 289ms\tremaining: 35.9s\n",
      "4:\tlearn: 0.6204130\ttotal: 353ms\tremaining: 35s\n",
      "5:\tlearn: 0.6079771\ttotal: 414ms\tremaining: 34.1s\n",
      "6:\tlearn: 0.5956882\ttotal: 480ms\tremaining: 33.8s\n",
      "7:\tlearn: 0.5838526\ttotal: 552ms\tremaining: 33.9s\n",
      "8:\tlearn: 0.5723843\ttotal: 612ms\tremaining: 33.4s\n",
      "9:\tlearn: 0.5610991\ttotal: 684ms\tremaining: 33.5s\n",
      "10:\tlearn: 0.5500478\ttotal: 752ms\tremaining: 33.4s\n",
      "11:\tlearn: 0.5386414\ttotal: 855ms\tremaining: 34.8s\n",
      "12:\tlearn: 0.5282993\ttotal: 929ms\tremaining: 34.8s\n",
      "13:\tlearn: 0.5183865\ttotal: 1.01s\tremaining: 35.2s\n",
      "14:\tlearn: 0.5077717\ttotal: 1.1s\tremaining: 35.5s\n",
      "15:\tlearn: 0.4975628\ttotal: 1.19s\tremaining: 36.1s\n",
      "16:\tlearn: 0.4879028\ttotal: 1.28s\tremaining: 36.4s\n",
      "17:\tlearn: 0.4788836\ttotal: 1.33s\tremaining: 35.8s\n",
      "18:\tlearn: 0.4703071\ttotal: 1.39s\tremaining: 35.3s\n",
      "19:\tlearn: 0.4614360\ttotal: 1.46s\tremaining: 35s\n",
      "20:\tlearn: 0.4533724\ttotal: 1.53s\tremaining: 35s\n",
      "21:\tlearn: 0.4454507\ttotal: 1.6s\tremaining: 34.7s\n",
      "22:\tlearn: 0.4377844\ttotal: 1.65s\tremaining: 34.3s\n",
      "23:\tlearn: 0.4301703\ttotal: 1.72s\tremaining: 34.1s\n",
      "24:\tlearn: 0.4229970\ttotal: 1.79s\tremaining: 34s\n",
      "25:\tlearn: 0.4158091\ttotal: 1.87s\tremaining: 34s\n",
      "26:\tlearn: 0.4090060\ttotal: 1.94s\tremaining: 34s\n",
      "27:\tlearn: 0.4014715\ttotal: 2.02s\tremaining: 34s\n",
      "28:\tlearn: 0.3950915\ttotal: 2.08s\tremaining: 33.8s\n",
      "29:\tlearn: 0.3883063\ttotal: 2.14s\tremaining: 33.5s\n",
      "30:\tlearn: 0.3823838\ttotal: 2.2s\tremaining: 33.3s\n",
      "31:\tlearn: 0.3765358\ttotal: 2.27s\tremaining: 33.2s\n",
      "32:\tlearn: 0.3706015\ttotal: 2.33s\tremaining: 33s\n",
      "33:\tlearn: 0.3647359\ttotal: 2.39s\tremaining: 32.8s\n",
      "34:\tlearn: 0.3590982\ttotal: 2.45s\tremaining: 32.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35:\tlearn: 0.3536721\ttotal: 2.52s\tremaining: 32.4s\n",
      "36:\tlearn: 0.3474826\ttotal: 2.6s\tremaining: 32.5s\n",
      "37:\tlearn: 0.3426284\ttotal: 2.65s\tremaining: 32.2s\n",
      "38:\tlearn: 0.3370493\ttotal: 2.72s\tremaining: 32.1s\n",
      "39:\tlearn: 0.3325746\ttotal: 2.79s\tremaining: 32.1s\n",
      "40:\tlearn: 0.3275410\ttotal: 2.85s\tremaining: 31.9s\n",
      "41:\tlearn: 0.3231959\ttotal: 2.92s\tremaining: 31.8s\n",
      "42:\tlearn: 0.3189906\ttotal: 2.98s\tremaining: 31.7s\n",
      "43:\tlearn: 0.3148231\ttotal: 3.04s\tremaining: 31.5s\n",
      "44:\tlearn: 0.3108164\ttotal: 3.09s\tremaining: 31.2s\n",
      "45:\tlearn: 0.3065166\ttotal: 3.14s\tremaining: 31s\n",
      "46:\tlearn: 0.3021032\ttotal: 3.21s\tremaining: 30.9s\n",
      "47:\tlearn: 0.2985179\ttotal: 3.29s\tremaining: 30.9s\n",
      "48:\tlearn: 0.2948921\ttotal: 3.35s\tremaining: 30.8s\n",
      "49:\tlearn: 0.2914385\ttotal: 3.4s\tremaining: 30.6s\n",
      "50:\tlearn: 0.2881058\ttotal: 3.47s\tremaining: 30.5s\n",
      "51:\tlearn: 0.2847046\ttotal: 3.53s\tremaining: 30.4s\n",
      "52:\tlearn: 0.2815943\ttotal: 3.59s\tremaining: 30.3s\n",
      "53:\tlearn: 0.2784069\ttotal: 3.66s\tremaining: 30.3s\n",
      "54:\tlearn: 0.2754356\ttotal: 3.72s\tremaining: 30.1s\n",
      "55:\tlearn: 0.2724523\ttotal: 3.79s\tremaining: 30s\n",
      "56:\tlearn: 0.2697119\ttotal: 3.85s\tremaining: 29.9s\n",
      "57:\tlearn: 0.2665511\ttotal: 3.92s\tremaining: 29.9s\n",
      "58:\tlearn: 0.2639064\ttotal: 3.98s\tremaining: 29.8s\n",
      "59:\tlearn: 0.2611960\ttotal: 4.04s\tremaining: 29.6s\n",
      "60:\tlearn: 0.2586951\ttotal: 4.09s\tremaining: 29.4s\n",
      "61:\tlearn: 0.2559542\ttotal: 4.16s\tremaining: 29.4s\n",
      "62:\tlearn: 0.2529568\ttotal: 4.22s\tremaining: 29.3s\n",
      "63:\tlearn: 0.2507230\ttotal: 4.28s\tremaining: 29.1s\n",
      "64:\tlearn: 0.2485578\ttotal: 4.34s\tremaining: 29.1s\n",
      "65:\tlearn: 0.2464611\ttotal: 4.41s\tremaining: 29s\n",
      "66:\tlearn: 0.2438911\ttotal: 4.47s\tremaining: 28.9s\n",
      "67:\tlearn: 0.2413050\ttotal: 4.55s\tremaining: 28.9s\n",
      "68:\tlearn: 0.2393410\ttotal: 4.6s\tremaining: 28.8s\n",
      "69:\tlearn: 0.2369656\ttotal: 4.67s\tremaining: 28.7s\n",
      "70:\tlearn: 0.2351683\ttotal: 4.72s\tremaining: 28.5s\n",
      "71:\tlearn: 0.2329198\ttotal: 4.79s\tremaining: 28.5s\n",
      "72:\tlearn: 0.2311721\ttotal: 4.86s\tremaining: 28.4s\n",
      "73:\tlearn: 0.2293700\ttotal: 4.92s\tremaining: 28.3s\n",
      "74:\tlearn: 0.2272937\ttotal: 4.99s\tremaining: 28.3s\n",
      "75:\tlearn: 0.2253867\ttotal: 5.04s\tremaining: 28.1s\n",
      "76:\tlearn: 0.2238922\ttotal: 5.1s\tremaining: 28s\n",
      "77:\tlearn: 0.2222790\ttotal: 5.18s\tremaining: 28s\n",
      "78:\tlearn: 0.2206552\ttotal: 5.25s\tremaining: 28s\n",
      "79:\tlearn: 0.2188744\ttotal: 5.31s\tremaining: 27.9s\n",
      "80:\tlearn: 0.2174877\ttotal: 5.37s\tremaining: 27.8s\n",
      "81:\tlearn: 0.2161609\ttotal: 5.45s\tremaining: 27.8s\n",
      "82:\tlearn: 0.2148053\ttotal: 5.51s\tremaining: 27.7s\n",
      "83:\tlearn: 0.2135028\ttotal: 5.57s\tremaining: 27.6s\n",
      "84:\tlearn: 0.2120969\ttotal: 5.62s\tremaining: 27.4s\n",
      "85:\tlearn: 0.2107719\ttotal: 5.68s\tremaining: 27.3s\n",
      "86:\tlearn: 0.2095649\ttotal: 5.76s\tremaining: 27.3s\n",
      "87:\tlearn: 0.2080262\ttotal: 5.85s\tremaining: 27.4s\n",
      "88:\tlearn: 0.2067435\ttotal: 5.94s\tremaining: 27.4s\n",
      "89:\tlearn: 0.2056511\ttotal: 6s\tremaining: 27.3s\n",
      "90:\tlearn: 0.2046223\ttotal: 6.05s\tremaining: 27.2s\n",
      "91:\tlearn: 0.2035162\ttotal: 6.11s\tremaining: 27.1s\n",
      "92:\tlearn: 0.2024927\ttotal: 6.18s\tremaining: 27s\n",
      "93:\tlearn: 0.2015263\ttotal: 6.25s\tremaining: 27s\n",
      "94:\tlearn: 0.2002834\ttotal: 6.31s\tremaining: 26.9s\n",
      "95:\tlearn: 0.1992714\ttotal: 6.38s\tremaining: 26.8s\n",
      "96:\tlearn: 0.1980059\ttotal: 6.46s\tremaining: 26.8s\n",
      "97:\tlearn: 0.1968549\ttotal: 6.55s\tremaining: 26.9s\n",
      "98:\tlearn: 0.1957284\ttotal: 6.63s\tremaining: 26.8s\n",
      "99:\tlearn: 0.1946706\ttotal: 6.7s\tremaining: 26.8s\n",
      "100:\tlearn: 0.1938148\ttotal: 6.77s\tremaining: 26.7s\n",
      "101:\tlearn: 0.1927772\ttotal: 6.84s\tremaining: 26.7s\n",
      "102:\tlearn: 0.1920420\ttotal: 6.93s\tremaining: 26.7s\n",
      "103:\tlearn: 0.1913254\ttotal: 7s\tremaining: 26.6s\n",
      "104:\tlearn: 0.1902943\ttotal: 7.07s\tremaining: 26.6s\n",
      "105:\tlearn: 0.1895926\ttotal: 7.12s\tremaining: 26.5s\n",
      "106:\tlearn: 0.1886548\ttotal: 7.19s\tremaining: 26.4s\n",
      "107:\tlearn: 0.1879777\ttotal: 7.26s\tremaining: 26.3s\n",
      "108:\tlearn: 0.1870456\ttotal: 7.32s\tremaining: 26.3s\n",
      "109:\tlearn: 0.1861486\ttotal: 7.39s\tremaining: 26.2s\n",
      "110:\tlearn: 0.1852940\ttotal: 7.46s\tremaining: 26.1s\n",
      "111:\tlearn: 0.1844845\ttotal: 7.54s\tremaining: 26.1s\n",
      "112:\tlearn: 0.1836541\ttotal: 7.62s\tremaining: 26.1s\n",
      "113:\tlearn: 0.1830732\ttotal: 7.69s\tremaining: 26s\n",
      "114:\tlearn: 0.1822676\ttotal: 7.78s\tremaining: 26.1s\n",
      "115:\tlearn: 0.1817519\ttotal: 7.83s\tremaining: 25.9s\n",
      "116:\tlearn: 0.1810155\ttotal: 7.91s\tremaining: 25.9s\n",
      "117:\tlearn: 0.1803149\ttotal: 8s\tremaining: 25.9s\n",
      "118:\tlearn: 0.1797181\ttotal: 8.06s\tremaining: 25.8s\n",
      "119:\tlearn: 0.1790369\ttotal: 8.12s\tremaining: 25.7s\n",
      "120:\tlearn: 0.1785473\ttotal: 8.19s\tremaining: 25.6s\n",
      "121:\tlearn: 0.1780515\ttotal: 8.26s\tremaining: 25.6s\n",
      "122:\tlearn: 0.1774273\ttotal: 8.32s\tremaining: 25.5s\n",
      "123:\tlearn: 0.1769298\ttotal: 8.39s\tremaining: 25.4s\n",
      "124:\tlearn: 0.1763318\ttotal: 8.47s\tremaining: 25.4s\n",
      "125:\tlearn: 0.1757240\ttotal: 8.54s\tremaining: 25.4s\n",
      "126:\tlearn: 0.1751478\ttotal: 8.63s\tremaining: 25.3s\n",
      "127:\tlearn: 0.1747032\ttotal: 8.7s\tremaining: 25.3s\n",
      "128:\tlearn: 0.1741749\ttotal: 8.79s\tremaining: 25.3s\n",
      "129:\tlearn: 0.1736195\ttotal: 8.88s\tremaining: 25.3s\n",
      "130:\tlearn: 0.1730810\ttotal: 8.98s\tremaining: 25.3s\n",
      "131:\tlearn: 0.1727452\ttotal: 9.03s\tremaining: 25.2s\n",
      "132:\tlearn: 0.1723964\ttotal: 9.09s\tremaining: 25.1s\n",
      "133:\tlearn: 0.1720413\ttotal: 9.16s\tremaining: 25s\n",
      "134:\tlearn: 0.1715628\ttotal: 9.22s\tremaining: 24.9s\n",
      "135:\tlearn: 0.1711014\ttotal: 9.29s\tremaining: 24.9s\n",
      "136:\tlearn: 0.1707729\ttotal: 9.35s\tremaining: 24.8s\n",
      "137:\tlearn: 0.1703218\ttotal: 9.42s\tremaining: 24.7s\n",
      "138:\tlearn: 0.1698988\ttotal: 9.49s\tremaining: 24.6s\n",
      "139:\tlearn: 0.1694615\ttotal: 9.56s\tremaining: 24.6s\n",
      "140:\tlearn: 0.1691353\ttotal: 9.65s\tremaining: 24.6s\n",
      "141:\tlearn: 0.1687169\ttotal: 9.73s\tremaining: 24.5s\n",
      "142:\tlearn: 0.1683255\ttotal: 9.81s\tremaining: 24.5s\n",
      "143:\tlearn: 0.1680668\ttotal: 9.87s\tremaining: 24.4s\n",
      "144:\tlearn: 0.1676750\ttotal: 9.93s\tremaining: 24.3s\n",
      "145:\tlearn: 0.1672870\ttotal: 10s\tremaining: 24.3s\n",
      "146:\tlearn: 0.1670444\ttotal: 10.1s\tremaining: 24.2s\n",
      "147:\tlearn: 0.1666770\ttotal: 10.1s\tremaining: 24.1s\n",
      "148:\tlearn: 0.1664023\ttotal: 10.2s\tremaining: 24s\n",
      "149:\tlearn: 0.1660575\ttotal: 10.3s\tremaining: 23.9s\n",
      "150:\tlearn: 0.1656903\ttotal: 10.3s\tremaining: 23.9s\n",
      "151:\tlearn: 0.1653775\ttotal: 10.4s\tremaining: 23.8s\n",
      "152:\tlearn: 0.1651180\ttotal: 10.5s\tremaining: 23.7s\n",
      "153:\tlearn: 0.1648067\ttotal: 10.5s\tremaining: 23.7s\n",
      "154:\tlearn: 0.1645092\ttotal: 10.6s\tremaining: 23.6s\n",
      "155:\tlearn: 0.1642972\ttotal: 10.7s\tremaining: 23.5s\n",
      "156:\tlearn: 0.1639984\ttotal: 10.7s\tremaining: 23.5s\n",
      "157:\tlearn: 0.1637120\ttotal: 10.8s\tremaining: 23.4s\n",
      "158:\tlearn: 0.1634243\ttotal: 10.9s\tremaining: 23.3s\n",
      "159:\tlearn: 0.1631569\ttotal: 10.9s\tremaining: 23.2s\n",
      "160:\tlearn: 0.1629030\ttotal: 11s\tremaining: 23.2s\n",
      "161:\tlearn: 0.1626546\ttotal: 11.1s\tremaining: 23.1s\n",
      "162:\tlearn: 0.1624647\ttotal: 11.1s\tremaining: 23s\n",
      "163:\tlearn: 0.1622162\ttotal: 11.2s\tremaining: 23s\n",
      "164:\tlearn: 0.1619999\ttotal: 11.3s\tremaining: 22.9s\n",
      "165:\tlearn: 0.1617659\ttotal: 11.3s\tremaining: 22.8s\n",
      "166:\tlearn: 0.1615545\ttotal: 11.4s\tremaining: 22.7s\n",
      "167:\tlearn: 0.1613176\ttotal: 11.5s\tremaining: 22.7s\n",
      "168:\tlearn: 0.1611163\ttotal: 11.5s\tremaining: 22.6s\n",
      "169:\tlearn: 0.1609521\ttotal: 11.6s\tremaining: 22.5s\n",
      "170:\tlearn: 0.1607696\ttotal: 11.7s\tremaining: 22.4s\n",
      "171:\tlearn: 0.1605537\ttotal: 11.7s\tremaining: 22.4s\n",
      "172:\tlearn: 0.1603495\ttotal: 11.8s\tremaining: 22.3s\n",
      "173:\tlearn: 0.1602138\ttotal: 11.9s\tremaining: 22.2s\n",
      "174:\tlearn: 0.1600163\ttotal: 11.9s\tremaining: 22.2s\n",
      "175:\tlearn: 0.1598112\ttotal: 12s\tremaining: 22.1s\n",
      "176:\tlearn: 0.1596719\ttotal: 12.1s\tremaining: 22s\n",
      "177:\tlearn: 0.1594923\ttotal: 12.1s\tremaining: 22s\n",
      "178:\tlearn: 0.1593090\ttotal: 12.2s\tremaining: 21.9s\n",
      "179:\tlearn: 0.1591836\ttotal: 12.3s\tremaining: 21.8s\n",
      "180:\tlearn: 0.1590148\ttotal: 12.3s\tremaining: 21.7s\n",
      "181:\tlearn: 0.1588460\ttotal: 12.4s\tremaining: 21.7s\n",
      "182:\tlearn: 0.1586832\ttotal: 12.5s\tremaining: 21.6s\n",
      "183:\tlearn: 0.1585404\ttotal: 12.5s\tremaining: 21.5s\n",
      "184:\tlearn: 0.1583559\ttotal: 12.6s\tremaining: 21.4s\n",
      "185:\tlearn: 0.1581921\ttotal: 12.7s\tremaining: 21.4s\n",
      "186:\tlearn: 0.1580430\ttotal: 12.7s\tremaining: 21.3s\n",
      "187:\tlearn: 0.1578984\ttotal: 12.8s\tremaining: 21.3s\n",
      "188:\tlearn: 0.1577573\ttotal: 12.9s\tremaining: 21.2s\n",
      "189:\tlearn: 0.1576401\ttotal: 12.9s\tremaining: 21.1s\n",
      "190:\tlearn: 0.1574913\ttotal: 13s\tremaining: 21s\n",
      "191:\tlearn: 0.1573312\ttotal: 13.1s\tremaining: 21s\n",
      "192:\tlearn: 0.1571851\ttotal: 13.2s\tremaining: 20.9s\n",
      "193:\tlearn: 0.1570595\ttotal: 13.2s\tremaining: 20.9s\n",
      "194:\tlearn: 0.1569150\ttotal: 13.3s\tremaining: 20.8s\n",
      "195:\tlearn: 0.1567758\ttotal: 13.4s\tremaining: 20.7s\n",
      "196:\tlearn: 0.1566433\ttotal: 13.4s\tremaining: 20.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197:\tlearn: 0.1565132\ttotal: 13.5s\tremaining: 20.6s\n",
      "198:\tlearn: 0.1563703\ttotal: 13.6s\tremaining: 20.5s\n",
      "199:\tlearn: 0.1562502\ttotal: 13.6s\tremaining: 20.5s\n",
      "200:\tlearn: 0.1561410\ttotal: 13.7s\tremaining: 20.4s\n",
      "201:\tlearn: 0.1560232\ttotal: 13.8s\tremaining: 20.3s\n",
      "202:\tlearn: 0.1559213\ttotal: 13.8s\tremaining: 20.3s\n",
      "203:\tlearn: 0.1558051\ttotal: 13.9s\tremaining: 20.2s\n",
      "204:\tlearn: 0.1557246\ttotal: 14s\tremaining: 20.1s\n",
      "205:\tlearn: 0.1556157\ttotal: 14s\tremaining: 20s\n",
      "206:\tlearn: 0.1555086\ttotal: 14.1s\tremaining: 19.9s\n",
      "207:\tlearn: 0.1554122\ttotal: 14.1s\tremaining: 19.9s\n",
      "208:\tlearn: 0.1553056\ttotal: 14.2s\tremaining: 19.8s\n",
      "209:\tlearn: 0.1551800\ttotal: 14.3s\tremaining: 19.7s\n",
      "210:\tlearn: 0.1550829\ttotal: 14.3s\tremaining: 19.7s\n",
      "211:\tlearn: 0.1549822\ttotal: 14.4s\tremaining: 19.6s\n",
      "212:\tlearn: 0.1548836\ttotal: 14.5s\tremaining: 19.5s\n",
      "213:\tlearn: 0.1547920\ttotal: 14.6s\tremaining: 19.5s\n",
      "214:\tlearn: 0.1547164\ttotal: 14.6s\tremaining: 19.4s\n",
      "215:\tlearn: 0.1546467\ttotal: 14.7s\tremaining: 19.3s\n",
      "216:\tlearn: 0.1545526\ttotal: 14.7s\tremaining: 19.2s\n",
      "217:\tlearn: 0.1544623\ttotal: 14.8s\tremaining: 19.2s\n",
      "218:\tlearn: 0.1543624\ttotal: 14.9s\tremaining: 19.1s\n",
      "219:\tlearn: 0.1542868\ttotal: 15s\tremaining: 19s\n",
      "220:\tlearn: 0.1541898\ttotal: 15s\tremaining: 19s\n",
      "221:\tlearn: 0.1541156\ttotal: 15.1s\tremaining: 18.9s\n",
      "222:\tlearn: 0.1540340\ttotal: 15.2s\tremaining: 18.8s\n",
      "223:\tlearn: 0.1539558\ttotal: 15.2s\tremaining: 18.8s\n",
      "224:\tlearn: 0.1538684\ttotal: 15.3s\tremaining: 18.7s\n",
      "225:\tlearn: 0.1537815\ttotal: 15.3s\tremaining: 18.6s\n",
      "226:\tlearn: 0.1537253\ttotal: 15.4s\tremaining: 18.5s\n",
      "227:\tlearn: 0.1536490\ttotal: 15.5s\tremaining: 18.5s\n",
      "228:\tlearn: 0.1535679\ttotal: 15.5s\tremaining: 18.4s\n",
      "229:\tlearn: 0.1534901\ttotal: 15.6s\tremaining: 18.3s\n",
      "230:\tlearn: 0.1534181\ttotal: 15.7s\tremaining: 18.2s\n",
      "231:\tlearn: 0.1533613\ttotal: 15.7s\tremaining: 18.2s\n",
      "232:\tlearn: 0.1532775\ttotal: 15.8s\tremaining: 18.1s\n",
      "233:\tlearn: 0.1531920\ttotal: 15.9s\tremaining: 18s\n",
      "234:\tlearn: 0.1531215\ttotal: 15.9s\tremaining: 18s\n",
      "235:\tlearn: 0.1530656\ttotal: 16s\tremaining: 17.9s\n",
      "236:\tlearn: 0.1530123\ttotal: 16s\tremaining: 17.8s\n",
      "237:\tlearn: 0.1529319\ttotal: 16.1s\tremaining: 17.7s\n",
      "238:\tlearn: 0.1528587\ttotal: 16.2s\tremaining: 17.7s\n",
      "239:\tlearn: 0.1527890\ttotal: 16.3s\tremaining: 17.6s\n",
      "240:\tlearn: 0.1527214\ttotal: 16.3s\tremaining: 17.5s\n",
      "241:\tlearn: 0.1526567\ttotal: 16.4s\tremaining: 17.5s\n",
      "242:\tlearn: 0.1525913\ttotal: 16.4s\tremaining: 17.4s\n",
      "243:\tlearn: 0.1525166\ttotal: 16.5s\tremaining: 17.3s\n",
      "244:\tlearn: 0.1524480\ttotal: 16.6s\tremaining: 17.3s\n",
      "245:\tlearn: 0.1523917\ttotal: 16.6s\tremaining: 17.2s\n",
      "246:\tlearn: 0.1523276\ttotal: 16.7s\tremaining: 17.1s\n",
      "247:\tlearn: 0.1522695\ttotal: 16.8s\tremaining: 17s\n",
      "248:\tlearn: 0.1522161\ttotal: 16.8s\tremaining: 17s\n",
      "249:\tlearn: 0.1521662\ttotal: 16.9s\tremaining: 16.9s\n",
      "250:\tlearn: 0.1521108\ttotal: 16.9s\tremaining: 16.8s\n",
      "251:\tlearn: 0.1520522\ttotal: 17s\tremaining: 16.7s\n",
      "252:\tlearn: 0.1520031\ttotal: 17.1s\tremaining: 16.7s\n",
      "253:\tlearn: 0.1519421\ttotal: 17.2s\tremaining: 16.6s\n",
      "254:\tlearn: 0.1518901\ttotal: 17.2s\tremaining: 16.6s\n",
      "255:\tlearn: 0.1518442\ttotal: 17.3s\tremaining: 16.5s\n",
      "256:\tlearn: 0.1517792\ttotal: 17.3s\tremaining: 16.4s\n",
      "257:\tlearn: 0.1517285\ttotal: 17.4s\tremaining: 16.4s\n",
      "258:\tlearn: 0.1516874\ttotal: 17.5s\tremaining: 16.3s\n",
      "259:\tlearn: 0.1516325\ttotal: 17.6s\tremaining: 16.2s\n",
      "260:\tlearn: 0.1515999\ttotal: 17.6s\tremaining: 16.1s\n",
      "261:\tlearn: 0.1515568\ttotal: 17.7s\tremaining: 16s\n",
      "262:\tlearn: 0.1515069\ttotal: 17.7s\tremaining: 16s\n",
      "263:\tlearn: 0.1514542\ttotal: 17.8s\tremaining: 15.9s\n",
      "264:\tlearn: 0.1514130\ttotal: 17.9s\tremaining: 15.8s\n",
      "265:\tlearn: 0.1513524\ttotal: 17.9s\tremaining: 15.8s\n",
      "266:\tlearn: 0.1513122\ttotal: 18s\tremaining: 15.7s\n",
      "267:\tlearn: 0.1512612\ttotal: 18.1s\tremaining: 15.6s\n",
      "268:\tlearn: 0.1512190\ttotal: 18.1s\tremaining: 15.6s\n",
      "269:\tlearn: 0.1511734\ttotal: 18.2s\tremaining: 15.5s\n",
      "270:\tlearn: 0.1511369\ttotal: 18.3s\tremaining: 15.4s\n",
      "271:\tlearn: 0.1510941\ttotal: 18.3s\tremaining: 15.4s\n",
      "272:\tlearn: 0.1510373\ttotal: 18.4s\tremaining: 15.3s\n",
      "273:\tlearn: 0.1509928\ttotal: 18.5s\tremaining: 15.2s\n",
      "274:\tlearn: 0.1509470\ttotal: 18.5s\tremaining: 15.2s\n",
      "275:\tlearn: 0.1509041\ttotal: 18.6s\tremaining: 15.1s\n",
      "276:\tlearn: 0.1508610\ttotal: 18.6s\tremaining: 15s\n",
      "277:\tlearn: 0.1508204\ttotal: 18.7s\tremaining: 14.9s\n",
      "278:\tlearn: 0.1507729\ttotal: 18.8s\tremaining: 14.9s\n",
      "279:\tlearn: 0.1507353\ttotal: 18.8s\tremaining: 14.8s\n",
      "280:\tlearn: 0.1507063\ttotal: 18.9s\tremaining: 14.7s\n",
      "281:\tlearn: 0.1506663\ttotal: 19s\tremaining: 14.7s\n",
      "282:\tlearn: 0.1506270\ttotal: 19s\tremaining: 14.6s\n",
      "283:\tlearn: 0.1505768\ttotal: 19.1s\tremaining: 14.5s\n",
      "284:\tlearn: 0.1505477\ttotal: 19.2s\tremaining: 14.5s\n",
      "285:\tlearn: 0.1505066\ttotal: 19.2s\tremaining: 14.4s\n",
      "286:\tlearn: 0.1504710\ttotal: 19.3s\tremaining: 14.3s\n",
      "287:\tlearn: 0.1504419\ttotal: 19.4s\tremaining: 14.3s\n",
      "288:\tlearn: 0.1504145\ttotal: 19.4s\tremaining: 14.2s\n",
      "289:\tlearn: 0.1503839\ttotal: 19.5s\tremaining: 14.1s\n",
      "290:\tlearn: 0.1503554\ttotal: 19.6s\tremaining: 14s\n",
      "291:\tlearn: 0.1503201\ttotal: 19.6s\tremaining: 14s\n",
      "292:\tlearn: 0.1502897\ttotal: 19.7s\tremaining: 13.9s\n",
      "293:\tlearn: 0.1502536\ttotal: 19.8s\tremaining: 13.8s\n",
      "294:\tlearn: 0.1502147\ttotal: 19.8s\tremaining: 13.8s\n",
      "295:\tlearn: 0.1501856\ttotal: 19.9s\tremaining: 13.7s\n",
      "296:\tlearn: 0.1501560\ttotal: 20s\tremaining: 13.6s\n",
      "297:\tlearn: 0.1501142\ttotal: 20s\tremaining: 13.6s\n",
      "298:\tlearn: 0.1500667\ttotal: 20.1s\tremaining: 13.5s\n",
      "299:\tlearn: 0.1500240\ttotal: 20.2s\tremaining: 13.4s\n",
      "300:\tlearn: 0.1499939\ttotal: 20.2s\tremaining: 13.4s\n",
      "301:\tlearn: 0.1499619\ttotal: 20.3s\tremaining: 13.3s\n",
      "302:\tlearn: 0.1499309\ttotal: 20.4s\tremaining: 13.2s\n",
      "303:\tlearn: 0.1499036\ttotal: 20.4s\tremaining: 13.2s\n",
      "304:\tlearn: 0.1498688\ttotal: 20.5s\tremaining: 13.1s\n",
      "305:\tlearn: 0.1498315\ttotal: 20.5s\tremaining: 13s\n",
      "306:\tlearn: 0.1498037\ttotal: 20.6s\tremaining: 13s\n",
      "307:\tlearn: 0.1497709\ttotal: 20.7s\tremaining: 12.9s\n",
      "308:\tlearn: 0.1497512\ttotal: 20.7s\tremaining: 12.8s\n",
      "309:\tlearn: 0.1497129\ttotal: 20.8s\tremaining: 12.8s\n",
      "310:\tlearn: 0.1496791\ttotal: 20.9s\tremaining: 12.7s\n",
      "311:\tlearn: 0.1496477\ttotal: 20.9s\tremaining: 12.6s\n",
      "312:\tlearn: 0.1496193\ttotal: 21s\tremaining: 12.5s\n",
      "313:\tlearn: 0.1495898\ttotal: 21.1s\tremaining: 12.5s\n",
      "314:\tlearn: 0.1495597\ttotal: 21.1s\tremaining: 12.4s\n",
      "315:\tlearn: 0.1495372\ttotal: 21.2s\tremaining: 12.3s\n",
      "316:\tlearn: 0.1495133\ttotal: 21.2s\tremaining: 12.3s\n",
      "317:\tlearn: 0.1494833\ttotal: 21.3s\tremaining: 12.2s\n",
      "318:\tlearn: 0.1494538\ttotal: 21.4s\tremaining: 12.1s\n",
      "319:\tlearn: 0.1494269\ttotal: 21.5s\tremaining: 12.1s\n",
      "320:\tlearn: 0.1493877\ttotal: 21.5s\tremaining: 12s\n",
      "321:\tlearn: 0.1493619\ttotal: 21.6s\tremaining: 11.9s\n",
      "322:\tlearn: 0.1493384\ttotal: 21.6s\tremaining: 11.9s\n",
      "323:\tlearn: 0.1493076\ttotal: 21.7s\tremaining: 11.8s\n",
      "324:\tlearn: 0.1492694\ttotal: 21.8s\tremaining: 11.7s\n",
      "325:\tlearn: 0.1492442\ttotal: 21.8s\tremaining: 11.7s\n",
      "326:\tlearn: 0.1492171\ttotal: 21.9s\tremaining: 11.6s\n",
      "327:\tlearn: 0.1491884\ttotal: 22s\tremaining: 11.5s\n",
      "328:\tlearn: 0.1491592\ttotal: 22s\tremaining: 11.4s\n",
      "329:\tlearn: 0.1491304\ttotal: 22.1s\tremaining: 11.4s\n",
      "330:\tlearn: 0.1491134\ttotal: 22.1s\tremaining: 11.3s\n",
      "331:\tlearn: 0.1490888\ttotal: 22.2s\tremaining: 11.2s\n",
      "332:\tlearn: 0.1490512\ttotal: 22.3s\tremaining: 11.2s\n",
      "333:\tlearn: 0.1490290\ttotal: 22.3s\tremaining: 11.1s\n",
      "334:\tlearn: 0.1490096\ttotal: 22.4s\tremaining: 11s\n",
      "335:\tlearn: 0.1489833\ttotal: 22.5s\tremaining: 11s\n",
      "336:\tlearn: 0.1489600\ttotal: 22.5s\tremaining: 10.9s\n",
      "337:\tlearn: 0.1489287\ttotal: 22.6s\tremaining: 10.8s\n",
      "338:\tlearn: 0.1489091\ttotal: 22.6s\tremaining: 10.8s\n",
      "339:\tlearn: 0.1488899\ttotal: 22.7s\tremaining: 10.7s\n",
      "340:\tlearn: 0.1488576\ttotal: 22.8s\tremaining: 10.6s\n",
      "341:\tlearn: 0.1488375\ttotal: 22.8s\tremaining: 10.5s\n",
      "342:\tlearn: 0.1488015\ttotal: 22.9s\tremaining: 10.5s\n",
      "343:\tlearn: 0.1487813\ttotal: 23s\tremaining: 10.4s\n",
      "344:\tlearn: 0.1487587\ttotal: 23s\tremaining: 10.3s\n",
      "345:\tlearn: 0.1487307\ttotal: 23.1s\tremaining: 10.3s\n",
      "346:\tlearn: 0.1487038\ttotal: 23.2s\tremaining: 10.2s\n",
      "347:\tlearn: 0.1486768\ttotal: 23.2s\tremaining: 10.1s\n",
      "348:\tlearn: 0.1486534\ttotal: 23.3s\tremaining: 10.1s\n",
      "349:\tlearn: 0.1486354\ttotal: 23.3s\tremaining: 10s\n",
      "350:\tlearn: 0.1486129\ttotal: 23.4s\tremaining: 9.94s\n",
      "351:\tlearn: 0.1485895\ttotal: 23.5s\tremaining: 9.87s\n",
      "352:\tlearn: 0.1485651\ttotal: 23.5s\tremaining: 9.8s\n",
      "353:\tlearn: 0.1485364\ttotal: 23.6s\tremaining: 9.73s\n",
      "354:\tlearn: 0.1485141\ttotal: 23.7s\tremaining: 9.66s\n",
      "355:\tlearn: 0.1484935\ttotal: 23.7s\tremaining: 9.6s\n",
      "356:\tlearn: 0.1484710\ttotal: 23.8s\tremaining: 9.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357:\tlearn: 0.1484493\ttotal: 23.9s\tremaining: 9.46s\n",
      "358:\tlearn: 0.1484275\ttotal: 23.9s\tremaining: 9.4s\n",
      "359:\tlearn: 0.1484021\ttotal: 24s\tremaining: 9.33s\n",
      "360:\tlearn: 0.1483848\ttotal: 24.1s\tremaining: 9.27s\n",
      "361:\tlearn: 0.1483542\ttotal: 24.1s\tremaining: 9.2s\n",
      "362:\tlearn: 0.1483369\ttotal: 24.2s\tremaining: 9.13s\n",
      "363:\tlearn: 0.1483127\ttotal: 24.2s\tremaining: 9.05s\n",
      "364:\tlearn: 0.1482893\ttotal: 24.3s\tremaining: 8.99s\n",
      "365:\tlearn: 0.1482626\ttotal: 24.4s\tremaining: 8.92s\n",
      "366:\tlearn: 0.1482433\ttotal: 24.4s\tremaining: 8.85s\n",
      "367:\tlearn: 0.1482255\ttotal: 24.5s\tremaining: 8.78s\n",
      "368:\tlearn: 0.1482087\ttotal: 24.5s\tremaining: 8.71s\n",
      "369:\tlearn: 0.1481935\ttotal: 24.6s\tremaining: 8.64s\n",
      "370:\tlearn: 0.1481697\ttotal: 24.7s\tremaining: 8.57s\n",
      "371:\tlearn: 0.1481516\ttotal: 24.7s\tremaining: 8.5s\n",
      "372:\tlearn: 0.1481308\ttotal: 24.8s\tremaining: 8.44s\n",
      "373:\tlearn: 0.1481040\ttotal: 24.8s\tremaining: 8.37s\n",
      "374:\tlearn: 0.1480799\ttotal: 24.9s\tremaining: 8.31s\n",
      "375:\tlearn: 0.1480633\ttotal: 25s\tremaining: 8.24s\n",
      "376:\tlearn: 0.1480459\ttotal: 25s\tremaining: 8.16s\n",
      "377:\tlearn: 0.1480278\ttotal: 25.1s\tremaining: 8.1s\n",
      "378:\tlearn: 0.1480077\ttotal: 25.2s\tremaining: 8.03s\n",
      "379:\tlearn: 0.1479913\ttotal: 25.2s\tremaining: 7.96s\n",
      "380:\tlearn: 0.1479643\ttotal: 25.3s\tremaining: 7.89s\n",
      "381:\tlearn: 0.1479455\ttotal: 25.3s\tremaining: 7.83s\n",
      "382:\tlearn: 0.1479297\ttotal: 25.4s\tremaining: 7.76s\n",
      "383:\tlearn: 0.1479109\ttotal: 25.5s\tremaining: 7.7s\n",
      "384:\tlearn: 0.1478855\ttotal: 25.5s\tremaining: 7.63s\n",
      "385:\tlearn: 0.1478718\ttotal: 25.6s\tremaining: 7.56s\n",
      "386:\tlearn: 0.1478542\ttotal: 25.7s\tremaining: 7.5s\n",
      "387:\tlearn: 0.1478295\ttotal: 25.7s\tremaining: 7.43s\n",
      "388:\tlearn: 0.1478092\ttotal: 25.8s\tremaining: 7.36s\n",
      "389:\tlearn: 0.1477893\ttotal: 25.9s\tremaining: 7.29s\n",
      "390:\tlearn: 0.1477638\ttotal: 25.9s\tremaining: 7.22s\n",
      "391:\tlearn: 0.1477406\ttotal: 26s\tremaining: 7.16s\n",
      "392:\tlearn: 0.1477170\ttotal: 26s\tremaining: 7.09s\n",
      "393:\tlearn: 0.1476993\ttotal: 26.1s\tremaining: 7.02s\n",
      "394:\tlearn: 0.1476757\ttotal: 26.2s\tremaining: 6.96s\n",
      "395:\tlearn: 0.1476631\ttotal: 26.2s\tremaining: 6.89s\n",
      "396:\tlearn: 0.1476369\ttotal: 26.3s\tremaining: 6.82s\n",
      "397:\tlearn: 0.1476183\ttotal: 26.4s\tremaining: 6.75s\n",
      "398:\tlearn: 0.1475999\ttotal: 26.4s\tremaining: 6.69s\n",
      "399:\tlearn: 0.1475818\ttotal: 26.5s\tremaining: 6.62s\n",
      "400:\tlearn: 0.1475679\ttotal: 26.5s\tremaining: 6.55s\n",
      "401:\tlearn: 0.1475488\ttotal: 26.6s\tremaining: 6.48s\n",
      "402:\tlearn: 0.1475347\ttotal: 26.7s\tremaining: 6.42s\n",
      "403:\tlearn: 0.1475215\ttotal: 26.7s\tremaining: 6.35s\n",
      "404:\tlearn: 0.1475092\ttotal: 26.8s\tremaining: 6.28s\n",
      "405:\tlearn: 0.1474935\ttotal: 26.8s\tremaining: 6.22s\n",
      "406:\tlearn: 0.1474792\ttotal: 26.9s\tremaining: 6.15s\n",
      "407:\tlearn: 0.1474587\ttotal: 27s\tremaining: 6.08s\n",
      "408:\tlearn: 0.1474387\ttotal: 27s\tremaining: 6.01s\n",
      "409:\tlearn: 0.1474212\ttotal: 27.1s\tremaining: 5.95s\n",
      "410:\tlearn: 0.1474064\ttotal: 27.2s\tremaining: 5.88s\n",
      "411:\tlearn: 0.1473928\ttotal: 27.2s\tremaining: 5.81s\n",
      "412:\tlearn: 0.1473761\ttotal: 27.3s\tremaining: 5.74s\n",
      "413:\tlearn: 0.1473613\ttotal: 27.3s\tremaining: 5.68s\n",
      "414:\tlearn: 0.1473352\ttotal: 27.4s\tremaining: 5.61s\n",
      "415:\tlearn: 0.1473223\ttotal: 27.5s\tremaining: 5.54s\n",
      "416:\tlearn: 0.1473080\ttotal: 27.5s\tremaining: 5.48s\n",
      "417:\tlearn: 0.1472931\ttotal: 27.6s\tremaining: 5.41s\n",
      "418:\tlearn: 0.1472728\ttotal: 27.7s\tremaining: 5.35s\n",
      "419:\tlearn: 0.1472493\ttotal: 27.7s\tremaining: 5.28s\n",
      "420:\tlearn: 0.1472298\ttotal: 27.8s\tremaining: 5.21s\n",
      "421:\tlearn: 0.1472075\ttotal: 27.8s\tremaining: 5.15s\n",
      "422:\tlearn: 0.1471920\ttotal: 27.9s\tremaining: 5.08s\n",
      "423:\tlearn: 0.1471787\ttotal: 28s\tremaining: 5.02s\n",
      "424:\tlearn: 0.1471624\ttotal: 28.1s\tremaining: 4.95s\n",
      "425:\tlearn: 0.1471491\ttotal: 28.1s\tremaining: 4.88s\n",
      "426:\tlearn: 0.1471302\ttotal: 28.2s\tremaining: 4.82s\n",
      "427:\tlearn: 0.1471153\ttotal: 28.2s\tremaining: 4.75s\n",
      "428:\tlearn: 0.1470961\ttotal: 28.3s\tremaining: 4.69s\n",
      "429:\tlearn: 0.1470796\ttotal: 28.4s\tremaining: 4.62s\n",
      "430:\tlearn: 0.1470662\ttotal: 28.4s\tremaining: 4.55s\n",
      "431:\tlearn: 0.1470527\ttotal: 28.5s\tremaining: 4.48s\n",
      "432:\tlearn: 0.1470384\ttotal: 28.6s\tremaining: 4.42s\n",
      "433:\tlearn: 0.1470244\ttotal: 28.6s\tremaining: 4.35s\n",
      "434:\tlearn: 0.1470103\ttotal: 28.7s\tremaining: 4.28s\n",
      "435:\tlearn: 0.1469972\ttotal: 28.7s\tremaining: 4.22s\n",
      "436:\tlearn: 0.1469794\ttotal: 28.8s\tremaining: 4.15s\n",
      "437:\tlearn: 0.1469600\ttotal: 28.9s\tremaining: 4.08s\n",
      "438:\tlearn: 0.1469468\ttotal: 28.9s\tremaining: 4.02s\n",
      "439:\tlearn: 0.1469351\ttotal: 29s\tremaining: 3.95s\n",
      "440:\tlearn: 0.1469233\ttotal: 29s\tremaining: 3.88s\n",
      "441:\tlearn: 0.1469078\ttotal: 29.1s\tremaining: 3.82s\n",
      "442:\tlearn: 0.1468952\ttotal: 29.2s\tremaining: 3.75s\n",
      "443:\tlearn: 0.1468839\ttotal: 29.2s\tremaining: 3.69s\n",
      "444:\tlearn: 0.1468679\ttotal: 29.3s\tremaining: 3.62s\n",
      "445:\tlearn: 0.1468478\ttotal: 29.4s\tremaining: 3.56s\n",
      "446:\tlearn: 0.1468342\ttotal: 29.4s\tremaining: 3.49s\n",
      "447:\tlearn: 0.1468208\ttotal: 29.5s\tremaining: 3.42s\n",
      "448:\tlearn: 0.1468069\ttotal: 29.5s\tremaining: 3.35s\n",
      "449:\tlearn: 0.1467904\ttotal: 29.6s\tremaining: 3.29s\n",
      "450:\tlearn: 0.1467736\ttotal: 29.7s\tremaining: 3.22s\n",
      "451:\tlearn: 0.1467583\ttotal: 29.7s\tremaining: 3.16s\n",
      "452:\tlearn: 0.1467476\ttotal: 29.8s\tremaining: 3.09s\n",
      "453:\tlearn: 0.1467357\ttotal: 29.8s\tremaining: 3.02s\n",
      "454:\tlearn: 0.1467229\ttotal: 29.9s\tremaining: 2.96s\n",
      "455:\tlearn: 0.1467107\ttotal: 29.9s\tremaining: 2.89s\n",
      "456:\tlearn: 0.1466934\ttotal: 30s\tremaining: 2.82s\n",
      "457:\tlearn: 0.1466797\ttotal: 30.1s\tremaining: 2.76s\n",
      "458:\tlearn: 0.1466645\ttotal: 30.1s\tremaining: 2.69s\n",
      "459:\tlearn: 0.1466530\ttotal: 30.2s\tremaining: 2.63s\n",
      "460:\tlearn: 0.1466414\ttotal: 30.3s\tremaining: 2.56s\n",
      "461:\tlearn: 0.1466287\ttotal: 30.3s\tremaining: 2.49s\n",
      "462:\tlearn: 0.1466168\ttotal: 30.4s\tremaining: 2.43s\n",
      "463:\tlearn: 0.1466065\ttotal: 30.4s\tremaining: 2.36s\n",
      "464:\tlearn: 0.1465913\ttotal: 30.5s\tremaining: 2.29s\n",
      "465:\tlearn: 0.1465687\ttotal: 30.5s\tremaining: 2.23s\n",
      "466:\tlearn: 0.1465561\ttotal: 30.6s\tremaining: 2.16s\n",
      "467:\tlearn: 0.1465430\ttotal: 30.7s\tremaining: 2.1s\n",
      "468:\tlearn: 0.1465319\ttotal: 30.7s\tremaining: 2.03s\n",
      "469:\tlearn: 0.1465187\ttotal: 30.8s\tremaining: 1.97s\n",
      "470:\tlearn: 0.1464970\ttotal: 30.9s\tremaining: 1.9s\n",
      "471:\tlearn: 0.1464845\ttotal: 30.9s\tremaining: 1.83s\n",
      "472:\tlearn: 0.1464714\ttotal: 31s\tremaining: 1.77s\n",
      "473:\tlearn: 0.1464569\ttotal: 31.1s\tremaining: 1.7s\n",
      "474:\tlearn: 0.1464390\ttotal: 31.1s\tremaining: 1.64s\n",
      "475:\tlearn: 0.1464203\ttotal: 31.2s\tremaining: 1.57s\n",
      "476:\tlearn: 0.1464106\ttotal: 31.2s\tremaining: 1.5s\n",
      "477:\tlearn: 0.1464000\ttotal: 31.3s\tremaining: 1.44s\n",
      "478:\tlearn: 0.1463870\ttotal: 31.4s\tremaining: 1.38s\n",
      "479:\tlearn: 0.1463771\ttotal: 31.4s\tremaining: 1.31s\n",
      "480:\tlearn: 0.1463634\ttotal: 31.5s\tremaining: 1.24s\n",
      "481:\tlearn: 0.1463474\ttotal: 31.6s\tremaining: 1.18s\n",
      "482:\tlearn: 0.1463290\ttotal: 31.6s\tremaining: 1.11s\n",
      "483:\tlearn: 0.1463190\ttotal: 31.6s\tremaining: 1.05s\n",
      "484:\tlearn: 0.1463031\ttotal: 31.7s\tremaining: 981ms\n",
      "485:\tlearn: 0.1462890\ttotal: 31.8s\tremaining: 915ms\n",
      "486:\tlearn: 0.1462797\ttotal: 31.8s\tremaining: 849ms\n",
      "487:\tlearn: 0.1462683\ttotal: 31.9s\tremaining: 784ms\n",
      "488:\tlearn: 0.1462549\ttotal: 32s\tremaining: 719ms\n",
      "489:\tlearn: 0.1462381\ttotal: 32s\tremaining: 653ms\n",
      "490:\tlearn: 0.1462292\ttotal: 32.1s\tremaining: 588ms\n",
      "491:\tlearn: 0.1462173\ttotal: 32.1s\tremaining: 522ms\n",
      "492:\tlearn: 0.1462030\ttotal: 32.2s\tremaining: 457ms\n",
      "493:\tlearn: 0.1461856\ttotal: 32.3s\tremaining: 392ms\n",
      "494:\tlearn: 0.1461761\ttotal: 32.3s\tremaining: 326ms\n",
      "495:\tlearn: 0.1461667\ttotal: 32.4s\tremaining: 261ms\n",
      "496:\tlearn: 0.1461521\ttotal: 32.4s\tremaining: 196ms\n",
      "497:\tlearn: 0.1461416\ttotal: 32.5s\tremaining: 130ms\n",
      "498:\tlearn: 0.1461189\ttotal: 32.5s\tremaining: 65.2ms\n",
      "499:\tlearn: 0.1461073\ttotal: 32.6s\tremaining: 0us\n",
      "[CV]  learning_rate=0.01, l2_leaf_reg=1, iterations=500, depth=5, total=  33.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.1664465\ttotal: 112ms\tremaining: 22.2s\n",
      "1:\tlearn: 0.1566221\ttotal: 217ms\tremaining: 21.5s\n",
      "2:\tlearn: 0.1538535\ttotal: 300ms\tremaining: 19.7s\n",
      "3:\tlearn: 0.1515280\ttotal: 392ms\tremaining: 19.2s\n",
      "4:\tlearn: 0.1496570\ttotal: 475ms\tremaining: 18.5s\n",
      "5:\tlearn: 0.1487204\ttotal: 548ms\tremaining: 17.7s\n",
      "6:\tlearn: 0.1479098\ttotal: 626ms\tremaining: 17.3s\n",
      "7:\tlearn: 0.1470989\ttotal: 704ms\tremaining: 16.9s\n",
      "8:\tlearn: 0.1465559\ttotal: 801ms\tremaining: 17s\n",
      "9:\tlearn: 0.1459240\ttotal: 882ms\tremaining: 16.8s\n",
      "10:\tlearn: 0.1453745\ttotal: 968ms\tremaining: 16.6s\n",
      "11:\tlearn: 0.1449820\ttotal: 1.04s\tremaining: 16.3s\n",
      "12:\tlearn: 0.1447006\ttotal: 1.11s\tremaining: 16s\n",
      "13:\tlearn: 0.1443757\ttotal: 1.21s\tremaining: 16s\n",
      "14:\tlearn: 0.1439942\ttotal: 1.31s\tremaining: 16.1s\n",
      "15:\tlearn: 0.1436677\ttotal: 1.38s\tremaining: 15.9s\n",
      "16:\tlearn: 0.1433146\ttotal: 1.48s\tremaining: 15.9s\n",
      "17:\tlearn: 0.1429199\ttotal: 1.56s\tremaining: 15.8s\n",
      "18:\tlearn: 0.1426795\ttotal: 1.64s\tremaining: 15.6s\n",
      "19:\tlearn: 0.1424095\ttotal: 1.73s\tremaining: 15.6s\n",
      "20:\tlearn: 0.1421610\ttotal: 1.83s\tremaining: 15.6s\n",
      "21:\tlearn: 0.1419197\ttotal: 1.94s\tremaining: 15.7s\n",
      "22:\tlearn: 0.1417277\ttotal: 2.04s\tremaining: 15.7s\n",
      "23:\tlearn: 0.1415218\ttotal: 2.14s\tremaining: 15.7s\n",
      "24:\tlearn: 0.1412538\ttotal: 2.26s\tremaining: 15.8s\n",
      "25:\tlearn: 0.1409784\ttotal: 2.37s\tremaining: 15.9s\n",
      "26:\tlearn: 0.1408364\ttotal: 2.48s\tremaining: 15.9s\n",
      "27:\tlearn: 0.1405857\ttotal: 2.62s\tremaining: 16.1s\n",
      "28:\tlearn: 0.1404826\ttotal: 2.73s\tremaining: 16.1s\n",
      "29:\tlearn: 0.1403483\ttotal: 2.85s\tremaining: 16.1s\n",
      "30:\tlearn: 0.1401886\ttotal: 2.98s\tremaining: 16.2s\n",
      "31:\tlearn: 0.1400216\ttotal: 3.1s\tremaining: 16.3s\n",
      "32:\tlearn: 0.1398791\ttotal: 3.21s\tremaining: 16.2s\n",
      "33:\tlearn: 0.1397116\ttotal: 3.32s\tremaining: 16.2s\n",
      "34:\tlearn: 0.1394521\ttotal: 3.42s\tremaining: 16.1s\n",
      "35:\tlearn: 0.1392753\ttotal: 3.51s\tremaining: 16s\n",
      "36:\tlearn: 0.1391251\ttotal: 3.63s\tremaining: 16s\n",
      "37:\tlearn: 0.1390032\ttotal: 3.74s\tremaining: 15.9s\n",
      "38:\tlearn: 0.1386849\ttotal: 3.83s\tremaining: 15.8s\n",
      "39:\tlearn: 0.1385637\ttotal: 3.91s\tremaining: 15.7s\n",
      "40:\tlearn: 0.1383969\ttotal: 4s\tremaining: 15.5s\n",
      "41:\tlearn: 0.1382893\ttotal: 4.1s\tremaining: 15.4s\n",
      "42:\tlearn: 0.1381330\ttotal: 4.17s\tremaining: 15.2s\n",
      "43:\tlearn: 0.1379891\ttotal: 4.24s\tremaining: 15s\n",
      "44:\tlearn: 0.1378706\ttotal: 4.36s\tremaining: 15s\n",
      "45:\tlearn: 0.1377633\ttotal: 4.46s\tremaining: 14.9s\n",
      "46:\tlearn: 0.1376300\ttotal: 4.55s\tremaining: 14.8s\n",
      "47:\tlearn: 0.1375094\ttotal: 4.65s\tremaining: 14.7s\n",
      "48:\tlearn: 0.1373695\ttotal: 4.73s\tremaining: 14.6s\n",
      "49:\tlearn: 0.1372761\ttotal: 4.83s\tremaining: 14.5s\n",
      "50:\tlearn: 0.1371684\ttotal: 4.91s\tremaining: 14.3s\n",
      "51:\tlearn: 0.1370837\ttotal: 4.98s\tremaining: 14.2s\n",
      "52:\tlearn: 0.1369860\ttotal: 5.08s\tremaining: 14.1s\n",
      "53:\tlearn: 0.1368504\ttotal: 5.16s\tremaining: 13.9s\n",
      "54:\tlearn: 0.1367412\ttotal: 5.23s\tremaining: 13.8s\n",
      "55:\tlearn: 0.1366101\ttotal: 5.29s\tremaining: 13.6s\n",
      "56:\tlearn: 0.1365055\ttotal: 5.38s\tremaining: 13.5s\n",
      "57:\tlearn: 0.1363640\ttotal: 5.46s\tremaining: 13.4s\n",
      "58:\tlearn: 0.1362425\ttotal: 5.54s\tremaining: 13.2s\n",
      "59:\tlearn: 0.1361014\ttotal: 5.64s\tremaining: 13.2s\n",
      "60:\tlearn: 0.1359995\ttotal: 5.74s\tremaining: 13.1s\n",
      "61:\tlearn: 0.1358946\ttotal: 5.81s\tremaining: 12.9s\n",
      "62:\tlearn: 0.1357666\ttotal: 5.89s\tremaining: 12.8s\n",
      "63:\tlearn: 0.1356809\ttotal: 5.97s\tremaining: 12.7s\n",
      "64:\tlearn: 0.1355565\ttotal: 6.07s\tremaining: 12.6s\n",
      "65:\tlearn: 0.1354540\ttotal: 6.15s\tremaining: 12.5s\n",
      "66:\tlearn: 0.1353588\ttotal: 6.22s\tremaining: 12.4s\n",
      "67:\tlearn: 0.1352604\ttotal: 6.29s\tremaining: 12.2s\n",
      "68:\tlearn: 0.1351878\ttotal: 6.38s\tremaining: 12.1s\n",
      "69:\tlearn: 0.1351080\ttotal: 6.46s\tremaining: 12s\n",
      "70:\tlearn: 0.1350063\ttotal: 6.53s\tremaining: 11.9s\n",
      "71:\tlearn: 0.1348871\ttotal: 6.6s\tremaining: 11.7s\n",
      "72:\tlearn: 0.1347826\ttotal: 6.68s\tremaining: 11.6s\n",
      "73:\tlearn: 0.1346805\ttotal: 6.77s\tremaining: 11.5s\n",
      "74:\tlearn: 0.1345855\ttotal: 6.85s\tremaining: 11.4s\n",
      "75:\tlearn: 0.1344873\ttotal: 6.92s\tremaining: 11.3s\n",
      "76:\tlearn: 0.1343877\ttotal: 7s\tremaining: 11.2s\n",
      "77:\tlearn: 0.1343165\ttotal: 7.08s\tremaining: 11.1s\n",
      "78:\tlearn: 0.1342099\ttotal: 7.17s\tremaining: 11s\n",
      "79:\tlearn: 0.1341266\ttotal: 7.25s\tremaining: 10.9s\n",
      "80:\tlearn: 0.1340673\ttotal: 7.34s\tremaining: 10.8s\n",
      "81:\tlearn: 0.1339667\ttotal: 7.41s\tremaining: 10.7s\n",
      "82:\tlearn: 0.1338719\ttotal: 7.49s\tremaining: 10.6s\n",
      "83:\tlearn: 0.1337702\ttotal: 7.57s\tremaining: 10.4s\n",
      "84:\tlearn: 0.1337024\ttotal: 7.64s\tremaining: 10.3s\n",
      "85:\tlearn: 0.1336137\ttotal: 7.73s\tremaining: 10.2s\n",
      "86:\tlearn: 0.1335279\ttotal: 7.8s\tremaining: 10.1s\n",
      "87:\tlearn: 0.1334701\ttotal: 7.88s\tremaining: 10s\n",
      "88:\tlearn: 0.1333841\ttotal: 7.95s\tremaining: 9.91s\n",
      "89:\tlearn: 0.1333079\ttotal: 8.03s\tremaining: 9.82s\n",
      "90:\tlearn: 0.1331969\ttotal: 8.12s\tremaining: 9.72s\n",
      "91:\tlearn: 0.1330836\ttotal: 8.18s\tremaining: 9.6s\n",
      "92:\tlearn: 0.1329988\ttotal: 8.26s\tremaining: 9.51s\n",
      "93:\tlearn: 0.1329107\ttotal: 8.36s\tremaining: 9.42s\n",
      "94:\tlearn: 0.1328300\ttotal: 8.43s\tremaining: 9.32s\n",
      "95:\tlearn: 0.1327628\ttotal: 8.51s\tremaining: 9.21s\n",
      "96:\tlearn: 0.1327068\ttotal: 8.61s\tremaining: 9.14s\n",
      "97:\tlearn: 0.1326373\ttotal: 8.69s\tremaining: 9.05s\n",
      "98:\tlearn: 0.1325643\ttotal: 8.78s\tremaining: 8.95s\n",
      "99:\tlearn: 0.1324813\ttotal: 8.85s\tremaining: 8.85s\n",
      "100:\tlearn: 0.1324190\ttotal: 8.92s\tremaining: 8.75s\n",
      "101:\tlearn: 0.1323613\ttotal: 9.02s\tremaining: 8.67s\n",
      "102:\tlearn: 0.1322822\ttotal: 9.11s\tremaining: 8.58s\n",
      "103:\tlearn: 0.1322165\ttotal: 9.2s\tremaining: 8.49s\n",
      "104:\tlearn: 0.1321273\ttotal: 9.29s\tremaining: 8.41s\n",
      "105:\tlearn: 0.1320373\ttotal: 9.38s\tremaining: 8.32s\n",
      "106:\tlearn: 0.1319785\ttotal: 9.46s\tremaining: 8.22s\n",
      "107:\tlearn: 0.1319073\ttotal: 9.54s\tremaining: 8.13s\n",
      "108:\tlearn: 0.1318385\ttotal: 9.63s\tremaining: 8.04s\n",
      "109:\tlearn: 0.1317718\ttotal: 9.73s\tremaining: 7.96s\n",
      "110:\tlearn: 0.1316949\ttotal: 9.82s\tremaining: 7.88s\n",
      "111:\tlearn: 0.1316198\ttotal: 9.9s\tremaining: 7.78s\n",
      "112:\tlearn: 0.1315583\ttotal: 9.98s\tremaining: 7.68s\n",
      "113:\tlearn: 0.1315138\ttotal: 10.1s\tremaining: 7.6s\n",
      "114:\tlearn: 0.1314465\ttotal: 10.1s\tremaining: 7.5s\n",
      "115:\tlearn: 0.1313844\ttotal: 10.2s\tremaining: 7.4s\n",
      "116:\tlearn: 0.1313047\ttotal: 10.3s\tremaining: 7.3s\n",
      "117:\tlearn: 0.1312447\ttotal: 10.4s\tremaining: 7.22s\n",
      "118:\tlearn: 0.1311498\ttotal: 10.5s\tremaining: 7.12s\n",
      "119:\tlearn: 0.1310695\ttotal: 10.5s\tremaining: 7.03s\n",
      "120:\tlearn: 0.1310061\ttotal: 10.6s\tremaining: 6.94s\n",
      "121:\tlearn: 0.1309265\ttotal: 10.7s\tremaining: 6.84s\n",
      "122:\tlearn: 0.1308738\ttotal: 10.8s\tremaining: 6.76s\n",
      "123:\tlearn: 0.1307840\ttotal: 10.9s\tremaining: 6.67s\n",
      "124:\tlearn: 0.1306962\ttotal: 11s\tremaining: 6.58s\n",
      "125:\tlearn: 0.1306306\ttotal: 11.1s\tremaining: 6.5s\n",
      "126:\tlearn: 0.1305617\ttotal: 11.1s\tremaining: 6.4s\n",
      "127:\tlearn: 0.1304964\ttotal: 11.2s\tremaining: 6.3s\n",
      "128:\tlearn: 0.1304463\ttotal: 11.3s\tremaining: 6.23s\n",
      "129:\tlearn: 0.1303631\ttotal: 11.4s\tremaining: 6.13s\n",
      "130:\tlearn: 0.1302946\ttotal: 11.5s\tremaining: 6.04s\n",
      "131:\tlearn: 0.1302161\ttotal: 11.5s\tremaining: 5.95s\n",
      "132:\tlearn: 0.1301510\ttotal: 11.6s\tremaining: 5.86s\n",
      "133:\tlearn: 0.1300884\ttotal: 11.7s\tremaining: 5.76s\n",
      "134:\tlearn: 0.1300305\ttotal: 11.8s\tremaining: 5.67s\n",
      "135:\tlearn: 0.1299746\ttotal: 11.9s\tremaining: 5.58s\n",
      "136:\tlearn: 0.1299167\ttotal: 11.9s\tremaining: 5.49s\n",
      "137:\tlearn: 0.1298605\ttotal: 12s\tremaining: 5.4s\n",
      "138:\tlearn: 0.1298089\ttotal: 12.1s\tremaining: 5.31s\n",
      "139:\tlearn: 0.1297583\ttotal: 12.2s\tremaining: 5.22s\n",
      "140:\tlearn: 0.1296974\ttotal: 12.3s\tremaining: 5.15s\n",
      "141:\tlearn: 0.1296321\ttotal: 12.4s\tremaining: 5.05s\n",
      "142:\tlearn: 0.1295834\ttotal: 12.5s\tremaining: 4.96s\n",
      "143:\tlearn: 0.1295205\ttotal: 12.5s\tremaining: 4.88s\n",
      "144:\tlearn: 0.1294633\ttotal: 12.6s\tremaining: 4.78s\n",
      "145:\tlearn: 0.1294199\ttotal: 12.7s\tremaining: 4.69s\n",
      "146:\tlearn: 0.1293555\ttotal: 12.8s\tremaining: 4.6s\n",
      "147:\tlearn: 0.1292989\ttotal: 12.9s\tremaining: 4.52s\n",
      "148:\tlearn: 0.1292216\ttotal: 12.9s\tremaining: 4.43s\n",
      "149:\tlearn: 0.1291546\ttotal: 13s\tremaining: 4.34s\n",
      "150:\tlearn: 0.1290871\ttotal: 13.1s\tremaining: 4.25s\n",
      "151:\tlearn: 0.1290303\ttotal: 13.2s\tremaining: 4.17s\n",
      "152:\tlearn: 0.1289726\ttotal: 13.3s\tremaining: 4.08s\n",
      "153:\tlearn: 0.1289268\ttotal: 13.4s\tremaining: 3.99s\n",
      "154:\tlearn: 0.1288567\ttotal: 13.5s\tremaining: 3.91s\n",
      "155:\tlearn: 0.1287443\ttotal: 13.6s\tremaining: 3.82s\n",
      "156:\tlearn: 0.1286811\ttotal: 13.6s\tremaining: 3.73s\n",
      "157:\tlearn: 0.1286292\ttotal: 13.7s\tremaining: 3.64s\n",
      "158:\tlearn: 0.1285645\ttotal: 13.8s\tremaining: 3.56s\n",
      "159:\tlearn: 0.1285034\ttotal: 13.9s\tremaining: 3.47s\n",
      "160:\tlearn: 0.1284473\ttotal: 13.9s\tremaining: 3.38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161:\tlearn: 0.1283892\ttotal: 14s\tremaining: 3.29s\n",
      "162:\tlearn: 0.1283390\ttotal: 14.1s\tremaining: 3.21s\n",
      "163:\tlearn: 0.1282849\ttotal: 14.2s\tremaining: 3.11s\n",
      "164:\tlearn: 0.1282368\ttotal: 14.3s\tremaining: 3.02s\n",
      "165:\tlearn: 0.1281816\ttotal: 14.3s\tremaining: 2.93s\n",
      "166:\tlearn: 0.1281274\ttotal: 14.4s\tremaining: 2.85s\n",
      "167:\tlearn: 0.1280773\ttotal: 14.5s\tremaining: 2.76s\n",
      "168:\tlearn: 0.1280316\ttotal: 14.6s\tremaining: 2.67s\n",
      "169:\tlearn: 0.1279708\ttotal: 14.6s\tremaining: 2.58s\n",
      "170:\tlearn: 0.1279336\ttotal: 14.7s\tremaining: 2.5s\n",
      "171:\tlearn: 0.1278920\ttotal: 14.8s\tremaining: 2.41s\n",
      "172:\tlearn: 0.1278413\ttotal: 14.9s\tremaining: 2.32s\n",
      "173:\tlearn: 0.1277902\ttotal: 15s\tremaining: 2.24s\n",
      "174:\tlearn: 0.1277330\ttotal: 15.1s\tremaining: 2.15s\n",
      "175:\tlearn: 0.1276851\ttotal: 15.1s\tremaining: 2.06s\n",
      "176:\tlearn: 0.1276221\ttotal: 15.2s\tremaining: 1.98s\n",
      "177:\tlearn: 0.1275804\ttotal: 15.3s\tremaining: 1.89s\n",
      "178:\tlearn: 0.1275294\ttotal: 15.4s\tremaining: 1.8s\n",
      "179:\tlearn: 0.1274682\ttotal: 15.5s\tremaining: 1.72s\n",
      "180:\tlearn: 0.1274242\ttotal: 15.6s\tremaining: 1.63s\n",
      "181:\tlearn: 0.1273917\ttotal: 15.6s\tremaining: 1.55s\n",
      "182:\tlearn: 0.1273381\ttotal: 15.7s\tremaining: 1.46s\n",
      "183:\tlearn: 0.1272966\ttotal: 15.8s\tremaining: 1.38s\n",
      "184:\tlearn: 0.1272507\ttotal: 15.9s\tremaining: 1.29s\n",
      "185:\tlearn: 0.1271880\ttotal: 16s\tremaining: 1.2s\n",
      "186:\tlearn: 0.1271349\ttotal: 16.1s\tremaining: 1.12s\n",
      "187:\tlearn: 0.1270934\ttotal: 16.2s\tremaining: 1.03s\n",
      "188:\tlearn: 0.1270440\ttotal: 16.2s\tremaining: 946ms\n",
      "189:\tlearn: 0.1270107\ttotal: 16.3s\tremaining: 860ms\n",
      "190:\tlearn: 0.1269602\ttotal: 16.4s\tremaining: 773ms\n",
      "191:\tlearn: 0.1269140\ttotal: 16.5s\tremaining: 687ms\n",
      "192:\tlearn: 0.1268661\ttotal: 16.6s\tremaining: 601ms\n",
      "193:\tlearn: 0.1268175\ttotal: 16.6s\tremaining: 514ms\n",
      "194:\tlearn: 0.1267631\ttotal: 16.7s\tremaining: 428ms\n",
      "195:\tlearn: 0.1267116\ttotal: 16.8s\tremaining: 343ms\n",
      "196:\tlearn: 0.1266592\ttotal: 16.9s\tremaining: 257ms\n",
      "197:\tlearn: 0.1266090\ttotal: 17s\tremaining: 171ms\n",
      "198:\tlearn: 0.1265666\ttotal: 17.1s\tremaining: 85.8ms\n",
      "199:\tlearn: 0.1265078\ttotal: 17.1s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model_ctb = ctb.CatBoostClassifier(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "distributions = {'learning_rate':[0.000001, 0.0001, 0.001, 0.01,0.05, 0.1, 0.5, 1],\n",
    "                 'depth' :[1,2,3,4,5],\n",
    "                 'l2_leaf_reg': [1, 3, 5, 7, 9], 'iterations':[100, 200, 300, 500]}\n",
    "\n",
    "model_ctb_1 = RandomizedSearchCV(model_ctb, distributions, random_state=0, verbose=2, n_iter = 5, cv = 3)\n",
    "model_ctb_1 = model_ctb_1.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_ctb = model_ctb_1.best_estimator_.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8619760759193608"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba_ctb[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', learning_rate=1, max_depth=3,\n",
       "               min_child_weight=1000.0, n_estimators=600, random_state=0,\n",
       "               reg_alpha=0.1, reg_lambda=0.1)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb7fa36c160>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ctb_1.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction based on ICA + 1/2Catboost & 1/2LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.replace(np.inf, 10000000,inplace=True)\n",
    "test.replace(-np.inf, -10000000, inplace=True)\n",
    "test.fillna(lambda x: x.mean(), axis = 0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0446672966135276                       485576\n",
       "0.040755348392494326                     278165\n",
       "<function <lambda> at 0x7fa5e07301f0>        66\n",
       "10                                            2\n",
       "Name: x_13, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['x_13'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid object type at position 14502",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid object type",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-de02c730d941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[1;32m    184\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid object type at position 14502"
     ]
    }
   ],
   "source": [
    "test = test.apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-9d69ac5b1a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_fastica.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNpDtype\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1993\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1995\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'function'"
     ]
    }
   ],
   "source": [
    "X_t = pd.DataFrame(transformer.transform(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/data/model_dataset_compatibility.cpp:81: At position 0 should be feature with name 0 (found x_2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-de2de2416814>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel_ctb_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m   4388\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevery\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \"\"\"\n\u001b[0;32m-> 4390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name)\u001b[0m\n\u001b[1;32m   1977\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_base_predict\u001b[0;34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_virtual_ensembles_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvirtual_ensembles_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/libs/data/model_dataset_compatibility.cpp:81: At position 0 should be feature with name 0 (found x_2)."
     ]
    }
   ],
   "source": [
    "y_predicted = 0.5*model_ctb_1.best_estimator_.predict_proba(X_t)[:,1]+\n",
    "              0.5*model.best_estimator_.predict_proba(X_t)[:,1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "catboost/libs/data/model_dataset_compatibility.cpp:81: At position 0 should be feature with name 0 (found x_2).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-88868609f7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ctb_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m   4388\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevery\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \"\"\"\n\u001b[0;32m-> 4390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Probability'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predict_proba'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, data, prediction_type, ntree_start, ntree_end, thread_count, verbose, parent_method_name)\u001b[0m\n\u001b[1;32m   1977\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_prediction_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata_is_single_object\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_base_predict\u001b[0;34m(self, pool, prediction_type, ntree_start, ntree_end, thread_count, verbose)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_virtual_ensembles_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvirtual_ensembles_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._base_predict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: catboost/libs/data/model_dataset_compatibility.cpp:81: At position 0 should be feature with name 0 (found x_2)."
     ]
    }
   ],
   "source": [
    "model_ctb_1.best_estimator_.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submit(y_predicted): \n",
    "    submission_link = '/kaggle/input/risk-management-uiim/submission.csv'\n",
    "    submission = pd.read_csv(submission_link)\n",
    "    \n",
    "    submission['Probability'] = y_predicted\n",
    "    print(submission)\n",
    "    submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stohastic gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "# define models and parameters\n",
    "model = GradientBoostingClassifier()\n",
    "n_estimators = [10, 100, 1000]\n",
    "learning_rate = [0.001, 0.01, 0.1]\n",
    "subsample = [0.5, 0.7, 1.0]\n",
    "max_depth = [3, 7, 9]\n",
    "# define grid search\n",
    "grid = dict(learning_rate=learning_rate, n_estimators=n_estimators, subsample=subsample, max_depth=max_depth)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/6lgb + 1/6xgb + 1/6catboost + 1/6logreg + 1/6naivebias + 1/6svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:14:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { enable_categorical } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-549eb45811f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mxgb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'eval_metric'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[1;32m    543\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m     return _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    209\u001b[0m                            \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1160\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBRegressor(enable_categorical= True)\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(xgb_model.feature_importances_, X_train.columns).reset_index().rename(columns={0:'importance', 1:'factor'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance.nlargest(25, 'importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use only 25 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_25 = np.array(importance.nlargest(25, 'importance')['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_reduced = xgb.XGBRegressor()\n",
    "xgb_model_reduced.fit(X_train[features_25], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reduced = xgb_model_reduced.predict(X_test[features_25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7932086532279361"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use only 20 most important features and significant categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new = list(np.array(importance.nlargest(19, 'importance')['index']))\n",
    "important_cat_values = list(['client_significance', 'day_of_week', 'credit_purpose',\n",
    "                                 'city', 'street', 'period'])\n",
    "\n",
    "features_new.extend(important_cat_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_reduced_with_cat = xgb.XGBRegressor()\n",
    "xgb_model_reduced_with_cat.fit(X_train[features_new], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_reduced_1 = xgb_model_reduced_with_cat.predict(X_test[features_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7948199717355685"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_reduced_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### catboost + hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import catboost\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import colorama\n",
    "\n",
    "N_HYPEROPT_PROBES = 60\n",
    "HYPEROPT_ALGO = tpe.suggest\n",
    "colorama.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catboost_params(space):\n",
    "    params = dict()\n",
    "    params['learning_rate'] = space['learning_rate']\n",
    "    params['depth'] = int(space['depth'])\n",
    "    params['l2_leaf_reg'] = space['l2_leaf_reg']\n",
    "    params['border_count'] = space['border_count']\n",
    "    #params['rsm'] = space['rsm']\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_call_count = 0\n",
    "cur_best_loss = np.inf\n",
    "log_writer = open( 'catboost-hyperopt-log.txt', 'w' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = catboost.Pool(X_train[features_new].iloc[:1000,:], y_train[:1000])\n",
    "D_test = catboost.Pool(X_test[features_new].iloc[:1000,:], y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_loss\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=1000,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='AUC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=300,\n",
    "                                        od_type=\"Iter\",\n",
    "                                        border_count=int(params['border_count']),\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    nb_trees = model.tree_count_\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} auc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, auc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if test_loss<cur_best_loss:\n",
    "        cur_best_loss = test_loss\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':test_loss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "CatBoost objective call #6 cur_best_loss=    inf\n",
      "Params: border_count=55.65632609422184 depth=4.0 l2_leaf_reg=7.99823809308144 learning_rate=0.02855826013286454\n",
      "nb_trees=42                                           \n",
      "NEW BEST LOSS=0.18683780140468706                     \n",
      "                                                                                 \n",
      "CatBoost objective call #7 cur_best_loss=0.18684\n",
      "Params: border_count=74.14586013188347 depth=5.0 l2_leaf_reg=4.144010752382719 learning_rate=0.014844559387032432\n",
      "nb_trees=30                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #8 cur_best_loss=0.18684\n",
      "Params: border_count=201.5866118855728 depth=3.0 l2_leaf_reg=3.2878835602715535 learning_rate=0.013415353835737304\n",
      "nb_trees=94                                                                      \n",
      "NEW BEST LOSS=0.1850400795019103                                                 \n",
      "                                                                                 \n",
      "CatBoost objective call #9 cur_best_loss=0.18504\n",
      "Params: border_count=154.75493908446498 depth=3.0 l2_leaf_reg=7.552369479942166 learning_rate=0.024365441902140534\n",
      "nb_trees=64                                                                     \n",
      "NEW BEST LOSS=0.17423573679456364                                               \n",
      "                                                                                 \n",
      "CatBoost objective call #10 cur_best_loss=0.17424\n",
      "Params: border_count=47.69202689445205 depth=1.0 l2_leaf_reg=5.929826284498931 learning_rate=0.05169059865992182\n",
      "nb_trees=992                                                                     \n",
      "NEW BEST LOSS=0.16392227261926595                                                \n",
      "                                                                                 \n",
      "CatBoost objective call #11 cur_best_loss=0.16392\n",
      "Params: border_count=53.32305695599375 depth=2.0 l2_leaf_reg=4.816465860429231 learning_rate=0.065159016822477\n",
      "nb_trees=23                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #12 cur_best_loss=0.16392\n",
      "Params: border_count=139.0323910561506 depth=2.0 l2_leaf_reg=6.65539836724512 learning_rate=0.009556607849088052\n",
      "nb_trees=22                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #13 cur_best_loss=0.16392\n",
      "Params: border_count=41.341609892061925 depth=1.0 l2_leaf_reg=5.9419072382520906 learning_rate=0.0602136964160962\n",
      "nb_trees=979                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #14 cur_best_loss=0.16392\n",
      "Params: border_count=137.82176797921707 depth=3.0 l2_leaf_reg=6.554196191676388 learning_rate=0.09009199578686462\n",
      "nb_trees=65                                                                      \n",
      "NEW BEST LOSS=0.16388218776612887                                                \n",
      "                                                                                 \n",
      "CatBoost objective call #15 cur_best_loss=0.16388\n",
      "Params: border_count=254.53850321473288 depth=1.0 l2_leaf_reg=4.801473949117543 learning_rate=0.022943380284945775\n",
      "nb_trees=163                                                                     \n",
      "                                                                                  \n",
      "CatBoost objective call #16 cur_best_loss=0.16388\n",
      "Params: border_count=61.65484064469314 depth=5.0 l2_leaf_reg=7.884362508407105 learning_rate=0.031517799958639584\n",
      "nb_trees=147                                                                      \n",
      "NEW BEST LOSS=0.1615043493391865                                                  \n",
      "                                                                                  \n",
      "CatBoost objective call #17 cur_best_loss=0.16150\n",
      "Params: border_count=88.32031631995108 depth=4.0 l2_leaf_reg=7.548888213428167 learning_rate=0.0500815624633114\n",
      "nb_trees=39                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #18 cur_best_loss=0.16150\n",
      "Params: border_count=78.1083293073342 depth=3.0 l2_leaf_reg=5.886988042815433 learning_rate=0.008436592268977111\n",
      "nb_trees=110                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #19 cur_best_loss=0.16150\n",
      "Params: border_count=151.78060884993204 depth=2.0 l2_leaf_reg=3.4281065193627445 learning_rate=0.010891530625169836\n",
      "nb_trees=161                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #20 cur_best_loss=0.16150\n",
      "Params: border_count=188.18381668241602 depth=4.0 l2_leaf_reg=6.995092436858373 learning_rate=0.02013191448951947\n",
      "nb_trees=72                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #21 cur_best_loss=0.16150\n",
      "Params: border_count=92.69976479203578 depth=2.0 l2_leaf_reg=4.3630968105730465 learning_rate=0.039707430210716856\n",
      "nb_trees=69                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #22 cur_best_loss=0.16150\n",
      "Params: border_count=48.75276969964469 depth=4.0 l2_leaf_reg=3.485228606225804 learning_rate=0.11037295163732565\n",
      "nb_trees=43                                                                      \n",
      "NEW BEST LOSS=0.16022148209761103                                                \n",
      "                                                                                  \n",
      "CatBoost objective call #23 cur_best_loss=0.16022\n",
      "Params: border_count=63.92238908786122 depth=5.0 l2_leaf_reg=6.978910023876418 learning_rate=0.04267638631795883\n",
      "nb_trees=54                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #24 cur_best_loss=0.16022\n",
      "Params: border_count=125.26645104567794 depth=2.0 l2_leaf_reg=4.553030269025046 learning_rate=0.00755115057128436\n",
      "nb_trees=145                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #25 cur_best_loss=0.16022\n",
      "Params: border_count=193.41495807171074 depth=4.0 l2_leaf_reg=7.314993976137757 learning_rate=0.010307560934251142\n",
      "nb_trees=93                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #26 cur_best_loss=0.16022\n",
      "Params: border_count=107.24342247916302 depth=6.0 l2_leaf_reg=3.941975825790941 learning_rate=0.09527161385389359\n",
      "nb_trees=40                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #27 cur_best_loss=0.16022\n",
      "Params: border_count=32.99733991646964 depth=5.0 l2_leaf_reg=5.384860945892086 learning_rate=0.11433592738185203\n",
      "nb_trees=105                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #28 cur_best_loss=0.16022\n",
      "Params: border_count=109.25980169971615 depth=6.0 l2_leaf_reg=3.8079278451575584 learning_rate=0.07265476329000091\n",
      "nb_trees=31                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #29 cur_best_loss=0.16022\n",
      "Params: border_count=34.40612856364615 depth=5.0 l2_leaf_reg=3.0601828970073965 learning_rate=0.036126723831035885\n",
      "nb_trees=58                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #30 cur_best_loss=0.16022\n",
      "Params: border_count=254.56724901574285 depth=6.0 l2_leaf_reg=5.351677949181132 learning_rate=0.017463492342179657\n",
      "nb_trees=66                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #31 cur_best_loss=0.16022\n",
      "Params: border_count=104.68960353967967 depth=5.0 l2_leaf_reg=7.966689633208011 learning_rate=0.12486044729056556\n",
      "nb_trees=13                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #32 cur_best_loss=0.16022\n",
      "Params: border_count=170.46562533419424 depth=4.0 l2_leaf_reg=5.0352096167414295 learning_rate=0.0813489027328666\n",
      "nb_trees=90                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #33 cur_best_loss=0.16022\n",
      "Params: border_count=230.39392367951987 depth=6.0 l2_leaf_reg=6.222859608921187 learning_rate=0.030590421835407475\n",
      "nb_trees=147                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #34 cur_best_loss=0.16022\n",
      "Params: border_count=64.35080218795852 depth=4.0 l2_leaf_reg=3.655929648047927 learning_rate=0.13104093496029287\n",
      "nb_trees=42                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #35 cur_best_loss=0.16022\n",
      "Params: border_count=119.4260942901586 depth=5.0 l2_leaf_reg=7.953860880522914 learning_rate=0.028954584307034483\n",
      "nb_trees=120                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #36 cur_best_loss=0.16022\n",
      "Params: border_count=118.97686839384778 depth=4.0 l2_leaf_reg=3.053991112309159 learning_rate=0.025273501510690636\n",
      "nb_trees=75                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #37 cur_best_loss=0.16022\n",
      "Params: border_count=219.76741971512826 depth=5.0 l2_leaf_reg=4.200337300427677 learning_rate=0.01367031496672545\n",
      "nb_trees=25                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #38 cur_best_loss=0.16022\n",
      "Params: border_count=172.63660240349782 depth=6.0 l2_leaf_reg=5.626763477376533 learning_rate=0.016445037982133613\n",
      "nb_trees=74                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #39 cur_best_loss=0.16022\n",
      "Params: border_count=92.0219686402539 depth=3.0 l2_leaf_reg=3.3525830436981794 learning_rate=0.05089684973715526\n",
      "nb_trees=29                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #40 cur_best_loss=0.16022\n",
      "Params: border_count=77.85436848542678 depth=5.0 l2_leaf_reg=6.469633927953156 learning_rate=0.021431359168607007\n",
      "nb_trees=60                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #41 cur_best_loss=0.16022\n",
      "Params: border_count=166.4913877154076 depth=4.0 l2_leaf_reg=5.1114603509700824 learning_rate=0.027340017009086316\n",
      "nb_trees=50                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #42 cur_best_loss=0.16022\n",
      "Params: border_count=125.72473990826535 depth=3.0 l2_leaf_reg=4.592500336640899 learning_rate=0.0349171964210189\n",
      "nb_trees=183                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #43 cur_best_loss=0.16022\n",
      "Params: border_count=49.58645216832985 depth=5.0 l2_leaf_reg=6.958798344261411 learning_rate=0.05856150296410958\n",
      "nb_trees=33                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #44 cur_best_loss=0.16022\n",
      "Params: border_count=146.4755820345806 depth=6.0 l2_leaf_reg=7.66901591774908 learning_rate=0.01229384085827172\n",
      "nb_trees=98                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #45 cur_best_loss=0.16022\n",
      "Params: border_count=208.30777075814564 depth=3.0 l2_leaf_reg=5.669129427910709 learning_rate=0.10265021725032025\n",
      "nb_trees=20                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #46 cur_best_loss=0.16022\n",
      "Params: border_count=135.12455113443178 depth=4.0 l2_leaf_reg=6.3146722073196235 learning_rate=0.01851976580779693\n",
      "nb_trees=425                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #47 cur_best_loss=0.16022\n",
      "Params: border_count=41.2336249868717 depth=5.0 l2_leaf_reg=7.317533433528186 learning_rate=0.046316613240108426\n",
      "nb_trees=29                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #48 cur_best_loss=0.16022\n",
      "Params: border_count=238.84599223254884 depth=4.0 l2_leaf_reg=6.067581857401587 learning_rate=0.06736393759307029\n",
      "nb_trees=29                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #49 cur_best_loss=0.16022\n",
      "Params: border_count=72.25946707951526 depth=3.0 l2_leaf_reg=3.5356664592253955 learning_rate=0.015374744351776963\n",
      "nb_trees=112                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #50 cur_best_loss=0.16022\n",
      "Params: border_count=98.59256432487855 depth=5.0 l2_leaf_reg=3.9612282151767664 learning_rate=0.05697890921926042\n",
      "nb_trees=34                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #51 cur_best_loss=0.16022\n",
      "Params: border_count=55.18177769624119 depth=6.0 l2_leaf_reg=6.725917374297884 learning_rate=0.07839115722417046\n",
      "nb_trees=55                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #52 cur_best_loss=0.16022\n",
      "Params: border_count=56.23823728423929 depth=1.0 l2_leaf_reg=6.738645419925472 learning_rate=0.08221809303866671\n",
      "nb_trees=894                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #53 cur_best_loss=0.16022\n",
      "Params: border_count=45.06989549674712 depth=2.0 l2_leaf_reg=6.790641247100007 learning_rate=0.11070712534566977\n",
      "nb_trees=76                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                  \n",
      "CatBoost objective call #54 cur_best_loss=0.16022\n",
      "Params: border_count=87.4549317536063 depth=1.0 l2_leaf_reg=7.355496121557307 learning_rate=0.07929822030726086\n",
      "nb_trees=39                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #55 cur_best_loss=0.16022\n",
      "Params: border_count=32.99655203339752 depth=6.0 l2_leaf_reg=5.900292634625017 learning_rate=0.06608976171458626\n",
      "nb_trees=180                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #56 cur_best_loss=0.16022\n",
      "Params: border_count=71.28036875704315 depth=2.0 l2_leaf_reg=7.69715123140464 learning_rate=0.13256182915718567\n",
      "nb_trees=35                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #57 cur_best_loss=0.16022\n",
      "Params: border_count=158.40066952269783 depth=3.0 l2_leaf_reg=4.971728129715847 learning_rate=0.09402153883797329\n",
      "nb_trees=72                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #58 cur_best_loss=0.16022\n",
      "Params: border_count=84.6454958367425 depth=6.0 l2_leaf_reg=6.485337063401186 learning_rate=0.1119339667062753\n",
      "nb_trees=21                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #59 cur_best_loss=0.16022\n",
      "Params: border_count=52.73491930375728 depth=2.0 l2_leaf_reg=7.1674130276304115 learning_rate=0.04237275254338755\n",
      "nb_trees=39                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #60 cur_best_loss=0.16022\n",
      "Params: border_count=38.9593775456648 depth=6.0 l2_leaf_reg=4.702994702896407 learning_rate=0.07438801936396057\n",
      "nb_trees=125                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #61 cur_best_loss=0.16022\n",
      "Params: border_count=183.29414085209498 depth=4.0 l2_leaf_reg=5.729861434853405 learning_rate=0.08681281331080706\n",
      "nb_trees=65                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #62 cur_best_loss=0.16022\n",
      "Params: border_count=61.819261877654554 depth=3.0 l2_leaf_reg=4.3907121876560655 learning_rate=0.05481112628227554\n",
      "nb_trees=35                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #63 cur_best_loss=0.16022\n",
      "Params: border_count=81.28998307367178 depth=1.0 l2_leaf_reg=5.294140209072223 learning_rate=0.1011014280871825\n",
      "nb_trees=51                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #64 cur_best_loss=0.16022\n",
      "Params: border_count=113.79595629636523 depth=2.0 l2_leaf_reg=3.1939063720212717 learning_rate=0.03542063868328561\n",
      "nb_trees=40                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #65 cur_best_loss=0.16022\n",
      "Params: border_count=133.66864114173922 depth=5.0 l2_leaf_reg=4.133383737611591 learning_rate=0.06350216728949584\n",
      "nb_trees=70                                                                       \n",
      "100%|██████████| 60/60 [00:42<00:00,  1.42trial/s, best loss: 0.16022148209761103]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'border_count': 48.75276969964469, 'depth': 4.0, 'l2_leaf_reg': 3.485228606225804, 'learning_rate': 0.11037295163732565}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "        'depth': hp.quniform(\"depth\", 1, 6, 1),\n",
    "        'border_count': hp.uniform ('border_count', 32, 255),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -5.0, -2),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=True)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.update({'border_count': int(best['border_count'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6516156\tbest: 0.6516156 (0)\ttotal: 3ms\tremaining: 3s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.8060568772\n",
      "bestIteration = 42\n",
      "\n",
      "Shrink model to first 43 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb4eb489760>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = catboost.CatBoostClassifier(iterations=1000,\n",
    "                    loss_function='Logloss',\n",
    "                    use_best_model=True,\n",
    "                    eval_metric='AUC',\n",
    "                    early_stopping_rounds=300,\n",
    "                    od_type=\"Iter\",\n",
    "                    verbose=2000,\n",
    "                    **best\n",
    "                    )\n",
    "\n",
    "model.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8060568772217664\n",
      "acc =  0.952\n",
      "loss =  0.16022148209761103\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"acc = \", sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Received better results AUC is 0.8060568772217664, while before was 0.7948199717355685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011236905486197935"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.8060568772217664 - 0.7948199717355685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "N_HYPEROPT_PROBES = 60\n",
    "HYPEROPT_ALGO = tpe.suggest\n",
    "colorama.init()\n",
    "\n",
    "D_train = catboost.Pool(X_train[features_new], y_train)\n",
    "D_test = catboost.Pool(X_test[features_new], y_test)\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_loss\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=100,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='AUC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=10,\n",
    "                                        od_type=\"Iter\",\n",
    "                                        border_count=int(params['border_count']),\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    nb_trees = model.tree_count_\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} auc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, auc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if test_loss<cur_best_loss:\n",
    "        cur_best_loss = test_loss\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':test_loss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.01 µs\n",
      "                                                      \n",
      "CatBoost objective call #254 cur_best_loss=0.15293\n",
      "Params: border_count=76.10890885883015 depth=4.0 l2_leaf_reg=7.238740801916636 learning_rate=0.017816332991421005\n",
      "nb_trees=100                                          \n",
      "                                                                               \n",
      "CatBoost objective call #255 cur_best_loss=0.15293\n",
      "Params: border_count=138.33121711368142 depth=5.0 l2_leaf_reg=7.673035732408229 learning_rate=0.01128873038504781\n",
      "nb_trees=52                                                                    \n",
      "                                                                               \n",
      "CatBoost objective call #256 cur_best_loss=0.15293\n",
      "Params: border_count=49.73363640044286 depth=5.0 l2_leaf_reg=7.395086153941822 learning_rate=0.009051463521493538\n",
      "nb_trees=47                                                                    \n",
      "                                                                               \n",
      "CatBoost objective call #257 cur_best_loss=0.15293\n",
      "Params: border_count=249.42740613271636 depth=2.0 l2_leaf_reg=7.324854698830839 learning_rate=0.08041658517559074\n",
      "nb_trees=100                                                                   \n",
      "                                                                                 \n",
      "CatBoost objective call #258 cur_best_loss=0.15293\n",
      "Params: border_count=238.25139460895738 depth=3.0 l2_leaf_reg=5.134044377306421 learning_rate=0.0439404150252393\n",
      "nb_trees=98                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #259 cur_best_loss=0.15293\n",
      "Params: border_count=228.1466844176287 depth=5.0 l2_leaf_reg=7.596852458871078 learning_rate=0.015810045131274833\n",
      "nb_trees=98                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #260 cur_best_loss=0.15293\n",
      "Params: border_count=105.32987984855336 depth=4.0 l2_leaf_reg=7.41746446165182 learning_rate=0.08368366663066999\n",
      "nb_trees=100                                                                     \n",
      "NEW BEST LOSS=0.15206514050597028                                                \n",
      "                                                                                 \n",
      "CatBoost objective call #261 cur_best_loss=0.15207\n",
      "Params: border_count=82.83877619454967 depth=2.0 l2_leaf_reg=3.7839588122692174 learning_rate=0.011804365131568118\n",
      "nb_trees=68                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #262 cur_best_loss=0.15207\n",
      "Params: border_count=200.06877369520532 depth=4.0 l2_leaf_reg=5.328791553521019 learning_rate=0.008101994102110818\n",
      "nb_trees=50                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #263 cur_best_loss=0.15207\n",
      "Params: border_count=137.90682492713034 depth=3.0 l2_leaf_reg=6.22793870856196 learning_rate=0.025674074560182975\n",
      "nb_trees=99                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #264 cur_best_loss=0.15207\n",
      "Params: border_count=90.91421292954473 depth=4.0 l2_leaf_reg=4.1661554101892495 learning_rate=0.016990487459653245\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #265 cur_best_loss=0.15207\n",
      "Params: border_count=95.54275042286939 depth=4.0 l2_leaf_reg=6.000794199541652 learning_rate=0.08490747262110415\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #266 cur_best_loss=0.15207\n",
      "Params: border_count=86.45850633243244 depth=2.0 l2_leaf_reg=4.08175419247758 learning_rate=0.014048866278397779\n",
      "nb_trees=72                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #267 cur_best_loss=0.15207\n",
      "Params: border_count=123.6599590683809 depth=1.0 l2_leaf_reg=3.3455370018164827 learning_rate=0.12922040599261642\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #268 cur_best_loss=0.15207\n",
      "Params: border_count=44.576599096004635 depth=2.0 l2_leaf_reg=3.7532699934931877 learning_rate=0.055529181967604604\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #269 cur_best_loss=0.15207\n",
      "Params: border_count=218.17866687262264 depth=3.0 l2_leaf_reg=5.873327700018598 learning_rate=0.01007105526480445\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #270 cur_best_loss=0.15207\n",
      "Params: border_count=243.0239992610714 depth=5.0 l2_leaf_reg=5.177084368944129 learning_rate=0.021679007851236602\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #271 cur_best_loss=0.15207\n",
      "Params: border_count=244.64584293634823 depth=4.0 l2_leaf_reg=6.341035353337924 learning_rate=0.011794820937749343\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #272 cur_best_loss=0.15207\n",
      "Params: border_count=93.94435016857625 depth=2.0 l2_leaf_reg=3.6392565740117453 learning_rate=0.03119144867490091\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #273 cur_best_loss=0.15207\n",
      "Params: border_count=195.61726488137418 depth=4.0 l2_leaf_reg=5.183531267969707 learning_rate=0.09796802817876989\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST LOSS=0.15190682149878248                                                 \n",
      "                                                                                  \n",
      "CatBoost objective call #274 cur_best_loss=0.15191\n",
      "Params: border_count=181.62768923130386 depth=6.0 l2_leaf_reg=4.6260276467252925 learning_rate=0.11744061581529261\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST LOSS=0.15017795777235035                                                 \n",
      "                                                                                  \n",
      "CatBoost objective call #275 cur_best_loss=0.15018\n",
      "Params: border_count=175.89250390932284 depth=6.0 l2_leaf_reg=4.65890756671723 learning_rate=0.129911088934506\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #276 cur_best_loss=0.15018\n",
      "Params: border_count=194.48162849915553 depth=6.0 l2_leaf_reg=4.679795054095235 learning_rate=0.13195969959774895\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST LOSS=0.1500380954609011                                                  \n",
      "                                                                                  \n",
      "CatBoost objective call #277 cur_best_loss=0.15004\n",
      "Params: border_count=168.6556573867822 depth=6.0 l2_leaf_reg=4.690755236797797 learning_rate=0.06236331295285284\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #278 cur_best_loss=0.15004\n",
      "Params: border_count=167.17236130056529 depth=6.0 l2_leaf_reg=4.614028182064691 learning_rate=0.1332600627875591\n",
      "nb_trees=100                                                                     \n",
      "NEW BEST LOSS=0.1499898924982758                                                 \n",
      "                                                                                 \n",
      "CatBoost objective call #279 cur_best_loss=0.14999\n",
      "Params: border_count=156.42035296377236 depth=6.0 l2_leaf_reg=3.164585641142847 learning_rate=0.04102603323847877\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #280 cur_best_loss=0.14999\n",
      "Params: border_count=209.51854751421195 depth=6.0 l2_leaf_reg=6.833237942957897 learning_rate=0.06324487632604059\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #281 cur_best_loss=0.14999\n",
      "Params: border_count=155.2297975105235 depth=5.0 l2_leaf_reg=4.252558736013104 learning_rate=0.10020767538015142\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #282 cur_best_loss=0.14999\n",
      "Params: border_count=191.00848537930722 depth=6.0 l2_leaf_reg=5.6224177077317465 learning_rate=0.03662800674012092\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #283 cur_best_loss=0.14999\n",
      "Params: border_count=120.92945819111026 depth=5.0 l2_leaf_reg=6.903286778327697 learning_rate=0.13532812992695045\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #284 cur_best_loss=0.14999\n",
      "Params: border_count=162.2173934831697 depth=5.0 l2_leaf_reg=4.842634891307878 learning_rate=0.106384478581309\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #285 cur_best_loss=0.14999\n",
      "Params: border_count=68.73558902352157 depth=6.0 l2_leaf_reg=7.973448818214142 learning_rate=0.05196574014361924\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #286 cur_best_loss=0.14999\n",
      "Params: border_count=140.98713509928717 depth=5.0 l2_leaf_reg=4.311369657141341 learning_rate=0.07182927578795434\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #287 cur_best_loss=0.14999\n",
      "Params: border_count=219.31267414498518 depth=1.0 l2_leaf_reg=3.0341273026381375 learning_rate=0.021909865649997064\n",
      "nb_trees=20                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #288 cur_best_loss=0.14999\n",
      "Params: border_count=187.2827412282228 depth=5.0 l2_leaf_reg=4.9456749341986885 learning_rate=0.007194445220258205\n",
      "nb_trees=93                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #289 cur_best_loss=0.14999\n",
      "Params: border_count=124.69396062093544 depth=6.0 l2_leaf_reg=5.550004912718732 learning_rate=0.04729040416187234\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #290 cur_best_loss=0.14999\n",
      "Params: border_count=254.6648093990906 depth=6.0 l2_leaf_reg=3.4481028295779526 learning_rate=0.07180622084470997\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #291 cur_best_loss=0.14999\n",
      "Params: border_count=61.85710229617641 depth=5.0 l2_leaf_reg=4.0184387926496 learning_rate=0.09294739719669373\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #292 cur_best_loss=0.14999\n",
      "Params: border_count=228.9222030047489 depth=3.0 l2_leaf_reg=4.5014168798537435 learning_rate=0.11437714313970594\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #293 cur_best_loss=0.14999\n",
      "Params: border_count=109.44605129330853 depth=5.0 l2_leaf_reg=6.428111670255564 learning_rate=0.03617412039643488\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #294 cur_best_loss=0.14999\n",
      "Params: border_count=206.01180586290016 depth=6.0 l2_leaf_reg=5.755620334594672 learning_rate=0.07436350548689304\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #295 cur_best_loss=0.14999\n",
      "Params: border_count=144.80139858922934 depth=3.0 l2_leaf_reg=5.399857259315484 learning_rate=0.13515113296093761\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #296 cur_best_loss=0.14999\n",
      "Params: border_count=230.0702364252914 depth=4.0 l2_leaf_reg=4.907805769322096 learning_rate=0.026867752435348724\n",
      "nb_trees=99                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #297 cur_best_loss=0.14999\n",
      "Params: border_count=178.3634706336213 depth=5.0 l2_leaf_reg=3.858234596639157 learning_rate=0.08906220744072303\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #298 cur_best_loss=0.14999\n",
      "Params: border_count=132.63130327583858 depth=6.0 l2_leaf_reg=4.42521243046121 learning_rate=0.013807048259604823\n",
      "nb_trees=47                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #299 cur_best_loss=0.14999\n",
      "Params: border_count=167.16976107722496 depth=4.0 l2_leaf_reg=6.663897189866606 learning_rate=0.06041870721561325\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #300 cur_best_loss=0.14999\n",
      "Params: border_count=108.03678943703113 depth=1.0 l2_leaf_reg=6.06563735429652 learning_rate=0.11570716133941177\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #301 cur_best_loss=0.14999\n",
      "Params: border_count=151.47911489476678 depth=5.0 l2_leaf_reg=3.390432170002335 learning_rate=0.08196838948021974\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #302 cur_best_loss=0.14999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: border_count=214.28258496392172 depth=4.0 l2_leaf_reg=3.951331803973593 learning_rate=0.019610716302638446\n",
      "nb_trees=98                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #303 cur_best_loss=0.14999\n",
      "Params: border_count=203.6363724181065 depth=2.0 l2_leaf_reg=5.117618830284612 learning_rate=0.0525869304602981\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #304 cur_best_loss=0.14999\n",
      "Params: border_count=238.0001248923852 depth=3.0 l2_leaf_reg=3.6142647795965592 learning_rate=0.04653351310729436\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #305 cur_best_loss=0.14999\n",
      "Params: border_count=196.38863401268128 depth=6.0 l2_leaf_reg=5.238887532926778 learning_rate=0.03182514997069541\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #306 cur_best_loss=0.14999\n",
      "Params: border_count=172.1877332059319 depth=6.0 l2_leaf_reg=5.711065584740058 learning_rate=0.025658058400310466\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #307 cur_best_loss=0.14999\n",
      "Params: border_count=184.53994826715532 depth=5.0 l2_leaf_reg=7.161739215364234 learning_rate=0.008907940487713279\n",
      "nb_trees=10                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #308 cur_best_loss=0.14999\n",
      "Params: border_count=115.66870086261099 depth=3.0 l2_leaf_reg=6.02528353017375 learning_rate=0.12468448136778826\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #309 cur_best_loss=0.14999\n",
      "Params: border_count=131.26094111664858 depth=4.0 l2_leaf_reg=5.048279917627101 learning_rate=0.1053172283998112\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #310 cur_best_loss=0.14999\n",
      "Params: border_count=222.13088995861654 depth=2.0 l2_leaf_reg=3.21256237664388 learning_rate=0.0766176148913389\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #311 cur_best_loss=0.14999\n",
      "Params: border_count=148.49792170437527 depth=6.0 l2_leaf_reg=5.379026447560169 learning_rate=0.0401265029273779\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #312 cur_best_loss=0.14999\n",
      "Params: border_count=160.98002415758467 depth=5.0 l2_leaf_reg=4.148590093762339 learning_rate=0.06714104655283369\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #313 cur_best_loss=0.14999\n",
      "Params: border_count=78.18449813248257 depth=6.0 l2_leaf_reg=4.819450867548898 learning_rate=0.0578127313032082\n",
      "nb_trees=100                                                                     \n",
      "100%|██████████| 60/60 [09:24<00:00,  9.40s/trial, best loss: 0.1499898924982758]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'border_count': 167.17236130056529, 'depth': 6.0, 'l2_leaf_reg': 4.614028182064691, 'learning_rate': 0.1332600627875591}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "space = {\n",
    "        'depth': hp.quniform(\"depth\", 1, 6, 1),\n",
    "        'border_count': hp.uniform ('border_count', 32, 255),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -5.0, -2),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best_1 = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=True)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best_1 )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_1.update({'border_count': int(best_1['border_count'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6470018\tbest: 0.6470018 (0)\ttotal: 87.2ms\tremaining: 1m 27s\n",
      "999:\ttest: 0.8048878\tbest: 0.8048878 (999)\ttotal: 1m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8048877684\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb4eb516af0>"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = catboost.CatBoostClassifier(iterations=1000,\n",
    "                    loss_function='Logloss',\n",
    "                    use_best_model=True,\n",
    "                    eval_metric='AUC',\n",
    "                    early_stopping_rounds=300,\n",
    "                    od_type=\"Iter\",\n",
    "                    verbose=2000,\n",
    "                    **best_1\n",
    "                    )\n",
    "\n",
    "model_1.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8048877684482741\n",
      "acc =  0.960187175787602\n",
      "loss =  0.13999716979377957\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"acc = \", sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize a little different metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "\n",
    "obj_call_count = 0\n",
    "cur_best_minus_auc = np.inf\n",
    "\n",
    "N_HYPEROPT_PROBES = 60\n",
    "HYPEROPT_ALGO = tpe.suggest\n",
    "colorama.init()\n",
    "\n",
    "D_train = catboost.Pool(X_train[features_new], y_train)\n",
    "D_test = catboost.Pool(X_test[features_new], y_test)\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_minus_auc\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=100,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='AUC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=10,\n",
    "                                        od_type=\"Iter\",\n",
    "                                        border_count=int(params['border_count']),\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    nb_trees = model.tree_count_\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "    minus_auc = -auc\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} auc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, auc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if minus_auc<cur_best_minus_auc:\n",
    "        cur_best_minus_auc = minus_auc\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST minus_auc={}'.format(cur_best_minus_auc) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':minus_auc, 'status': STATUS_OK }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n",
      "                                                      \n",
      "CatBoost objective call #1 cur_best_loss=    inf\n",
      "Params: border_count=109.6993314873069 depth=5.0 l2_leaf_reg=5.0514002526193575 learning_rate=0.024868377820762948\n",
      "nb_trees=100                                          \n",
      "NEW BEST minus_auc=-0.7631474061602792                \n",
      "                                                                                 \n",
      "CatBoost objective call #2 cur_best_loss=    inf\n",
      "Params: border_count=230.05618272280682 depth=4.0 l2_leaf_reg=7.347526571660698 learning_rate=0.03654557769921731\n",
      "nb_trees=100                                                                     \n",
      "NEW BEST minus_auc=-0.7639561052909645                                           \n",
      "                                                                                 \n",
      "CatBoost objective call #3 cur_best_loss=    inf\n",
      "Params: border_count=173.1553662338939 depth=4.0 l2_leaf_reg=3.36372840221106 learning_rate=0.010043092976782521\n",
      "nb_trees=22                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #4 cur_best_loss=    inf\n",
      "Params: border_count=161.97637268424145 depth=5.0 l2_leaf_reg=3.985611833608085 learning_rate=0.06555334871780769\n",
      "nb_trees=100                                                                     \n",
      "NEW BEST minus_auc=-0.7687290577680499                                           \n",
      "                                                                                 \n",
      "CatBoost objective call #5 cur_best_loss=    inf\n",
      "Params: border_count=209.4538479784205 depth=3.0 l2_leaf_reg=4.066675389784782 learning_rate=0.026860457659976494\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #6 cur_best_loss=    inf\n",
      "Params: border_count=246.3096661863137 depth=5.0 l2_leaf_reg=7.486954987526131 learning_rate=0.02789709664817723\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #7 cur_best_loss=    inf\n",
      "Params: border_count=99.35870376387047 depth=5.0 l2_leaf_reg=5.333394118732432 learning_rate=0.036989445806886324\n",
      "nb_trees=100                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #8 cur_best_loss=    inf\n",
      "Params: border_count=45.93177684682261 depth=4.0 l2_leaf_reg=7.926628291360542 learning_rate=0.020277521011643096\n",
      "nb_trees=92                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #9 cur_best_loss=    inf\n",
      "Params: border_count=199.03866748273958 depth=4.0 l2_leaf_reg=3.0173069070073097 learning_rate=0.04843089081635939\n",
      "nb_trees=99                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #10 cur_best_loss=    inf\n",
      "Params: border_count=219.71462442856452 depth=4.0 l2_leaf_reg=3.273306002622331 learning_rate=0.006969681220674962\n",
      "nb_trees=75                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #11 cur_best_loss=    inf\n",
      "Params: border_count=183.51415021184405 depth=5.0 l2_leaf_reg=7.141508313535886 learning_rate=0.05828765180573929\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #12 cur_best_loss=    inf\n",
      "Params: border_count=246.80203372954927 depth=6.0 l2_leaf_reg=3.5694050628334213 learning_rate=0.06937408397911617\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7707085278005004                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #13 cur_best_loss=    inf\n",
      "Params: border_count=214.1710760107475 depth=2.0 l2_leaf_reg=3.5095623441883292 learning_rate=0.05236206475426316\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #14 cur_best_loss=    inf\n",
      "Params: border_count=91.51371643402716 depth=3.0 l2_leaf_reg=7.3972868869836965 learning_rate=0.061251643710470184\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #15 cur_best_loss=    inf\n",
      "Params: border_count=38.46585696477473 depth=4.0 l2_leaf_reg=6.767347010216354 learning_rate=0.022778171325121114\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #16 cur_best_loss=    inf\n",
      "Params: border_count=103.15726771261212 depth=5.0 l2_leaf_reg=6.61069387378351 learning_rate=0.020119591015190043\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #17 cur_best_loss=    inf\n",
      "Params: border_count=54.00666401505742 depth=1.0 l2_leaf_reg=4.5624408790130415 learning_rate=0.12765220419435025\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #18 cur_best_loss=    inf\n",
      "Params: border_count=82.06461394133655 depth=2.0 l2_leaf_reg=6.150464216334444 learning_rate=0.007274049564253487\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #19 cur_best_loss=    inf\n",
      "Params: border_count=83.10820829379594 depth=3.0 l2_leaf_reg=7.463578830067595 learning_rate=0.00964219495561575\n",
      "nb_trees=74                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #20 cur_best_loss=    inf\n",
      "Params: border_count=141.86240076555916 depth=1.0 l2_leaf_reg=6.197678027300358 learning_rate=0.10663460783222517\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #21 cur_best_loss=    inf\n",
      "Params: border_count=148.10249256136018 depth=6.0 l2_leaf_reg=4.009758587300315 learning_rate=0.08346556733626541\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7721426086617962                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #22 cur_best_loss=    inf\n",
      "Params: border_count=134.0824675500709 depth=6.0 l2_leaf_reg=4.477814952398809 learning_rate=0.09471346838658477\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7728009855383563                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #23 cur_best_loss=    inf\n",
      "Params: border_count=126.98541246341381 depth=6.0 l2_leaf_reg=4.6680910541531055 learning_rate=0.09112262147825097\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #24 cur_best_loss=    inf\n",
      "Params: border_count=120.76009295703743 depth=6.0 l2_leaf_reg=4.745688261859608 learning_rate=0.1347894958088375\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7745284936969374                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #25 cur_best_loss=    inf\n",
      "Params: border_count=125.404231495742 depth=6.0 l2_leaf_reg=5.653701861951282 learning_rate=0.11319401191686929\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #26 cur_best_loss=    inf\n",
      "Params: border_count=71.71354317337018 depth=6.0 l2_leaf_reg=5.773096005690152 learning_rate=0.12316078941033012\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #27 cur_best_loss=    inf\n",
      "Params: border_count=65.86578391575085 depth=6.0 l2_leaf_reg=5.7644289055991695 learning_rate=0.1299975611763093\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7748897664698854                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #28 cur_best_loss=    inf\n",
      "Params: border_count=64.67056835112727 depth=6.0 l2_leaf_reg=5.026906909842536 learning_rate=0.13041700719288182\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7750167491956994                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #29 cur_best_loss=    inf\n",
      "Params: border_count=62.09911718560402 depth=5.0 l2_leaf_reg=5.140025467333146 learning_rate=0.012891435738954017\n",
      "nb_trees=97                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #30 cur_best_loss=    inf\n",
      "Params: border_count=64.30105296299908 depth=5.0 l2_leaf_reg=6.046418073240951 learning_rate=0.07640946123612861\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #31 cur_best_loss=    inf\n",
      "Params: border_count=36.73605394378039 depth=2.0 l2_leaf_reg=5.389017986762385 learning_rate=0.04214932809972193\n",
      "nb_trees=26                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #32 cur_best_loss=    inf\n",
      "Params: border_count=34.79104622370535 depth=6.0 l2_leaf_reg=4.904064906020427 learning_rate=0.015746246892751226\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #33 cur_best_loss=    inf\n",
      "Params: border_count=114.66202050104835 depth=5.0 l2_leaf_reg=5.8648586524960615 learning_rate=0.10047344254451648\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #34 cur_best_loss=    inf\n",
      "Params: border_count=79.13101503264792 depth=6.0 l2_leaf_reg=6.569919576738961 learning_rate=0.033016588654117614\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #35 cur_best_loss=    inf\n",
      "Params: border_count=159.93222251865376 depth=5.0 l2_leaf_reg=4.3126838189971055 learning_rate=0.1339389505404557\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #36 cur_best_loss=    inf\n",
      "Params: border_count=57.08990842923043 depth=4.0 l2_leaf_reg=5.1408842556692855 learning_rate=0.07262576585945156\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #37 cur_best_loss=    inf\n",
      "Params: border_count=94.73761959871831 depth=3.0 l2_leaf_reg=6.880875187272267 learning_rate=0.041858518662950206\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #38 cur_best_loss=    inf\n",
      "Params: border_count=108.6120658718842 depth=5.0 l2_leaf_reg=6.443944504745375 learning_rate=0.053704343876614075\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #39 cur_best_loss=    inf\n",
      "Params: border_count=43.727289947079186 depth=6.0 l2_leaf_reg=7.854245890170464 learning_rate=0.08184707398797653\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #40 cur_best_loss=    inf\n",
      "Params: border_count=180.70352715148465 depth=4.0 l2_leaf_reg=4.257417607528404 learning_rate=0.030434309751835982\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #41 cur_best_loss=    inf\n",
      "Params: border_count=51.23722849552772 depth=5.0 l2_leaf_reg=5.432837951005939 learning_rate=0.04272989088026103\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #42 cur_best_loss=    inf\n",
      "Params: border_count=73.3147766315269 depth=5.0 l2_leaf_reg=4.970952484816755 learning_rate=0.11148909629862781\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #43 cur_best_loss=    inf\n",
      "Params: border_count=153.7059111048308 depth=3.0 l2_leaf_reg=3.7635213513756494 learning_rate=0.06613388834718101\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #44 cur_best_loss=    inf\n",
      "Params: border_count=92.13009543975059 depth=6.0 l2_leaf_reg=3.0738689176064105 learning_rate=0.017032728724280025\n",
      "nb_trees=30                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #45 cur_best_loss=    inf\n",
      "Params: border_count=173.50084788979956 depth=4.0 l2_leaf_reg=6.38495570537237 learning_rate=0.08951392973621969\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #46 cur_best_loss=    inf\n",
      "Params: border_count=231.529615183612 depth=2.0 l2_leaf_reg=6.994250709569539 learning_rate=0.03631539156367302\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #47 cur_best_loss=    inf\n",
      "Params: border_count=105.25678587824956 depth=5.0 l2_leaf_reg=3.8162916656486674 learning_rate=0.008291460350573831\n",
      "nb_trees=58                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #48 cur_best_loss=    inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: border_count=69.27221637804827 depth=4.0 l2_leaf_reg=7.739050351122218 learning_rate=0.06004854079103749\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #49 cur_best_loss=    inf\n",
      "Params: border_count=45.381537362586016 depth=6.0 l2_leaf_reg=5.590631154087692 learning_rate=0.02364756111044745\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #50 cur_best_loss=    inf\n",
      "Params: border_count=135.08447729042402 depth=5.0 l2_leaf_reg=7.160072558507705 learning_rate=0.11908554357146188\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #51 cur_best_loss=    inf\n",
      "Params: border_count=115.89839416231676 depth=1.0 l2_leaf_reg=5.884587316961574 learning_rate=0.026255132323427667\n",
      "nb_trees=24                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #52 cur_best_loss=    inf\n",
      "Params: border_count=84.47982081163595 depth=6.0 l2_leaf_reg=4.231587053710249 learning_rate=0.04868099632042336\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #53 cur_best_loss=    inf\n",
      "Params: border_count=202.6575235833211 depth=3.0 l2_leaf_reg=5.1886845125309575 learning_rate=0.07779191039750064\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #54 cur_best_loss=    inf\n",
      "Params: border_count=33.18784216640252 depth=4.0 l2_leaf_reg=4.832481407551992 learning_rate=0.012899209038978543\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #55 cur_best_loss=    inf\n",
      "Params: border_count=102.01697453857827 depth=6.0 l2_leaf_reg=6.037375152212245 learning_rate=0.1352649511541227\n",
      "nb_trees=100                                                                      \n",
      "NEW BEST minus_auc=-0.7750600863677897                                            \n",
      "                                                                                  \n",
      "CatBoost objective call #56 cur_best_loss=    inf\n",
      "Params: border_count=98.6266902362177 depth=2.0 l2_leaf_reg=7.63939311863549 learning_rate=0.05567720109229945\n",
      "nb_trees=32                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #57 cur_best_loss=    inf\n",
      "Params: border_count=167.71409875656428 depth=5.0 l2_leaf_reg=6.295984412178947 learning_rate=0.09774258282487656\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #58 cur_best_loss=    inf\n",
      "Params: border_count=192.49665548863462 depth=4.0 l2_leaf_reg=6.078700826947065 learning_rate=0.06550991132954637\n",
      "nb_trees=100                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #59 cur_best_loss=    inf\n",
      "Params: border_count=140.9817862197729 depth=6.0 l2_leaf_reg=7.241293098120897 learning_rate=0.019970745001120373\n",
      "nb_trees=99                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #60 cur_best_loss=    inf\n",
      "Params: border_count=132.18730604134277 depth=1.0 l2_leaf_reg=4.505859697132577 learning_rate=0.04666223231276447\n",
      "nb_trees=21                                                                       \n",
      "100%|██████████| 60/60 [09:23<00:00,  9.39s/trial, best loss: -0.7750600863677897]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'border_count': 102.01697453857827, 'depth': 6.0, 'l2_leaf_reg': 6.037375152212245, 'learning_rate': 0.1352649511541227}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "space = {\n",
    "        'depth': hp.quniform(\"depth\", 1, 6, 1),\n",
    "        'border_count': hp.uniform ('border_count', 32, 255),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -5.0, -2),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "       }\n",
    "\n",
    "trials = Trials()\n",
    "best_1 = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=True)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best_1 )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_1.update({'border_count': int(best_1['border_count'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6502255\tbest: 0.6502255 (0)\ttotal: 80ms\tremaining: 1m 19s\n",
      "999:\ttest: 0.8058296\tbest: 0.8058296 (999)\ttotal: 1m 32s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8058295812\n",
      "bestIteration = 999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb3dd57c0d0>"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = catboost.CatBoostClassifier(iterations=1000,\n",
    "                    loss_function='Logloss',\n",
    "                    use_best_model=True,\n",
    "                    eval_metric='AUC',\n",
    "                    early_stopping_rounds=300,\n",
    "                    od_type=\"Iter\",\n",
    "                    verbose=2000,\n",
    "                    **best_1\n",
    "                    )\n",
    "\n",
    "model_1.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.8058295812199296\n",
      "acc =  0.9603102488432442\n",
      "loss =  0.13956042905421484\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"acc = \", sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.25 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "N_HYPEROPT_PROBES = 60\n",
    "HYPEROPT_ALGO = tpe.suggest\n",
    "colorama.init()\n",
    "\n",
    "D_train = catboost.Pool(X_train[features_new].iloc[:10000,:], y_train[:10000])\n",
    "D_test = catboost.Pool(X_test[features_new].iloc[:10000,:], y_test[:10000])\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_loss\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=2000,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='AUC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=300,\n",
    "                                        od_type=\"Iter\",\n",
    "                                        border_count=int(params['border_count']),\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    nb_trees = model.tree_count_\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} auc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, auc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if test_loss<cur_best_loss:\n",
    "        cur_best_loss = test_loss\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':test_loss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 8.34 µs\n",
      "                                                      \n",
      "CatBoost objective call #134 cur_best_loss=0.15293\n",
      "Params: border_count=44.18442618014259 depth=2.0 l2_leaf_reg=5.8501581939044645 learning_rate=0.09565032097424465 random_strength=65.08591493875477\n",
      "nb_trees=263                                          \n",
      "                                                                                \n",
      "CatBoost objective call #135 cur_best_loss=0.15293\n",
      "Params: border_count=181.00620423293208 depth=5.0 l2_leaf_reg=5.050884950163192 learning_rate=0.5163662422796392 random_strength=96.89445930406278\n",
      "nb_trees=11                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #136 cur_best_loss=0.15293\n",
      "Params: border_count=100.99149003513901 depth=6.0 l2_leaf_reg=7.3293545610790645 learning_rate=0.3654930575569984 random_strength=81.48156164279176\n",
      "nb_trees=8                                                                      \n",
      "                                                                                \n",
      "CatBoost objective call #137 cur_best_loss=0.15293\n",
      "Params: border_count=106.54841371722863 depth=4.0 l2_leaf_reg=4.1069715480266344 learning_rate=0.5577046403947515 random_strength=93.92452393319513\n",
      "nb_trees=23                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #138 cur_best_loss=0.15293\n",
      "Params: border_count=168.10970517754805 depth=1.0 l2_leaf_reg=7.092052835166929 learning_rate=0.3371796597538487 random_strength=2.149366080711823\n",
      "nb_trees=68                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #139 cur_best_loss=0.15293\n",
      "Params: border_count=74.52739497115277 depth=1.0 l2_leaf_reg=5.19849553193163 learning_rate=0.9875444626179078 random_strength=65.00397883149427\n",
      "nb_trees=35                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #140 cur_best_loss=0.15293\n",
      "Params: border_count=42.04295718333114 depth=4.0 l2_leaf_reg=6.031499367855329 learning_rate=0.24721891758467168 random_strength=72.50183252940225\n",
      "nb_trees=25                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #141 cur_best_loss=0.15293\n",
      "Params: border_count=240.6576054428329 depth=5.0 l2_leaf_reg=4.1440727381668605 learning_rate=0.6738296768377209 random_strength=10.503342064869292\n",
      "nb_trees=10                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #142 cur_best_loss=0.15293\n",
      "Params: border_count=81.10649686973888 depth=5.0 l2_leaf_reg=7.078499839340713 learning_rate=0.41435786119290685 random_strength=33.53516492500543\n",
      "nb_trees=8                                                                      \n",
      "                                                                                \n",
      "CatBoost objective call #143 cur_best_loss=0.15293\n",
      "Params: border_count=34.846860983341955 depth=6.0 l2_leaf_reg=4.813427850290443 learning_rate=0.8016199331984999 random_strength=98.72941388789592\n",
      "nb_trees=7                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #144 cur_best_loss=0.15293\n",
      "Params: border_count=243.36937732925014 depth=5.0 l2_leaf_reg=7.684045032015407 learning_rate=0.4894663870042468 random_strength=75.69677986812688\n",
      "nb_trees=9                                                                       \n",
      "                                                                                 \n",
      "CatBoost objective call #145 cur_best_loss=0.15293\n",
      "Params: border_count=169.04591846738438 depth=4.0 l2_leaf_reg=5.241129333335412 learning_rate=0.5716314386522445 random_strength=63.308291828019115\n",
      "nb_trees=24                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #146 cur_best_loss=0.15293\n",
      "Params: border_count=49.59657446069101 depth=3.0 l2_leaf_reg=7.271712933808422 learning_rate=0.9513042623235456 random_strength=61.53838239424666\n",
      "nb_trees=10                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #147 cur_best_loss=0.15293\n",
      "Params: border_count=226.63144028271455 depth=4.0 l2_leaf_reg=6.46802637688053 learning_rate=0.4169154940512292 random_strength=66.51359681822474\n",
      "nb_trees=23                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #148 cur_best_loss=0.15293\n",
      "Params: border_count=91.22517517394519 depth=4.0 l2_leaf_reg=5.853303882657348 learning_rate=0.03280534148267044 random_strength=50.698485387492276\n",
      "nb_trees=308                                                                     \n",
      "                                                                                  \n",
      "CatBoost objective call #149 cur_best_loss=0.15293\n",
      "Params: border_count=93.83346256318472 depth=3.0 l2_leaf_reg=4.630215036329332 learning_rate=0.020296643296028254 random_strength=41.62120158550749\n",
      "nb_trees=495                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #150 cur_best_loss=0.15293\n",
      "Params: border_count=244.1887835430775 depth=5.0 l2_leaf_reg=6.798419881298531 learning_rate=0.44631211217553485 random_strength=48.41250149605476\n",
      "nb_trees=15                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #151 cur_best_loss=0.15293\n",
      "Params: border_count=113.32457480572582 depth=3.0 l2_leaf_reg=5.806513803366988 learning_rate=0.02310417935149542 random_strength=12.36587844792999\n",
      "nb_trees=442                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #152 cur_best_loss=0.15293\n",
      "Params: border_count=173.8857703063033 depth=6.0 l2_leaf_reg=4.277853606533914 learning_rate=0.47534427989295774 random_strength=63.140675438880855\n",
      "nb_trees=8                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #153 cur_best_loss=0.15293\n",
      "Params: border_count=129.95613910643868 depth=5.0 l2_leaf_reg=3.004730428968405 learning_rate=0.606411189036293 random_strength=16.421632058171088\n",
      "nb_trees=12                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #154 cur_best_loss=0.15293\n",
      "Params: border_count=72.98531734506048 depth=2.0 l2_leaf_reg=3.028414575475619 learning_rate=0.16123174253198122 random_strength=35.61065085205545\n",
      "nb_trees=125                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #155 cur_best_loss=0.15293\n",
      "Params: border_count=145.19213237831767 depth=3.0 l2_leaf_reg=3.537249821776643 learning_rate=0.01785934380288706 random_strength=41.272154114146105\n",
      "nb_trees=612                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #156 cur_best_loss=0.15293\n",
      "Params: border_count=91.81804941559605 depth=2.0 l2_leaf_reg=4.520900190341971 learning_rate=0.18529922777702634 random_strength=27.676262917810806\n",
      "nb_trees=47                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #157 cur_best_loss=0.15293\n",
      "Params: border_count=128.79665162433673 depth=3.0 l2_leaf_reg=6.2582786948670535 learning_rate=0.08560117605190994 random_strength=52.499454500857176\n",
      "nb_trees=123                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #158 cur_best_loss=0.15293\n",
      "Params: border_count=58.36640352658502 depth=2.0 l2_leaf_reg=3.5607322414973064 learning_rate=0.2678362110461725 random_strength=51.292925450970344\n",
      "nb_trees=70                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #159 cur_best_loss=0.15293\n",
      "Params: border_count=150.3690694543242 depth=3.0 l2_leaf_reg=5.549517548316994 learning_rate=0.0951517515100222 random_strength=22.862540097111378\n",
      "nb_trees=98                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #160 cur_best_loss=0.15293\n",
      "Params: border_count=123.71886049390739 depth=4.0 l2_leaf_reg=3.676471623170402 learning_rate=0.029604464467379226 random_strength=43.955412261819276\n",
      "nb_trees=334                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #161 cur_best_loss=0.15293\n",
      "Params: border_count=201.56102435806264 depth=3.0 l2_leaf_reg=4.64541400007613 learning_rate=0.211231013626036 random_strength=53.32477615049031\n",
      "nb_trees=90                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #162 cur_best_loss=0.15293\n",
      "Params: border_count=60.03804450086947 depth=2.0 l2_leaf_reg=5.65082524570525 learning_rate=0.13488412129398755 random_strength=37.615483078837386\n",
      "nb_trees=108                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #163 cur_best_loss=0.15293\n",
      "Params: border_count=87.978415437917 depth=4.0 l2_leaf_reg=6.561238521352381 learning_rate=0.2938776730899302 random_strength=84.70009789494569\n",
      "nb_trees=24                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #164 cur_best_loss=0.15293\n",
      "Params: border_count=65.14425707626086 depth=3.0 l2_leaf_reg=4.876896791778666 learning_rate=0.7601547585302479 random_strength=29.934399257204355\n",
      "nb_trees=16                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #165 cur_best_loss=0.15293\n",
      "Params: border_count=100.00475445504189 depth=1.0 l2_leaf_reg=5.275623398741375 learning_rate=0.1026171612904937 random_strength=57.949691584600664\n",
      "nb_trees=197                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #166 cur_best_loss=0.15293\n",
      "Params: border_count=120.18708455663052 depth=4.0 l2_leaf_reg=7.885296608505573 learning_rate=0.05043430590237316 random_strength=22.924451957294696\n",
      "nb_trees=160                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #167 cur_best_loss=0.15293\n",
      "Params: border_count=197.1332215075128 depth=2.0 l2_leaf_reg=6.103430860740808 learning_rate=0.861740999407123 random_strength=87.87527727641438\n",
      "nb_trees=20                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #168 cur_best_loss=0.15293\n",
      "Params: border_count=102.31408142916564 depth=4.0 l2_leaf_reg=5.495823103825338 learning_rate=0.34034379080262944 random_strength=46.29260007007628\n",
      "nb_trees=31                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #169 cur_best_loss=0.15293\n",
      "Params: border_count=155.03551611451613 depth=1.0 l2_leaf_reg=3.874384359738321 learning_rate=0.21093823833791905 random_strength=72.99483945657173\n",
      "nb_trees=108                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #170 cur_best_loss=0.15293\n",
      "Params: border_count=32.381505899538155 depth=3.0 l2_leaf_reg=3.267815811426658 learning_rate=0.3186315620236418 random_strength=40.66991393305628\n",
      "nb_trees=32                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #171 cur_best_loss=0.15293\n",
      "Params: border_count=133.0432746086333 depth=5.0 l2_leaf_reg=5.010348247684675 learning_rate=0.3783939062024929 random_strength=0.6424495908564865\n",
      "nb_trees=15                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #172 cur_best_loss=0.15293\n",
      "Params: border_count=111.04093889761259 depth=6.0 l2_leaf_reg=4.403268283825329 learning_rate=0.24751508616242235 random_strength=57.68143566850383\n",
      "nb_trees=18                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #173 cur_best_loss=0.15293\n",
      "Params: border_count=45.61863267284196 depth=4.0 l2_leaf_reg=4.05481326398433 learning_rate=0.1393134937922612 random_strength=30.321460645784157\n",
      "nb_trees=97                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #174 cur_best_loss=0.15293\n",
      "Params: border_count=81.39440939372668 depth=4.0 l2_leaf_reg=6.833709440817965 learning_rate=0.6474173442821425 random_strength=7.172658971608797\n",
      "nb_trees=4                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #175 cur_best_loss=0.15293\n",
      "Params: border_count=136.50831684143773 depth=1.0 l2_leaf_reg=5.867727275173046 learning_rate=0.5285652305755079 random_strength=79.50739285448662\n",
      "nb_trees=55                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #176 cur_best_loss=0.15293\n",
      "Params: border_count=95.15928855030474 depth=5.0 l2_leaf_reg=4.696971071733744 learning_rate=0.7263489358222134 random_strength=68.52866407713107\n",
      "nb_trees=10                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #177 cur_best_loss=0.15293\n",
      "Params: border_count=71.67262381627125 depth=3.0 l2_leaf_reg=7.609760803914591 learning_rate=0.890557695739947 random_strength=18.61596159410884\n",
      "nb_trees=13                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #178 cur_best_loss=0.15293\n",
      "Params: border_count=158.91919921834193 depth=6.0 l2_leaf_reg=5.123199342990559 learning_rate=0.38293115585311965 random_strength=58.96147214012251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=14                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #179 cur_best_loss=0.15293\n",
      "Params: border_count=192.647522737345 depth=2.0 l2_leaf_reg=6.38499911382412 learning_rate=0.05058744390152494 random_strength=90.57868924636776\n",
      "nb_trees=417                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #180 cur_best_loss=0.15293\n",
      "Params: border_count=85.6655200804106 depth=5.0 l2_leaf_reg=6.677850892839218 learning_rate=0.011015500651758806 random_strength=79.11044470093773\n",
      "nb_trees=764                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #181 cur_best_loss=0.15293\n",
      "Params: border_count=53.70038321192758 depth=5.0 l2_leaf_reg=7.318879584327378 learning_rate=0.07254993960872742 random_strength=77.50938375390817\n",
      "nb_trees=92                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #182 cur_best_loss=0.15293\n",
      "Params: border_count=37.538792644236445 depth=6.0 l2_leaf_reg=6.747156543556225 learning_rate=0.22404524555787794 random_strength=94.3056198743675\n",
      "nb_trees=22                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #183 cur_best_loss=0.15293\n",
      "Params: border_count=84.55627516345004 depth=6.0 l2_leaf_reg=7.039335641827886 learning_rate=0.1291205124758347 random_strength=68.86243090267266\n",
      "nb_trees=28                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #184 cur_best_loss=0.15293\n",
      "Params: border_count=215.97460262770215 depth=5.0 l2_leaf_reg=7.544989497476071 learning_rate=0.4372158814584918 random_strength=98.0991405937061\n",
      "nb_trees=16                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #185 cur_best_loss=0.15293\n",
      "Params: border_count=117.12935277990948 depth=5.0 l2_leaf_reg=7.941570897518225 learning_rate=0.17394533359706366 random_strength=81.61549323798458\n",
      "nb_trees=41                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #186 cur_best_loss=0.15293\n",
      "Params: border_count=66.87152182271387 depth=5.0 l2_leaf_reg=6.067564725636159 learning_rate=0.5774983446098495 random_strength=72.4307244726783\n",
      "nb_trees=15                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #187 cur_best_loss=0.15293\n",
      "Params: border_count=183.43738183107277 depth=6.0 l2_leaf_reg=6.648365887140471 learning_rate=0.2886630205743584 random_strength=86.52949144420677\n",
      "nb_trees=22                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #188 cur_best_loss=0.15293\n",
      "Params: border_count=142.99932758655743 depth=4.0 l2_leaf_reg=7.101434643452402 learning_rate=0.0120336012611671 random_strength=93.79884241636705\n",
      "nb_trees=970                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #189 cur_best_loss=0.15293\n",
      "Params: border_count=107.37376147941957 depth=5.0 l2_leaf_reg=6.260901540244173 learning_rate=0.3478317788367574 random_strength=47.837010176983156\n",
      "nb_trees=33                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #190 cur_best_loss=0.15293\n",
      "Params: border_count=42.61241245474173 depth=4.0 l2_leaf_reg=5.389362409549674 learning_rate=0.9904400385214762 random_strength=55.14265031679806\n",
      "nb_trees=5                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #191 cur_best_loss=0.15293\n",
      "Params: border_count=78.41816968220945 depth=6.0 l2_leaf_reg=5.717343866905761 learning_rate=0.5091430077203921 random_strength=65.76690478106542\n",
      "nb_trees=10                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #192 cur_best_loss=0.15293\n",
      "Params: border_count=165.93967065809898 depth=4.0 l2_leaf_reg=6.351126633385954 learning_rate=0.947235379176258 random_strength=74.45302101401266\n",
      "nb_trees=7                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #193 cur_best_loss=0.15293\n",
      "Params: border_count=52.21886753552195 depth=4.0 l2_leaf_reg=5.925804963643834 learning_rate=0.6554948278458106 random_strength=61.55637499591616\n",
      "nb_trees=17                                                                       \n",
      "100%|██████████| 60/60 [03:59<00:00,  4.00s/trial, best loss: 0.15870874253795975]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'border_count': 91.22517517394519, 'depth': 4.0, 'l2_leaf_reg': 5.853303882657348, 'learning_rate': 0.03280534148267044, 'random_strength': 50.698485387492276}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "space = {'depth': hp.quniform(\"depth\", 1, 6, 1),\n",
    "        'border_count': hp.uniform ('border_count', 32, 255),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 1),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "        'random_strength': hp.uniform('random_strength', 0.0, 100)}\n",
    "\n",
    "trials = Trials()\n",
    "best_1 = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=True)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best_1 )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_1.update({'border_count': int(best_1['border_count'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6527584\tbest: 0.6527584 (0)\ttotal: 12.3ms\tremaining: 24.6s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.7591598653\n",
      "bestIteration = 466\n",
      "\n",
      "Shrink model to first 467 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb3dd5626a0>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = catboost.CatBoostClassifier(iterations=2000,\n",
    "                    loss_function='Logloss',\n",
    "                    use_best_model=True,\n",
    "                    eval_metric='AUC',\n",
    "                    early_stopping_rounds=300,\n",
    "                    od_type=\"Iter\",\n",
    "                    verbose=2000,\n",
    "                    **best_1\n",
    "                    )\n",
    "\n",
    "model_1.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.7591598653449091\n",
      "acc =  0.9565\n",
      "loss =  0.15911881855277707\n"
     ]
    }
   ],
   "source": [
    "pred = model_1.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"acc = \", sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1e+03 ns, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "N_HYPEROPT_PROBES = 60\n",
    "HYPEROPT_ALGO = tpe.suggest\n",
    "colorama.init()\n",
    "\n",
    "D_train = catboost.Pool(X_train[features_new].iloc[:10000,:], y_train[:10000])\n",
    "D_test = catboost.Pool(X_test[features_new].iloc[:10000,:], y_test[:10000])\n",
    "\n",
    "\n",
    "def objective(space):\n",
    "    global obj_call_count, cur_best_loss\n",
    "\n",
    "    obj_call_count += 1\n",
    "\n",
    "    print('\\nCatBoost objective call #{} cur_best_loss={:7.5f}'.format(obj_call_count,cur_best_loss) )\n",
    "\n",
    "    params = get_catboost_params(space)\n",
    "\n",
    "    sorted_params = sorted(space.items(), key=lambda z: z[0])\n",
    "    params_str = str.join(' ', ['{}={}'.format(k, v) for k, v in sorted_params])\n",
    "    print('Params: {}'.format(params_str) )\n",
    "\n",
    "    model = catboost.CatBoostClassifier(iterations=10000,\n",
    "                                        learning_rate=params['learning_rate'],\n",
    "                                        depth=int(params['depth']),\n",
    "                                        loss_function='Logloss',\n",
    "                                        use_best_model=True,\n",
    "                                        eval_metric='AUC',\n",
    "                                        l2_leaf_reg=params['l2_leaf_reg'],\n",
    "                                        early_stopping_rounds=300,\n",
    "                                        od_type=\"Iter\",\n",
    "                                        border_count=int(params['border_count']),\n",
    "                                        verbose=False\n",
    "                                        )\n",
    "    \n",
    "    model.fit(D_train, eval_set=D_test, verbose=False)\n",
    "    nb_trees = model.tree_count_\n",
    "\n",
    "    print('nb_trees={}'.format(nb_trees))\n",
    "\n",
    "    y_pred = model.predict_proba(D_test.get_features())\n",
    "    test_loss = sklearn.metrics.log_loss(D_test.get_label(), y_pred, labels=[0, 1])\n",
    "    acc = sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(y_pred, axis=1))\n",
    "    auc = sklearn.metrics.roc_auc_score(D_test.get_label(), y_pred[:,1])\n",
    "\n",
    "    log_writer.write('loss={:<7.5f} acc={} auc={} Params:{} nb_trees={}\\n'.format(test_loss, acc, auc, params_str, nb_trees ))\n",
    "    log_writer.flush()\n",
    "\n",
    "    if test_loss<cur_best_loss:\n",
    "        cur_best_loss = test_loss\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(cur_best_loss) + colorama.Fore.RESET)\n",
    "\n",
    "\n",
    "    return{'loss':test_loss, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.96 µs\n",
      "                                                      \n",
      "CatBoost objective call #194 cur_best_loss=0.15293\n",
      "Params: border_count=65.20347642021926 depth=3.0 l2_leaf_reg=4.326186868317737 learning_rate=0.8513894749565964 random_strength=12.551373577866187\n",
      "nb_trees=10                                           \n",
      "                                                                                \n",
      "CatBoost objective call #195 cur_best_loss=0.15293\n",
      "Params: border_count=251.9806917873872 depth=2.0 l2_leaf_reg=7.079631565898139 learning_rate=0.037484926968818805 random_strength=25.053286842416878\n",
      "nb_trees=629                                                                    \n",
      "                                                                                \n",
      "CatBoost objective call #196 cur_best_loss=0.15293\n",
      "Params: border_count=196.07161919003335 depth=4.0 l2_leaf_reg=4.709714504450045 learning_rate=0.542361630045862 random_strength=86.22630953260236\n",
      "nb_trees=18                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #197 cur_best_loss=0.15293\n",
      "Params: border_count=214.34719805464607 depth=3.0 l2_leaf_reg=3.8471694937838716 learning_rate=0.3511458710481694 random_strength=59.62635369118623\n",
      "nb_trees=34                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #198 cur_best_loss=0.15293\n",
      "Params: border_count=237.13739919746433 depth=2.0 l2_leaf_reg=4.799122525414939 learning_rate=0.8248051752556635 random_strength=80.01314238990813\n",
      "nb_trees=16                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #199 cur_best_loss=0.15293\n",
      "Params: border_count=209.4327647910551 depth=6.0 l2_leaf_reg=4.261033446091111 learning_rate=0.3593258520689405 random_strength=51.53721577075402\n",
      "nb_trees=10                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #200 cur_best_loss=0.15293\n",
      "Params: border_count=206.9413881699181 depth=2.0 l2_leaf_reg=7.076481369738291 learning_rate=0.2809986129464462 random_strength=93.07664162571497\n",
      "nb_trees=47                                                                     \n",
      "                                                                                \n",
      "CatBoost objective call #201 cur_best_loss=0.15293\n",
      "Params: border_count=138.786330114122 depth=4.0 l2_leaf_reg=5.6527280615520645 learning_rate=0.5164574624874935 random_strength=60.54470210741372\n",
      "nb_trees=8                                                                      \n",
      "                                                                                \n",
      "CatBoost objective call #202 cur_best_loss=0.15293\n",
      "Params: border_count=127.49710679401407 depth=4.0 l2_leaf_reg=3.5500995006522813 learning_rate=0.768252395390365 random_strength=84.81063387589491\n",
      "nb_trees=8                                                                      \n",
      "                                                                                \n",
      "CatBoost objective call #203 cur_best_loss=0.15293\n",
      "Params: border_count=115.51798984427874 depth=5.0 l2_leaf_reg=4.669496890899348 learning_rate=0.04209443744345833 random_strength=63.156429931980654\n",
      "nb_trees=180                                                                    \n",
      "                                                                                 \n",
      "CatBoost objective call #204 cur_best_loss=0.15293\n",
      "Params: border_count=77.42326169877984 depth=3.0 l2_leaf_reg=4.434274049366936 learning_rate=0.9594301816674937 random_strength=1.7317513602148282\n",
      "nb_trees=7                                                                       \n",
      "                                                                                 \n",
      "CatBoost objective call #205 cur_best_loss=0.15293\n",
      "Params: border_count=230.3919956137878 depth=5.0 l2_leaf_reg=3.4928527333314845 learning_rate=0.844021050546909 random_strength=87.17503188674324\n",
      "nb_trees=11                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #206 cur_best_loss=0.15293\n",
      "Params: border_count=100.95600596050517 depth=2.0 l2_leaf_reg=6.421334942611628 learning_rate=0.5613694328563098 random_strength=46.35606986617178\n",
      "nb_trees=20                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #207 cur_best_loss=0.15293\n",
      "Params: border_count=175.24380897698427 depth=5.0 l2_leaf_reg=4.141599914012819 learning_rate=0.3523260611725743 random_strength=98.98019197181962\n",
      "nb_trees=20                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #208 cur_best_loss=0.15293\n",
      "Params: border_count=174.7231995488671 depth=2.0 l2_leaf_reg=4.385587303060174 learning_rate=0.9198482947706447 random_strength=17.13026708539559\n",
      "nb_trees=14                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #209 cur_best_loss=0.15293\n",
      "Params: border_count=161.78930495481228 depth=2.0 l2_leaf_reg=3.832448630013207 learning_rate=0.6473423663341985 random_strength=45.52987694252052\n",
      "nb_trees=21                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #210 cur_best_loss=0.15293\n",
      "Params: border_count=74.5604404069211 depth=6.0 l2_leaf_reg=5.988069327151503 learning_rate=0.5401491654056328 random_strength=33.38646760689075\n",
      "nb_trees=9                                                                       \n",
      "                                                                                 \n",
      "CatBoost objective call #211 cur_best_loss=0.15293\n",
      "Params: border_count=220.5829259604433 depth=2.0 l2_leaf_reg=4.6569476772235046 learning_rate=0.31348112615688184 random_strength=30.683492967181923\n",
      "nb_trees=84                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #212 cur_best_loss=0.15293\n",
      "Params: border_count=245.4966801840085 depth=5.0 l2_leaf_reg=7.259149088957506 learning_rate=0.1749434842923906 random_strength=16.613792488052106\n",
      "nb_trees=49                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #213 cur_best_loss=0.15293\n",
      "Params: border_count=110.72552789774186 depth=2.0 l2_leaf_reg=7.634289463349829 learning_rate=0.38563860377278036 random_strength=46.96345302004029\n",
      "nb_trees=53                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #214 cur_best_loss=0.15293\n",
      "Params: border_count=41.134099927201305 depth=1.0 l2_leaf_reg=7.970423304960155 learning_rate=0.04078204313073795 random_strength=72.16470741521063\n",
      "nb_trees=719                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #215 cur_best_loss=0.15293\n",
      "Params: border_count=112.9070335608856 depth=1.0 l2_leaf_reg=3.0177305258836515 learning_rate=0.1655607471955509 random_strength=68.75190004926489\n",
      "nb_trees=121                                                                     \n",
      "                                                                                 \n",
      "CatBoost objective call #216 cur_best_loss=0.15293\n",
      "Params: border_count=93.79244198869785 depth=6.0 l2_leaf_reg=5.192783264657559 learning_rate=0.1981570663660369 random_strength=39.04951889169888\n",
      "nb_trees=33                                                                      \n",
      "                                                                                 \n",
      "CatBoost objective call #217 cur_best_loss=0.15293\n",
      "Params: border_count=46.15864776877508 depth=5.0 l2_leaf_reg=7.962250903395458 learning_rate=0.01054883201695278 random_strength=62.97255102337573\n",
      "nb_trees=778                                                                     \n",
      "                                                                                  \n",
      "CatBoost objective call #218 cur_best_loss=0.15293\n",
      "Params: border_count=35.463299386620804 depth=5.0 l2_leaf_reg=6.25135239011684 learning_rate=0.09502786281633328 random_strength=72.87000753778715\n",
      "nb_trees=53                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #219 cur_best_loss=0.15293\n",
      "Params: border_count=56.800974766046934 depth=5.0 l2_leaf_reg=5.091686133695453 learning_rate=0.09603561533866002 random_strength=60.75519595189867\n",
      "nb_trees=95                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #220 cur_best_loss=0.15293\n",
      "Params: border_count=32.79196994484566 depth=6.0 l2_leaf_reg=5.545566492046892 learning_rate=0.013964421600978574 random_strength=67.13282681831167\n",
      "nb_trees=357                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #221 cur_best_loss=0.15293\n",
      "Params: border_count=50.96227319914183 depth=4.0 l2_leaf_reg=3.0890196307974165 learning_rate=0.2567272447793828 random_strength=55.198009333670115\n",
      "nb_trees=21                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #222 cur_best_loss=0.15293\n",
      "Params: border_count=83.65563610769695 depth=5.0 l2_leaf_reg=6.4872943428845335 learning_rate=0.4367585787063392 random_strength=75.61530323189277\n",
      "nb_trees=8                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #223 cur_best_loss=0.15293\n",
      "Params: border_count=150.08908455650345 depth=6.0 l2_leaf_reg=5.89925109322434 learning_rate=0.09763647461287758 random_strength=64.21578199730185\n",
      "nb_trees=71                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #224 cur_best_loss=0.15293\n",
      "Params: border_count=62.53390308958999 depth=4.0 l2_leaf_reg=5.197610537219247 learning_rate=0.011619758769198196 random_strength=96.91609556362998\n",
      "nb_trees=798                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #225 cur_best_loss=0.15293\n",
      "Params: border_count=60.59875403565047 depth=4.0 l2_leaf_reg=6.772882804472042 learning_rate=0.6584755831082318 random_strength=98.30773962649934\n",
      "nb_trees=10                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #226 cur_best_loss=0.15293\n",
      "Params: border_count=46.95395493802258 depth=3.0 l2_leaf_reg=7.860579559018569 learning_rate=0.20873748937343262 random_strength=94.13319671221673\n",
      "nb_trees=81                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #227 cur_best_loss=0.15293\n",
      "Params: border_count=67.00553541657695 depth=4.0 l2_leaf_reg=5.163399905214646 learning_rate=0.4427529455223552 random_strength=83.32499331771612\n",
      "nb_trees=7                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #228 cur_best_loss=0.15293\n",
      "Params: border_count=33.650159311589874 depth=3.0 l2_leaf_reg=7.499427120005921 learning_rate=0.1343350948116372 random_strength=2.6037464966650745\n",
      "nb_trees=127                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #229 cur_best_loss=0.15293\n",
      "Params: border_count=94.77595683965747 depth=4.0 l2_leaf_reg=6.856370338569154 learning_rate=0.2654842705020691 random_strength=91.66264185944092\n",
      "nb_trees=26                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #230 cur_best_loss=0.15293\n",
      "Params: border_count=126.39665634242408 depth=3.0 l2_leaf_reg=5.8340864448764105 learning_rate=0.015513504738263047 random_strength=79.17592995392894\n",
      "nb_trees=708                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #231 cur_best_loss=0.15293\n",
      "Params: border_count=66.92360374298354 depth=4.0 l2_leaf_reg=4.9654878749072076 learning_rate=0.7192460120103217 random_strength=53.56104146766875\n",
      "nb_trees=8                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #232 cur_best_loss=0.15293\n",
      "Params: border_count=85.80294100880076 depth=6.0 l2_leaf_reg=6.085899535062165 learning_rate=0.46288968842909667 random_strength=25.1856929138398\n",
      "nb_trees=10                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #233 cur_best_loss=0.15293\n",
      "Params: border_count=186.96448745580628 depth=5.0 l2_leaf_reg=5.5667993099697455 learning_rate=0.22532804150410055 random_strength=36.91329006987913\n",
      "nb_trees=32                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #234 cur_best_loss=0.15293\n",
      "Params: border_count=139.70468016101722 depth=4.0 l2_leaf_reg=5.4336079723492725 learning_rate=0.07597124307388649 random_strength=88.03988760873386\n",
      "nb_trees=118                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #235 cur_best_loss=0.15293\n",
      "Params: border_count=126.81218744453102 depth=3.0 l2_leaf_reg=4.0590981857993045 learning_rate=0.3100081353866591 random_strength=78.32956916116025\n",
      "nb_trees=54                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #236 cur_best_loss=0.15293\n",
      "Params: border_count=48.792181704066586 depth=5.0 l2_leaf_reg=6.6627421085982235 learning_rate=0.12700794645521782 random_strength=8.863445057570353\n",
      "nb_trees=31                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #237 cur_best_loss=0.15293\n",
      "Params: border_count=73.87009713713896 depth=4.0 l2_leaf_reg=7.109823251811059 learning_rate=0.5931913270284398 random_strength=56.794551079232754\n",
      "nb_trees=10                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #238 cur_best_loss=0.15293\n",
      "Params: border_count=101.83293915600441 depth=6.0 l2_leaf_reg=3.4293691497029477 learning_rate=0.011548818436253914 random_strength=42.828867977159035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_trees=459                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #239 cur_best_loss=0.15293\n",
      "Params: border_count=146.5046513300961 depth=3.0 l2_leaf_reg=4.837476892656008 learning_rate=0.059477505889160114 random_strength=99.84478005447161\n",
      "nb_trees=218                                                                      \n",
      "                                                                                  \n",
      "CatBoost objective call #240 cur_best_loss=0.15293\n",
      "Params: border_count=159.61660740581436 depth=5.0 l2_leaf_reg=5.341493292962689 learning_rate=0.796323594203127 random_strength=25.398692808891926\n",
      "nb_trees=7                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #241 cur_best_loss=0.15293\n",
      "Params: border_count=198.35839448981085 depth=4.0 l2_leaf_reg=4.565403582960269 learning_rate=0.4866687151510587 random_strength=82.62423365003592\n",
      "nb_trees=22                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #242 cur_best_loss=0.15293\n",
      "Params: border_count=86.22176164076325 depth=5.0 l2_leaf_reg=6.239083475579977 learning_rate=0.9912006453637129 random_strength=90.86087943924005\n",
      "nb_trees=6                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #243 cur_best_loss=0.15293\n",
      "Params: border_count=55.64257863579229 depth=6.0 l2_leaf_reg=3.7434449842948174 learning_rate=0.907275396171314 random_strength=48.99194724412788\n",
      "nb_trees=4                                                                        \n",
      "                                                                                  \n",
      "CatBoost objective call #244 cur_best_loss=0.15293\n",
      "Params: border_count=254.81522914526488 depth=4.0 l2_leaf_reg=5.7274988940869145 learning_rate=0.39412177548335947 random_strength=94.88072421136683\n",
      "nb_trees=15                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #245 cur_best_loss=0.15293\n",
      "Params: border_count=41.89716598135481 depth=5.0 l2_leaf_reg=4.213206205650207 learning_rate=0.30875065106336225 random_strength=69.96818374936309\n",
      "nb_trees=16                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #246 cur_best_loss=0.15293\n",
      "Params: border_count=122.87382122268126 depth=6.0 l2_leaf_reg=7.353630002449913 learning_rate=0.14098538646032555 random_strength=63.93989594703677\n",
      "nb_trees=38                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #247 cur_best_loss=0.15293\n",
      "Params: border_count=105.2833959367943 depth=3.0 l2_leaf_reg=4.443403435151076 learning_rate=0.24156441763666267 random_strength=19.93823580790205\n",
      "nb_trees=51                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #248 cur_best_loss=0.15293\n",
      "Params: border_count=76.91716056903817 depth=5.0 l2_leaf_reg=4.909330673470685 learning_rate=0.17393579551275687 random_strength=29.72726773444774\n",
      "nb_trees=39                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #249 cur_best_loss=0.15293\n",
      "Params: border_count=91.86509457536633 depth=1.0 l2_leaf_reg=3.978052352510903 learning_rate=0.3718599967789505 random_strength=74.801348042858\n",
      "nb_trees=44                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #250 cur_best_loss=0.15293\n",
      "Params: border_count=118.25858514713786 depth=4.0 l2_leaf_reg=7.706078514953699 learning_rate=0.7314193746643417 random_strength=41.58228123013385\n",
      "nb_trees=11                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #251 cur_best_loss=0.15293\n",
      "Params: border_count=135.1475782510953 depth=3.0 l2_leaf_reg=6.517446898688413 learning_rate=0.5948179802479995 random_strength=87.66955385047162\n",
      "nb_trees=15                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #252 cur_best_loss=0.15293\n",
      "Params: border_count=171.0426528961111 depth=2.0 l2_leaf_reg=5.3539372561141825 learning_rate=0.33103559677891736 random_strength=96.15640331709304\n",
      "nb_trees=59                                                                       \n",
      "                                                                                  \n",
      "CatBoost objective call #253 cur_best_loss=0.15293\n",
      "Params: border_count=228.3460537097287 depth=6.0 l2_leaf_reg=6.112746552380052 learning_rate=0.415507235663925 random_strength=57.08394998542045\n",
      "nb_trees=14                                                                       \n",
      "100%|██████████| 60/60 [04:11<00:00,  4.19s/trial, best loss: 0.15894593733351198]\n",
      "--------------------------------------------------\n",
      "The best params:\n",
      "{'border_count': 91, 'depth': 4.0, 'l2_leaf_reg': 5.853303882657348, 'learning_rate': 0.03280534148267044, 'random_strength': 50.698485387492276}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "space = {'depth': hp.quniform(\"depth\", 1, 6, 1),\n",
    "        'border_count': hp.uniform ('border_count', 32, 255),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.01, 1),\n",
    "        'l2_leaf_reg': hp.uniform('l2_leaf_reg', 3, 8),\n",
    "        'random_strength': hp.uniform('random_strength', 0.0, 100)}\n",
    "\n",
    "trials = Trials()\n",
    "best_2 = hyperopt.fmin(fn=objective,\n",
    "                     space=space,\n",
    "                     algo=HYPEROPT_ALGO,\n",
    "                     max_evals=N_HYPEROPT_PROBES,\n",
    "                     trials=trials,\n",
    "                     verbose=True)\n",
    "\n",
    "print('-'*50)\n",
    "print('The best params:')\n",
    "print( best_1 )\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_2.update({'border_count': int(best_2['border_count'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.6663952\tbest: 0.6663952 (0)\ttotal: 14.3ms\tremaining: 2m 22s\n",
      "Stopped by overfitting detector  (300 iterations wait)\n",
      "\n",
      "bestTest = 0.7621648195\n",
      "bestIteration = 940\n",
      "\n",
      "Shrink model to first 941 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa9182520d0>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = catboost.CatBoostClassifier(iterations=10000,\n",
    "                    loss_function='Logloss',\n",
    "                    use_best_model=True,\n",
    "                    eval_metric='AUC',\n",
    "                    early_stopping_rounds=300,\n",
    "                    od_type=\"Iter\",\n",
    "                    verbose=2000,\n",
    "                    **best_2\n",
    "                    )\n",
    "\n",
    "model_2.fit(D_train, eval_set=D_test, verbose=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc =  0.762164819526915\n",
      "acc =  0.9566\n",
      "loss =  0.159220586293924\n"
     ]
    }
   ],
   "source": [
    "pred = model_2.predict_proba(D_test.get_features())\n",
    "print(\"auc = \", sklearn.metrics.roc_auc_score(D_test.get_label(), pred[:,1]))\n",
    "print(\"acc = \", sklearn.metrics.accuracy_score(D_test.get_label(), np.argmax(pred, axis=1)))\n",
    "print(\"loss = \", sklearn.metrics.log_loss(D_test.get_label(), pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoodst + random search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(random_state=0)\n",
    "\n",
    "distributions = {'learning_rate':[0.000001, 0.0001, 0.001, 0.01,0.05, 0.1, 0.5, 1],\n",
    "                 'max_depth' :[1,2,3,4,5,-1],\n",
    "                 'n_estimators':[100,200, 300, 400, 600],\n",
    "                 'random_state':[0],\n",
    "                 'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "                 'subsample': uniform(loc=0.2, scale=0.8), \n",
    "                 'colsample_bytree': uniform(loc=0.4, scale=0.6),\n",
    "                 'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "                 'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "model = RandomizedSearchCV(model, distributions, random_state=0, n_iter = 100, cv = 8, verbose=2, n_jobs = -1)\n",
    "model = model.fit(X_train, y_train)\n",
    "y_pred = model.best_estimator_.predict(X_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "best_params.append(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comapre_data.drop(['x_646'], axis = 1)\n",
    "comapre_data.replace([np.inf, -np.inf], np.nan)\n",
    "comapre_data.dropna(inplace=True)\n",
    "comapre_data = comapre_data.astype('float16')\n",
    "\n",
    "X = comapre_data.drop(columns=['ID', 'TARGET'])\n",
    "y = comapre_data['TARGET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap  # package used to calculate Shap values\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Kernel SHAP to explain test set predictions\n",
    "k_explainer = shap.KernelExplainer(xgb_model, X_train)\n",
    "k_shap_values = k_explainer.shap_values(X_test)\n",
    "shap.force_plot(k_explainer.expected_value[1], k_shap_values[1], data_for_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comapre_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only non numeric and 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = comapre_data[new_important].iloc[:1000,:]\n",
    "y = comapre_data['TARGET'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_train = xgb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All and 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = comapre_data.iloc[:1000,:]\n",
    "y = comapre_data['TARGET'][:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_train = xgb_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_pert_1 and train_part_2 are similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>x_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_10</th>\n",
       "      <th>x_100</th>\n",
       "      <th>x_101</th>\n",
       "      <th>x_102</th>\n",
       "      <th>x_103</th>\n",
       "      <th>x_104</th>\n",
       "      <th>x_105</th>\n",
       "      <th>x_106</th>\n",
       "      <th>x_107</th>\n",
       "      <th>x_108</th>\n",
       "      <th>x_109</th>\n",
       "      <th>x_11</th>\n",
       "      <th>x_110</th>\n",
       "      <th>x_111</th>\n",
       "      <th>x_112</th>\n",
       "      <th>x_113</th>\n",
       "      <th>x_114</th>\n",
       "      <th>x_115</th>\n",
       "      <th>x_116</th>\n",
       "      <th>x_117</th>\n",
       "      <th>x_118</th>\n",
       "      <th>x_119</th>\n",
       "      <th>x_120</th>\n",
       "      <th>x_121</th>\n",
       "      <th>x_122</th>\n",
       "      <th>x_123</th>\n",
       "      <th>x_124</th>\n",
       "      <th>x_125</th>\n",
       "      <th>x_126</th>\n",
       "      <th>x_127</th>\n",
       "      <th>x_128</th>\n",
       "      <th>x_129</th>\n",
       "      <th>x_130</th>\n",
       "      <th>x_131</th>\n",
       "      <th>x_132</th>\n",
       "      <th>x_133</th>\n",
       "      <th>x_134</th>\n",
       "      <th>x_135</th>\n",
       "      <th>x_136</th>\n",
       "      <th>x_137</th>\n",
       "      <th>x_138</th>\n",
       "      <th>x_139</th>\n",
       "      <th>x_14</th>\n",
       "      <th>x_140</th>\n",
       "      <th>x_141</th>\n",
       "      <th>x_142</th>\n",
       "      <th>x_143</th>\n",
       "      <th>x_144</th>\n",
       "      <th>x_145</th>\n",
       "      <th>x_146</th>\n",
       "      <th>x_147</th>\n",
       "      <th>x_148</th>\n",
       "      <th>x_149</th>\n",
       "      <th>x_15</th>\n",
       "      <th>x_150</th>\n",
       "      <th>x_151</th>\n",
       "      <th>x_152</th>\n",
       "      <th>x_153</th>\n",
       "      <th>x_154</th>\n",
       "      <th>x_155</th>\n",
       "      <th>x_156</th>\n",
       "      <th>x_157</th>\n",
       "      <th>x_158</th>\n",
       "      <th>x_159</th>\n",
       "      <th>x_16</th>\n",
       "      <th>x_160</th>\n",
       "      <th>x_161</th>\n",
       "      <th>x_162</th>\n",
       "      <th>x_163</th>\n",
       "      <th>x_164</th>\n",
       "      <th>x_165</th>\n",
       "      <th>x_166</th>\n",
       "      <th>x_167</th>\n",
       "      <th>x_168</th>\n",
       "      <th>x_169</th>\n",
       "      <th>x_170</th>\n",
       "      <th>x_171</th>\n",
       "      <th>x_172</th>\n",
       "      <th>x_173</th>\n",
       "      <th>x_174</th>\n",
       "      <th>x_175</th>\n",
       "      <th>x_176</th>\n",
       "      <th>x_177</th>\n",
       "      <th>x_178</th>\n",
       "      <th>x_179</th>\n",
       "      <th>x_180</th>\n",
       "      <th>x_181</th>\n",
       "      <th>x_182</th>\n",
       "      <th>x_183</th>\n",
       "      <th>x_184</th>\n",
       "      <th>x_185</th>\n",
       "      <th>x_186</th>\n",
       "      <th>x_187</th>\n",
       "      <th>x_188</th>\n",
       "      <th>x_189</th>\n",
       "      <th>x_19</th>\n",
       "      <th>x_190</th>\n",
       "      <th>x_191</th>\n",
       "      <th>x_192</th>\n",
       "      <th>x_193</th>\n",
       "      <th>x_194</th>\n",
       "      <th>x_195</th>\n",
       "      <th>x_196</th>\n",
       "      <th>x_197</th>\n",
       "      <th>x_198</th>\n",
       "      <th>x_199</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_20</th>\n",
       "      <th>x_200</th>\n",
       "      <th>x_201</th>\n",
       "      <th>x_202</th>\n",
       "      <th>x_203</th>\n",
       "      <th>x_204</th>\n",
       "      <th>x_205</th>\n",
       "      <th>x_206</th>\n",
       "      <th>x_207</th>\n",
       "      <th>x_208</th>\n",
       "      <th>x_209</th>\n",
       "      <th>x_210</th>\n",
       "      <th>x_211</th>\n",
       "      <th>x_212</th>\n",
       "      <th>x_213</th>\n",
       "      <th>x_214</th>\n",
       "      <th>x_215</th>\n",
       "      <th>x_216</th>\n",
       "      <th>x_217</th>\n",
       "      <th>x_218</th>\n",
       "      <th>x_219</th>\n",
       "      <th>x_22</th>\n",
       "      <th>x_220</th>\n",
       "      <th>x_221</th>\n",
       "      <th>x_222</th>\n",
       "      <th>x_223</th>\n",
       "      <th>x_224</th>\n",
       "      <th>x_225</th>\n",
       "      <th>x_226</th>\n",
       "      <th>x_227</th>\n",
       "      <th>x_228</th>\n",
       "      <th>x_229</th>\n",
       "      <th>x_23</th>\n",
       "      <th>x_230</th>\n",
       "      <th>x_231</th>\n",
       "      <th>x_232</th>\n",
       "      <th>x_233</th>\n",
       "      <th>x_234</th>\n",
       "      <th>x_235</th>\n",
       "      <th>x_236</th>\n",
       "      <th>x_237</th>\n",
       "      <th>x_238</th>\n",
       "      <th>x_239</th>\n",
       "      <th>x_24</th>\n",
       "      <th>x_240</th>\n",
       "      <th>x_241</th>\n",
       "      <th>x_242</th>\n",
       "      <th>x_243</th>\n",
       "      <th>x_244</th>\n",
       "      <th>x_245</th>\n",
       "      <th>x_246</th>\n",
       "      <th>x_247</th>\n",
       "      <th>x_248</th>\n",
       "      <th>x_249</th>\n",
       "      <th>x_250</th>\n",
       "      <th>x_251</th>\n",
       "      <th>x_252</th>\n",
       "      <th>x_253</th>\n",
       "      <th>x_254</th>\n",
       "      <th>x_255</th>\n",
       "      <th>x_256</th>\n",
       "      <th>x_257</th>\n",
       "      <th>x_258</th>\n",
       "      <th>x_259</th>\n",
       "      <th>x_260</th>\n",
       "      <th>x_261</th>\n",
       "      <th>x_262</th>\n",
       "      <th>x_263</th>\n",
       "      <th>x_264</th>\n",
       "      <th>x_265</th>\n",
       "      <th>x_266</th>\n",
       "      <th>x_267</th>\n",
       "      <th>x_268</th>\n",
       "      <th>x_269</th>\n",
       "      <th>x_270</th>\n",
       "      <th>x_271</th>\n",
       "      <th>x_272</th>\n",
       "      <th>x_273</th>\n",
       "      <th>x_274</th>\n",
       "      <th>x_275</th>\n",
       "      <th>x_276</th>\n",
       "      <th>x_277</th>\n",
       "      <th>x_278</th>\n",
       "      <th>x_279</th>\n",
       "      <th>x_28</th>\n",
       "      <th>x_280</th>\n",
       "      <th>x_281</th>\n",
       "      <th>x_282</th>\n",
       "      <th>x_283</th>\n",
       "      <th>x_284</th>\n",
       "      <th>x_285</th>\n",
       "      <th>x_286</th>\n",
       "      <th>x_287</th>\n",
       "      <th>x_288</th>\n",
       "      <th>x_289</th>\n",
       "      <th>x_29</th>\n",
       "      <th>x_290</th>\n",
       "      <th>x_291</th>\n",
       "      <th>x_292</th>\n",
       "      <th>x_293</th>\n",
       "      <th>x_294</th>\n",
       "      <th>x_295</th>\n",
       "      <th>x_296</th>\n",
       "      <th>x_297</th>\n",
       "      <th>x_298</th>\n",
       "      <th>x_299</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_30</th>\n",
       "      <th>x_300</th>\n",
       "      <th>x_301</th>\n",
       "      <th>x_302</th>\n",
       "      <th>x_303</th>\n",
       "      <th>x_304</th>\n",
       "      <th>x_305</th>\n",
       "      <th>x_306</th>\n",
       "      <th>x_307</th>\n",
       "      <th>x_308</th>\n",
       "      <th>x_309</th>\n",
       "      <th>x_31</th>\n",
       "      <th>x_310</th>\n",
       "      <th>x_311</th>\n",
       "      <th>x_312</th>\n",
       "      <th>x_313</th>\n",
       "      <th>x_314</th>\n",
       "      <th>x_315</th>\n",
       "      <th>x_316</th>\n",
       "      <th>x_317</th>\n",
       "      <th>x_318</th>\n",
       "      <th>x_319</th>\n",
       "      <th>x_32</th>\n",
       "      <th>x_320</th>\n",
       "      <th>x_321</th>\n",
       "      <th>x_322</th>\n",
       "      <th>x_323</th>\n",
       "      <th>x_324</th>\n",
       "      <th>x_325</th>\n",
       "      <th>x_326</th>\n",
       "      <th>x_327</th>\n",
       "      <th>x_328</th>\n",
       "      <th>x_329</th>\n",
       "      <th>x_33</th>\n",
       "      <th>x_330</th>\n",
       "      <th>x_331</th>\n",
       "      <th>x_332</th>\n",
       "      <th>x_333</th>\n",
       "      <th>x_334</th>\n",
       "      <th>x_335</th>\n",
       "      <th>x_336</th>\n",
       "      <th>x_337</th>\n",
       "      <th>x_338</th>\n",
       "      <th>x_339</th>\n",
       "      <th>x_34</th>\n",
       "      <th>x_340</th>\n",
       "      <th>x_341</th>\n",
       "      <th>x_342</th>\n",
       "      <th>x_343</th>\n",
       "      <th>x_344</th>\n",
       "      <th>x_345</th>\n",
       "      <th>x_346</th>\n",
       "      <th>x_347</th>\n",
       "      <th>x_348</th>\n",
       "      <th>x_349</th>\n",
       "      <th>x_35</th>\n",
       "      <th>x_350</th>\n",
       "      <th>x_351</th>\n",
       "      <th>x_352</th>\n",
       "      <th>x_353</th>\n",
       "      <th>x_354</th>\n",
       "      <th>x_355</th>\n",
       "      <th>x_356</th>\n",
       "      <th>x_357</th>\n",
       "      <th>x_358</th>\n",
       "      <th>x_359</th>\n",
       "      <th>x_36</th>\n",
       "      <th>x_360</th>\n",
       "      <th>x_361</th>\n",
       "      <th>x_362</th>\n",
       "      <th>x_363</th>\n",
       "      <th>x_364</th>\n",
       "      <th>x_365</th>\n",
       "      <th>x_366</th>\n",
       "      <th>x_367</th>\n",
       "      <th>x_368</th>\n",
       "      <th>x_369</th>\n",
       "      <th>x_37</th>\n",
       "      <th>x_370</th>\n",
       "      <th>x_371</th>\n",
       "      <th>x_372</th>\n",
       "      <th>x_373</th>\n",
       "      <th>x_374</th>\n",
       "      <th>x_375</th>\n",
       "      <th>x_376</th>\n",
       "      <th>x_377</th>\n",
       "      <th>x_378</th>\n",
       "      <th>x_379</th>\n",
       "      <th>x_38</th>\n",
       "      <th>x_380</th>\n",
       "      <th>x_381</th>\n",
       "      <th>x_382</th>\n",
       "      <th>x_383</th>\n",
       "      <th>x_384</th>\n",
       "      <th>x_385</th>\n",
       "      <th>x_386</th>\n",
       "      <th>x_387</th>\n",
       "      <th>x_388</th>\n",
       "      <th>x_389</th>\n",
       "      <th>x_39</th>\n",
       "      <th>x_390</th>\n",
       "      <th>x_391</th>\n",
       "      <th>x_392</th>\n",
       "      <th>x_393</th>\n",
       "      <th>x_394</th>\n",
       "      <th>x_395</th>\n",
       "      <th>x_396</th>\n",
       "      <th>x_397</th>\n",
       "      <th>x_398</th>\n",
       "      <th>x_399</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_40</th>\n",
       "      <th>x_400</th>\n",
       "      <th>x_401</th>\n",
       "      <th>x_402</th>\n",
       "      <th>x_403</th>\n",
       "      <th>x_404</th>\n",
       "      <th>x_405</th>\n",
       "      <th>x_406</th>\n",
       "      <th>x_407</th>\n",
       "      <th>x_408</th>\n",
       "      <th>x_409</th>\n",
       "      <th>x_41</th>\n",
       "      <th>x_410</th>\n",
       "      <th>x_411</th>\n",
       "      <th>x_412</th>\n",
       "      <th>x_413</th>\n",
       "      <th>x_414</th>\n",
       "      <th>x_415</th>\n",
       "      <th>x_416</th>\n",
       "      <th>x_417</th>\n",
       "      <th>x_418</th>\n",
       "      <th>x_419</th>\n",
       "      <th>x_42</th>\n",
       "      <th>x_420</th>\n",
       "      <th>x_421</th>\n",
       "      <th>x_422</th>\n",
       "      <th>x_423</th>\n",
       "      <th>x_424</th>\n",
       "      <th>x_425</th>\n",
       "      <th>x_426</th>\n",
       "      <th>x_427</th>\n",
       "      <th>x_428</th>\n",
       "      <th>x_429</th>\n",
       "      <th>x_43</th>\n",
       "      <th>x_430</th>\n",
       "      <th>x_431</th>\n",
       "      <th>x_432</th>\n",
       "      <th>x_433</th>\n",
       "      <th>x_434</th>\n",
       "      <th>x_435</th>\n",
       "      <th>x_436</th>\n",
       "      <th>x_437</th>\n",
       "      <th>x_438</th>\n",
       "      <th>x_439</th>\n",
       "      <th>x_44</th>\n",
       "      <th>x_440</th>\n",
       "      <th>x_441</th>\n",
       "      <th>x_442</th>\n",
       "      <th>x_443</th>\n",
       "      <th>x_444</th>\n",
       "      <th>x_445</th>\n",
       "      <th>x_446</th>\n",
       "      <th>x_447</th>\n",
       "      <th>x_448</th>\n",
       "      <th>x_449</th>\n",
       "      <th>x_45</th>\n",
       "      <th>x_450</th>\n",
       "      <th>x_451</th>\n",
       "      <th>x_452</th>\n",
       "      <th>x_453</th>\n",
       "      <th>x_454</th>\n",
       "      <th>x_455</th>\n",
       "      <th>x_456</th>\n",
       "      <th>x_457</th>\n",
       "      <th>x_458</th>\n",
       "      <th>x_459</th>\n",
       "      <th>x_46</th>\n",
       "      <th>x_460</th>\n",
       "      <th>x_461</th>\n",
       "      <th>x_462</th>\n",
       "      <th>x_463</th>\n",
       "      <th>x_464</th>\n",
       "      <th>x_465</th>\n",
       "      <th>x_466</th>\n",
       "      <th>x_467</th>\n",
       "      <th>x_468</th>\n",
       "      <th>x_469</th>\n",
       "      <th>x_47</th>\n",
       "      <th>x_470</th>\n",
       "      <th>x_471</th>\n",
       "      <th>x_472</th>\n",
       "      <th>x_473</th>\n",
       "      <th>x_474</th>\n",
       "      <th>x_475</th>\n",
       "      <th>x_476</th>\n",
       "      <th>x_477</th>\n",
       "      <th>x_478</th>\n",
       "      <th>x_479</th>\n",
       "      <th>x_48</th>\n",
       "      <th>x_480</th>\n",
       "      <th>x_481</th>\n",
       "      <th>x_482</th>\n",
       "      <th>x_483</th>\n",
       "      <th>x_484</th>\n",
       "      <th>x_485</th>\n",
       "      <th>x_486</th>\n",
       "      <th>x_487</th>\n",
       "      <th>x_488</th>\n",
       "      <th>x_489</th>\n",
       "      <th>x_49</th>\n",
       "      <th>x_490</th>\n",
       "      <th>x_491</th>\n",
       "      <th>x_492</th>\n",
       "      <th>x_493</th>\n",
       "      <th>x_494</th>\n",
       "      <th>x_495</th>\n",
       "      <th>x_496</th>\n",
       "      <th>x_497</th>\n",
       "      <th>x_498</th>\n",
       "      <th>x_499</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_50</th>\n",
       "      <th>x_500</th>\n",
       "      <th>x_501</th>\n",
       "      <th>x_502</th>\n",
       "      <th>x_503</th>\n",
       "      <th>x_504</th>\n",
       "      <th>x_505</th>\n",
       "      <th>x_506</th>\n",
       "      <th>x_507</th>\n",
       "      <th>x_508</th>\n",
       "      <th>x_509</th>\n",
       "      <th>x_51</th>\n",
       "      <th>x_510</th>\n",
       "      <th>x_511</th>\n",
       "      <th>x_512</th>\n",
       "      <th>x_513</th>\n",
       "      <th>x_514</th>\n",
       "      <th>x_515</th>\n",
       "      <th>x_516</th>\n",
       "      <th>x_517</th>\n",
       "      <th>x_518</th>\n",
       "      <th>x_519</th>\n",
       "      <th>x_52</th>\n",
       "      <th>x_520</th>\n",
       "      <th>x_521</th>\n",
       "      <th>x_522</th>\n",
       "      <th>x_523</th>\n",
       "      <th>x_524</th>\n",
       "      <th>x_525</th>\n",
       "      <th>x_526</th>\n",
       "      <th>x_527</th>\n",
       "      <th>x_528</th>\n",
       "      <th>x_529</th>\n",
       "      <th>x_53</th>\n",
       "      <th>x_530</th>\n",
       "      <th>x_531</th>\n",
       "      <th>x_532</th>\n",
       "      <th>x_533</th>\n",
       "      <th>x_534</th>\n",
       "      <th>x_535</th>\n",
       "      <th>x_536</th>\n",
       "      <th>x_537</th>\n",
       "      <th>x_538</th>\n",
       "      <th>x_539</th>\n",
       "      <th>x_54</th>\n",
       "      <th>x_540</th>\n",
       "      <th>x_541</th>\n",
       "      <th>x_542</th>\n",
       "      <th>x_543</th>\n",
       "      <th>x_544</th>\n",
       "      <th>x_545</th>\n",
       "      <th>x_546</th>\n",
       "      <th>x_547</th>\n",
       "      <th>x_548</th>\n",
       "      <th>x_549</th>\n",
       "      <th>x_55</th>\n",
       "      <th>x_550</th>\n",
       "      <th>x_551</th>\n",
       "      <th>x_552</th>\n",
       "      <th>x_553</th>\n",
       "      <th>x_554</th>\n",
       "      <th>x_555</th>\n",
       "      <th>x_556</th>\n",
       "      <th>x_557</th>\n",
       "      <th>x_558</th>\n",
       "      <th>x_559</th>\n",
       "      <th>x_56</th>\n",
       "      <th>x_560</th>\n",
       "      <th>x_561</th>\n",
       "      <th>x_562</th>\n",
       "      <th>x_563</th>\n",
       "      <th>x_564</th>\n",
       "      <th>x_565</th>\n",
       "      <th>x_566</th>\n",
       "      <th>x_567</th>\n",
       "      <th>x_568</th>\n",
       "      <th>x_569</th>\n",
       "      <th>x_57</th>\n",
       "      <th>x_570</th>\n",
       "      <th>x_571</th>\n",
       "      <th>x_572</th>\n",
       "      <th>x_573</th>\n",
       "      <th>x_574</th>\n",
       "      <th>x_575</th>\n",
       "      <th>x_576</th>\n",
       "      <th>x_577</th>\n",
       "      <th>x_578</th>\n",
       "      <th>x_579</th>\n",
       "      <th>x_58</th>\n",
       "      <th>x_580</th>\n",
       "      <th>x_581</th>\n",
       "      <th>x_582</th>\n",
       "      <th>x_583</th>\n",
       "      <th>x_584</th>\n",
       "      <th>x_585</th>\n",
       "      <th>x_586</th>\n",
       "      <th>x_587</th>\n",
       "      <th>x_588</th>\n",
       "      <th>x_589</th>\n",
       "      <th>x_59</th>\n",
       "      <th>x_590</th>\n",
       "      <th>x_591</th>\n",
       "      <th>x_592</th>\n",
       "      <th>x_593</th>\n",
       "      <th>x_594</th>\n",
       "      <th>x_595</th>\n",
       "      <th>x_596</th>\n",
       "      <th>x_597</th>\n",
       "      <th>x_598</th>\n",
       "      <th>x_599</th>\n",
       "      <th>x_60</th>\n",
       "      <th>x_600</th>\n",
       "      <th>x_601</th>\n",
       "      <th>x_602</th>\n",
       "      <th>x_603</th>\n",
       "      <th>x_604</th>\n",
       "      <th>x_605</th>\n",
       "      <th>x_606</th>\n",
       "      <th>x_607</th>\n",
       "      <th>x_608</th>\n",
       "      <th>x_609</th>\n",
       "      <th>x_61</th>\n",
       "      <th>x_610</th>\n",
       "      <th>x_611</th>\n",
       "      <th>x_612</th>\n",
       "      <th>x_613</th>\n",
       "      <th>x_614</th>\n",
       "      <th>x_615</th>\n",
       "      <th>x_616</th>\n",
       "      <th>x_619</th>\n",
       "      <th>x_62</th>\n",
       "      <th>x_620</th>\n",
       "      <th>x_621</th>\n",
       "      <th>x_622</th>\n",
       "      <th>x_623</th>\n",
       "      <th>x_624</th>\n",
       "      <th>x_626</th>\n",
       "      <th>x_627</th>\n",
       "      <th>x_629</th>\n",
       "      <th>x_63</th>\n",
       "      <th>x_630</th>\n",
       "      <th>x_631</th>\n",
       "      <th>x_632</th>\n",
       "      <th>x_633</th>\n",
       "      <th>x_634</th>\n",
       "      <th>x_635</th>\n",
       "      <th>x_636</th>\n",
       "      <th>x_637</th>\n",
       "      <th>x_638</th>\n",
       "      <th>x_639</th>\n",
       "      <th>x_64</th>\n",
       "      <th>x_640</th>\n",
       "      <th>x_641</th>\n",
       "      <th>x_642</th>\n",
       "      <th>x_643</th>\n",
       "      <th>x_644</th>\n",
       "      <th>x_645</th>\n",
       "      <th>x_646</th>\n",
       "      <th>x_65</th>\n",
       "      <th>x_66</th>\n",
       "      <th>x_67</th>\n",
       "      <th>x_68</th>\n",
       "      <th>x_69</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_70</th>\n",
       "      <th>x_71</th>\n",
       "      <th>x_72</th>\n",
       "      <th>x_73</th>\n",
       "      <th>x_74</th>\n",
       "      <th>x_75</th>\n",
       "      <th>x_76</th>\n",
       "      <th>x_77</th>\n",
       "      <th>x_78</th>\n",
       "      <th>x_79</th>\n",
       "      <th>x_80</th>\n",
       "      <th>x_81</th>\n",
       "      <th>x_82</th>\n",
       "      <th>x_83</th>\n",
       "      <th>x_84</th>\n",
       "      <th>x_85</th>\n",
       "      <th>x_86</th>\n",
       "      <th>x_87</th>\n",
       "      <th>x_88</th>\n",
       "      <th>x_89</th>\n",
       "      <th>x_90</th>\n",
       "      <th>x_91</th>\n",
       "      <th>x_92</th>\n",
       "      <th>x_93</th>\n",
       "      <th>x_94</th>\n",
       "      <th>x_95</th>\n",
       "      <th>x_96</th>\n",
       "      <th>x_97</th>\n",
       "      <th>x_98</th>\n",
       "      <th>x_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-881.000000</td>\n",
       "      <td>-881.000000</td>\n",
       "      <td>-881.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>947.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-404.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-300.000000</td>\n",
       "      <td>-300.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.00000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>947.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>947.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>-471.000000</td>\n",
       "      <td>-394.000000</td>\n",
       "      <td>-471.000000</td>\n",
       "      <td>-394.000000</td>\n",
       "      <td>-391.000000</td>\n",
       "      <td>-300.000000</td>\n",
       "      <td>-335.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-553.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.00000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>862.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-508.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-585.000000</td>\n",
       "      <td>-585.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-763.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-763.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-763.000000</td>\n",
       "      <td>-351.000000</td>\n",
       "      <td>-564.000000</td>\n",
       "      <td>-351.000000</td>\n",
       "      <td>-564.000000</td>\n",
       "      <td>-888.000000</td>\n",
       "      <td>-585.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-610.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-822.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-1082.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.00000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>591.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-567.000000</td>\n",
       "      <td>-567.000000</td>\n",
       "      <td>-567.000000</td>\n",
       "      <td>-552.000000</td>\n",
       "      <td>-793.000000</td>\n",
       "      <td>-552.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-793.000000</td>\n",
       "      <td>-552.000000</td>\n",
       "      <td>-793.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>-425.000000</td>\n",
       "      <td>-793.000000</td>\n",
       "      <td>-422.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-479.000000</td>\n",
       "      <td>-422.000000</td>\n",
       "      <td>-479.000000</td>\n",
       "      <td>-422.000000</td>\n",
       "      <td>-479.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>-84.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>924.000000</td>\n",
       "      <td>-203.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-479.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-498.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-498.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-498.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>-751.000000</td>\n",
       "      <td>-498.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-318.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-2.240000e+02</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-4.00000</td>\n",
       "      <td>-318.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.00000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-493.000000</td>\n",
       "      <td>-569.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-349.000000</td>\n",
       "      <td>389.000000</td>\n",
       "      <td>-336.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>-171.000000</td>\n",
       "      <td>-116.000000</td>\n",
       "      <td>-216.000000</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>-185.000000</td>\n",
       "      <td>-65.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-218.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-2.240000e+02</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-2.240000e+02</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-599.000000</td>\n",
       "      <td>-89.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-599.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-329.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-329.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-24.000000</td>\n",
       "      <td>-254.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-2.240000e+02</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-224.0</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-246.000000</td>\n",
       "      <td>-249.000000</td>\n",
       "      <td>-246.000000</td>\n",
       "      <td>-249.000000</td>\n",
       "      <td>-246.000000</td>\n",
       "      <td>-249.000000</td>\n",
       "      <td>-270.000000</td>\n",
       "      <td>-270.000000</td>\n",
       "      <td>-270.000000</td>\n",
       "      <td>-465.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-253.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-224.000000</td>\n",
       "      <td>-4.650000e+02</td>\n",
       "      <td>-1082.000000</td>\n",
       "      <td>-464.000000</td>\n",
       "      <td>-763.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-103.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-105.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-1082.000000</td>\n",
       "      <td>-4.000000e+00</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-782.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-246.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-465.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-465.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>-107.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>-107.000000</td>\n",
       "      <td>-483.000000</td>\n",
       "      <td>-318.000000</td>\n",
       "      <td>-265.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-357.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-496.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "      <td>-248.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>971578.005803</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1499.563706</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.024427</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.021305</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.08515</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.025606</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.024427</td>\n",
       "      <td>-0.008634</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-0.000574</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000377</td>\n",
       "      <td>-0.000684</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>0.128976</td>\n",
       "      <td>0.042056</td>\n",
       "      <td>0.055002</td>\n",
       "      <td>-0.069558</td>\n",
       "      <td>-0.025717</td>\n",
       "      <td>-0.032926</td>\n",
       "      <td>-0.029325</td>\n",
       "      <td>0.114364</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>0.053419</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.007020</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>-0.000597</td>\n",
       "      <td>-0.012176</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>-0.000363</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.00079</td>\n",
       "      <td>-0.000287</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>-0.000319</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.000362</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.00067</td>\n",
       "      <td>-0.001382</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.014868</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.003153</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>31.644734</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-0.004284</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>-0.000320</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>-0.001282</td>\n",
       "      <td>-0.003366</td>\n",
       "      <td>-0.000796</td>\n",
       "      <td>-0.000197</td>\n",
       "      <td>0.08515</td>\n",
       "      <td>-0.001555</td>\n",
       "      <td>-0.004284</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>-0.003610</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>-0.000143</td>\n",
       "      <td>1499.563706</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.002407</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>0.040824</td>\n",
       "      <td>0.013496</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>-0.040651</td>\n",
       "      <td>-0.017797</td>\n",
       "      <td>8116.755139</td>\n",
       "      <td>-0.018535</td>\n",
       "      <td>-0.017931</td>\n",
       "      <td>0.054291</td>\n",
       "      <td>-0.010960</td>\n",
       "      <td>0.020098</td>\n",
       "      <td>0.018688</td>\n",
       "      <td>-0.011038</td>\n",
       "      <td>0.013884</td>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.014659</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.000513</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>-0.000751</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.000333</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.000779</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>-0.001270</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.001269</td>\n",
       "      <td>-0.000340</td>\n",
       "      <td>-0.001233</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>-0.000114</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.033862</td>\n",
       "      <td>-0.002529</td>\n",
       "      <td>-0.000628</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>-0.012232</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.00322</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.041171</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>-0.000407</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>0.032833</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>-0.018523</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.004781</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000382</td>\n",
       "      <td>-0.001506</td>\n",
       "      <td>-0.000972</td>\n",
       "      <td>1276.584897</td>\n",
       "      <td>1425.891890</td>\n",
       "      <td>1594.680256</td>\n",
       "      <td>-0.007857</td>\n",
       "      <td>2981.316371</td>\n",
       "      <td>1180.314018</td>\n",
       "      <td>915.790222</td>\n",
       "      <td>0.002858</td>\n",
       "      <td>-0.010786</td>\n",
       "      <td>-0.019496</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.006067</td>\n",
       "      <td>2201.720629</td>\n",
       "      <td>-0.006355</td>\n",
       "      <td>2242.259659</td>\n",
       "      <td>2933.734333</td>\n",
       "      <td>3559.660135</td>\n",
       "      <td>1662.597419</td>\n",
       "      <td>1433.360827</td>\n",
       "      <td>-0.009407</td>\n",
       "      <td>-0.010848</td>\n",
       "      <td>-0.003780</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.018818</td>\n",
       "      <td>0.082339</td>\n",
       "      <td>-1032.345333</td>\n",
       "      <td>906.111932</td>\n",
       "      <td>-580.964906</td>\n",
       "      <td>1915.759128</td>\n",
       "      <td>-1317.609597</td>\n",
       "      <td>349.438419</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>-0.055176</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>-0.002639</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.117211</td>\n",
       "      <td>-0.000730</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.002085</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.006747</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>-0.017210</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>9.253045e-07</td>\n",
       "      <td>-0.000168</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>1014.43072</td>\n",
       "      <td>-0.004725</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.001073</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000336</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.010431</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>-0.000561</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>-0.00142</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.001153</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.001152</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>0.011402</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>18.882688</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>5.811196</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>0.012937</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.026102</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>-0.004954</td>\n",
       "      <td>67.667436</td>\n",
       "      <td>-0.015699</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-0.020162</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.022329</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>-0.006609</td>\n",
       "      <td>-0.008830</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.016212</td>\n",
       "      <td>-0.015824</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>0.028453</td>\n",
       "      <td>0.031768</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.001498</td>\n",
       "      <td>-0.001731</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>-0.002333</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>-0.000329</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>2665.938526</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>-0.001781</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.599564e-08</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>2.065951e-08</td>\n",
       "      <td>-0.001805</td>\n",
       "      <td>-0.000982</td>\n",
       "      <td>-0.002787</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>-0.000332</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000562</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000863</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>-0.000183</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>8082.993127</td>\n",
       "      <td>2689.502945</td>\n",
       "      <td>439.187284</td>\n",
       "      <td>85.523897</td>\n",
       "      <td>-0.001487</td>\n",
       "      <td>62.009477</td>\n",
       "      <td>5047.492374</td>\n",
       "      <td>-0.007700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000294</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.005138</td>\n",
       "      <td>-0.000304</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.065951e-08</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>-0.000371</td>\n",
       "      <td>-0.001483</td>\n",
       "      <td>-0.001431</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>-0.000261</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>-0.001718</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>-0.000854</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>1821.912495</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.026028</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.015047</td>\n",
       "      <td>0.017836</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>-0.102906</td>\n",
       "      <td>0.094645</td>\n",
       "      <td>-0.036238</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.045563</td>\n",
       "      <td>-0.031143</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>636.356841</td>\n",
       "      <td>326.769116</td>\n",
       "      <td>994.333121</td>\n",
       "      <td>1736.339336</td>\n",
       "      <td>747.664456</td>\n",
       "      <td>961.509423</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>-0.001618</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>8.756610e-07</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1499.563706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>1712.091893</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>0.007898</td>\n",
       "      <td>1840.928505</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92.886731</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>-0.001721</td>\n",
       "      <td>2.928901e+05</td>\n",
       "      <td>67.165313</td>\n",
       "      <td>77.484640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.405292</td>\n",
       "      <td>-0.001051</td>\n",
       "      <td>14.263849</td>\n",
       "      <td>144.649953</td>\n",
       "      <td>-0.000425</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>-0.105325</td>\n",
       "      <td>-0.054781</td>\n",
       "      <td>1.521508</td>\n",
       "      <td>0.023061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001039</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.001443</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>-0.002098</td>\n",
       "      <td>2540.323651</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>-0.001928</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>-0.004864</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.003175</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>-0.003603</td>\n",
       "      <td>-0.000080</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>-0.001859</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>-0.001597</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>282.852694</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4473.288192</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>-0.000682</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.005063</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.18970</td>\n",
       "      <td>-0.003307</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>-0.049185</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>0.069933</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.073064</td>\n",
       "      <td>0.092015</td>\n",
       "      <td>0.047265</td>\n",
       "      <td>0.038234</td>\n",
       "      <td>0.376431</td>\n",
       "      <td>-0.033236</td>\n",
       "      <td>-0.051396</td>\n",
       "      <td>-0.046083</td>\n",
       "      <td>0.409463</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>0.128589</td>\n",
       "      <td>0.206866</td>\n",
       "      <td>0.428176</td>\n",
       "      <td>0.072924</td>\n",
       "      <td>0.291923</td>\n",
       "      <td>0.274152</td>\n",
       "      <td>0.302228</td>\n",
       "      <td>0.226257</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.020959</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-3.534072</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000592</td>\n",
       "      <td>-0.000338</td>\n",
       "      <td>-0.001864</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.000507</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>0.007834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.184413</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.260542</td>\n",
       "      <td>0.243937</td>\n",
       "      <td>0.010763</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>182.889382</td>\n",
       "      <td>0.039927</td>\n",
       "      <td>0.030175</td>\n",
       "      <td>0.022995</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.055206</td>\n",
       "      <td>0.109378</td>\n",
       "      <td>0.066444</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>-0.002195</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>0.18970</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>-0.003457</td>\n",
       "      <td>-0.077485</td>\n",
       "      <td>-0.079018</td>\n",
       "      <td>-0.026932</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>-0.000734</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>4473.288192</td>\n",
       "      <td>-0.001163</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>-0.399389</td>\n",
       "      <td>0.198025</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.090661</td>\n",
       "      <td>-0.008217</td>\n",
       "      <td>0.038111</td>\n",
       "      <td>0.290371</td>\n",
       "      <td>-0.033638</td>\n",
       "      <td>40621.021783</td>\n",
       "      <td>-0.039477</td>\n",
       "      <td>-0.037675</td>\n",
       "      <td>0.224224</td>\n",
       "      <td>0.055407</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.344071</td>\n",
       "      <td>-0.032997</td>\n",
       "      <td>0.103780</td>\n",
       "      <td>0.112162</td>\n",
       "      <td>0.108179</td>\n",
       "      <td>0.069592</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>0.019294</td>\n",
       "      <td>0.015514</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.007109</td>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>-0.000255</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.001572</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.002567</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>-0.002599</td>\n",
       "      <td>-0.000121</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.001973</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>-0.021271</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>0.006843</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004951</td>\n",
       "      <td>0.004101</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.070735</td>\n",
       "      <td>0.011366</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.008007</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.168822</td>\n",
       "      <td>0.280044</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.040116</td>\n",
       "      <td>0.260253</td>\n",
       "      <td>0.24378</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.039810</td>\n",
       "      <td>0.030158</td>\n",
       "      <td>0.023014</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001166</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.054796</td>\n",
       "      <td>0.109260</td>\n",
       "      <td>0.064080</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.006704</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.001166</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.086297</td>\n",
       "      <td>0.009371</td>\n",
       "      <td>0.021675</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>-0.020770</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000162</td>\n",
       "      <td>-0.071502</td>\n",
       "      <td>-0.273385</td>\n",
       "      <td>-0.034318</td>\n",
       "      <td>12825.727935</td>\n",
       "      <td>8556.910787</td>\n",
       "      <td>-7856.959936</td>\n",
       "      <td>-0.023247</td>\n",
       "      <td>-403.274405</td>\n",
       "      <td>17365.371515</td>\n",
       "      <td>8914.214895</td>\n",
       "      <td>-0.001922</td>\n",
       "      <td>-0.002003</td>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.001645</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.029026</td>\n",
       "      <td>25848.747753</td>\n",
       "      <td>-0.022683</td>\n",
       "      <td>20750.915477</td>\n",
       "      <td>43758.143787</td>\n",
       "      <td>48201.972386</td>\n",
       "      <td>19245.850658</td>\n",
       "      <td>13222.772605</td>\n",
       "      <td>-0.006756</td>\n",
       "      <td>-0.009062</td>\n",
       "      <td>-0.011801</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.048627</td>\n",
       "      <td>0.190848</td>\n",
       "      <td>-32227.070935</td>\n",
       "      <td>-6849.602166</td>\n",
       "      <td>-46754.917871</td>\n",
       "      <td>-32503.494174</td>\n",
       "      <td>-12629.313979</td>\n",
       "      <td>5636.455254</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.007938</td>\n",
       "      <td>0.112121</td>\n",
       "      <td>-0.002789</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.193951</td>\n",
       "      <td>-0.028685</td>\n",
       "      <td>0.042490</td>\n",
       "      <td>0.010004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>-0.001490</td>\n",
       "      <td>0.107308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.179717</td>\n",
       "      <td>0.099773</td>\n",
       "      <td>0.260518</td>\n",
       "      <td>0.026858</td>\n",
       "      <td>0.074682</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.093404</td>\n",
       "      <td>-0.020043</td>\n",
       "      <td>0.021801</td>\n",
       "      <td>-0.006222</td>\n",
       "      <td>0.009939</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>-0.011989</td>\n",
       "      <td>0.002246</td>\n",
       "      <td>6.020113e-03</td>\n",
       "      <td>0.011358</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>-0.018620</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>-0.026217</td>\n",
       "      <td>4009.43419</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.011686</td>\n",
       "      <td>0.166906</td>\n",
       "      <td>-0.035781</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>0.252039</td>\n",
       "      <td>0.026770</td>\n",
       "      <td>-0.020540</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>-0.009601</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.00553</td>\n",
       "      <td>0.012326</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>-0.023277</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>-0.001508</td>\n",
       "      <td>-0.001174</td>\n",
       "      <td>-0.001800</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>0.018341</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.000386</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>-0.000326</td>\n",
       "      <td>1852.787661</td>\n",
       "      <td>0.014697</td>\n",
       "      <td>455.672355</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>-0.018173</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>-0.004610</td>\n",
       "      <td>6565.938441</td>\n",
       "      <td>-0.084602</td>\n",
       "      <td>0.011515</td>\n",
       "      <td>-0.184576</td>\n",
       "      <td>-0.033360</td>\n",
       "      <td>-0.128675</td>\n",
       "      <td>-0.184679</td>\n",
       "      <td>-0.015638</td>\n",
       "      <td>-0.022577</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.012332</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>-0.250458</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>-0.022139</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.013021</td>\n",
       "      <td>0.008467</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.000521</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>0.007188</td>\n",
       "      <td>0.006772</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.007179</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>9123.948706</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.007520</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.002699</td>\n",
       "      <td>-0.002487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.431505e-06</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>0.010688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>2.939630e-06</td>\n",
       "      <td>-0.013104</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>-0.015675</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>-0.001741</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.000308</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009289</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>-0.004300</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.000604</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>56640.863126</td>\n",
       "      <td>35655.502744</td>\n",
       "      <td>1379.050374</td>\n",
       "      <td>448.437418</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>1008.776877</td>\n",
       "      <td>45447.967831</td>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011989</td>\n",
       "      <td>-0.011686</td>\n",
       "      <td>-0.002733</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.005111</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>-0.034306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.939630e-06</td>\n",
       "      <td>-0.000479</td>\n",
       "      <td>-0.018863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.030885</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>0.011558</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.005669</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>24686.989838</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.027003</td>\n",
       "      <td>0.133084</td>\n",
       "      <td>0.036942</td>\n",
       "      <td>-0.196997</td>\n",
       "      <td>0.245038</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.091749</td>\n",
       "      <td>0.008077</td>\n",
       "      <td>-0.022460</td>\n",
       "      <td>0.008147</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>9488.047429</td>\n",
       "      <td>-6248.803987</td>\n",
       "      <td>-7995.435572</td>\n",
       "      <td>10878.379816</td>\n",
       "      <td>7727.761173</td>\n",
       "      <td>-1209.668312</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-2.231914e-04</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4473.288192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009830</td>\n",
       "      <td>5445.677702</td>\n",
       "      <td>-0.001044</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>8022.584491</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>906.356506</td>\n",
       "      <td>0.010149</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-5.775136e+04</td>\n",
       "      <td>560.600444</td>\n",
       "      <td>1256.629689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>716.306666</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>-4309.825080</td>\n",
       "      <td>1360.713718</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.057985</td>\n",
       "      <td>-0.057985</td>\n",
       "      <td>-6.170351</td>\n",
       "      <td>-0.002228</td>\n",
       "      <td>-54.489134</td>\n",
       "      <td>4.735858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.002768</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>9468.379225</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>-0.000607</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>-0.000249</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.015373</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>-0.016601</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>971632.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>53000.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>924.730000</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>971190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002151</td>\n",
       "      <td>-0.001623</td>\n",
       "      <td>-0.001103</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.010695</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>198.714286</td>\n",
       "      <td>235.500000</td>\n",
       "      <td>419.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>412.000000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-195.000000</td>\n",
       "      <td>-231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.040323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2500.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.840000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256.767500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-168.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-115.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.440000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082650e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>-0.000577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>971298.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.950000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001979</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012903</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-126.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>217.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.625000</td>\n",
       "      <td>616.000000</td>\n",
       "      <td>509.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-916.163333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1600.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.043011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1000.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1351.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.760000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>828.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.106500e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-32.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.000974</td>\n",
       "      <td>-0.079390</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.280000</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-49.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>971609.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000844</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.114683</td>\n",
       "      <td>-0.075269</td>\n",
       "      <td>-0.097619</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.064516</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>-0.040511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.001519</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>-0.022581</td>\n",
       "      <td>6000.000000</td>\n",
       "      <td>-0.010753</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.058065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>-0.083282</td>\n",
       "      <td>0.012644</td>\n",
       "      <td>0.024731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.129032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>666.666667</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1922.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>1577.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.043011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.002714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2977.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1960.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>-21.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-151.720000</td>\n",
       "      <td>-347.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.412500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>-818.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>953.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.176290e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.091648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.940000</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2827.210000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>971896.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.225806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.161290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>413547.390000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>417410.940000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID    TARGET  x_0  x_1         x_10      x_100       x_101  \\\n",
       "count      -4.000000 -4.000000 -4.0 -4.0    -4.000000  10.000000 -109.000000   \n",
       "mean   971578.005803  0.000599  0.0  0.0  1499.563706   0.000469   -0.003546   \n",
       "std       282.852694  0.001381  0.0  0.0  4473.288192   0.000088   -0.002190   \n",
       "min    971632.000000  0.000000  0.0  0.0     0.000000   0.000000    0.000000   \n",
       "25%    971190.000000  0.000000  0.0  0.0     0.000000   0.000000    0.000000   \n",
       "50%    971298.000000  0.000000  0.0  0.0     0.000000   0.000000    0.000000   \n",
       "75%    971609.000000  0.000000  0.0  0.0     0.000000   0.000000    0.000000   \n",
       "max    971896.000000  0.000000  0.0  0.0     0.000000   0.000000    0.000000   \n",
       "\n",
       "           x_102      x_103      x_104       x_105      x_106      x_107  \\\n",
       "count -31.000000 -26.000000  10.000000 -109.000000 -31.000000 -26.000000   \n",
       "mean    0.008667   0.024427   0.000326   -0.006054   0.003777   0.021305   \n",
       "std     0.001695   0.001686  -0.000300   -0.000682  -0.000642  -0.005063   \n",
       "min     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "50%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "75%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "max     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "\n",
       "            x_108       x_109     x_11       x_110      x_111       x_112  \\\n",
       "count -248.000000 -248.000000 -4.00000 -248.000000  10.000000 -109.000000   \n",
       "mean     0.000071    0.000181  0.08515   -0.000263   0.000393   -0.002771   \n",
       "std      0.000266    0.003642  0.18970   -0.003307   0.000006   -0.001368   \n",
       "min      0.000000    0.000000  0.00000    0.000000   0.000000    0.000000   \n",
       "25%      0.000000    0.000000  0.00000    0.000000   0.000000    0.000000   \n",
       "50%      0.000000    0.000000  0.00000    0.000000   0.000000    0.000000   \n",
       "75%      0.000000    0.000000  0.00000    0.000000   0.000000    0.000000   \n",
       "max      0.000000    0.000000  0.00000    0.000000   0.000000    0.000000   \n",
       "\n",
       "           x_113      x_114      x_115       x_116      x_117      x_118  \\\n",
       "count -31.000000 -26.000000  10.000000 -109.000000 -31.000000 -26.000000   \n",
       "mean    0.009465   0.025606   0.000469   -0.003546   0.008667   0.024427   \n",
       "std     0.002168   0.002155   0.000088   -0.002190   0.001695   0.001686   \n",
       "min     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "25%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "50%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "75%     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "max     0.000000   0.000000   0.000000    0.000000   0.000000   0.000000   \n",
       "\n",
       "            x_119       x_120       x_121      x_122      x_123       x_124  \\\n",
       "count -248.000000 -248.000000 -248.000000  10.000000  10.000000 -496.000000   \n",
       "mean    -0.008634    0.007806    0.000814   0.000767  -0.000574    0.000152   \n",
       "std     -0.049185    0.117291    0.069933   0.000226  -0.000036   -0.000074   \n",
       "min      0.000000    0.000000    0.000000   0.000000   0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   0.000000   0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000   0.000000   0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000   0.000000   0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000   0.000000   0.000000    0.000000   \n",
       "\n",
       "            x_125       x_126       x_127       x_128       x_129       x_130  \\\n",
       "count -496.000000 -496.000000 -496.000000 -881.000000 -881.000000 -881.000000   \n",
       "mean    -0.000022   -0.000005   -0.000004   -0.000377   -0.000684   -0.000448   \n",
       "std      0.000095   -0.000015    0.000118    0.001422    0.001194    0.001262   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   -0.002151   -0.001623   -0.001103   \n",
       "50%      0.000000    0.000000    0.000000   -0.000780   -0.001970   -0.000441   \n",
       "75%      0.000000    0.000000    0.000000   -0.000844    0.000176   -0.000391   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_131       x_132       x_133      x_134       x_135      x_136  \\\n",
       "count -25.000000  947.000000 -553.000000 -25.000000 -404.000000 -25.000000   \n",
       "mean    0.086792    0.128976    0.042056   0.055002   -0.069558  -0.025717   \n",
       "std     0.073064    0.092015    0.047265   0.038234    0.376431  -0.033236   \n",
       "min     0.000000    0.000000    0.000000   0.000000    0.000000   0.000000   \n",
       "25%     0.096774    0.064516    0.064516   0.032258    0.000000   0.000000   \n",
       "50%     0.032258    0.129032   -0.032258   0.032258   -0.032258   0.000000   \n",
       "75%     0.000000    0.161290    0.000000   0.129032    0.000000  -0.114683   \n",
       "max     0.000000    0.000000    0.000000   0.000000    3.225806   0.000000   \n",
       "\n",
       "           x_137      x_138       x_139      x_14       x_140       x_141  \\\n",
       "count -25.000000 -25.000000 -553.000000 -4.000000 -553.000000 -553.000000   \n",
       "mean   -0.032926  -0.029325    0.114364  0.001619    0.015055    0.053419   \n",
       "std    -0.051396  -0.046083    0.409463 -0.009830    0.128589    0.206866   \n",
       "min     0.000000   0.000000    0.000000  0.000000    0.000000    0.000000   \n",
       "25%     0.000000   0.000000    0.000000  0.000000    0.000000    0.000000   \n",
       "50%     0.000000   0.000000    0.000000  0.000000    0.000000    0.000000   \n",
       "75%    -0.075269  -0.097619    0.064516  0.000000    0.000000    0.000000   \n",
       "max     0.000000   0.000000    0.000000  0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_142       x_143       x_144       x_145       x_146       x_147  \\\n",
       "count -300.000000 -300.000000 -553.000000 -553.000000 -553.000000 -553.000000   \n",
       "mean     0.036207   -0.000012    0.007020    0.001582    0.022614    0.016658   \n",
       "std      0.428176    0.072924    0.291923    0.274152    0.302228    0.226257   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     -0.064516    0.000000   -0.033333   -0.040511    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_148      x_149      x_15       x_150       x_151       x_152  \\\n",
       "count -248.000000 -25.000000  8.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.000777  -0.000597 -0.012176    0.002636   -0.000363    0.002999   \n",
       "std      0.001455  -0.000604  0.020959    0.009235    0.004580    0.003324   \n",
       "min      0.000000   0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000   0.000000  0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_153       x_154       x_155       x_156       x_157       x_158  \\\n",
       "count -248.00000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean    -0.00079   -0.000287   -0.000908    0.000621   -0.001199    0.000973   \n",
       "std      0.00447    0.005407    0.003951   -0.000140    0.003733    0.001978   \n",
       "min      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.00000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_159       x_16       x_160       x_161      x_162       x_163  \\\n",
       "count -248.000000 -10.000000 -248.000000 -248.000000 -25.000000 -464.000000   \n",
       "mean     0.000542   0.003687    0.000432    0.000491  -0.000909    0.000087   \n",
       "std      0.001994  -3.534072    0.001767    0.002082   0.000315    0.000009   \n",
       "min      0.000000   0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "25%      0.000000   0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "50%      0.000000   0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "75%      0.000000   0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "max      1.000000   0.000000    0.000000    1.000000   0.000000    0.000000   \n",
       "\n",
       "            x_164      x_165       x_166       x_167       x_168       x_169  \\\n",
       "count  947.000000 -25.000000  947.000000 -553.000000 -464.000000 -553.000000   \n",
       "mean    -0.000930  -0.000319   -0.001618   -0.000174   -0.000165   -0.000538   \n",
       "std     -0.000592  -0.000338   -0.001864   -0.000097   -0.000199   -0.000469   \n",
       "min      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_170       x_171       x_172       x_173       x_174       x_175  \\\n",
       "count -464.000000 -471.000000 -394.000000 -471.000000 -394.000000 -391.000000   \n",
       "mean    -0.000143   -0.000008    0.000375    0.000159    0.000673   -0.000124   \n",
       "std     -0.000039   -0.000667   -0.000507   -0.000288    0.000349   -0.000915   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_176       x_177      x_178       x_179       x_180       x_181  \\\n",
       "count -300.000000 -335.000000 -25.000000 -553.000000 -553.000000 -553.000000   \n",
       "mean    -0.000362   -0.000330   0.001941    0.000613    0.001163    0.000807   \n",
       "std     -0.003327   -0.000125   0.005768    0.002687    0.002877    0.001683   \n",
       "min      0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_182       x_183       x_184       x_185       x_186      x_187  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.00000   \n",
       "mean     0.000074    0.000613    0.000026   -0.000045   -0.000052   -0.00067   \n",
       "std      0.000482    0.000909    0.000133   -0.000422   -0.000581    0.00266   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.00000   \n",
       "\n",
       "           x_188       x_189  x_19       x_190       x_191       x_192  \\\n",
       "count -25.000000 -248.000000   NaN -248.000000 -248.000000 -248.000000   \n",
       "mean   -0.001382    0.003297   NaN    0.000083   -0.000110   -0.000088   \n",
       "std     0.001297    0.007834   NaN    0.000476   -0.000232   -0.000259   \n",
       "min     0.000000    0.000000   NaN    0.000000    0.000000    0.000000   \n",
       "25%     0.000000    0.000000   NaN    0.000000    0.000000    0.000000   \n",
       "50%     0.000000    0.000000   NaN    0.000000    0.000000    0.000000   \n",
       "75%     0.000000    0.000000   NaN    0.000000    0.000000    0.000000   \n",
       "max     0.000000    0.000000   NaN    0.000000    0.000000   -1.000000   \n",
       "\n",
       "            x_193       x_194       x_195       x_196       x_197       x_198  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean    -0.000032   -0.000047    0.014868    0.004974    0.002987    0.003153   \n",
       "std      0.000221    0.000342    0.184413    0.280988    0.260542    0.243937   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_199       x_2        x_20       x_200       x_201       x_202  \\\n",
       "count -248.000000 -4.000000   -4.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.004216  0.000118   31.644734    0.000820    0.000345    0.000283   \n",
       "std      0.010763  0.000438  182.889382    0.039927    0.030175    0.022995   \n",
       "min      0.000000  0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000  0.000000  -13.950000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000  0.000000    1.360000    0.000000    0.000000    0.000000   \n",
       "max      0.000000  0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_203      x_204      x_205      x_206       x_207      x_208  \\\n",
       "count  862.000000  20.000000 -84.000000 -64.000000  862.000000  20.000000   \n",
       "mean    -0.000796  -0.000197  -0.001555  -0.004284   -0.000238   0.001869   \n",
       "std     -0.000541  -0.000528  -0.001409  -0.003457   -0.000032   0.000495   \n",
       "min      0.000000   0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "25%      0.000000   0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "50%      0.000000   0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "75%      0.000000   0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "max      0.000000   0.000000   0.000000   0.000000    0.000000   0.000000   \n",
       "\n",
       "           x_209      x_210       x_211       x_212       x_213       x_214  \\\n",
       "count -84.000000 -64.000000 -248.000000 -248.000000 -248.000000  862.000000   \n",
       "mean    0.001546  -0.001026    0.000461    0.000737    0.000899   -0.000320   \n",
       "std     0.000247  -0.000601    0.055206    0.109378    0.066444   -0.000025   \n",
       "min     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_215      x_216      x_217       x_218      x_219     x_22  \\\n",
       "count  20.000000 -84.000000 -64.000000  862.000000  20.000000 -4.00000   \n",
       "mean    0.000410  -0.001282  -0.003366   -0.000796  -0.000197  0.08515   \n",
       "std     0.000181  -0.000850  -0.002195   -0.000541  -0.000528  0.18970   \n",
       "min     0.000000   0.000000   0.000000    0.000000   0.000000  0.00000   \n",
       "25%     0.000000   0.000000   0.000000    0.000000   0.000000  0.00000   \n",
       "50%     0.000000   0.000000   0.000000    0.000000   0.000000  0.00000   \n",
       "75%     0.000000   0.000000   0.000000    0.000000   0.000000  0.00000   \n",
       "max     0.000000   0.000000   0.000000    0.000000   0.000000  0.00000   \n",
       "\n",
       "           x_220      x_221       x_222       x_223       x_224       x_225  \\\n",
       "count -84.000000 -64.000000 -248.000000 -248.000000 -248.000000  325.000000   \n",
       "mean   -0.001555  -0.004284   -0.007982   -0.003610   -0.000080    0.001144   \n",
       "std    -0.001409  -0.003457   -0.077485   -0.079018   -0.026932    0.000270   \n",
       "min     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     0.000000   0.000000    0.000000    0.000000    0.000000    0.005525   \n",
       "75%     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_226      x_227      x_228      x_229         x_23      x_230  \\\n",
       "count  325.000000 -25.000000 -25.000000 -25.000000    -4.000000 -25.000000   \n",
       "mean    -0.000308   0.001368  -0.000108  -0.000143  1499.563706  -0.000128   \n",
       "std      0.000166   0.001278  -0.000734  -0.001032  4473.288192  -0.001163   \n",
       "min      0.000000   0.000000   0.000000   0.000000     0.000000   0.000000   \n",
       "25%      0.000000   0.000000   0.000000   0.000000     0.000000   0.000000   \n",
       "50%      0.000000   0.000000   0.000000   0.000000     0.000000   0.000000   \n",
       "75%      0.000000   0.000000   0.000000   0.000000     0.000000   0.000000   \n",
       "max      0.000000   0.000000   0.000000   0.000000     0.000000   0.000000   \n",
       "\n",
       "           x_231      x_232      x_233       x_234      x_235       x_236  \\\n",
       "count  51.000000  51.000000  51.000000 -248.000000  76.000000 -822.000000   \n",
       "mean    0.001296  -0.002407   0.002125    0.027363   0.040824    0.013496   \n",
       "std     0.006177  -0.399389   0.198025    0.001974   0.090661   -0.008217   \n",
       "min     0.000000   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "25%     0.000441   0.001125  -0.001692    0.064516  -0.032258    0.032258   \n",
       "50%    -0.001979   0.001460   0.000203    0.032258   0.032258    0.032258   \n",
       "75%     0.001157  -0.000312   0.001519    0.032258   0.032258    0.032258   \n",
       "max     0.000000   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "\n",
       "            x_237       x_238       x_239          x_24       x_240  \\\n",
       "count -248.000000 -508.000000 -248.000000     -4.000000 -248.000000   \n",
       "mean     0.025374   -0.040651   -0.017797   8116.755139   -0.018535   \n",
       "std      0.038111    0.290371   -0.033638  40621.021783   -0.039477   \n",
       "min      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   3000.000000    0.000000   \n",
       "50%      0.032258    0.032258    0.000000   1000.000000    0.000000   \n",
       "75%      0.000000    0.032258   -0.022581   6000.000000   -0.010753   \n",
       "max      0.000000   14.161290    0.000000      0.000000    0.000000   \n",
       "\n",
       "            x_241       x_242       x_243       x_244       x_245       x_246  \\\n",
       "count -248.000000 -822.000000 -822.000000 -822.000000 -585.000000 -585.000000   \n",
       "mean    -0.017931    0.054291   -0.010960    0.020098    0.018688   -0.011038   \n",
       "std     -0.037675    0.224224    0.055407    0.107686    0.344071   -0.032997   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   -0.010753    0.000000    0.000000   \n",
       "50%      0.000000   -0.064516    0.000000   -0.012903   -0.032258    0.000000   \n",
       "75%     -0.032258    0.064516   -0.032258    0.058065    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_247       x_248       x_249       x_250       x_251       x_252  \\\n",
       "count -822.000000 -822.000000 -822.000000 -822.000000 -248.000000 -248.000000   \n",
       "mean     0.013884    0.010340    0.014659    0.010053   -0.000003   -0.000600   \n",
       "std      0.103780    0.112162    0.108179    0.069592    0.005584   -0.000529   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     -0.032258   -0.083282    0.012644    0.024731    0.000000   -0.015873   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_253       x_254       x_255       x_256       x_257       x_258  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.001358   -0.000403    0.001761   -0.001859    0.000524   -0.000328   \n",
       "std      0.019294    0.015514    0.002841    0.007109    0.015057    0.013172   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     21.000000    2.000000    0.000000    0.000000   18.000000    0.000000   \n",
       "\n",
       "            x_259       x_260       x_261       x_262       x_263       x_264  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.000852   -0.001536   -0.000513    0.000238   -0.000751    0.000282   \n",
       "std      0.001067    0.006362    0.003780    0.004358   -0.000003    0.002195   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_265       x_266      x_267       x_268      x_269       x_270  \\\n",
       "count -248.000000 -763.000000  76.000000 -248.000000  76.000000 -822.000000   \n",
       "mean    -0.000333    0.000172   0.000469   -0.000779  -0.001919   -0.000186   \n",
       "std      0.000099   -0.000255   0.000196   -0.000648  -0.001572   -0.000025   \n",
       "min      0.000000    0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "25%     -0.010695    0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "50%     -0.006494    0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "75%     -0.017857    0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "max      0.000000    0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "\n",
       "            x_271       x_272       x_273       x_274       x_275       x_276  \\\n",
       "count -763.000000 -822.000000 -763.000000 -351.000000 -564.000000 -351.000000   \n",
       "mean    -0.000688   -0.000786   -0.001270   -0.000292   -0.001269   -0.000340   \n",
       "std     -0.002567   -0.000315   -0.002599   -0.000121   -0.002669    0.000282   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000   -0.041667    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_277       x_278       x_279        x_28       x_280       x_281  \\\n",
       "count -564.000000 -888.000000 -585.000000 -496.000000 -610.000000 -248.000000   \n",
       "mean    -0.001233    0.000992    0.000854    0.027597   -0.000428   -0.000451   \n",
       "std     -0.001973   -0.000027   -0.003330   -0.021271   -0.000141    0.006843   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     -0.017857    0.000000    0.000000    0.032258    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.161290    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.032258    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "\n",
       "            x_282       x_283       x_284       x_285       x_286       x_287  \\\n",
       "count -822.000000 -822.000000 -822.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean    -0.000080   -0.000053   -0.000136    0.000002    0.000409   -0.000114   \n",
       "std      0.004546    0.004951    0.004101    0.000012    0.000325   -0.000441   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      2.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_288       x_289         x_29       x_290       x_291  \\\n",
       "count -248.000000 -248.000000 -1082.000000 -248.000000 -248.000000   \n",
       "mean    -0.000004    0.000027     0.033862   -0.002529   -0.000628   \n",
       "std     -0.000028    0.000217     0.070735    0.011366    0.000364   \n",
       "min      0.000000    0.000000     0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    -0.032258    0.000000    0.000000   \n",
       "50%      0.000000    0.000000     0.032258    0.000000    0.000000   \n",
       "75%      0.000000    0.000000     0.161290    0.000000    0.000000   \n",
       "max      0.000000    0.000000     0.000000   19.000000    0.000000   \n",
       "\n",
       "            x_292       x_293       x_294       x_295       x_296       x_297  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.003878    0.000122   -0.000126   -0.000095   -0.000106   -0.000041   \n",
       "std      0.008007    0.001769   -0.000115    0.000004   -0.000098    0.000165   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_298       x_299       x_3        x_30       x_300      x_301  \\\n",
       "count -248.000000 -248.000000 -4.000000 -357.000000 -248.000000 -248.00000   \n",
       "mean     0.013890    0.004733  0.000145   -0.012232    0.003008    0.00322   \n",
       "std      0.168822    0.280044  0.000303   -0.040116    0.260253    0.24378   \n",
       "min      0.000000    0.000000  0.000000    0.000000    0.000000    0.00000   \n",
       "25%      0.000000    0.000000  0.000000   -0.032258    0.000000    0.00000   \n",
       "50%      0.000000    0.000000  0.000000    0.000000    0.000000    0.00000   \n",
       "75%      0.000000    0.000000  0.000000   -0.129032    0.000000    0.00000   \n",
       "max      0.000000    0.000000  0.000000    0.000000    0.000000    0.00000   \n",
       "\n",
       "            x_302       x_303       x_304       x_305       x_306       x_307  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000  591.000000 -117.000000   \n",
       "mean     0.002619    0.000798    0.000333    0.000322   -0.000327   -0.001709   \n",
       "std      0.002931    0.039810    0.030158    0.023014    0.000017   -0.001166   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.038462    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_308      x_309        x_31       x_310       x_311       x_312  \\\n",
       "count -109.000000 -88.000000 -496.000000  591.000000 -117.000000 -109.000000   \n",
       "mean     0.001881   0.004102    0.041171    0.000006   -0.000931    0.002800   \n",
       "std      0.000698   0.001235    0.060329   -0.000019    0.000128    0.000114   \n",
       "min      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   0.000000   -0.064516    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   0.000000    0.161290    0.000000    0.000000    0.000000   \n",
       "max      0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_313       x_314       x_315       x_316       x_317       x_318  \\\n",
       "count -88.000000 -248.000000 -248.000000 -248.000000  591.000000 -117.000000   \n",
       "mean    0.005900    0.000533    0.000918    0.000636   -0.000407   -0.001206   \n",
       "std     0.000234    0.054796    0.109260    0.064080    0.000009   -0.000544   \n",
       "min     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_319       x_32      x_320       x_321       x_322       x_323  \\\n",
       "count -109.000000  73.000000 -88.000000  591.000000 -117.000000 -109.000000   \n",
       "mean     0.002191   0.032833   0.005299   -0.000327   -0.001709    0.001881   \n",
       "std      0.001048   0.006704   0.002295    0.000017   -0.001166    0.000698   \n",
       "min      0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   0.032258   0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   0.088710   0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000   0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_324       x_325       x_326       x_327       x_328       x_329  \\\n",
       "count -88.000000 -248.000000 -248.000000 -248.000000  198.000000  198.000000   \n",
       "mean    0.004102   -0.018523    0.000991   -0.000334    0.001194    0.000080   \n",
       "std     0.001235   -0.086297    0.009371    0.021675    0.000271   -0.000095   \n",
       "min     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_33       x_330       x_331       x_332       x_333       x_334  \\\n",
       "count -496.000000 -248.000000 -248.000000 -248.000000 -248.000000 -567.000000   \n",
       "mean    -0.004781    0.000626    0.000024   -0.000068   -0.000043   -0.000382   \n",
       "std     -0.020770    0.000365    0.000302   -0.000357   -0.000162   -0.071502   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000   -0.000551   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000   -0.000459   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000111   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_335       x_336         x_337        x_338        x_339  \\\n",
       "count -567.000000 -567.000000   -552.000000  -793.000000  -552.000000   \n",
       "mean    -0.001506   -0.000972   1276.584897  1425.891890  1594.680256   \n",
       "std     -0.273385   -0.034318  12825.727935  8556.910787 -7856.959936   \n",
       "min      0.000000    0.000000      0.000000     0.000000     0.000000   \n",
       "25%      0.001102   -0.000915    198.714286   235.500000   419.000000   \n",
       "50%     -0.000028   -0.000284      0.000000   260.333333     0.000000   \n",
       "75%      0.000045    0.000607    110.000000   666.666667   750.000000   \n",
       "max      0.000000    0.000000      0.000000     0.000000     0.000000   \n",
       "\n",
       "             x_34        x_340         x_341        x_342       x_343  \\\n",
       "count -496.000000  -793.000000   -552.000000  -793.000000 -117.000000   \n",
       "mean    -0.007857  2981.316371   1180.314018   915.790222    0.002858   \n",
       "std     -0.023247  -403.274405  17365.371515  8914.214895   -0.001922   \n",
       "min      0.000000     0.000000      0.000000     0.000000    0.000000   \n",
       "25%      0.000000   412.000000     14.370000    17.000000    0.000000   \n",
       "50%      0.000000  -126.000000    234.000000   194.000000    0.000000   \n",
       "75%      0.000000  2000.000000   1000.000000     0.000000    0.000000   \n",
       "max      0.000000     0.000000      0.000000     0.000000    0.000000   \n",
       "\n",
       "            x_344      x_345       x_346       x_347       x_348  \\\n",
       "count -109.000000 -88.000000  670.000000 -425.000000 -793.000000   \n",
       "mean    -0.010786  -0.019496   -0.000924   -0.000052   -0.006067   \n",
       "std     -0.002003  -0.001236   -0.001645    0.000507    0.029026   \n",
       "min      0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000   0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "              x_349        x_35         x_350         x_351         x_352  \\\n",
       "count   -422.000000 -496.000000   -479.000000   -422.000000   -479.000000   \n",
       "mean    2201.720629   -0.006355   2242.259659   2933.734333   3559.660135   \n",
       "std    25848.747753   -0.022683  20750.915477  43758.143787  48201.972386   \n",
       "min        0.000000    0.000000      0.000000      0.000000      0.000000   \n",
       "25%      -12.666667    0.000000      0.000000     39.000000     37.000000   \n",
       "50%      217.380000    0.000000    114.625000    616.000000    509.000000   \n",
       "75%     1106.000000    0.000000   1922.500000      0.000000   1000.000000   \n",
       "max        0.000000    0.000000      0.000000      0.000000      0.000000   \n",
       "\n",
       "              x_353         x_354      x_355      x_356      x_357  \\\n",
       "count   -422.000000   -479.000000  20.000000 -84.000000 -64.000000   \n",
       "mean    1662.597419   1433.360827  -0.009407  -0.010848  -0.003780   \n",
       "std    19245.850658  13222.772605  -0.006756  -0.009062  -0.011801   \n",
       "min        0.000000      0.000000   0.000000   0.000000   0.000000   \n",
       "25%      -30.000000     -8.000000   0.000000   0.000000   0.000000   \n",
       "50%       60.000000     60.000000   0.000000   0.000000   0.000000   \n",
       "75%      220.000000   1577.000000   0.000000   0.000000   0.000000   \n",
       "max        0.000000      0.000000   0.000000   0.000000   0.000000   \n",
       "\n",
       "            x_358       x_359        x_36       x_360         x_361  \\\n",
       "count  924.000000 -203.000000 -357.000000 -479.000000    -53.000000   \n",
       "mean     0.001564   -0.000024   -0.018818    0.082339  -1032.345333   \n",
       "std      0.001922    0.000648    0.048627    0.190848 -32227.070935   \n",
       "min      0.000000    0.000000    0.000000    0.000000      0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000      0.000000   \n",
       "50%      0.000000    0.000000   -0.032258    0.000000      0.000000   \n",
       "75%      0.000000    0.000000    0.032258    0.000000      0.000000   \n",
       "max      0.000000    0.000000    0.000000   28.000000      0.000000   \n",
       "\n",
       "             x_362         x_363         x_364         x_365        x_366  \\\n",
       "count  -498.000000    -53.000000   -498.000000    -53.000000  -498.000000   \n",
       "mean    906.111932   -580.964906   1915.759128  -1317.609597   349.438419   \n",
       "std   -6849.602166 -46754.917871 -32503.494174 -12629.313979  5636.455254   \n",
       "min       0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "25%    -195.000000   -231.000000      0.000000      0.000000   170.000000   \n",
       "50%    -916.163333      0.000000  -1600.000000      0.000000     0.000000   \n",
       "75%     532.000000      0.000000      0.000000      0.000000  1800.000000   \n",
       "max       0.000000      0.000000      0.000000      0.000000     0.000000   \n",
       "\n",
       "            x_367      x_368      x_369        x_37      x_370       x_371  \\\n",
       "count -109.000000 -31.000000 -26.000000 -357.000000  34.000000 -751.000000   \n",
       "mean     0.022540  -0.006519  -0.055176    0.003062  -0.002639   -0.000047   \n",
       "std      0.007575   0.014992   0.007938    0.112121  -0.002789    0.000093   \n",
       "min      0.000000   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "25%      0.000000   0.000000   0.000000   -0.096774   0.000000    0.000000   \n",
       "50%      0.000000   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "75%      0.000000   0.000000   0.000000   -0.096774   0.000000    0.000000   \n",
       "max      0.000000   0.000000   0.000000    0.000000   0.000000    0.000000   \n",
       "\n",
       "            x_372       x_373       x_374       x_375  x_376       x_377  \\\n",
       "count -498.000000 -224.000000 -224.000000 -224.000000 -224.0 -224.000000   \n",
       "mean    -0.117211   -0.000730    0.000289   -0.000441    0.0   -0.000018   \n",
       "std     -0.193951   -0.028685    0.042490    0.010004    0.0   -0.000918   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.0    0.000000   \n",
       "\n",
       "            x_378       x_379        x_38  x_380       x_381       x_382  \\\n",
       "count -224.000000 -224.000000 -357.000000 -224.0 -224.000000 -224.000000   \n",
       "mean    -0.000014   -0.000032    0.000296    0.0    0.002292    0.002085   \n",
       "std     -0.001175   -0.001490    0.107308    0.0    0.179717    0.099773   \n",
       "min      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "25%      0.000000    0.000000   -0.040323    0.0    0.000000    0.000000   \n",
       "50%      0.000000    0.000000   -0.043011    0.0    0.000000    0.000000   \n",
       "75%      0.000000    0.000000   -0.043011    0.0    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "\n",
       "            x_383       x_384       x_385       x_386       x_387       x_388  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.004377    0.000173    0.005267    0.001479    0.006747   -0.000288   \n",
       "std      0.260518    0.026858    0.074682    0.012308    0.093404   -0.020043   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_389        x_39       x_390       x_391       x_392       x_393  \\\n",
       "count -224.000000 -318.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.001645   -0.017210    0.000541    0.002186   -0.000117   -0.000169   \n",
       "std      0.021801   -0.006222    0.009939    0.037100   -0.011989    0.002246   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000   -0.032258    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    5.000000    0.000000    0.000000   \n",
       "\n",
       "              x_394       x_395       x_396       x_397       x_398  \\\n",
       "count -2.240000e+02 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean   9.253045e-07   -0.000168   -0.000019    0.003864    0.002001   \n",
       "std    6.020113e-03    0.011358   -0.002733   -0.018620   -0.008714   \n",
       "min    0.000000e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    0.000000e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    0.000000e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "75%    0.000000e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "max    0.000000e+00    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_399          x_4        x_40       x_400       x_401  \\\n",
       "count -224.000000     -4.00000 -318.000000 -224.000000 -224.000000   \n",
       "mean     0.005865   1014.43072   -0.004725   -0.000294    0.001147   \n",
       "std     -0.026217   4009.43419   -0.007812   -0.011686    0.166906   \n",
       "min      0.000000  53000.00000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  -2500.00000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000  -1000.00000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000      0.00000    0.000000    0.000000    0.000000   \n",
       "max      0.000000      0.00000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_402       x_403       x_404       x_405       x_406       x_407  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean    -0.001073   -0.000714   -0.000010    0.003566    0.000164   -0.000336   \n",
       "std     -0.035781    0.005282   -0.001366    0.252039    0.026770   -0.020540   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_408       x_409        x_41       x_410       x_411       x_412  \\\n",
       "count -224.000000 -224.000000 -357.000000 -224.000000 -218.000000 -218.000000   \n",
       "mean     0.000135   -0.000201    0.010431   -0.000010    0.000236   -0.000561   \n",
       "std      0.004364   -0.009601   -0.004934   -0.001366   -0.000632    0.001170   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.040860    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_413      x_414       x_415       x_416       x_417       x_418  \\\n",
       "count -224.000000 -224.00000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.001150   -0.00142    0.003147    0.001419   -0.000436   -0.000034   \n",
       "std      0.015292    0.00553    0.012326    0.012379    0.000471    0.002531   \n",
       "min      0.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      4.000000    0.00000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_419        x_42       x_420       x_421       x_422       x_423  \\\n",
       "count -224.000000 -357.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean    -0.001979   -0.002056   -0.000269   -0.001153   -0.000086   -0.000052   \n",
       "std      0.008197   -0.023277    0.001673    0.000536   -0.000113   -0.000593   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.052688    0.000000    0.000000    0.000000    0.000000   \n",
       "max     15.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_424       x_425       x_426       x_427       x_428       x_429  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean    -0.001152    0.000350   -0.000753   -0.000021   -0.000351   -0.000162   \n",
       "std      0.000017    0.002406   -0.001508   -0.001174   -0.001800   -0.001904   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      4.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_43       x_430       x_431       x_432       x_433       x_434  \\\n",
       "count -357.000000 -224.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.011402    0.000133   -0.000047   -0.000092   -0.000274   -0.000017   \n",
       "std      0.018341    0.001240   -0.000328   -0.000406   -0.000608   -0.000386   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_435       x_436       x_437       x_438        x_439  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000  -224.000000   \n",
       "mean    -0.000091    0.000005   -0.000022   -0.000003    18.882688   \n",
       "std     -0.001712    0.000207   -0.000711   -0.000326  1852.787661   \n",
       "min      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000     0.000000   \n",
       "\n",
       "             x_44       x_440       x_441       x_442       x_443       x_444  \\\n",
       "count -357.000000 -224.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.009378    5.811196    0.000522   -0.000231    0.012937    0.000847   \n",
       "std      0.014697  455.672355    0.001714   -0.001954   -0.018173   -0.004300   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_445       x_446       x_447       x_448       x_449        x_45  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000 -224.000000 -248.000000   \n",
       "mean     0.000291    0.000203    0.000351   -0.000022    0.026102   -0.000780   \n",
       "std      0.000283    0.000252    0.000999   -0.000033    0.002190    0.004807   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.032877    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.032877    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.098630    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_450        x_451       x_452       x_453       x_454  \\\n",
       "count -224.000000  -224.000000 -224.000000 -218.000000 -218.000000   \n",
       "mean    -0.004954    67.667436   -0.015699    0.000579   -0.020162   \n",
       "std     -0.004610  6565.938441   -0.084602    0.011515   -0.184576   \n",
       "min      0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "25%     -0.065753     0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.032877     0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_455       x_456       x_457       x_458       x_459        x_46  \\\n",
       "count -218.000000 -218.000000 -218.000000 -253.000000 -253.000000 -496.000000   \n",
       "mean    -0.009426   -0.022329   -0.032901   -0.006609   -0.008830   -0.000023   \n",
       "std     -0.033360   -0.128675   -0.184679   -0.015638   -0.022577    0.000014   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_460       x_461       x_462      x_463       x_464       x_465  \\\n",
       "count -253.000000 -253.000000 -253.000000 -24.000000 -218.000000 -493.000000   \n",
       "mean    -0.016212   -0.015824    0.000933  -0.001456    0.025294    0.028453   \n",
       "std     -0.012332   -0.011841    0.002360  -0.250458    0.002511   -0.022139   \n",
       "min      0.000000    0.000000    0.000000   0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000   0.000000    0.000000    1.000000   \n",
       "50%      0.000000    0.000000    0.000000   0.000000    0.000000    1.000000   \n",
       "75%      0.000000    0.000000    0.000000  -0.002714    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000   0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_466       x_467       x_468       x_469        x_47       x_470  \\\n",
       "count -569.000000 -253.000000 -218.000000 -218.000000 -248.000000 -253.000000   \n",
       "mean     0.031768    0.000104    0.001210    0.000613   -0.001278   -0.000413   \n",
       "std      0.005173    0.000942    0.002587    0.002056    0.013021    0.008467   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.032258    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.096774    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000   32.000000    0.000000   \n",
       "\n",
       "            x_471       x_472       x_473       x_474       x_475       x_476  \\\n",
       "count -218.000000 -218.000000 -218.000000 -218.000000 -253.000000 -218.000000   \n",
       "mean    -0.000602   -0.001498   -0.001731   -0.000232    0.001070    0.000224   \n",
       "std      0.002082    0.006481    0.004562    0.003031    0.001488    0.002187   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_477       x_478       x_479        x_48       x_480       x_481  \\\n",
       "count -218.000000 -218.000000 -218.000000 -248.000000 -218.000000 -218.000000   \n",
       "mean     0.001706    0.001360    0.000104   -0.000040    0.000207    0.000457   \n",
       "std      0.002842    0.003914    0.000625    0.012557    0.001596    0.006113   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000   18.000000    2.000000    0.000000   \n",
       "\n",
       "            x_482       x_483       x_484       x_485       x_486       x_487  \\\n",
       "count -253.000000 -218.000000 -253.000000 -253.000000 -218.000000 -253.000000   \n",
       "mean     0.000049    0.001650   -0.000130    0.000367    0.000677   -0.000070   \n",
       "std      0.000842    0.005365    0.011889    0.002527    0.001246   -0.000817   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_488       x_489        x_49       x_490       x_491       x_492  \\\n",
       "count -253.000000 -218.000000 -248.000000 -349.000000  389.000000 -336.000000   \n",
       "mean     0.000156    0.000026   -0.001238    0.001202   -0.002333    0.001453   \n",
       "std      0.001368   -0.000521    0.001075    0.006352    0.002261    0.007188   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "           x_493       x_494       x_495       x_496      x_497       x_498  \\\n",
       "count  17.000000 -171.000000 -116.000000 -216.000000 -61.000000 -185.000000   \n",
       "mean   -0.000329    0.001133    0.000482    0.002245   0.000185    0.003015   \n",
       "std     0.006772    0.006518    0.005180    0.007179   0.005908    0.008914   \n",
       "min     0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "25%     0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "50%     0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "75%     0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "max     0.000000    0.000000    0.000000    0.000000   0.000000    0.000000   \n",
       "\n",
       "           x_499            x_5        x_50       x_500       x_501  \\\n",
       "count -65.000000      -4.000000 -248.000000 -218.000000 -253.000000   \n",
       "mean    0.002603    2665.938526   -0.001068   -0.001781    0.000083   \n",
       "std     0.005892    9123.948706    0.001805    0.007520   -0.000707   \n",
       "min     0.000000       0.200000    0.000000    0.000000    0.000000   \n",
       "25%     0.000000     651.000000    0.000000    0.000000    0.000000   \n",
       "50%     0.000000     400.690000    0.000000    0.000000    0.000000   \n",
       "75%     0.000000    2977.210000    0.000000    0.000000    0.000000   \n",
       "max    -1.000000  413547.390000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_502       x_503       x_504       x_505  x_506         x_507  \\\n",
       "count -218.000000 -224.000000 -224.000000 -224.000000 -224.0 -2.240000e+02   \n",
       "mean     0.000635   -0.000027   -0.000043   -0.000070    0.0  6.599564e-08   \n",
       "std      0.007683   -0.000939   -0.002699   -0.002487    0.0  2.431505e-06   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.0  0.000000e+00   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.0  0.000000e+00   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.0  0.000000e+00   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.0  0.000000e+00   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.0  0.000000e+00   \n",
       "\n",
       "            x_508       x_509        x_51  x_510       x_511       x_512  \\\n",
       "count -224.000000 -224.000000 -248.000000 -224.0 -224.000000 -224.000000   \n",
       "mean    -0.000029   -0.000029    0.000810    0.0   -0.000072   -0.000025   \n",
       "std     -0.001372   -0.000836    0.010688    0.0   -0.000614   -0.000103   \n",
       "min      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "max      0.000000    0.000000   23.000000    0.0    0.000000    0.000000   \n",
       "\n",
       "            x_513         x_514       x_515       x_516       x_517  \\\n",
       "count -224.000000 -2.240000e+02 -224.000000 -224.000000 -224.000000   \n",
       "mean    -0.000097  2.065951e-08   -0.001805   -0.000982   -0.002787   \n",
       "std      0.000317  2.939630e-06   -0.013104    0.000215   -0.015675   \n",
       "min      0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "50%      0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "75%      0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "max      0.000000  0.000000e+00    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_518       x_519        x_52       x_520       x_521       x_522  \\\n",
       "count -224.000000 -224.000000 -248.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean    -0.000735   -0.000332    0.000580    0.000334    0.000002   -0.000003   \n",
       "std     -0.034306   -0.001741    0.009556    0.004145    0.001362   -0.000479   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000   11.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_523       x_524       x_525  x_526       x_527       x_528  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.0 -224.000000 -224.000000   \n",
       "mean    -0.000044    0.000063    0.000018    0.0   -0.000562    0.001408   \n",
       "std     -0.000308    0.001125    0.000374    0.0   -0.009289    0.003650   \n",
       "min      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.0    0.000000    0.000000   \n",
       "\n",
       "            x_529        x_53       x_530       x_531       x_532       x_533  \\\n",
       "count -224.000000 -248.000000 -224.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean     0.000847    0.000231   -0.000317    0.000037    0.000021    0.000058   \n",
       "std     -0.004300    0.002198   -0.018863    0.001013    0.000954    0.001388   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "       x_534     x_535     x_536     x_537     x_538     x_539        x_54  \\\n",
       "count -224.0 -4.000000 -4.000000 -4.000000 -4.000000 -4.000000 -248.000000   \n",
       "mean     0.0 -0.000863 -0.000041 -0.000183 -0.000680 -0.000207   -0.000337   \n",
       "std      0.0  0.000266  0.000409 -0.000441 -0.000604  0.000528    0.001256   \n",
       "min      0.0  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "25%      0.0  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "50%      0.0  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "75%      0.0  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "max      0.0  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000   \n",
       "\n",
       "            x_540      x_541     x_542       x_543     x_544     x_545  \\\n",
       "count -599.000000 -89.000000 -4.000000 -599.000000 -4.000000 -4.000000   \n",
       "mean     0.000554   0.001307  0.000125   -0.000554 -0.001372  0.000070   \n",
       "std     -0.000025   0.001215 -0.000061   -0.000025 -0.000687  0.000468   \n",
       "min      0.000000   0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "25%      0.000000   0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "50%      0.000000   0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "75%      0.000000   0.000000 -0.028571    0.000000  0.000000  0.000000   \n",
       "max      0.000000   0.000000  0.000000    0.000000  0.000000  0.000000   \n",
       "\n",
       "              x_546         x_547        x_548       x_549        x_55  \\\n",
       "count   -329.000000   -224.000000    -5.000000 -329.000000 -248.000000   \n",
       "mean    8082.993127   2689.502945   439.187284   85.523897   -0.001487   \n",
       "std    56640.863126  35655.502744  1379.050374  448.437418    0.004076   \n",
       "min        0.000000      0.000000     0.000000    0.000000    0.000000   \n",
       "25%     1300.000000      0.000000     0.000000   25.840000    0.000000   \n",
       "50%     1351.000000     75.000000     0.000000   17.760000    0.000000   \n",
       "75%    -1960.000000    183.000000   500.000000  -21.710000    0.000000   \n",
       "max        0.000000      0.000000     0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_550         x_551     x_552  x_553  x_554       x_555  \\\n",
       "count   -24.000000   -254.000000 -4.000000 -224.0 -224.0 -224.000000   \n",
       "mean     62.009477   5047.492374 -0.007700    0.0    0.0   -0.000117   \n",
       "std    1008.776877  45447.967831  0.011079    0.0    0.0   -0.011989   \n",
       "min       0.000000      0.000000  0.000000    0.0    0.0    0.000000   \n",
       "25%       0.000000    256.767500  0.000000    0.0    0.0    0.000000   \n",
       "50%       0.000000    828.500000  0.000000    0.0    0.0    0.000000   \n",
       "75%    -151.720000   -347.130000  0.000000    0.0    0.0    0.000000   \n",
       "max       0.000000      0.000000  0.000000    0.0    0.0    0.000000   \n",
       "\n",
       "            x_556       x_557       x_558       x_559        x_56       x_560  \\\n",
       "count -224.000000 -224.000000 -224.000000 -224.000000 -248.000000 -224.000000   \n",
       "mean    -0.000294   -0.000019   -0.000010   -0.005138   -0.000304   -0.000735   \n",
       "std     -0.011686   -0.002733   -0.001366   -0.005111    0.004143   -0.034306   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "       x_561  x_562         x_563       x_564       x_565  x_566  x_567  \\\n",
       "count -224.0 -224.0 -2.240000e+02 -224.000000 -224.000000 -224.0 -224.0   \n",
       "mean     0.0    0.0  2.065951e-08   -0.000003   -0.000317    0.0    0.0   \n",
       "std      0.0    0.0  2.939630e-06   -0.000479   -0.018863    0.0    0.0   \n",
       "min      0.0    0.0  0.000000e+00    0.000000    0.000000    0.0    0.0   \n",
       "25%      0.0    0.0  0.000000e+00    0.000000    0.000000    0.0    0.0   \n",
       "50%      0.0    0.0  0.000000e+00    0.000000    0.000000    0.0    0.0   \n",
       "75%      0.0    0.0  0.000000e+00    0.000000    0.000000    0.0    0.0   \n",
       "max      0.0    0.0  0.000000e+00    0.000000    0.000000    0.0    0.0   \n",
       "\n",
       "            x_568       x_569        x_57       x_570       x_571       x_572  \\\n",
       "count -253.000000 -253.000000 -248.000000 -253.000000 -253.000000 -253.000000   \n",
       "mean     0.004381   -0.000429   -0.001183   -0.000047    0.001807   -0.001854   \n",
       "std     -0.030885   -0.000009   -0.000936    0.011558    0.002859    0.007267   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_573       x_574       x_575       x_576       x_577       x_578  \\\n",
       "count -253.000000 -253.000000 -253.000000 -253.000000 -253.000000 -253.000000   \n",
       "mean     0.000738    0.001070   -0.000371   -0.001483   -0.001431   -0.000577   \n",
       "std      0.001256    0.001488    0.000856    0.006561    0.005669    0.002184   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_579        x_58       x_580       x_581       x_582       x_583  \\\n",
       "count -253.000000 -248.000000 -253.000000 -253.000000 -253.000000 -253.000000   \n",
       "mean    -0.000261   -0.000209   -0.001718   -0.000795    0.000156   -0.000070   \n",
       "std      0.003087    0.001466    0.004614    0.004400    0.001368   -0.000817   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_584       x_585       x_586         x_587       x_588  \\\n",
       "count -253.000000 -253.000000 -224.000000   -253.000000 -253.000000   \n",
       "mean    -0.000854    0.000119    0.000331   1821.912495    0.004578   \n",
       "std     -0.000064    0.000388   -0.000007  24686.989838    0.023966   \n",
       "min      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000     30.412500    0.000000   \n",
       "max      0.000000    0.000000    0.000000      0.000000    0.000000   \n",
       "\n",
       "            x_589        x_59       x_590       x_591       x_592       x_593  \\\n",
       "count -253.000000 -496.000000 -253.000000 -246.000000 -249.000000 -246.000000   \n",
       "mean     0.026028    0.000872    0.015047    0.017836    0.025063   -0.102906   \n",
       "std      0.041562    0.000040    0.027003    0.133084    0.036942   -0.196997   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000   -1.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "            x_594       x_595       x_596       x_597       x_598       x_599  \\\n",
       "count -249.000000 -246.000000 -249.000000 -270.000000 -270.000000 -270.000000   \n",
       "mean     0.094645   -0.036238    0.054267   -0.024396   -0.045563   -0.031143   \n",
       "std      0.245038    0.044558    0.091749    0.008077   -0.022460    0.008147   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000   -1.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_60        x_600        x_601        x_602         x_603  \\\n",
       "count -465.000000  -253.000000  -253.000000  -253.000000   -253.000000   \n",
       "mean     0.000508   636.356841   326.769116   994.333121   1736.339336   \n",
       "std     -0.000474  9488.047429 -6248.803987 -7995.435572  10878.379816   \n",
       "min      0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "25%      0.000000   -35.000000     0.000000  -168.000000      0.000000   \n",
       "50%      0.000000    10.000000     0.000000   840.000000      0.000000   \n",
       "75%      0.000000  1000.000000   500.000000  -818.000000      0.000000   \n",
       "max      0.000000     0.000000     0.000000     0.000000      0.000000   \n",
       "\n",
       "             x_604        x_605       x_606       x_607       x_608  \\\n",
       "count  -253.000000  -253.000000 -224.000000 -224.000000 -224.000000   \n",
       "mean    747.664456   961.509423    0.000628   -0.001618   -0.000010   \n",
       "std    7727.761173 -1209.668312    0.000748   -0.000402   -0.001366   \n",
       "min       0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "25%    -115.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "50%       0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "75%     953.000000   500.000000    0.000000    0.000000    0.000000   \n",
       "max       0.000000     0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "              x_609         x_61       x_610       x_611  x_612        x_613  \\\n",
       "count -4.650000e+02 -1082.000000 -464.000000 -763.000000   -4.0    -4.000000   \n",
       "mean   8.756610e-07     0.000356    0.000007    0.000096    0.0  1499.563706   \n",
       "std   -2.231914e-04     0.000076    0.000151   -0.000011    0.0  4473.288192   \n",
       "min    0.000000e+00     0.000000    0.000000    0.000000    0.0     0.000000   \n",
       "25%    0.000000e+00     0.000000    0.000000    0.000000    0.0     0.000000   \n",
       "50%    0.000000e+00     0.000000    0.000000    0.000000    0.0     0.000000   \n",
       "75%    0.000000e+00     0.000000    0.000000    0.000000    0.0     0.000000   \n",
       "max    0.000000e+00     0.000000    0.000000    0.000000    0.0     0.000000   \n",
       "\n",
       "       x_614  x_615     x_616        x_619        x_62       x_620  \\\n",
       "count    NaN    NaN -4.000000  -103.000000 -496.000000 -105.000000   \n",
       "mean     NaN    NaN  0.001619  1712.091893   -0.001500    0.007898   \n",
       "std      NaN    NaN -0.009830  5445.677702   -0.001044    0.001630   \n",
       "min      NaN    NaN  0.000000     0.000000    0.000000    0.000000   \n",
       "25%      NaN    NaN  0.000000     0.000000    0.000000    0.065000   \n",
       "50%      NaN    NaN  0.000000     0.000000    0.000000    0.000000   \n",
       "75%      NaN    NaN  0.000000     0.000000    0.000000    0.050000   \n",
       "max      NaN    NaN  0.000000     0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_621     x_622  x_623  x_624  x_626       x_627     x_629  \\\n",
       "count   -53.000000 -2.000000   -4.0   -4.0   -4.0   -4.000000 -4.000000   \n",
       "mean   1840.928505  0.008896    0.0    0.0    0.0   92.886731  0.017699   \n",
       "std    8022.584491  0.007558    0.0    0.0    0.0  906.356506  0.010149   \n",
       "min       0.000000  0.000000    0.0    0.0    0.0    0.000000  0.000000   \n",
       "25%       0.000000  0.000000    0.0    0.0    0.0   41.440000  0.000000   \n",
       "50%       0.000000  0.000000    0.0    0.0    0.0   82.200000  0.000000   \n",
       "75%       0.000000  0.000000    0.0    0.0    0.0   31.000000  0.000000   \n",
       "max       0.000000  0.000000    0.0    0.0    0.0    0.000000  0.000000   \n",
       "\n",
       "              x_63         x_630       x_631        x_632  x_633  x_634  \\\n",
       "count -1082.000000 -4.000000e+00   -4.000000    -4.000000 -782.0    NaN   \n",
       "mean     -0.001721  2.928901e+05   67.165313    77.484640    0.0    NaN   \n",
       "std      -0.001042 -5.775136e+04  560.600444  1256.629689    0.0    NaN   \n",
       "min       0.000000  0.000000e+00    0.000000     0.000000    0.0    NaN   \n",
       "25%       0.000000  1.082650e+05    0.000000     0.000000    0.0    NaN   \n",
       "50%       0.000000  1.106500e+06    0.000000     0.000000    0.0    NaN   \n",
       "75%       0.000000  1.176290e+05    0.000000     0.000000    0.0    NaN   \n",
       "max       0.000000  0.000000e+00    0.000000     0.000000    0.0    NaN   \n",
       "\n",
       "            x_635     x_636        x_637        x_638     x_639        x_64  \\\n",
       "count   -4.000000 -4.000000    -4.000000    -4.000000 -4.000000 -357.000000   \n",
       "mean    14.405292 -0.001051    14.263849   144.649953 -0.000425   -0.000475   \n",
       "std    716.306666  0.000161 -4309.825080  1360.713718  0.003012   -0.000281   \n",
       "min      0.000000  0.000000     0.000000     0.000000  0.000000    0.000000   \n",
       "25%      0.000000  0.000000     0.000000     0.000000  0.000000    0.000000   \n",
       "50%    -32.190000  0.000000     0.000000     0.000000  0.000000    0.000000   \n",
       "75%     45.110000  0.000000     0.000000     0.000000  0.000000    0.000000   \n",
       "max      0.000000  0.000000     0.000000     0.000000  0.000000    0.000000   \n",
       "\n",
       "          x_640     x_641       x_642     x_643       x_644     x_645  \\\n",
       "count  2.000000  2.000000 -246.000000 -4.000000   -4.000000 -4.000000   \n",
       "mean  -0.001634 -0.001634   -0.105325 -0.054781    1.521508  0.023061   \n",
       "std   -0.057985 -0.057985   -6.170351 -0.002228  -54.489134  4.735858   \n",
       "min    0.000000  0.000000    0.000000  0.000000  924.730000  0.001545   \n",
       "25%   -0.000389 -0.000389   -0.000257  0.000000    2.560000 -0.000374   \n",
       "50%   -0.000974 -0.000974   -0.079390 -1.000000    4.280000 -0.000503   \n",
       "75%   -0.000695 -0.000695   -0.091648  0.000000   24.940000 -0.000791   \n",
       "max    0.000000  0.000000    0.000000  0.000000    0.000000  0.000000   \n",
       "\n",
       "          x_646        x_65        x_66        x_67        x_68        x_69  \\\n",
       "count -4.000000 -465.000000 -357.000000 -465.000000  166.000000 -107.000000   \n",
       "mean        NaN   -0.001039   -0.000816   -0.001443   -0.000987   -0.002098   \n",
       "std         NaN   -0.003370   -0.000184   -0.002768    0.000094   -0.001484   \n",
       "min    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%   -0.000577    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%   -0.001604    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%   -0.000831    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max         NaN    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "                 x_7        x_70        x_71        x_72        x_73  \\\n",
       "count      -4.000000  166.000000 -107.000000 -483.000000 -318.000000   \n",
       "mean     2540.323651   -0.000666   -0.001928    0.002699   -0.004864   \n",
       "std      9468.379225    0.000647   -0.000285    0.005081   -0.007267   \n",
       "min         0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%       250.250000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%       -49.960000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      2827.210000    0.000000    0.000000    0.000000    0.000000   \n",
       "max    417410.940000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_74        x_75        x_76        x_77        x_78        x_79  \\\n",
       "count -265.000000 -496.000000 -357.000000 -357.000000 -357.000000 -248.000000   \n",
       "mean    -0.000781   -0.003175   -0.002114   -0.003018   -0.003603   -0.000080   \n",
       "std     -0.000296    0.004113    0.005260    0.002970    0.004157   -0.000607   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    1.000000    3.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_80        x_81        x_82        x_83        x_84        x_85  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -496.000000   \n",
       "mean     0.000155   -0.000113    0.000049    0.000087   -0.001859   -0.000152   \n",
       "std      0.000178   -0.000681    0.000466    0.001001    0.012577   -0.000074   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000   28.000000    0.000000   \n",
       "\n",
       "             x_86        x_87        x_88        x_89        x_90        x_91  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean     0.000581    0.000039   -0.000016   -0.000008   -0.000074    0.000006   \n",
       "std      0.001333    0.001737    0.000314    0.000544   -0.000249    0.000086   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_92        x_93        x_94        x_95        x_96        x_97  \\\n",
       "count -248.000000 -248.000000 -248.000000 -248.000000 -248.000000 -248.000000   \n",
       "mean    -0.001574   -0.000215   -0.000008    0.000045   -0.001597   -0.000021   \n",
       "std     -0.015373    0.000587    0.001570    0.002056   -0.016601   -0.000182   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      0.000000    0.000000    1.000000    0.000000    0.000000    0.000000   \n",
       "\n",
       "             x_98        x_99  \n",
       "count -248.000000 -248.000000  \n",
       "mean    -0.000012    0.000039  \n",
       "std      0.000486    0.001032  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.000000  \n",
       "75%      0.000000    0.000000  \n",
       "max      0.000000    0.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part2.describe() - train_part1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORT_DT', 'x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_7', 'x_9',\n",
       "       'x_10',\n",
       "       ...\n",
       "       'x_639', 'x_640', 'x_641', 'x_642', 'x_643', 'x_644', 'x_645', 'x_646',\n",
       "       'TARGET', 'ID'],\n",
       "      dtype='object', length=648)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['REPORT_DT', 'x_0', 'x_1', 'x_2', 'x_3', 'x_4', 'x_5', 'x_7', 'x_9',\n",
       "       'x_10',\n",
       "       ...\n",
       "       'x_639', 'x_640', 'x_641', 'x_642', 'x_643', 'x_644', 'x_645', 'x_646',\n",
       "       'TARGET', 'ID'],\n",
       "      dtype='object', length=648)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_part2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_part1.value_countse_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'class_weight': hp.choice('class_weight', [None, 'balanced']),\n",
    "    'warm_start' : hp.choice('warm_start', [True, False]),\n",
    "    'fit_intercept' : hp.choice('fit_intercept', [True, False]),\n",
    "    'tol' : hp.loguniform('tol', 0.00001, 10),\n",
    "    'C' : hp.loguniform('C', 1, 5000),\n",
    "    'solver' : hp.choice('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']),\n",
    "    'max_iter' : hp.choice('max_iter', range(5,1000))\n",
    "}\n",
    "\n",
    "space_dict = {\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'warm_start' : [True, False],\n",
    "    'fit_intercept' : [True, False],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
